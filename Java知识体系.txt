Java:Java是一个面向对象高级编程语言，通过Java编译器生成字节码文件在计算机里运行。
与C++不同，Java运用Java Virtual Machine（JVM）执行Java字节码（二进制形式），并通过JVM在多台机器上运行。
正因为Java运用了JVM在计算机上运行，并弱化了指针，因此Java不适合操作系统层面的源码编写，Java的应用在应用程序和web层面比较广泛。

Java官方文档：https://www.w3cschool.cn/java/dict

基本语法：关键字和保留字、标识符、变量、运算符、程序流程控制 
关键字：Java关键字是电脑语言里事先定义的，有特别意义的标识符，有时又叫保留字，还有特别意义的变量。
Java的关键字对Java的编译器有特殊的意义，他们用来表示一种数据类型，或者表示程序的结构等，关键字不能用作变量名、方法名、类名、包名和参数。
1、48个关键字：
用于定义类、函数、变量修饰符的关键字：
abstract、final、static、synchronized
用于定义类与类之间关系的关键字：
extends、implements
用于定义建立实例及引用实例、判断实例的关键字：
new、this、super、instanceof
用于异常处理的关键字：
try catch finally throw throws
用于包的关键字：
package import
其他修饰符关键字：
native、assert、transient、volatile、strictfp 
*用于定义数据类型值的字面值：
true、false、null。

2、Java保留字是指现有Java版本尚未使用 但以后版本可能会作为关键字使用，是C语言里用到但是Java里没有用到的关键字。
goto、const。

3、3个特殊直接量：true、false、null。

4、标识符：Java标识符由数字，字母和下划线（_），美元符号（$）或人民币符号（￥）组成。
在Java中是区分大小写的，而且还要求首位不能是数字。最重要的是，Java关键字不能当作Java标识符。
简单来说就是，在Java中凡是可以自己起名字的地方都叫标识符。

4.1 Java中的名称命名规范：
包名：多单词组成时所有字母都小写：xxxyyyzzz
类名、接口名：多单词组成时，所有单词的首字母大写：XxxYyyZzz
变量名、方法名：多单词组成时，第一个单词首字母小写，
第二个单词开始每个单词首字母大写：xxxYyyZzz
常量名：所有字母都大写。多单词时每个单词用下划线连接：XXX_YYY_ZZZ

5、变量
概念：本质上来说变量是内存中的一小块区域，通过变量名来访问这块区域。因此，使用每一个变量前必须要先申请（声明）然后必须对其进行赋值，才能使用

按照数据类型来分：
基本数据类型（primitive type,在栈stack中）：
整数类型：byte（1字节）、short（2字节）、int（4字节）、long（8字节）
浮点类型：float（4字节）、double（8字节）
整数类型默认为int、浮点类型默认为double。
字符型： char（使用Unicode编码、每个字符占两个字节，8个bite一个字节）
布尔型： boolean（与C语言布尔类型取0和1不同，只能取true和false）
引用数据类型（reference type,在堆heap中）：
类（字符串定义在类里）
接口
数组
（ *若想让基础类型存放在堆中，可以将基础类型包装为一个对象。将会用到基础类型的包装类）

按照声明的位置来分：
局部变量：方法体内，或者语句块内部定义的变量（局部变量不会默认初始化、必须先声明并赋值）
成员变量：方法体之外，类体中（需要先声明、赋值，若没有先赋值、则默认初始化后再使用）

基本数据类型大小：
类型 占用存储空间     表数范围
byte  1字节 = 8bit位   -128~127
short 2字节            -2^15~2^15-1
int   4字节            -2^31~2^31-1
long  8字节            -2^63~2^63-1
float 4字节 		   -3.40E+38 ~ +3.40E+38
double 8字节		   -1.79E+308 ~ +1.79E+308
注意：
bit : 计算机最小存储单位    byte：计算机中基本存储单元
整数类型默认为int、浮点类型默认为double。

字符型数据类型：
char用单引号'',String用双引号"";
String类型是字符串数据类型，用来存储多个字符，char类型只能存储一个字符。
String可以和8种数据类型做运算，运算的结果仍为String类型。
String是一个引用数据类型，但同时是一个final类，可以用字面量的定义方式去赋值。
通过字面量的方式（区别于new）赋值，会声明在常量池中。而常量池中不会存在相同内容的字符串。
所以，用==去比较两个相同内容的字符串，会返回true。

String代表不可变的字符串序列，称作"不可变性"
>当对字符串重新赋值时，需要重新写内存区域
>当对现有的字符串进行连接操作时，需要重新写内存区域赋值，不能在原有的基础上赋值
>当调用String的replace方法时，也需要重新写内存区域赋值，不能在原有的基础上赋值
>String字符串拼接的方式，常量和常量拼接的结果在常量池；只要其中有一个是变量，结果就在堆中；
 如果拼接的结果使用intern()方法，返回值在常量池中

String的实例化方式：
1.通过字面量的方式，声明在方法区中，两个相同的字符串返回true（即使是在对象中通过字面量定义的两个相同的字符串，返回的也是true）
2.通过new的方式，声明在堆中，两个相同的对象对比返回false

String与char之间的转换：
String → char ：使用String中的toCharArray()
char → String ：调用String中的构造器

String与byte之间的转换：
String → char ：使用String中的getByte()
char → String ：调用String中的构造器

不同于String是不可变的字符串序列，StringBuffer和StringBuilder是可变的字符串序列。
String：不可变的字符串序列
StringBuffer ：可变的字符串序列，线程安全，效率低，多线程时用
StringBuilder ：可变的字符串序列，线程不安全，效率高

创建StringBuffer时，底层创建了一个长度为16的字符串char型数组；
如果创建时传了参数，则在此基础上增加一个长度为16的字符串char型数组，
默认情况下，扩容为原来的2倍+2，同时将原有数组的元素复制到新的数组中

基础数据类型的转换：
容量小的数据类型与容量大的数据类型运算，结果自动转换为容量大的数据类型。
当byte,short,char做运算时，结果必须是int类型。
byte,short,char -> int -> long -> float -> double

容量大的转换为容量小的：强制类型转换
注意：强制类型转换，可能导致精度损失。
// Widening
// byte<short<int<long<float<double
int i = 10;
long l = i;               // 10
// Narrowing 
double d = 10.02;
long l = (long)d;         // 10
String.valueOf(10);       // "10"
Integer.parseInt("10");   // 10
Double.parseDouble("10"); // 10.0

6、在Java当中，运算符可以分为：算术运算符(+ - * /)、 关系运算符(< > ==)、逻辑运算符、位运算符、移位运算符以及条件运算符等。
一、算术运算符
1，基本的四则运算：加减乘除模(+ - * / %)
注意点：

（1）这些运算符都是二元运算符，使用时必须要有左右两个操作数。

int a = 20;
int b = 10;
System.out.println(a + b); // 30
System.out.println(a - b); // 10
System.out.println(a * b); // 200
System.out.println(a / b); // 2
System.out.println(a % b); // 0 --->模运算相当于数学中除法的余数

（2）同C语言一样，int / int的结果还是int，而且会向下取整。

要出现小数点，那就转成double类型或在最后*1.0。

（3）除法和取模操作时，右操作数不能为0，否则会报出异常。

（4）%在Java中不但可以对整数进行取模，还可以对double进行取模操作。

（5）两边操作数不相同的时候，会发生类型提升。看一个特例：

对两个short类型进行相加，在用short进行接受，发现报错，提示是从int到short可能会有损失。
这是因为为了计算的方便，Java在将小于4个字节的类型进行计算的时候，会将其隐形提升到int类型。
上面两个short均被提升到int，在用short接收，就会报错。解决办法是进行强制类型转换。

2，增量运算符 = += -= *= %=
不会改变变量本身的数据类型。该种类型运算符操作完成后，会将操纵的结果赋值给左操作数。要注意只有变量才可以使用该运算符，常量不允许被修改，不能使用。

3，自增/自减运算符 ++/--
不会改变变量本身的数据类型。这两种运算符有前置和后置之分。如果是单独使用，那么前置和后置是没有区别的，如果是混合使用：

int a = 1;
a++; // 后置++ 表示给a的值加1，此时a的值为2
System.out.println(a++); // 注意：后置++是先使用变量原来值，表示式结束时给变量+1，因此输出2
System.out.println(a); // 输出3
++a; // 前置++ 表示给a的值加1
System.out.println(++a); // 注意：前置++是先给变量+1，然后使用变量中的值，因此输出5
System.out.println(a); // 输出5

混合使用，【前置++】先+1，然后使用变量+1之后的值，【后置++】先使用变量原来的值，表达式结束时给变量+1 只有变量才能使用自增/自减运算符，常量不能使用，因为常量不允许被修改。

二、关系运算符
主要有六个: == != < > <= >=，其计算结果是 true 或者 false 。在Java中，只有true和false，不存在0表示假，非0表示真。

当需要多次判断时，不能连着写，比如：3 < a < 5，在C语言当中，是可以运行的，但是在Java当中会报错，需要写成3 < a &&  a < 5。

==和equals的区别？
==：运算符
如果比较的是基本数据类型：比较两个变量保存的数据是否相同（不一定类型要相同）
如果比较的是引用数据类型：比较两个变量的地址值是否相同，是否指向同一个对象实体
equals(): 方法
只能适用于引用数据类型
Object类中equals（）的定义：Object类中定义的equals()和==的作用是相同的，比较两个对象的地址值
public boolean equals(Object obj){
	return (this == obj)
}
像String、Date、File、包装类等都重写了Object类中的equals()方法，比较两个对象的实体内容

通常情况下，自定义的类需要重写equals()方法
重写equals()方法的步骤一般如下：
1、先用“==”判断是否相等。

2、判断equals()方法的参数是否为null，如果为null，则返回false；因为当前对象不可能为null，如果为null，则不能调用其equals()方法，否则抛java.lang.NullPointerException异常。

3、当参数不为null，则如果两个对象的运行时类（通过getClass()获取）不相等，返回false，否则继续判断。

三、逻辑运算符
逻辑运算符主要有六个: &  &&  |  || ! ^，运算结果都是boolean类型。

1、逻辑与 & 短路与 &&
语法规则：表达式1 && 表达式2，左右表达式必须是boolean类型的结果。相当于数学中的且。
短路与遵守短路求值的规则。即表达式1为假，表达式2就不再执行。逻辑与继续执行表达式2。

2、逻辑或 | 短路或 ||
语法规则：表达式1 || 表达式2，左右表达式必须是boolean类型的结果。相当于数学中的或。
短路或遵守短路求值的规则。即表达式1为真，表达式2就不再执行。逻辑或继续执行表达式2。

|| 遵守短路求值的规则。即表达式1为真，表达式2就不在执行，否则，执行表达式2。

& 和 | 也可以进行逻辑运算。如果他们的表达式为boolean，也表示逻辑运算，但是和&& ||相比不支持短路求值。

3、逻辑非 !
语法规则：!表达式1，相当于数学中的非。

4、逻辑异或
语法规则：表达式1^表达式2，左右表达式必须是boolean类型的结果。当表达式1和表达式2相同时为true，不同时为false。


四、位运算符
数据存储的最小单位是字节，而数据操作的最小单位是比特位。
字节是最小的存储单位，每个字节是由8个二进制比特位组成的，多个字节组合在一起可以表示各种不同的数据。
位运算表示按照二进制的每一位进行运算。
位运算符的左右两边是数值类型。

1，按位与&
如果两个二进制位都是 1，则结果为 1，否则结果为 0。

int a = 10;
int b = 20;
System.out.println(a & b); // 0


2，按位或|
如果两个二进制位有一个是1，则结果是1，否则都是0，结果是0。 

int a = 10;
int b = 20;
System.out.println(a | b); //30

 3，按位异或^
如果两个二进制位相同，则结果是0，否则是1。

4，按位取反~
如果该二进制位是1，则变成0，是0，变成1。

五、移位运算
    Java和C语言不同的地方在于，Java多了一个>>>，表示无符号右移。但是没有无符号左移。Java的移位运算符有三个: <<，>>，>>> 。都是二元运算符，且都是按照二进制比特位来运算的。

（1）左移：<<最左侧位不要了N位，在最右侧补零。左移 1 位，相当于原数字 * 2。左移 N 位，相当于原数字 * 2 的N次方。

（2）右移：>>最右侧不要了N位，在最左侧如果是正数，补0，负数补1。右移 1 位，相当于原数字 / 2。右移 N 位，相当于原数字 / 2 的N次方。

（3）无符号右移：>>>最右侧位不要了，最左侧补0。被移位二进制最高位无论是0还是1，空缺位都拿0补。

（4）移动负数位或者移位位数过大都没有意义。

    计算机在进行运算的时候，实际上是按照二进制运算的。加减等在运算的时候被转化成二进制的形式进行运算。计算机计算移位效率高于计算乘除，比如当某个代码正好乘除 2 的N次方的时候可以用移位运算代替。有的时候，可以拿来装逼用用。

六、条件运算符
条件运算符只有一个：表达式1 ? 表达式2 : 表达式3。
当表达式1为true时，执行表达式2，表达式3不在执行，否则执行表达式2。这个是Java当中唯一的一个三目运算符。表达式2和表达式3的结果需要同类型的，表达式不能单独存在。
int a = 10;
int b = 20;
int max = (a > b) ? a : b;
// 输出: 20
System.out.println(max);

七、在Java程序中，JVM默认总是顺序执行以分号;结束的语句。但是，在实际的代码中，程序经常需要做条件判断、循环，因此，需要有多种流程控制语句，来实现程序的跳转和循环等功能。
流程控制语句是用来控制程序中各语句执行顺序的语句，可以把语句组合成能完成一定功能的小逻辑模块。

if..else if..else：条件判断语句。
int j = 10;
if (j == 10) {
  System.out.println("I get printed");
} else if (j > 10) {
  System.out.println("I don't");
} else {
  System.out.println("I also don't");
}

for：循环语句，限定循环体的执行次数
for (int i = 0; i < 10; i++) {
  System.out.print(i);
}
// 输出: 0123456789

//增强for循环
int[] numbers = {1,2,3,4,5};
for (int number: numbers) {
  System.out.print(number);
}
// 输出: 12345

while：循环语句，反复执行语句或代码块，直到条件不满足时跳出
int count = 0;
while (count < 5) {
  System.out.print(count);
  count++;
}
// 输出: 01234

//do while循环
int count = 0;
do {
  System.out.print(count);
  count++;
} while (count < 5);
// 输出: 01234

switch..case:根据switch表达式中的值，依次匹配各个case中的常量。
一旦匹配成功，进入case结构，调用其执行语句。如果没有break关键字，则继续执行其他case结构的表达式。
int month = 3;
String str;
switch (month) {
  case 1:
    str = "January";
    break;
  case 2:
    str = "February";
    break;
  case 3:
    str = "March";
    break;
  default:
    str = "Some other month";
    break;
}
// 输出: Result March
System.out.println("Result " + str);

break和continue关键字：
1、break用于跳出一个循环体或者完全结束一个循环，不仅可以结束其所在的循环，还可结束其外层循环。
注意：
（1）只能在循环体内和switch语句体内使用break。
（2）不管是哪种循环，一旦在循环体中遇到break，系统将完全结束循环，开始执行循环之后的代码。
（3）当break出现在循环体中的switch语句体内时，起作用只是跳出该switch语句体，并不能终止循环体的执行。若想强行终止循环体的执行，可以在循环体中，但并不在switch语句中设置break语句，满足某种条件则跳出本层循环体。
for (int i = 0; i < 5; i++) {
  System.out.print(i);
  if (i == 3) {
    break;
  }
}
// 输出: 0123

2、continue语句的作用是跳过本次循环体中剩下尚未执行的语句，立即进行下一次的循环条件判定，可以理解为只是中止(跳过)本次循环，接着开始下一次循环。
注意：
（1）continue语句并没有使整个循环终止。
（2）continue 只能在循环语句中使用，即只能在 for、while 和 do…while 语句中使用。
for (int i = 0; i < 5; i++) {
  if (i == 3) {
    continue;
  }
  System.out.print(i);
}
// 输出: 01245

7、注释、文档注释
注释的内容不参与编译。
文档注释：注释内容可以被jdk提供的工具javadoc解析，生成一套网页文件形式体现的该程序的说明文档。
注意：javadoc解析的类要加上public

// 我是单行注释！
 
/*
而我是一个
多行注释！
*/
/**
  * 这个
  * 是
  * 文档
  * 注释
 */

8、注解
Annotation(注解)也被称为元数据(Metadata)是JDK1.5及以后版本引入的，
用于修饰解释 包、类、方法、属性、构造器、局部变量等数据信息。
它可以用于创建文档，跟踪代码中的依赖性，甚至执行基本编译时检查。
注解是以‘@注解名’在代码中存在的，根据注解参数的个数，我们可以将注解分为：标记注解、单值注解、完整注解三类。
和注释一样，注解不影响程序逻辑，但注解可以被编译或运行，相当于嵌入在代码中的补充信息。
另外，你可以在编译时选择代码里的注解是否只存在于源代码级，
或者它也能在class文件、或者运行时中出现（SOURCE/CLASS/RUNTIME）。
在 JavaSE 中，注解的使用目的比较简单，例如标记过时的功能，忽略警告等。
在 JavaEE 中注解占据了更重要的角色，例如用来配置应用程序的任何切面，
代替 java EE 旧版中所遗留的繁冗代码和 XML 配置等。
 
元注解：标注在一个注解上，用于定义一个注解的状态
@Documented - 一个简单的标记注解，它标识了是否将注解添加到 Javadoc 中。

@Retention - 定义应保留注解的时间。
RetentionPolicy.SOURCE 在编译期间丢弃。这些注解在编译完成后没有任何意义，因此它们不会被写入字节码。例子：@Override, @SuppressWarnings
RetentionPolicy.CLASS – 在类加载期间丢弃。应用在进行字节码级别的编译期间。有些令人惊讶的是，这是默认的。
RetentionPolicy.RUNTIME – 不会丢弃。该注解可以在运行时进行反射。这是我们通常用于自定义注解的内容。

@Target - 注解可以使用的地方。如果不指定这一属性，注解可以应用在任何地方。
以下是该注解的有效值。这里的一个要点，它只有包含的形式，这意味着如果您想要对7个属性进行注解，
并且只想排除一个属性，这时需要在定义目标时包含所有7个属性。 

@Documented: 用于指定被该元注解修饰的 Annotation 类将被javadoc 工具提取成文档，即在生成文档时，可以看到该注解。
注意：
定义为@Documented 的注解必须设置Retention值为RUNTIME。

@Inherited 
被@Inherited 修饰的注解 将具有继承性，如果某个类使用了被 @Inherited修饰的注解，则其子类将自动具有该注解

Java数组（Array）：数组是多个相同类型的数据按照一定顺序排列的集合，并使用一个名字命名，并通过编号的方式对这些数据进行统一处理。
数组的声明：数组的长度一旦确定，就不能修改。
数组有一维数组和二维数组。
//声明 Declare
int[] a1;
int[] a2 = {1, 2, 3};
int[] a3 = new int[]{1, 2, 3};
int[] a4 = new int[3];
a4[0] = 1;
a4[2] = 2;
a4[3] = 3;

数组的初始化：数组的初始化有两种形式，静态初始化和动态初始化。
静态初始化:数组的初始化和数组的元素赋值同时进行 
ids = new int[]{11,22,12,12,12,123};
ids = {11,22,12,12,12,123};
动态初始化：数组的初始化和数组的元素赋值分开进行
String[] names = new String[5];

注意：数组一旦初始化完成，数组长度就确定了

数组元素通过角标调用。从第一个角标0开始，一直到-1。
通过数组的属性length获取数组的长度。
数组元素的默认初始化值：
>数组元素是整型：0
>数组元素是浮点型：0.0
>数组元素是char型：0或'\u0000' 而非'0'
>数组元素是Boolean型：false
>数组元素是引用数据类型: null

二维数组的初始化：
静态初始化：
int [][] arr = new int [][]{{1,2,3},{4,5},{6,7,8}};
int []arr [] = new int [][]{{1,2,3},{4,5},{6,7,8}};
int [][] arr = {{1,2,3},{4,5},{6,7,8}};
动态初始化：
String [][] arr2 = new String[5][3]; 
String [][] arr2 = new String[5][];

Java比较器：比较对象的大小
Comparable 的使用举例：
1.像String、包装类等实现了Comparable接口，重写了CompareTo()方法，给出了比较两个对象大小的方法
2.像String、包装类重写CompareTo()方法以后，进行了从小到大的排列
3.重写CompareTo(obj)的规则：
	如果当前对象this大于形参对象obj，则返回正整数；
	如果当前对象this小于形参对象obj，则返回负整数；
	如果当前对象this等于形参对象obj，则返回零；

Comparator定制排序：
当元素的类型没有实现Comparable接口而又不方便修改代码，或者实现了Comparable
接口的排序规则不适合当前的操作，可以考虑使用Comparator的对象来排序

Java面向对象：
"万事万物皆对象"
1.在Java语言中，我们把功能、结构等封装到类中，通过类的实例化，来调用具体的功能结构
2.涉及到Java语言与前端HTML或者后端数据库做交互时，都体现为用类、对象去做交互
面向对象特点：封装、继承、多态
面向对象包括：类、对象、属性、方法、成员变量、局部变量、修饰符、方法的重载、继承、方法的重写、多态、static关键字、abstract关键字、接口 → JVM调优，设计模式，web和大数据框架

类：是一组相关属性和行为的集合。可以看成是一类事物的模板，使用事物的属性特征和行为特征来描述该类事物；如：人类
实例对象：是一类事物的具体体现。对象是类的一个实例（对象并不是找个女朋友），必然具备该类事物的属性和行为；如：小红、小明、小南
Scanner scanner = new Scanner();
具有静态描述的特征称之为属性
具有动态动作的行为(做事情)称之为方法
创建类的对象 = 类的实例化 = 实例化类
匿名对象：创建的对象没有显式的赋给一个变量名。匿名对象只能调用一次。
new Phone().sendEmail();
匿名对象的使用：将匿名对象的值赋值给方法的形参
mall.show(new Phone())

成员变量（属性，非static的）：
位置：在方法外部，直接写在类当中
作用范围：整个类全都可以通用
默认值：根据其类型，有默认值
内存位置：位于堆内存
生命周期：随着对象创建而诞生，随着对象被垃圾回收而消失
可以使用权限修饰符

局部变量：
位置：在方法内部
作用范围：只有方法当中才可以使用，出了方法就不能再用
默认值：无默认值
内存位置：位于栈内存
生命周期：随着方法进栈而诞生，随着方法出栈而消失
不可以使用权限修饰符

修饰符：private：同类下访问  → 缺省：同包下访问 → protected：子包下可以访问，同包也可以访问。不同包下的子类，访问protected修饰的，需要使用子类的对象访问，不能使用父类的对象访问  → public ：项目中所有类都可以访问
修饰类的时候，只能用缺省和public。

方法的重载：在 Java 类中可以定义 多个名称相同的方法 ，若只是参数不同，功能类似，那么可以将这类方法称为同名方法，也可以叫做方法重载
例如：sort(byte[] a) 与 sort(char[] a) 构成了方法的重载
Java中可变个数的形参 jdk5.0以上 格式：public void show(String ... strs){}
可变个数的形参与相同的数组之间不构成重载，二者不能共存，编译器认为这两种方法没有区别。

Java里面值传递机制只有一种：值传递。即将实际参数值的副本（复制）传入方法内，而参数本身不受影响。
>形参是基本数据类型，将实参的数据值传递给形参；形参是引用数据类型，将实参的地址值（含变量的数据类型）传递给形参。

封装（数据的隐藏）：
通常，应禁止直接访问一个对象中数据的实际表示，而是应该通过操作接口来访问，这叫信息隐藏。
程序设计中的“高内聚，低耦合”：我们在程序设计的过程中要追求“高内聚，低耦合”。高内聚就是类的内部数据操作细节自己来完成，不允许外部干涉，低耦合：就是， 仅暴露少量的方法给外部使用
封装的体现：
将类的属性私有化，同时提供公共的(public)方法来获取(get)和设置(set)
将类的方法私有化，仅用于内部方法调用
单例模式

构造器（构造方法）：
1.如果没有显式的定义的构造器，则系统默认定义空参的构造器
2.定义构造器的格式：权限修饰符 类名（形参列表）{}
3.一个类中可以有多个形参构造器，彼此构成重载
4.一旦我们显式的定义了构造器之后，系统就不再提供默认的空参构造器
5.一个类中，至少要有一个构造器

构造器的作用：
1.创建对象
2.初始化对象的属性

Java属性赋值的先后顺序：
1.默认初始化
2.显式初始化
3.构造器中初始化
4.通过 "对象.方法" 或 "对象.属性" 的方式初始化

在Java中，new一个对象是给怎么样的一个过程？

在Java中，创建一个对象主要经历了以下几个步骤：

1.加载类：首先，Java虚拟机（JVM）需要加载类。这个过程包括解析类的字节码，确定类的字段和方法，并为类的静态变量分配内存。
为实例变量分配内存：在类被加载后，JVM会为实例变量（即非静态字段）分配内存。
2.初始化实例变量：这个步骤会为实例变量赋予默认值。所有的数值类型默认值为0，所有的引用类型默认值为null。
如果类中有实例变量的初始化语句，或者从父类或接口中继承的实例变量初始化，那么这些初始化语句会被执行。
3.创建对象：接下来，使用new关键字来创建对象。这个过程包括为对象分配内存，复制构造函数的参数值到相应的实例变量，
调用构造函数来初始化对象，最后返回新创建对象的引用。
4.使用对象：现在，你可以使用这个新创建的对象来进行各种操作，比如调用方法、访问字段等。

Java之this关键字：
1.this可以修饰属性、方法、构造器
2.this修饰属性和方法
>this可以理解为当前对象
>在类的方法或类的构造器中，this修饰属性或方法时，一般情况下省略。特殊情况下，如果方法的形参和类的属性同名时，
必须显式使用"this.属性"声明此变量是属性，而非形参。
>this可以修饰构造器，结构为"this.形参列表"
>构造器中，不能通过方式"this.形参列表"调用自己
>如果一个类中有n个构造器，最多有n-1个构造器使用了"this.形参列表"方式
>规定："this.形参列表"必须声明在构造器的首行
>构造器内部，只能声明一个"this.形参列表"调用其他构造器

Java之package关键字：
1.为了更好的实现类的管理，提供包的概念
2.声明在原文件的首行
3.每"."一次，就代表一层文件目录
注意：相同或不同包下，不能引入同名的类、接口

Java之import关键字：
1.在源文件中显式的使用import结构导入指定包下的类、接口
2.声明在包的声明和类的声明之间
3.使用"xxx.*"的形式，表示可以导入xxx包下的所有结构
4.如果使用的类或接口是Java.lang包下定义的，则可以省略import结构
5.如果使用的类或接口是本包下定义的，则可以省略import结构

Java面向对象之继承：继承的基本思想是，基于已有的类创造新的类。
继承已存在的类就是复用这些类的方法，而且可以增加一些新的方法和字段，使新类能够适应新的情况，
继承是Java程序设计中一项核心技术，它主要解决的问题是：共性的抽取，实现代码复用。

Java中表现继承的关系需要借助关键字extends，子类继承父类。Class A extends B(){} A:子类、派生类、subclass B：父类、超类、基类、superclass
注意：
· 子类将继承父类的成员变量和成员方法。特别的，父类中声明为private的属性或方法，子类继承后，仍然认为子类获取了父类中私有的结构。
· Java中只支持单继承和多继承，不允许多重继承（C++允许多重继承）
· 子类继承父类之后，需要添加自己特有的成员，体现出与基类的不同
· 如果访问的成员变量子类中有，则优先访问子类本身的
· 如果访问的成员变量子类中无，父类中有，则访问继承下来的
· 如果子类与父类中有同名的成员变量，则优先访问子类自己的，即子类将父类的同名变量隐藏
· 如果我们没有显式的声明一个类的父类，则该类继承于Object类。Object类是所有类的父类

继承之super关键字：
1.super可以用来调用属性、方法、构造器。
2.通过使用"super.属性"或"super.方法"的形式在子类中显式的调用父类的属性和方法
>所有类都继承Object类，任何类用super都可以调用Object类。
3.如果子类重写了父类的方法，此时子类中想调用父类被重写的方法。必须显式的使用"super.方法"的形式调用父类被重写的方法
4.在子类中显式的使用"super(形参列表)"调用父类中声明的构造器
>在子类构造方法中，super(形参列表)调用父类构造时，必须是子类构造方法中的第一条语句
>super(形参列表)只能在子类的构造方法中出现一次，并不能和this同时出现
>在类的多个构造器中，至少有一个子类调用了父类的空参构造器
>若父类显式定义无参或者默认的构造方法，在子类构造方法的第一行默认有隐含的super调用，即调用基类的构造方法
 构造哪个类的对象，就调用哪个类的构造方法，调用构造方法时先调用基类，在调用子类(即在子类中隐藏super())
>如果父类的构造方法是带有参数的，此时编译器不会给子类生成默认的构造方法，此时需要用户在子类中显式定义构造方法，并在子类构造方法中选取合适的父类构造方法调用


继承之执行顺序：
无继承关系时的执行顺序：
静态代码块先执行，且只执行一次，在类加载阶段执行
当有对象创建时，才会执行实例代码块，实例代码块执行完后，再执行构造方法
有继承关系时的执行顺序：
· 父类静态代码块优先子类静态代码块执行，都是最早执行的
· 父类实例代码块和父类构造方法紧接着执行
· 子类的实例代码块和子类构造方法在接着执行
· 第二次实例化对象时，父类和子类的静态代码块都不会在执行 

继承方式：单继承、多继承、不同的类继承同一个类（不支持一个类继承不同的父类）
final关键字修饰类不能被继承。

方法的重写（Override）：
重写以后，当创建子类对象以后，通过子类对象调用子父类中，同名同参的方法时，实际执行的方法是子类重写父类的方法。

方法重写的规则：

1.参数列表必须完全与被重写方法相同；也就是说，在被重写的方法里，输入参数必须与父类的参数相同
>父类的成员方法只能被它的子类重写。
>构造方法不能被重写
>如果不能继承一个方法，则不能重写这个方法。

2.返回类型必须完全与被重写方法的返回类型相同

3.子类重写父类的方法，权限修饰符不能大于父类被重写的方法
>父类中的访问权限是protected，那么，重写的的权限不能为public
>父类中的访问权限是private，子类不能重写父类
>子类和父类在同一个包中，那么子类可以重写父类所有除了声明为private和final的方法。
 子类和父类不在同一个包中，那么子类只能够重写父类的声明为public和protect的非final方法。
 
4.重写方法不能抛出新的检查异常或者比被重写方法申明更加宽泛的异常。例如：父类的一个方法声明了一个检查异常IOException,但是在重写这个方法的时候不能抛出Exception异常，因为Exception是IOException的父类，只能抛出IOException的子类异常。
>重写的方法能够抛出任何非强制异常，无论被重写的方法是否抛出异常。但是，重写方法不能抛出新的强制性异常，或者比被重写方法声明的更广泛的强制性异常，反之则可以。

5.声明为static的方法不能被重写，但是能够被再次声明（可以被继承）;声明为final的方法不能被重写。


Java多态：
父类的引用指向子类的对象。
多态的前提是两个对象（类）存在继承关系，多态是建立在封装和继承基础之上的。
在编译期，只能调用父类中声明的方法，但在执行期，实际执行的是子类中重写父类的方法。(编译，看左边；运行，看右边)
>多态性不适用于属性，只适用于方法。(属性的编译和运行都是谁声明，谁调用)
>多态性不能调用子类特有的方法，编译时，对象是父类类型

如何在内存的层面理解多态性？
在 Java 内存层面，多态性中子类对象指向父类对象的行为是通过类型转换实现的。
在内存中，子类对象是父类对象的一个实例，因此它们都存储在堆内存中。
子类对象是父类对象的完整副本，并且拥有自己的方法和属性。由于子类对象是父类对象的完整副本，因此它们都可以被转换为父类对象的引用。
因此，我们可以在程序中使用父类对象的引用指向子类对象，这种行为称为向上转型。

当向上转型时，我们仍然可以使用父类对象的引用访问子类对象中的方法和属性，
但是如果父类对象没有定义这些方法和属性，则不能访问。
多态性允许我们在编译时使用父类对象的引用，而在运行时实际访问的是子类对象中的方法和属性。
这种行为允许我们在不改变现有代码的情况下实现子类特定的功能。

实现多态的条件，缺一不可：
1.子类继承父类
2.子类必须要对父类中方法进行重写

对于重载而言，在方法调用之前，编译器就确定了要调用的方法，这是"早绑定";
对于多态，在方法调用之后，编译器才确定要调用的方法，这是"晚绑定"

Java instanceof 关键字：
判断对象a是否是类A的一个实例，如果是，返回true(如果是多态对象，也会返回true);如果不是，返回false
使用instanceof关键字避免多态对象强制转化出现ClassCastException异常。

Java 包装类：
针对八种基本数据类型定义相应的引用类型（具有类的特征）

基本数据类型和包装类的转换：
基本数据类型→包装类：调用包装类的构造器;自动装箱
包装类→基本数据类型：调用包装类的xxxValue();自动拆箱
(自动装箱和自动拆箱是jdk5.0以后的特性)

基本数据类型、包装类转换为String类型：
1.连接运算 String str1 = num1 + "";
2.调用String的valueOf()方法 String str2 = String.valueOf();

String类型转换为基本数据类型、包装类：
调用包装类的静态方法 parseXXX

Java static关键字：
static关键字可以用来修饰属性、方法、代码块、内部类

static方法：
static修饰的方法一般称作静态方法，由于静态方法不依赖于任何对象就可以进行访问，因此对于静态方法来说，是没有this的，因为它不依附于任何对象，既然都没有对象，就谈不上this了。
并且由于这个特性，在静态方法中不能访问类的非静态成员变量和非静态成员方法，因为非静态成员方法/变量都是必须依赖具体的对象才能够被调用。
但是要注意的是，虽然在静态方法中不能访问非静态成员方法和非静态成员变量，但是在非静态成员方法中是可以访问静态成员方法/变量的。

static变量：
static修饰的属性也称作静态变量，静态变量和非静态变量的区别是：静态变量被所有的对象所共享，声明在方法区，在内存中只有一个副本，它当且仅当在类初次加载时会被初始化。
而非静态变量是对象所拥有的，在创建对象的时候被初始化，声明在堆中，存在多个副本，各个对象拥有的副本互不影响。
static成员变量的初始化顺序按照定义的顺序进行初始化。

static代码块：
(代码块的作用：用来初始化类、对象）
static关键字还有一个比较关键的作用就是 用来形成静态代码块以优化程序性能。static块可以置于类中的任何地方，类中可以有多个static块。在类初次被加载的时候，会按照static块的顺序来执行每个static块，并且只会执行一次。
因此，很多时候会将一些只需要进行一次的初始化操作都放在static代码块中进行。
静态代码块的执行顺序按照声明的前后顺序执行。
静态代码块的执行要优于非静态代码块的执行，而且静态代码块只能调用静态的属性、方法，不能调用非静态的结构。

开发中，如何确定一个属性是否要声明为static？
属性是可以被多个对象所共享的
操作静态属性的方法，通常设计成static的
工具类中的方法，习惯上声明为static的

Java final关键字
1.用来修饰类
>此类不能被其他类继承

2.用来修饰方法
>方法不能被重写

3.final用来修饰变量
>此时修饰的"变量"被称为常量
>final修饰属性，可以考虑修饰的位置有：显示初始化、代码块中初始化、构造器中初始化
>final修饰局部变量，修饰形参时，表示此形参是一个常量。一旦赋值此形参，不能重新赋值
>final修饰属性，用来当作全局常量

Java abstract关键字
1.用来修饰类:被修饰的类称为抽象类,可能包含抽象方法,也可能不包含抽象方法
>此类不能被实例化,即不能创建对象(因为其中包含抽象方法),其他功能与类相同
>抽象类中一定有构造器,便于子类实例化时调用
>开发中,提供抽象类的子类,让子类对象实例化,完成相关操作
>抽象类一般位于体系结构的上层,用来定义功能

注意:如果一个类继承了抽象类,那么这个类要么重写抽象类中所有的抽象方法,要么将此类也抽象化

2.用来修饰方法: 被修饰的方法称为抽象方法
>抽象方法只有方法的声明,没有方法体(在一些比较顶层的类中,它的方法实现与子类大多不同,此时没必要在顶层实现具体的方法,只需声明功能即可)
>包含抽象方法的类一定是一个抽象类;反之,抽象类中可无方法体
>若子类重写父类中所有的抽象方法,则子类才可实例化
>若未重写父类抽象类所有的方法,则此子类也是一个抽象类,需要用abstract修饰

注意:
abstract不能用来修饰属性,方法
abstract不能用来修饰: 私有方法,静态方法,final修饰的方法,final修饰的类

抽象类的匿名子类：
Worker worker = new Worker();
//非匿名类的非匿名对象
method1(worker);
//非匿名类的匿名对象
method1(new Worker());
//匿名类的匿名对象
//person类是抽象类
Person p = new Person(){

    @Override
    public void eat();

    @Override
    public void breath();

}

Java接口：
接口（英文：Interface），在JAVA编程语言中是一个抽象类型，是抽象方法的集合，接口通常以interface来声明。一个类通过继承接口的方式，从而来继承接口的抽象方法。
接口并不是类，编写接口的方式和类很相似，但是它们属于不同的概念。类描述对象的属性和方法。接口则包含类要实现的方法。
除非实现接口的类是抽象类，否则该类要定义接口中的所有方法。
接口无法被实例化，但是可以被实现。一个实现接口的类，必须实现接口内所描述的所有方法，否则就必须声明为抽象类。另外，在 Java 中，接口类型可用来声明一个变量，他们可以成为一个空指针，或是被绑定在一个以此接口实现的对象。

抽象类和接口的对比：
1、抽象类和接口都不能直接实例化。如果要实例化，抽象类变量必须指向实现所有抽象方法的子类对象，接口变量必须指向实现所有接口方法的类对象。
2、抽象类要被子类继承，接口要被类实现。
3、接口只能做方法申明，抽象类中可以做方法申明，也可以做方法实现。
4、接口里定义的变量只能是公共的静态的常量，抽象类中的变量是普通变量。
5、抽象类里的抽象方法必须全部被子类所实现，如果子类不能全部实现父类抽象方法，那么该子类只能是抽象类。同样，实现接口的时候，如不能全部实现接口方法，那么该类也只能为抽象类。
6、抽象方法只能申明，不能实现。
7、抽象类里可以没有抽象方法
8、如果—个类里有抽象方法，那么这个类只能是抽象类
9、抽象方法要被实现，所以不能是静态的，也不能是私有的。
10、接口可以继承接口，并且可多继承接口，但类只能单—继承。
11.接口可以通过匿名内部类实例化。接口是对动作的抽象，抽象类是对根源的抽象。抽象类表示的是，这个对象是什么。而接口表示的是，这个对象能做什么。

接口和抽象类的区别？
1.抽象类是对事物的抽象，即对类抽象；接口是对行为抽象，即局部抽象。抽象类对整体形为进行抽象，包括形为和属性。接口只对行为进行抽象。
2.抽象类是多个子类的像类，是一种模板式设计；接口是一种形为规范，是一种辐射式设计。

Java高级应用：
异步、多线程、集合、泛型、序列化、IO、网络编程、反射、动态代理、jdk8.0以及以后新特性

Java多线程：
Java多线程编程需要注意以下几点：

1.同步问题，如果不同步可能导致线程安全问题；
2.线程间通信，如果不能有效的沟通，线程的任务可能无法完成；
3.线程上下文切换，如果频繁的切换，可能导致性能问题；
4.防止死锁，如果两个线程互相等待对方释放资源，可能造成死锁。
5.线程生命周期的管理，线程不能永久存在，需要正确的关闭和管理。

Java多线程生命周期：
就绪状态：就绪状态的线程又叫做可运行状态，表示当前线程具有抢夺CPU时间片的权力（CPU时间片就是执行权）。当一个线程抢夺到CPU时间片之后，就开始执行run方法，run方法的开始执行标志着线程进入运行状态。
运行状态：run方法的开始执行标志着这个线程进入运行状态，当之前占有的CPU时间片用完之后，会重新回到就绪状态继续抢夺CPU时间片，当再次抢到CPU时间之后，会重新进入run方法接着上一次的代码继续往下执行。
阻塞状态：当一个线程遇到阻塞事件，例如接收用户键盘输入，或者sleep方法等，此时线程会进入阻塞状态，阻塞状态的线程会放弃之前占有的CPU时间片。之前的时间片没了需要再次回到就绪状态抢夺CPU时间片。
锁池：在这里找共享对象的对象锁线程进入锁池找共享对象的对象锁的时候，会释放之前占有CPU时间片，有可能找到了，有可能没找到，没找到则在锁池中等待，如果找到了会进入就绪状态继续抢夺CPU时间片。（这个进入锁池，可以理解为一种阻塞状态）

多线程的实现方式（一）
继承Thread类
1、自定义一个类MyThread类，用来继承与Thread类
2、在MyThread类中重写run（）方法
3、在测试类中创建MyThread类的对象
4、启动线程


public class Demo01 {
    public static void main(String[] args) {
        //创建线程
        MyThread t01 = new MyThread();
        MyThread t02 = new MyThread();
        MyThread t03 = new MyThread("线程03");
 
        //开启线程
//        t01.run();
//        t02.run();
//        t03.run();
        // 不会启动线程，不会分配新的分支栈。（这种方式就是单线程。）
        // start()方法的作用是：启动一个分支线程，在JVM中开辟一个新的栈空间，这段代码任务完成之后，瞬间就结束了。
        // 这段代码的任务只是为了开启一个新的栈空间，只要新的栈空间开出来，start()方法就结束了。线程就启动成功了。
        // 启动成功的线程会自动调用run方法，并且run方法在分支栈的栈底部（压栈）。
        // run方法在分支栈的栈底部，main方法在主栈的栈底部。run和main是平级的。
        t01.start();
        t02.start();
        t03.start();
        //设置线程名（补救的设置线程名的方式）
        t01.setName("线程01");
        t02.setName("线程02");
        //设置主线程名称
        Thread.currentThread().setName("主线程");
        for (int i = 0; i < 50; i++) {
            //Thread.currentThread() 获取当前正在执行线程的对象
            System.out.println(Thread.currentThread().getName() + ":" + i);
        }
    }
}
class MyThread extends Thread{
    public MyThread() {
    }
 
    public MyThread(String name) {
        super(name);
    }
 
    //run方法是每个线程运行过程中都必须执行的方法
    @Override
    public void run() {
        for (int i = 0; i < 50; i++) {
            System.out.println(this.getName() + ":" + i);
        }
    }
}

此处最重要的为start()方法。单纯调用run()方法不会启动线程，不会分配新的分支栈。
start()方法的作用是：启动一个分支线程，在JVM中开辟一个新的栈空间，这段代码任务完成之后，瞬间就结束了。线程就启动成功了。
启动成功的线程会自动调用run方法（由JVM线程调度机制来运作的），并且run方法在分支栈的栈底部（压栈）。
run方法在分支栈的栈底部，main方法在主栈的栈底部。run和main是平级的。
单纯使用run()方法是不能多线程并发的。

多线程的实现方式（二）
实现Runnable接口
1、自定义一个MyRunnable类来实现Runnable接口
2、在MyRunnable类中重写run（）方法
3、创建Thread对象，并把MyRunnable对象作为Tread类构造方法的参数传递进去
4、启动线程
开发中使用这种方式创建多线程，而不是继承Thread类


public class Demo02 {
    public static void main(String[] args) {
        MyRunnable myRun = new MyRunnable();//将一个任务提取出来，让多个线程共同去执行
        //封装线程对象
        Thread t01 = new Thread(myRun, "线程01");
        Thread t02 = new Thread(myRun, "线程02");
        Thread t03 = new Thread(myRun, "线程03");
        //开启线程
        t01.start();
        t02.start();
        t03.start();
        //通过匿名内部类的方式创建线程
        new Thread(new Runnable() {
            @Override
            public void run() {
                for (int i = 0; i < 20; i++) {
                    System.out.println(Thread.currentThread().getName() + " - " + i);
                }
            }
        },"线程04").start();
    }
}
//自定义线程类，实现Runnable接口
//这并不是一个线程类，是一个可运行的类，它还不是一个线程。
class MyRunnable implements Runnable{
    @Override
    public void run() {
        for (int i = 0; i < 50; i++) {
            System.out.println(Thread.currentThread().getName() + " - " + i);
        }
    }
}

多线程的实现方式（三）
实现Callable接口（ java.util.concurrent.FutureTask; /JUC包下的，属于java的并发包，老JDK中没有这个包。新特性。）
1、自定义一个MyCallable类来实现Callable接口
2、在MyCallable类中重写call()方法
3、创建FutureTask，Thread对象，并把MyCallable对象作为FutureTask类构造方法的参数传递进去，把FutureTask对象传递给Thread对象。
4、启动线程

        这种方式的优点：可以获取到线程的执行结果；方法可以抛出异常；返回结果支持泛型的返回值

        这种方式的缺点：效率比较低，在获取t线程执行结果的时候，当前线程受阻塞，效率较低。

		
package com.lmw.thread3;

import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.FutureTask;

public class ThreadCallableTest {
    public static void main(String[] args) {
        //3.创建callable接口实现类的对象
        Number number = new Number();
        //4.将callable实现接口实现类的对象作为参数传递到FutureTask构造器中，创建FutureTask的对象
        FutureTask futureTask = new FutureTask(number);
        //5.将FutureTask的对象作为参数传递到Thread类的构造器中，创建Thread对象，并调用start()
        new Thread(futureTask).start();

        try {
            // get方法的返回值即为futureTask构造器的参数Callable实现类重写的call方法的返回值
            //6.获取callable中call方法的返回值
            Object sum = futureTask.get();
            System.out.println("总和为:" + sum);
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();
        }


    }
}

// 1.创建一个实现callable接口的实现类
class Number implements Callable {
    // 2.实现call方法，将此线程需要执行的操作写在call方法中
    @Override
    public Object call() throws Exception {
        int sum = 0;
        for (int i = 1; i <= 100; i++) {
            if(i % 2 == 0) {
                sum  = sum + i;
            }
        }
        return sum;
    }
}

多线程的实现方式（四）
创建线程池		
优点：1.提高响应速度 2.降低资源消耗 3.便于线程管理
		
		import java.util.ArrayList;
import java.util.Date;
import java.util.List;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
​
public class ThreadDemo {
    
    @SuppressWarnings({ "rawtypes", "unchecked" })
    public static void main(String[] args) throws ExecutionException, InterruptedException {
        System.out.println("---- 主程序开始运行 ----");
        Date startTime = new Date();
        
        int taskSize = 5;
        // 创建一个线程池,Executors提供了创建各种类型线程池的方法，具体详情请自行查阅
        ExecutorService executorService = Executors.newFixedThreadPool(taskSize);
        
        // 创建多个有返回值的任务
        List<Future> futureList = new ArrayList<Future>();
        for (int i = 0; i < taskSize; i++) {
            Callable callable = new MyCallable(i);
            // 执行任务并获取Future对象
            Future future = executorService.submit(callable);
            futureList.add(future);
        }
        
        // 关闭线程池
        executorService.shutdown();
​
        // 获取所有并发任务的运行结果
        for (Future future : futureList) {
            // 从Future对象上获取任务的返回值，并输出到控制台
            System.out.println(">>> " + future.get().toString());
        }
​
        Date endTime = new Date();
        System.out.println("---- 主程序结束运行 ----，程序运行耗时【" + (endTime.getTime() - startTime.getTime()) + "毫秒】");
    }
}
​
class MyCallable implements Callable<Object> {
    private int taskNum;
​
    MyCallable(int taskNum) {
        this.taskNum = taskNum;
    }
​	@Override
    public Object call() throws Exception {
        System.out.println(">>> " + taskNum + " 线程任务启动");
        Date startTime = new Date();
        Thread.sleep(1000);
        Date endTime = new Date();
        long time = endTime.getTime() - startTime.getTime();
        System.out.println(">>> " + taskNum + " 线程任务终止");
        return taskNum + "线程任务返回运行结果, 当前任务耗时【" + time + "毫秒】";
    }
}


Java synchronized 关键字：同步代码块，解决线程安全问题，解决多线程上下文冲突问题，保证线程原子性
synchronized(同步监视器){
//需要被同步的代码
}
注：1.同步监视器，俗称：锁。使用当前类的对象当成锁，锁住需要同步的代码。
    2.可以使用this关键字，也可以使用Object对象充当锁。
	3.非静态的同步方法，同步监视器是this；静态的同步方法，同步监视器是当前类本身

lock方法解决线程安全问题：
ReentrantLock lock = new ReentrantLock();
lock.lock();
lock.unlock();

lock方法与synchronized关键字解决线程安全问题的区别：
synchronized在执行完同步的代码块后，自动释放同步监视器
lock需要手动的启动同步，也要手动的实现解锁

Java多线程实现线程通讯：sleep()   wait()
sleep和wait的区别
1、sleep是线程中的方法，但是wait是Object中的方法。
2、sleep方法不会释放资源锁，但是wait会释放资源锁，而且会加入到等待队列中。
3、sleep方法不依赖于同步器synchronized，但是wait需要依赖synchronized关键字。
4、sleep不需要被唤醒（休眠之后推出阻塞），但是wait需要（不指定时间需要被别人中断）。


Java线程异步：
Java 的线程异步是指在 Java 应用程序中，多个线程同时执行不同的任务，并且他们是独立的，互不影响，
任意一个线程的完成不会影响其他线程的运行。 在 Java 异步编程中，不同的线程可以在不需要阻塞等待的情况下并行执行，
这样可以提高程序的执行效率。

线程异步需要考虑原子性：
在Java中异步编程中，线程原子性是需要考虑的因素。线程原子性指的是线程执行过程中不会被其他线程打断的特性。
如果不考虑线程原子性，那么会有可能出现线程在执行过程中对数据的不一致性问题。
因此，在异步编程中，为了保证数据的一致性，需要考虑线程的原子性。

public class AsyncThread extends Thread{
    @Override
    public void run() {
        System.out.println("当前线程名称:" + this.getName() + ", 执行线程名称:" + Thread.currentThread().getName() + "-hello");
    }
}
Future 异步：
@Test
public void futureTest() throws Exception {
 
    System.out.println("main函数开始执行");
 
    ExecutorService executor = Executors.newFixedThreadPool(1);
    Future<Integer> future = executor.submit(new Callable<Integer>() {
        @Override
        public Integer call() throws Exception {
 
            System.out.println("===task start===");
            Thread.sleep(5000);
            System.out.println("===task finish===");
            return 3;
        }
    });
    //这里需要返回值时会阻塞主线程，如果不需要返回值使用是OK的。倒也还能接收
    //Integer result=future.get();
    System.out.println("main函数执行结束");
    System.in.read();
 
}


CompletableFuture异步：
CompletableFuture<Long> completableFuture = CompletableFuture.supplyAsync(() -> factorial(number));
while (!completableFuture.isDone()) {
    System.out.println("CompletableFuture is not finished yet...");
}
long result = completableFuture.get();

SpringBoot @Async异步：
@SpringBootApplication
@EnableAsync
public class StartApplication {

    public static void main(String[] args) {
        SpringApplication.run(StartApplication.class, args);
    }
}
自定义线程池：

@Configuration
@Slf4j
public class ThreadPoolConfiguration {

    @Bean(name = "defaultThreadPoolExecutor", destroyMethod = "shutdown")
    public ThreadPoolExecutor systemCheckPoolExecutorService() {

        return new ThreadPoolExecutor(3, 10, 60, TimeUnit.SECONDS,
                new LinkedBlockingQueue<Runnable>(10000),
                new ThreadFactoryBuilder().setNameFormat("default-executor-%d").build(),
                (r, executor) -> log.error("system pool is full! "));
    }
}
Guava异步：
ExecutorService threadpool = Executors.newCachedThreadPool();
ListeningExecutorService service = MoreExecutors.listeningDecorator(threadpool);
ListenableFuture<Long> guavaFuture = (ListenableFuture<Long>) service.submit(()-> factorial(number));
long result = guavaFuture.get();

Java中的object类：
Object类是Javajava.lang包下的核心类，Object类是所有类的父类，何一个类时候如果没有明确的继承一个父类的话，那么它就是Object的子类；

1. clone()
保护方法，实现对象的浅复制，只有实现了Cloneable接口才可以调用该方法，否则抛出CloneNotSupportedException异常。

2. getClass()
final方法，返回Class类型的对象，反射来获取对象。

3. toString()
该方法用得比较多，一般子类都有覆盖，来获取对象的信息。

4. finalize()
该方法用于释放资源。因为无法确定该方法什么时候被调用，很少使用。

5. equals()
比较对象的内容是否相等

6. hashCode()
该方法用于哈希查找，重写了equals方法一般都要重写hashCode方法。这个方法在一些具有哈希功能的Collection中用到。

7. wait()
wait方法就是使当前线程等待该对象的锁，当前线程必须是该对象的拥有者，也就是具有该对象的锁。wait()方法一直等待，直到获得锁或者被中断。wait(long timeout)设定一个超时间隔，如果在规定时间内没有获得锁就返回。

调用该方法后当前线程进入睡眠状态，直到以下事件发生。

其他线程调用了该对象的notify方法。
其他线程调用了该对象的notifyAll方法。
其他线程调用了interrupt中断该线程。
时间间隔到了。
此时该线程就可以被调度了，如果是被中断的话就抛出一个InterruptedException异常。

8. notify()
该方法唤醒在该对象上等待的某个线程。

9. notifyAll()
该方法唤醒在该对象上等待的所有线程。


Java集合：
集合 → 数组 ：toArray()
数组 → 集合 ：调用Array类的静态方法asList()

遍历集合的方法：
1.迭代器
Collection coll = new ArrayList();
Iterator iterator = coll.iterator();
while(iterator.hasNext()){
	System.out.println(iterator.next());
};
2.foreach()
for (集合元素的类型 局部变量 ：集合对象)


Java集合可分为Collection和Set两个体系：
Collection接口：单列数据，定义了存取一组对象的方法的集合
	
	List：元素有序、可重复的集合 
	>ArrayList:作为list接口的主要实现类；线程不安全的，效率高；底层使用Object[]elementData存储
	>LinkedList：对于频繁的插入、删除操作，使用效率比ArrayList高；底层使用双向链表存储
	>Vector：作为list接口的古老实现类；线程安全的，效率低；底层使用Object[]elementData存储
	
	Set：元素无序、不可重复的集合
	>HashSet:作为Set接口的主要实现类；线程不安全的；可以存储null值（底层：数组+链表）
	>LinkedHashSet：作为HashSet的一个子类；遍历其内部数据时，可以按照添加的顺序遍历
	>TreeSet：只能添加同一类型的对象，可以按照添加对象的指定属性，进行排序（底层：红黑树）

Map接口：双列数据，存储的是键值对

ArrayList的源码分析:
jdk 7情况下
ArrayList arrayList=new ArrayList();//底层建了长度是10的Object[]数组elementData
list.add (123);//elementData[0] = new Integer(123);
...
list.add(11);//如果此次的添加导致底层元素数据数组容量不够，则扩容
默认情况下，扩容为原来的容量的1.5倍，同时需要将原有数组中的数据复制到新的数组中
结论:建议开发中使用带参的构造器:ArrayList arrayList=new ArrayList(int capacity)

jdk 8中ArrayList的变化:
ArrayList list = new ArrayList();//底层Object[] elementData始化为{}并没有创建长度为10的数组
list.add(123);//第一次调用add()时，底层才创建了长度10的数组，并将数据123添加到elementData[0]
...
后续的添加和扩容操作与jdk 7 无异

小结：jdk7中的ArrayList对象创建类似于单列模式的饿汉式；
而jdk8中的ArrayList对象创建类似于单列模式的懒汉式，延迟了数组的创建，节省内存

LinkedList的源码分析：
LinkedLtst List = new LinkedList(); 内部明JNode类型的first和last属性，默认值为null 
List.add(123);//将123封装到Node 中，创建了Node对象。
其中，Node定义为:体现了LinkedList的双向链表的说法
private static class Node<E> {
	E item;
	Node<E> next;
	Node<E> prev;
	Node(Node<E> prev， E element， Node<E> next) {
	this.item = element;
	this.next = next;
	this.prev = prev;
	}
}

总结:List常用方法
增: add(object obj)
删：remove(int index) / remove(Object obj)
改：set(int index, Object ele)
查：get(int index)
插: add(int index, Object ele)
长度: size()
遍历: ①@Iterator送代器方式
	②增强for循环
	③普通的循环

Set：
1.无序性：存储的数据在底层数组中并非按照数组索引添加，而是根据数据的哈希值来决定
2.不可重复性：保证添加的元素按照equals()判断时，不能返回true.即: 相同的元素只能添加一个
	
添加元素的过程(以Hashset 为例):
我们向Hashset中添加元素a,首先调用元素a所在类的hashcode()方法，计算元素a的哈希值，此哈希值接着通过某种算法计算出在HashSet底层数组中的存放位置(即为: 索引位置)，
判断数组此位置上是否已经有元素:
如果此位置上没有其他元素，则元素a添加成功。--->情况1
如果此位置上有其他元素b(或以链表形式存在的多个元素)，则比较元素a与元素b的hash值:如果hash值不相同，则元素a添加成功。--->情况2
如果hash值相同，进而需要调用元素a所在类的equlas()方法:equaLs()返回true，元素a添加失败equaLs()返回false，则元素a添加成功。--->情况2
	对于添加成功的情况2和情况3而言: 元素 与已经存在指定索引位置上数据以链表的方式存储
	jdk 7 : 元素a放到数组中，指向原来的元素。jdk 8 : 原来的元素在数组中，指向元素a	

Set中相同元素的比较：先比较两个元素的哈希值，然后再比较两个元素是否相同

关于hashCode()和equals()方法重写的规则	
	1。Set接口中没有额外定义新的方法，使用的都是CoLLection 中声明过的方法
	要求:向Set中添加的数据，其所在的类一定要重写hashCode()和equals()
	2.要求:重写的hashCode()和eguals()尽可能保一致性: 相等的对象必须具有相等的散列码
	重写两个方法的小技巧: 对象中用作 equals() 方法比较的 Feld，都应该用来计算 hashcode

Map接口：双列数据，存储的是键值对	
>Map:双列数据，存储key-value对的数据---类似于高中的函数: y = f(x)
>HashMap:作为Map的主要实现类，线程不安全的，效率高: 存储null的key和value
>LinkedHashMap: 保证在遍历map元素时，可以按照添加的顺序实现遍历。
原因:在原有的HashMap 底层结构基础上，添加了一对指针，指向前一个和后一个元素。
对于频繁的遍历操作，此类执行效率高于HashMap。
>TreeMap:保证按照添加的key-value对进行排序，实现排序遍历。此时考key的自然排序或定制排序。底层使用红黑树
>Hashtable: 作为古老的实现类: 线程安全的，效率低:不能存nulL的key和value
>Properties: 常用来处理配置文件。key和value都是string类型

HashMap的底层实现原理? 以jdk7为例说明:
HashMap map = new HashMap():在实例化以后，底层创建了长度是16的一维数组Entry[] table
...可能已经执行过多次put...
map.put(key1, value1):
首先，调用key1所在类的hashCode()计算key1哈希值，此哈希值经过某种算法计算以后，得到在Entry数组中的存放位置。
	如果此位置上的数据为空，此时的key1-value1添加成功。 ---- 情况1
	如果此位置上的数据不为空，(意味着此位置上存在一个或多个数据(以链表形式存在)，
	比较key1和已经存在的一个或多个数的哈希值:
		如果key1的哈希值与已经存在的数据的哈希值都不相同，此时key1-value1添加成功。----情况2
		如key1的哈希值和已经存在的某一个数(key2-value2)的哈希值相同，继续比较: 调用key1所在类的equals(key2)
			如果equals()返回false: 此时key1-value1添加成功。---- 情况3
			如果equals()返回true: 使用vaLue1 vaLue2.

补充:关于情况2和情况3: 此时key1-value1和原来的数据以链表的方式存储
在不断的添加过程中，会涉及到扩容问题，默认的扩容方式:扩容为原来容量的2倍，并将原有的数据复制过来。

jdk8相较于jdk7在底层安现方面的不同:
1.new HashMap(): 底层没有创建一个长度为16的数组
2.jdk8底层的数组是: Node[]，而Entry[]首次调用put()方法时，底层创建长度为16的数组
3.jdk7底层结构只有:数组+ 链表。jdk8中底层结构: 数组+链表+红黑树。
当数组的某一个索引位置上的元素以链表形式存在的数个数 >8 且当前数组的长度>64时此时此索引位置上的所有数据改为使用红黑树存储。

Java泛型：
所操作的数据类型被指定为一个参数（type parameter）这种参数类型可以用在类、接口和方法的创建中，分别称为泛型类、泛型接口、泛型方法。

在集合中使用泛型:
>集合接口或集合类在jdk5.0时都修改为带泛型的结构
>在实例化集合类时，可以指明具体的泛型类型
>指明完以后，在集合类或接口中凡是定义类或接口时，内部结构使用到类的泛型的位置，都指定为实例化的泛型类型
(比如: add(E e) --->实例化以后: add(Integer e))
注意点: 泛型的类型必须是类，不能是基本数据类型。需要用到基本数据类型的位置，拿包装类替换 
>如果实例化时，没有指明泛型的类型。默认类型为java.lang.object类型。

自定义泛型接口：
语法：Interface 接口名<T, R…>{ }
使用注意事项：
① 接口中，静态成员也不能使用泛型；
② 泛型接口的类型，在继承接口或者实现接口时确定；
③ 没有指定类型，默认为Object。
	
泛型的通配符：?
① <?>：支持任意泛型
② <? extends A>：支持A类以及A类的子类，规定了泛型的上限
③ <? Super A>：支持A类以及A类的父类，不限于直接父类，规定了泛型的下限。	
④ 不能向List<?> 内添加除null之外的数据
⑤ 允许读取数据，读取数据的类型为Object

Java IO（Flie类、IO流、网络编程、序列化与反序列化）:
Java的IO是实现输入和输出的基础，可以方便的实现数据的输入和输出操作。在Java中把对于输入/输出操作是以流的方式进行操作的。java.io 包下提供了大量的供我们使用的操作【流】的方法和接口，用于进行各类数据的处理和传输。
注意： Windows各个文件之间分隔符为：” \ “；Linux各个文件之间分割符为：” / “

Java Flie类：Flie类是文件和目录路径名的抽象表示，主要用于文件和目录的创建、查找和删除等操作。
Flie类构造方法：
public File(String pathname) ：通过将给定的路径名字符串转换为抽象路径名来创建新的 File实例。
public File(String parent, String child) ：从父路径名字符串和子路径名字符串创建新的 File实例。
public File(File parent, String child) ：从父抽象路径名和子路径名字符串创建新的 File实例。

Java IO流：通过IO可以完成硬盘文件的读和写   I:Input 往内存中去 O:Output 从内存中出来
在java中只要"类名"以 Stream 结尾的都是字节流。以"Reader/Writer"结尾的都是字符流。
字符流不能处理图片文件，字节流不能处理文本文件

流的体系结构
抽象基类
InputStream
OutputStream
Reader
Writer
节点流(或文件流)
FileInputStream
FileOutputstream
FileReader
Filewriter
缓冲流(处理流的一种)
BufferedInputStream
BufferedOutputstream
BufferedReader
Bufferedwriter

文件专属字符流FlieReader：
//1.实例化File类的对象，指明要操作的文件
File file = new File( pathname:"hello.txt");//相较于当前Module
//2.提供具体的流
FileReader fr = new FileReader(file);
//3.数据的读入
int data;
while((data = fr.read()) != -1){
System.out.print((char)data);
}
//4.流的关闭操作
try {
fr.close();
} catch (IOException e) {
e.printStackTrace()
};

文件专属字节流FileInputStream：
public class FileInputStreamTest04 {
    public static void main(String[] args) {
        FileInputStream fis = null;
        try {
            fis = new FileInputStream("chapter23/src/tempfile3");
            // 开始读，采用byte数组，一次读取多个字节。最多读取“数组.length”个字节。
            byte[] bytes = new byte[4];// 准备一个4个长度的byte数组，一次最多读取4个字节。
            int readCount = 0;
            // 这个方法的返回值是：读取到的字节数量。（不是字节本身）;1个字节都没有读取到返回-1(文件读到末尾)
            while((readCount = fis.read(bytes)) != -1) {
            	// 不应该全部都转换，应该是读取了多少个字节，转换多少个。
                System.out.print(new String(bytes, 0, readCount));
            }
        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
        	// 在finally语句块当中确保流一定关闭。
            if (fis != null) {// 避免空指针异常！
            	// 关闭流的前提是：流不是空。流是null的时候没必要关闭。
                try {
                    fis.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
    }
}

缓冲字符流BufferReader：
包装流的方法
public class BufferedReaderTest01 {
    public static void main(String[] args) throws Exception{

        FileReader reader = new FileReader("Copy02.java");
        // 当一个流的构造方法中需要一个流的时候，这个被传进来的流叫做：节点流。
        // 外部负责包装的这个流，叫做：包装流，还有一个名字叫做：处理流。
        // 像当前这个程序来说：FileReader就是一个节点流。BufferedReader就是包装流/处理流。
        BufferedReader br = new BufferedReader(reader);

        // br.readLine()方法读取一个文本行，但不带换行符。
        String s = null;
        while((s = br.readLine()) != null){
            System.out.print(s);
        }

        // 关闭流
        // 对于包装流来说，只需要关闭最外层流就行，里面的节点流会自动关闭。（可以看源代码。）
        br.close();
    }
}

缓冲流InputStreamReader转换流FileInputStream：
public class BufferedReaderTest02 {
    public static void main(String[] args) throws Exception{

        /*// 字节流
        FileInputStream in = new FileInputStream("Copy02.java");

        // 通过转换流转换（InputStreamReader将字节流转换成字符流。）
        // in是节点流。reader是包装流。
        InputStreamReader reader = new InputStreamReader(in);

        // 这个构造方法只能传一个字符流。不能传字节流。
        // reader是节点流。br是包装流。
        BufferedReader br = new BufferedReader(reader);*/

        // 合并
        BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream("Copy02.java")));

        String line = null;
        while((line = br.readLine()) != null){
            System.out.println(line);
        }

        // 关闭最外层
        br.close();
    }
}

DataInputStream:数据字节输入流。
DataOutputStream写的文件，只能使用DataInputStream去读。并且读的时候你需要提前知道写入的顺序。
读的顺序需要和写的顺序一致。才可以正常取出数据。。


序列化：将对象写入到IO流中，说的简单一点就是将内存模型的对象变成字节数字，可以进行存储和传输。
使用ObjectOutputStream实现序列化：
public class ObjectOutputStreamTest01 {
    public static void main(String[] args) throws Exception{
        // 创建java对象
        Student s = new Student(1111, "zhangsan");
        // 序列化
        ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream("students"));
        // 序列化对象
        oos.writeObject(s);
        // 刷新
        oos.flush();
        // 关闭
        oos.close();
    }
}
注意：序列化的对象需要实现Serializable接口，用static和transient修饰的变量不可序列化

反序列化：从IO流中恢复对象，将存储在磁盘或者从网络接收的数据恢复成对象模型。
使用ObjectInputStream实现反序列化：
public class ObjectInputStreamTest01 {
    public static void main(String[] args) throws Exception{
        ObjectInputStream ois = new ObjectInputStream(new FileInputStream("students"));
        // 开始反序列化，读
        Object obj = ois.readObject();
        // 反序列化回来是一个学生对象，所以会调用学生对象的toString方法。
        System.out.println(obj);
        ois.close();
    }
}

使用场景：所有可在网络上传输的对象都必须是可序列化的，否则会出错；所有需要保存到磁盘的Java对象都必须是可序列化的。

RandomAccessFlie的使用：
1.RandomAccessFlie直接继承于java.lang.Object，实现了DataInput和DataOutput
2.RandomAccessFlie既可以作为输入流，又可以作为输出流
3.如果RandomAccessFlie作为一个输出流时，写出的文件如果不存在，则在执行过程中自动创建；
如果文件存在，则会对原有文件内容进行覆盖。（默认情况下，从头覆盖）
4.用seak方法可以实现在第N位后覆盖原文件

Java NIO：
NIO 中的 N 可以理解为 Non-blocking，不单纯是 New，是解决高并发、I/O高性能的有效方式。
Java NIO是Java1.4之后推出来的一套IO接口，NIO提供了一种完全不同的操作方式， NIO支持面向缓冲区的、基于通道的IO操作。
新增了许多用于处理输入输出的类，这些类都被放在java.nio包及子包下，并且对原java.io包中的很多类进行改写，新增了满足NIO的功能。

Java NIO： 同步非阻塞，服务器实现模式为一个线程处理多个请求(连接)，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求就进行处理。
一个线程中就可以调用多路复用接口（java中是select）阻塞同时监听来自多个客户端的IO请求，一旦有收到IO请求就调用对应函数处理，NIO擅长1个线程管理多条连接，节约系统资源。

运用Java NIO通信框架有Mina、Netty、Grizzly等。

Java NIO详解：https://www.cnblogs.com/mikechenshare/p/16587635.html

NIO 包含3个核心的组件：

Channel(通道)
Buffer(缓冲区)
Selector(选择器)

关系图：
https://static.mikechen.cc/wp-content/uploads/2022/03/java-nio-08.png

关系图的说明：
每个 Channel 对应一个 Buffer。
Selector 对应一个线程，一个线程对应多个 Channel。
该图反应了有三个 Channel 注册到该 Selector。
程序切换到那个 Channel 是由事件决定的（Event）。
Selector 会根据不同的事件，在各个通道上切换。
Buffer 就是一个内存块，底层是有一个数组。
数据的读取和写入是通过 Buffer，但是需要flip()切换读写模式，而 BIO 是单向的，要么输入流要么输出流。

网络编程：网络编程是指编写运行在多个设备（计算机）的程序，这些设备都通过网络连接起来。程序之间可以通信，互相发送消息。

网络七层架构的作用与协议：
层		功能								协议
应用层	提供应用程序之间的通信。		TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet
表示层	处理数据格式，数据加密和压缩等。	没有协议
会话层	建立、管理、终止两主机的会话。		没有协议
传输层	建立主机的端到端连接。			TCP，UDP
网络层	路径选择。						ICMP，RIP，OSPF，BGP，IGMP，IP
数据链路层	负责两个相邻结点之间的数据传输。		SLIP，CSLIP，PPP，ARP，RARP，MTU
物理层	使原始的数据比特流能在物理媒介上传输。	ISO2110，IEEE802，IEEE802.2

       
IP：唯一的标识 Internet上的计算机（通信实体）
IP分类：IPV4和IPV6；万维网和局域网
域名：由于IP地址具有不方便记忆并且不能显示地址组织的名称和性质等缺点，人们设计出了域名，并通过网域名称系统（DNS，Domain Name System）来将域名和IP地址相互映射，
使人更方便地访问互联网，而不用去记住能够被机器直接读取的IP地址数串
本地回路地址：127.0.0.1 对应：localhost
在Java中使用InetAddress类代表IP，实例化InetAddress的两个方法：
getByName(String host) getLocalHost()
两个常用方法：getHostName() / getHostAddress()
端口号：正在计算机上运行的进程
  要求：不同的进程有不同的端口号
  范围：被规定为一个16位的整数0-65535
端口号与IP地址的组合得出一个网络套接字:Socket

TCP和UDP协议是TCP/IP协议的核心。 TCP 传输协议：TCP 协议是一TCP (Transmission Control Protocol)和UDP(User Datagram Protocol)协议属于传输层协议。
其中TCP提供IP环境下的数据可靠传输，它提供的服务包括数据流传送、可靠性、有效流控、全双工操作和多路复用。通过面向连接、端到端和可靠的数据包发送。
通俗说，它是事先为所发送的数据开辟出连接好的通道，然后再进行数据发送；而UDP则不为IP提供可靠性、流控或差错恢复功能。
一般来说，TCP对应的是可靠性要求高的应用，而UDP对应的则是可靠性要求低、传输经济的应用。

网络编程之实现InetAddress实例化：
public class InetAddressTest {
    public static void main(String[] args) {
 
        InetAddress inet1 = null;
        try {
            inet1 = InetAddress.getByName("192.168.10.14");
            System.out.println(inet1);
 
            InetAddress inet2 = InetAddress.getByName("www.baidu.com");
            System.out.println(inet2);
 
            InetAddress inet3 = InetAddress.getByName("127.0.0.1");
            System.out.println(inet3);
 
            //获取本地ip
            InetAddress inet4 = InetAddress.getLocalHost();
            System.out.println(inet4);
 
            //getHostName()
            System.out.println(inet2.getHostName());
            //getHostAddress()
            System.out.println(inet2.getHostAddress());
        } catch (UnknownHostException e) {
            e.printStackTrace();
        }
 
    }
}


网络编程之Socket编程：
我们可以发现Socket就在应用程序的传输层和应用层之间，设计了一个Socket抽象层，传输层的底一层的服务提供给Socket抽象层，Socket抽象层再提供给应用层。
套接字使用TCP提供了两台计算机之间的通信机制。 客户端程序创建一个套接字，并尝试连接服务器的套接字。
当连接建立时，服务器会创建一个 Socket 对象。客户端和服务器现在可以通过对 Socket 对象的写入和读取来进行通信。
java.net.Socket 类代表一个套接字，并且 java.net.ServerSocket 类为服务器程序提供了一种来监听客户端，并与他们建立连接的机制。
IP和端口号通过Socket传输。

以下步骤在两台计算机之间使用套接字建立TCP连接时会出现：

服务器实例化一个 ServerSocket 对象，表示通过服务器上的端口通信。
服务器调用 ServerSocket 类的 accept() 方法，该方法将一直等待，直到客户端连接到服务器上给定的端口。
服务器正在等待时，一个客户端实例化一个 Socket 对象，指定服务器名称和端口号来请求连接。
Socket 类的构造函数试图将客户端连接到指定的服务器和端口号。如果通信被建立，则在客户端创建一个 Socket 对象能够与服务器进行通信。
在服务器端，accept() 方法返回服务器上一个新的 Socket 引用，该 Socket 连接到客户端的 Socket。

Java实现TCP网络程序设计：
服务器端类：
package dreamfly.net.server;

//读取客户端发来的数据，给客户端写出数据

import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.net.ServerSocket;
import java.net.Socket;

public class Server {

    public static void main(String[] args) throws IOException {

        //1.开启服务器，参数是指开着的端口号
        ServerSocket server = new ServerSocket(8899);
        System.out.println("服务器已成功启动");
        //2.接收客户端发来的连接
        Socket socket = server.accept();
        System.out.println("接收到客户端发来的请求");
        //3.获取读取流
        InputStream in = socket.getInputStream();
        //4.读取数据
//        int data = in.read();      //默认返回的是整数
        for (int i = 0;i < 5;i++){
            char data = (char)in.read();
            System.out.print(data);
        }
        //5.给客户端写出数据
        System.out.println();
        OutputStream out = socket.getOutputStream();
        out.write("world".getBytes());
        System.out.println("服务器端成功发送数据");
        out.close();
    }
}

客户端类：
package dreamfly.net.client;

//读取服务器端发来的数据，给服务器端写出数据

import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.net.Socket;

public class Client {

    public static void main(String[] args) throws IOException {
        //1.连接到指定的服务器(ip+port)
        Socket socket = new Socket("127.0.0.1",8899);
        System.out.println("已连接成功");
        //2.获取写出流
        OutputStream out = socket.getOutputStream();
        //3.写出数据,字节流只能写出整数或字节数组
        //将hello对应整数编程对应的字节数组，getBytes()将String转换为byte[]
        out.write("hello".getBytes());
        System.out.println("客户端成功发送数据");
        InputStream in = socket.getInputStream();
        for (int i = 0;i < 5;i++){
            char data = (char)in.read();
            System.out.print(data);
        }
        System.out.println();
        System.out.println("成功接收服务器端数据");
        out.close();
    }
}



Java实现UDP编程：
服务器端
DatagramSocket serverSocket = new DatagramSocket(1234)；//设置监听端口，可以和TCP端口重复，及一个应用程序用TCP占用端口1234，另一个程序可以用UDP占用端口1234

byte[] buff = new byte[1024];

客户端
DatagramPacket packet = new DatagramPacket(buff, buff.length);//设置接受长度为buff.leng的buff数据

serverSocket.receive(packet)；//收取UDP数据包

String word = new String( packet.getData(), packet.getOffset(), packet.getLength(),StandardCharsets.UTF_8 );//将收到的数据按UTF-8转换为String

System.out.println("已经收到"+word);//在服务器做出提示
                byte[] resultbuff = word.getBytes();
                packet.setData(resultbuff);
                serverSocket.send(packet);//发送数据给客户端做出回应


URL：在WWW上，每一信息资源都有统一的且在网上的地址，该地址就叫URL（Uniform Resource Locator,统一资源定位器），它是WWW的统一资源定位标志，就是指网络地址。
URL格式：协议 主机名 端口号 资源地址

Java实现URL网络编程：
public class UrlTest02 {

    public static void main(String[] args) throws Exception {

        HttpURLConnection urlConnection = null;
        InputStream is = null;
        FileOutputStream fos = null;
        try {
            URL url = new URL("http://localhost:8080/examples/beauty.jpg");

            urlConnection = (HttpURLConnection) url.openConnection();

            urlConnection.connect();

            is = urlConnection.getInputStream();
            fos = new FileOutputStream("day10\\beauty3.jpg");

            byte[] buffer = new byte[1024];
            int len;
            while((len = is.read(buffer)) != -1){
                fos.write(buffer,0,len);
            }

            System.out.println("下载完成");
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            //关闭资源
            if(is != null){
                try {
                    is.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
            if(fos != null){
                try {
                    fos.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
            if(urlConnection != null){
                urlConnection.disconnect();
            }
        }
    }
}

Java Stream：
Stream流是一种顺序的元素集合，它支持类似于SQL语句的操作，如过滤、映射、排序等。通过使用Stream流，我们可以以声明式的方式对数据进行处理，而不需要关心具体的实现细节。

Stream流的主要特点包括：
Stream流不存储数据，而是通过管道传输数据。
Stream流可以操作任何数据源，如集合、数组、I/O通道等。
Stream流可以进行串行操作和并行操作。
Java中的Stream流主要包含两种类型：中间操作和终端操作。中间操作用于对流进行一系列的转换和操作，而终端操作用于从流中获取结果。

使用Stream流可以通过以下几个步骤进行：

创建流：可以从集合、数组、I/O通道等数据源中创建Stream流。
中间操作：对流进行一系列的转换和操作，如过滤、映射、排序等。
终端操作：从流中获取结果，如聚合、收集、遍历等。


常用的 Stream 函数包括：
中间操作符：通常对于Stream的中间操作，可以视为是源的查询，并且是懒惰式的设计，对于源数据进行的计算只有在需要时才会被执行，
与数据库中视图的原理相似；Stream流的强大之处便是在于提供了丰富的中间操作，相比集合或数组这类容器，极大的简化源数据的计算复杂度
一个流可以跟随零个或多个中间操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用

1. filter(Predicate<T> predicate)：根据指定的条件过滤出符合条件的元素。
userList.stream().filter(user -> user.getId() > 6).collect(Collectors.toList());
2. map(Function<T, R> mapper)：将每个元素映射为另一个元素。
userList.stream().map(user -> user.getName() + "用户").collect(Collectors.toList());
3. flatMap(Function<T, Stream<R>> mapper)：将每个元素映射为一个 Stream，并将所有 Stream 的元素合并为一个 Stream。
userList.stream().flatMap(user -> Arrays.stream(user.getCity().split(","))).forEach(System.out::println);

map：对流中每一个元素进行处理
flatMap：流扁平化，让你把一个流中的“每个值”都换成另一个流，然后把所有的流连接起来成为一个流 
本质区别：map是对一级元素进行操作，flatmap是对二级元素操作map返回一个值；flatmap返回一个流，多个值

4. distinct()：去除重复的元素。
userList.stream().map(User::getCity).distinct().collect(Collectors.toList());
5. sorted()：对元素进行排序。
userList.stream().sorted(Comparator.comparing(User::getName).reversed()).collect(Collectors.toList()).forEach(System.out::println);
6. limit(long maxSize)：限制 Stream 的大小。
userList.stream().limit(5).collect(Collectors.toList()).forEach(System.out::println);
7. skip(long n)：跳过前 n 个元素。
userList.stream().skip(7).collect(Collectors.toList()).forEach(System.out::println);
8. peek():对元素进行遍历处理
//每个用户ID加1输出
userList.stream().peek(user -> user.setId(user.getId()+1)).forEach(System.out::println);

---------------------终端操作符-----------------------------------------------------------------
终端操作符：Stream流执行完终端操作之后，无法再执行其他动作，否则会报状态异常，提示该流已经被执行操作或者被关闭，
想要再次执行操作必须重新创建Stream流。一个流有且只能有一个终端操作，当这个操作执行后，流就被关闭了，无法再被操作，
因此一个流只能被遍历一次，若想在遍历需要通过源数据在生成流。

9. forEach(Consumer<T> action)：对每个元素执行指定的操作。
userList.stream().forEach(user -> System.out.println(user));
userList.stream().filter(user -> "上海".equals(user.getCity())).forEach(System.out::println);
10. collect(Collector<T, A, R> collector)：收集器，将流转换为其他形式。
Set set = userList.stream().collect(Collectors.toSet());
List list = userList.stream().collect(Collectors.toList());
11. findFirst():返回第一个元素
User firstUser = userList.stream().findFirst().get();
User firstUser1 = userList.stream().filter(user -> "上海".equals(user.getCity())).findFirst().get();        
12. findAny():返回当前流中的任意元素
User findUser = userList.stream().findAny().get();
User findUser1 = userList.stream().filter(user -> "上海".equals(user.getCity())).findAny().get();
13. count():返回流中元素总数
long count = userList.stream().filter(user -> user.getAge() > 20).count();		
14. sum():求和
int sum = userList.stream().mapToInt(User::getId).sum();
15. max():最大值
int max = userList.stream().max(Comparator.comparingInt(User::getId)).get().getId();
16. min():最小值
int min = userList.stream().min(Comparator.comparingInt(User::getId)).get().getId();
17. anyMatch():检查是否至少匹配一个元素，返回boolean
boolean matchAny = userList.stream().anyMatch(user -> "北京".equals(user.getCity()));
18. allMatch():检查是否匹配所有元素，返回boolean
boolean matchAll = userList.stream().allMatch(user -> "北京".equals(user.getCity()));
19. noneMatch():检查是否没有匹配所有元素，返回boolean
boolean nonaMatch = userList.stream().allMatch(user -> "云南".equals(user.getCity()));
20.reduce():可以将流中元素反复结合起来，得到一个值
Optional reduce = userList.stream().reduce((user, user2) -> {
    return user;
});


		
通过使用这些函数，可以简化代码、提高效率，并且使代码更加易读和可维护。

Java反射：
反射是作为动态语言的关键，反射机制允许程序在执行期借助于Reflection API取得任何类的内部信息，并能直接操作任意对象的内部属性和方法。

动态语言和静态语言概念：
动态类型语言：动态类型语言是指在运行期间才去做数据类型检查的语言，也就是说，在用动态类型的语言编程时，永远也不用给任何变量指定数据类型（变量使用之前不需要类型声明），该语言会在你第一次赋值给变量时，在内部将数据类型记录下来。
Python 和 Ruby 就是一种典型的动态类型语言，其他的各种脚本语言如 JavaScript 、Shell也属于动态类型语言。
静态类型语言：静态类型语言与动态类型语言刚好相反，它的数据类型是在编译其间检查的，也就是说在写程序时要声明所有变量的数据类型，C/C++ 是静态类型语言的典型代表，其他的静态类型语言还有 C#、JAVA 、golang等。
总结：静态类型和动态类型的本质区别在于：变量的数据类型确定的时机不同，前者在运行时根据变量值确定；后者在编译时根据声明类型确定。

Java反射概述：
>Java反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；
对于任意一个对象，都能够调用它的任意一个方法和属性；
这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。
>要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法。
所以先要获取到每一个字节码文件对应的Class类型的对象。
>比如之前在没有使用反射的时候，我们这里有一个类，如果我们想要调用里面的属性、方法等，
我们要先创建一个对象，才可以调用里面的属性等。
>类似的，我们如果使用反射，想要使用一个类的成员变量，方法，构造器等，我们就要先获取一个Class对象，
这个Class对象里面有类的成员变量，方法等信息，这样我们才可以进行相关的操作。
>正因为反射是在运行时获取类的信息，所以用反射去获取类的注解时只能获取到运行时的注解。

Class 类：反射的核心类，可以获取类的属性，方法等信息。
Field 类：Java.lang.reflec 包中的类，表示类的成员变量，可以用来获取和设置类之中的属性值。
Method 类： Java.lang.reflec 包中的类，表示类的方法，它可以用来获取类中的方法信息或 者执行方法。
Constructor 类： Java.lang.reflec 包中的类，表示类的构造方法。

getFields():获取当前运行时类及父类中声明为public访问权限的属性
getDeclaredFields()：获取当前运行时类中声明的所有属性（不包括父类）
getMethods():获取当前运行时类及其父类中声明为public的方法
				
Java JVM：
Java虚拟机(Jvm)是可运行Java代码的假想计算机。Java虚拟机包括一套字节码指令集、一组寄存器、一个栈、一个垃圾回收堆和一个存储方法域。
JVM让Java成为跨平台语言，Java有JVM从软件层面屏蔽了底层硬件、指令层面的细节让他兼容各种系统。

Java虚拟机主要由以下几个部分组成：
虚拟机栈。每个线程都在这个空间有一个私有的空间，每个线程会执行一个或多个方法，一个方法对应一个栈帧，栈帧包括局部变量表、操作数栈、动态链接、方法返回地址、附加信息等。
堆。所有线程共享的内存区域，用于存放对象实例和数组。
方法区。用于存放已被虚拟机加载的类信息、常量、静态变量等数据。
程序计数器。用于保存当前线程所执行的字节码指令的行号。

JVM的原理：				
Java源文件，通过编译器，能够生产相应的.Class文件，也就是字节码文件，而字节码文件又通过Java虚拟机中的解释器，
也就是前面所有的Java虚拟机中的字节码指令集编译成特定机器上的机器码
实现步骤：
1.Java源文件—->编译器—->字节码文件
2.字节码文件—->Jvm—->机器码

每一种平台的解释器是不同的，但是实现的虚拟机是相同的。这也就是Java为什么能够跨平台的原因
当一个程序从开始运行一个程序，这时虚拟机就开始实例化了。多个程序启动就会存在多个虚拟机实例。
程序退出或者关闭。则虚拟机实例消亡。多个虚拟机实例之间数据不能共享。				



区别于其他后端语言，C++在计算机上的运行原理与Java完全不同。C++程序是通过编译和链接过程转换为可执行程序后运行的。

1.首先，C++源代码被编译器转换成机器码，并链接成一个可执行文件。这个过程包括将源代码翻译成汇编语言，
然后将汇编语言转换为机器语言。链接器则将这个可执行文件与系统库和其他必要的库文件链接在一起，形成一个完整的程序。
2.当程序被执行时，操作系统会将程序加载到内存中，创建一个进程，并分配给该进程一些系统资源，如内存、文件、设备等。
程序中的代码会在CPU上运行，并按照程序员的指令执行各种操作。
3.在程序的运行过程中，操作系统会管理程序的执行，包括任务调度、内存管理、文件系统等方面。
程序运行结束后，操作系统会将程序的状态保存下来，并释放分配给该进程的资源。

总之，从计算机底层的角度来看，C++程序的运行过程包括编译、链接、加载、执行和退出等阶段，需要操作系统和硬件的支持。



Java在运行原理上与C++的对比：
相比于Java，C++没有虚拟机和垃圾回收机制，这使得C++在运行时的确更加复杂。

首先，C++需要手动管理内存，这意味着开发人员需要手动分配和释放内存。如果没有正确地管理内存，可能会导致内存泄漏、野指针等问题，
这会增加程序的复杂性和运行风险。

其次，C++没有类似于Java的垃圾回收机制，因此需要开发人员手动管理对象的生命周期，以避免内存泄漏和悬挂指针等问题。
这需要更加精细的内存管理技巧和经验，增加了程序的复杂性和开发难度。

此外，C++支持多种编程范式和语言特性，如面向对象编程、泛型编程、函数式编程等，这使得C++程序可能更加灵活和复杂。

总的来说，虽然C++没有虚拟机和垃圾回收机制，但它提供了更低级别的控制和更高的性能，同时也需要更严格的内存管理和更多的编程技巧。
因此，在运行原理上，C++的确比Java更加复杂。


python的运行原理与Java也不相同：
从计算机底层的角度来说，Python运行的过程可以大致分为以下几个步骤：

编译：当Python代码被执行时，首先会经过一个编译的过程。Python的编译过程与传统的编译过程有些不同，
它并不是将代码直接编译成机器码，而是将代码编译成一种叫做字节码（bytecode）的形式。
这些字节码是平台无关的，可以在任何支持Python的平台上运行。这个编译过程是由Python解释器自动完成的，无需程序员手动干预。

解释执行：接下来，编译后的字节码会被加载到Python解释器中。Python解释器会按照字节码的指令顺序逐条解释执行。
在这个过程中，解释器会根据字节码指令调用相应的Python函数或对象方法，完成代码的逻辑执行。

对象引用：Python是一种动态类型语言，变量可以引用任何类型的对象。
在解释执行过程中，当一个变量被引用时，解释器会根据变量的类型和值，动态地创建相应的对象。
这些对象可以是Python内置类型（如整数、字符串、列表等），也可以是用户自定义的类型。

垃圾回收：为了防止内存泄漏，Python使用了垃圾回收机制。当一个对象不再被引用时，垃圾回收器会自动将其标记为可回收对象，
并在适当的时候释放其内存空间。

交互式模式：Python还支持交互式模式，可以在命令行中直接执行Python代码。当在交互式模式下输入代码时，解释器会立即执行并输出结果。

总之，Python的运行过程可以看作是将源代码编译成字节码，然后由解释器逐条解释执行字节码的过程。
在这个过程中，解释器还会处理变量引用、垃圾回收等操作，以保证程序的正常运行。



Java与python对比，在运行上的区别：
Python是一种解释性语言，它的解释器会在运行时解释执行代码。虽然Python解释器可以通过字节码进行编译，
但是在运行时仍然需要进行解释，这可能会影响Python的运行速度。

相反，Java是一种编译性语言，它的代码在编译时会生成与平台相关的机器码，因此Java的执行速度通常比Python更快。

然而，在实际应用中，Python和Java的运行速度差异可能并不明显。对于一些需要快速开发迭代的项目，Python的灵活性和易用性可能会更受欢迎。而对于一些需要更高运行效率的项目，Java可能会更适合。

JVM的结构：
JVM运行时数据区：

方法区（Method Area）
方法区是所有线程共享的内存区域，它用于存储已被Java虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。
它有个别命叫Non-Heap（非堆）。当方法区无法满足内存分配需求时，抛出OutOfMemoryError异常。

Java堆（Java Heap）
java堆是java虚拟机所管理的内存中最大的一块，是被所有线程共享的一块内存区域，在虚拟机启动时创建。
此内存区域的唯一目的就是存放对象实例。
在Java虚拟机规范中的描述是：所有的对象实例以及数组都要在堆上分配。
java堆是垃圾收集器管理的主要区域，因此也被成为“GC堆”。
从内存回收角度来看java堆可分为：新生代和老生代。


从内存分配的角度看，线程共享的Java堆中可能划分出多个线程私有的分配缓冲区。
无论怎么划分，都与存放内容无关，无论哪个区域，存储的都是对象实例，进一步的划分都是为了更好的回收内存，或者更快的分配内存。
根据Java虚拟机规范的规定，java堆可以处于物理上不连续的内存空间中。当前主流的虚拟机都是可扩展的（通过 -Xmx 和 -Xms 控制）。
如果堆中没有内存可以完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。


程序计数器（Program Counter Register）
程序计数器是一块较小的内存空间，它可以看作是：保存当前线程所正在执行的字节码指令的地址(行号)
由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，一个处理器都只会执行一条线程中的指令。
因此，为了线程切换后能恢复到正确的执行位置，每条线程都有一个独立的程序计数器，各个线程之间计数器互不影响，独立存储。
称之为“线程私有”的内存。程序计数器内存区域是虚拟机中唯一没有规定OutOfMemoryError情况的区域。


Java虚拟机栈（Java Virtual Machine Stacks）
java虚拟机是线程私有的，它的生命周期和线程相同。
虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。
解释：每虚拟机栈中是有单位的，单位就是栈帧，一个方法一个栈帧。一个栈帧中他又要存储，局部变量，操作数栈，动态链接，出口等。


JVM内存结构：
直接内存（Direct Memory）：
直接内存不是虚拟机运行时数据区的一部分，也不是java虚拟机规范中定义的内存区域。
但是既然是内存，肯定还是受本机总内存（包括RAM以及SWAP区或者分页文件）大小以及处理器寻址空间的限制。

在JDK1.4 中新加入了NIO(New Input/Output)类，引入了一种基于通道(Channel)与缓冲区（Buffer）的I/O 方式，
它可以使用native 函数库直接分配堆外内存，然后通脱一个存储在Java堆中的DirectByteBuffer 对象作为这块内存的引用进行操作。
这样能在一些场景中显著提高性能，因为避免了在Java堆和Native（本地）堆中来回复制数据。

直接内存与堆内存的区别：
直接内存申请空间耗费很高的性能，堆内存申请空间耗费比较低
直接内存的IO读写的性能要优于堆内存，在多次读写操作的情况相差非常明显

JVM的垃圾回收机制：
垃圾回收机制简称GC

GC主要用于Java堆的管理。Java 中的堆是 JVM 所管理的最大的一块内存空间，主要用于存放各种类的实例对象。

关于什么是垃圾回收机制：
程序在运行过程中，会产生大量的内存垃圾（一些没有引用指向的内存对象都属于内存垃圾，因为这些对象已经无法访问，程序用不了它们了，
对程序而言它们已经死亡），为了确保程序运行时的性能，java虚拟机在程序运行的过程中不断地进行自动的垃圾回收（GC）。

GC是不定时去堆内存中清理不可达对象。不可达的对象并不会马上就会直接回收， 垃圾收集器在一个Java程序中的执行是自动的，
不能强制执行清楚那个对象，即使程序员能明确地判断出有一块内存已经无用了，是应该回收的，程序员也不能强制垃圾收集器回收该内存块。
程序员唯一能做的就是通过调用System.gc 方法来"建议"执行垃圾收集器，但是他是否执行，什么时候执行却都是不可知的。
这也是垃圾收集器的最主要的缺点。当然相对于它给程序员带来的巨大方便性而言，这个缺点是瑕不掩瑜的。

手动执行GC：System.gc(); 

finalize方法作用：
-finalize()方法是在每次执行GC操作之前时会调用的方法，可以用它做必要的清理工作。
-它是在Object类中定义的，因此所有的类都继承了它。子类覆盖finalize()方法以整理系统资源或者执行其他清理工作。
finalize()方法是在垃圾收集器删除对象之前对这个对象调用的。

新生代、老年代、永久代(方法区)的区别：
-Java 中的堆是 JVM 所管理的最大的一块内存空间，主要用于存放各种类的实例对象。
-在 Java 中，堆被划分成两个不同的区域：新生代 ( Young )、老年代 ( Old )。
-老年代就一个区域。新生代 ( Young ) 又被划分为三个区域：Eden、From Survivor、To Survivor。
-这样划分的目的是为了使 JVM 能够更好的管理堆内存中的对象，包括内存的分配以及回收。

-默认的，新生代 ( Young ) 与老年代 ( Old ) 的比例的值为 1:2 ( 该值可以通过参数 –XX:NewRatio 来指定 )，
即：新生代 ( Young ) = 1/3 的堆空间大小。老年代 ( Old ) = 2/3 的堆空间大小。
-其中，新生代 ( Young ) 被细分为 Eden 和 两个 Survivor 区域，这两个 Survivor 区域分别被命名为 From Survivor 和 ToSurvivor ，以示区分。
-默认的，Edem ：From Survivor ： To Survivor = 8 : 1 : 1 ( 可以通过参数 –XX:SurvivorRatio 来设定 )，
即： Eden = 8/10 的新生代空间大小，From Survivor = To Survivor = 1/10 的新生代空间大小。

-JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块 Survivor 区域是空闲着的。
-因此，新生代实际可用的内存空间为 9/10 ( 即90% )的新生代空间。
-永久代就是JVM的方法区。在这里都是放着一些被虚拟机加载的类信息，静态变量，常量等数据。
这个区中的东西比老年代和新生代更不容易回收。

GC算法：
Minor GC、Major GC、Full GC区别及触发条件：
-Minor GC是新生代GC，指的是发生在新生代的垃圾收集动作。由于java对象大都是朝生夕死的，所以Minor GC非常频繁，一般回收速度也比较快。
-Major GC是老年代GC，指的是发生在老年代的GC，通常执行Major GC会连着Minor GC一起执行。Major GC的速度要比Minor GC慢的多。
-Full GC是清理整个堆空间，包括年轻代和老年代

Minor GC 触发条件一般为：

eden区满时，触发MinorGC。即申请一个对象时，发现eden区不够用，则触发一次MinorGC。
​ 新创建的对象大小 > Eden所剩空间
Major GC和Full GC 触发条件一般为：
Major GC通常是跟full GC是等价的

每次晋升到老年代的对象平均大小>老年代剩余空间
MinorGC后存活的对象超过了老年代剩余空间
永久代空间不足
执行System.gc()
CMS GC异常
堆内存分配很大的对象

JVM垃圾收集器：

垃圾收集器是垃圾回收算法（引用计数法、标记清楚法、标记整理法、复制算法）的具体实现，
不同垃圾收集器、不同版本的JVM所提供的垃圾收集器可能会有很在差别。

1.Serial 收集器：新生代。发展历史最悠久的收集器。它是一个单线程收集器，它只会使用一个 CPU 或者线程去完成垃圾收集工作，而且在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。
特点：

新生代收集器，使用复制算法收集新生代垃圾。
单线程的收集器，GC工作时，其它所有线程都将停止工作。
简单高效，适合单 CPU 环境。单线程没有线程交互的开销，因此拥有最高的单线程收集效率。


2.ParNew 收集器：新生代。Serial 的多线程版本，即同时启动多个线程去进行垃圾收集。
特点：

新生代收集器。ParNew垃圾收集器是Serial收集器的多线程版本，采用复制算法。
除了多线程外，其余的行为、特点和Serial收集器一样。
只有它能与 CMS 收集器配合使用。
但在单个CPU环境中，不比Serail收集器好，多线程使用它比较好。


3.Parallel Scavenge 收集器：新生代。和 ParNew 的关注点不一样，该收集器更关注吞吐量，尽快地完成计算任务。
特点：

新生代收集器。
采用复制算法。
多线程收集。
与ParNew 不同的是：高吞吐量为目标，（减少垃圾收集时间，让用户代码获得更长的运行时间）


4.Serial Old 收集器：Serial 的老年代版本，使用标记 - 整理算法。
特点：

老年代收集器， 采用"标记-整理"算法。
单线程收集。

5.Parallnel old 收集器，多线程：Parallel 的老年代版本，使用标记 - 整理算法。
特点：

针对老年代。
采用"标记-整理"算法。
多线程收集。
但在单个CPU环境中，不比Serial Old收集器好，多线程使用它比较好。

6.CMS 收集器：老年代。是一种以获取最短回收停顿时间为目标的收集器，适用于互联网站或者 B/S 系统的服务端上。
特点：

针对老年代，采用标记-清楚法清除垃圾；
基于"标记-清除"算法(不进行压缩操作，产生内存碎片)；
以获取最短回收停顿时间为目标；
并发收集、低停顿；
CMS收集器有3个明显的缺点：1.对CPU资源非常敏感、2.无法处理浮动垃圾，可能出现"Concurrent Mode Failure"失败、3.产生大量内存碎片
垃圾收集线程与用户线程（基本上）可以同时工作

7.G1 收集器：分代收集器。当今收集器技术发展最前沿成果之一，是一款面向服务端应用的垃圾收集器。G1可以说是CMS的终极改进版，解决了CMS内存碎片、更多的内存空间登问题。虽然流程与CMS比较相似，但底层的原理已是完全不同。
特点：

能充分利用多CPU、多核环境下的硬件优势；
可以并行来缩短(Stop The World)停顿时间；
也可以并发让垃圾收集与用户程序同时进行；
分代收集，收集范围包括新生代和老年代
能独立管理整个GC堆（新生代和老年代），而不需要与其他收集器搭配；
能够采用不同方式处理不同时期的对象；
应用场景可以面向服务端应用，针对具有大内存、多处理器的机器；
采用标记-整理 + 复制算法来回收垃圾



Java程序通过设计模式、数据结构与算法等技术组成框架

设计模式：
设计模式的七大原则
开闭原则：对扩展开放、对修改关闭。
单一指责原则：一个类只做一件事。
依赖倒转原则：类似于ioc，采用接口编程。
迪米特原则：高内聚，低耦合。
接口隔离原则：应该使用多个接口，而不是用单一的总接口。
合成复用原则：尽量使用对象组合，而不是继承来达到复用目的。
里氏替换原则：子类可以扩展父类的功能，但不能改变原有的功能。

Java的23种设计模式：

1、创建型-工厂方法模式：
工厂方法模式分为三种：

（1）简单工厂模式：

建立一个工厂类，并定义一个接口对实现了同一接口的产品类进行创建。

（2）工厂方法模式：

工厂方法模式是对简单工厂模式的改进，简单工厂的缺陷在于不符合“开闭原则”，每次添加新产品类就需要修改工厂类，不利于系统的扩展维护。而工厂方法将工厂抽象化，并定义一个创建对象的接口。每增加新产品，只需增加该产品以及对应的具体实现工厂类，由具体工厂类决定要实例化的产品是哪个，将对象的创建与实例化延迟到子类，这样工厂的设计就符合“开闭原则”了，扩展时不必去修改原来的代码。UML关系图如下：

（3）静态工厂方法模式：

静态工厂模式是将工厂方法模式里的方法置为静态的，不需要创建实例，直接调用即可。

// 抽象产品类
public interface class Car {
    public void run();
    public void stop();
}
 
//两个具体实现类
public class Benz implements Car {
    public void run() {
        System.out.println("Benz开始启动了。。。。。");
    }
 
    public void stop() {
        System.out.println("Benz停车了。。。。。");
    }
}
public class Ford implements Car {
    public void run() {
        System.out.println("Ford开始启动了。。。");
    }
 
    public void stop() {
        System.out.println("Ford停车了。。。。");
    }
}
 
// 工厂类
public class Factory {
    public static Car getCarInstance(String type) {
        Car c = null;
        if ("Benz".equals(type)) {
            c = new Benz();
        }
        if ("Ford".equals(type)) {
            c = new Ford();
        }
        return c;
    }
}
//测试类
public class Test {
    public static void main(String[] args) {
        Car c = Factory.getCarInstance("Benz");
        if (c != null) {
            c.run();
            c.stop();
        } else {
            System.out.println("造不了这种汽车。。。");
        }
    }
}


2、创建型-抽象工厂模式：
抽象工厂模式主要用于创建相关对象的家族。当一个产品族中需要被设计在一起工作时，
通过抽象工厂模式，能够保证客户端始终只使用同一个产品族中的对象；并且通过隔离具体类的生成，
使得客户端不需要明确指定具体生成类；所有的具体工厂都实现了抽象工厂中定义的公共接口，
因此只需要改变具体工厂的实例，就可以在某种程度上改变整个软件系统的行为。
但该模式的缺点在于添加新的行为时比较麻烦，如果需要添加一个新产品族对象时，
需要更改接口及其下所有子类，这必然会带来很大的麻烦。

	//抽象类
	public interface Sender {
		public void Send();
	}
	
	//两个具体实现类
    public class MailSender implements Sender {
    	@Override
    	public void Send() {
    		System.out.println("this is mailsender!");
    	}
    }
    public class MailSender implements Sender {
    	@Override
    	public void Send() {
    		System.out.println("this is mailsender!");
    	}
    }
    
    //提供的接口类
    public interface Provider {
		public Sender produce();
	}

	//两个工厂类
    public class SendMailFactory implements Provider {
    	@Override
    	public Sender produce(){
    		return new MailSender();
    	}
    }
    public class SendSmsFactory implements Provider{
    	@Override
    	public Sender produce() {
    		return new SmsSender();
    	}
    }

	//测试类
	public class Test {
		public static void main(String[] args) {
			Provider provider = new SendMailFactory();
			Sender sender = provider.produce();
			sender.Send();
		}
	}
        





3、创建型-建造者模式：
建造者模式将复杂产品的创建步骤分解在在不同的方法中，使得创建过程更加清晰，从而更精确控制复杂对象的产生过程；
通过隔离复杂对象的构建与使用，也就是将产品的创建与产品本身分离开来，使得同样的构建过程可以创建不同的对象；
并且每个具体建造者都相互独立，因此可以很方便地替换具体建造者或增加新的具体建造者，
用户使用不同的具体建造者即可得到不同的产品对象。

建造者模式结构组成
Product: 表示被构造的复杂对象,其中包含需要构建的部件属性。
Builder: 创建一个产品对象的各个部件指定抽象接口。
ConcreteBuilder： 实现Builder的接口以构造和装配该产品的各个部件，定义并明确它所创建的表示。
Director： 调用具体建造者角色以创建产品对象。

	//抽象类
	public interface Sender {
		public void Send();
	}
	
	//两个具体实现类
    public class MailSender implements Sender {
    	@Override
    	public void Send() {
    		System.out.println("this is mailsender!");
    	}
    }
    public class MailSender implements Sender {
    	@Override
    	public void Send() {
    		System.out.println("this is mailsender!");
    	}
    }
    
    public class Builder {
		private List<Sender> list = new ArrayList<Sender>();
	
		public void produceMailSender(int count){
			for(int i=0; i<count; i++){
				list.add(new MailSender());
			}
		}
	
		public void produceSmsSender(int count){
			for(int i=0; i<count; i++){
				list.add(new SmsSender());
			}
		}
	}

	//测试类
	public class Test {
		public static void main(String[] args) {
			Builder builder = new Builder();
			builder.produceMailSender(10);
		}
	}


4、创建型-单例模式：
        单例模式可以确保系统中某个类只有一个实例，该类自行实例化并向整个系统提供这个实例的公共访问点，除了该公共访问点，不能通过其他途径访问该实例。单例模式的优点在于：
	>系统中只存在一个共用的实例对象，无需频繁创建和销毁对象，节约了系统资源，提高系统的性能
	>可以严格控制客户怎么样以及何时访问单例对象。
	>单例模式的写法有好几种，主要有三种：懒汉式单例、饿汉式单例、登记式单例。

饿汉式单例：
class Bank {
    private Bank(){

    }
    private static Bank instance = new Bank();

    private static Bank getInstance(){
        return instance;
    }
}

懒汉式单例：
class Order{
    private Order(){

    }
    private static Order instance = null;

    public static Order getInstance(){
            if(instance == null){
            	instance = new Order();
        	  }
        return instance;
    }
}

区分饿汉式单例和懒汉式单例：
饿汉式：好处：线程安全 坏处：对象加载时间过长
懒汉式：好处：延迟对象的创建 坏处：线程不安全

登记式单例：
import java.util.HashMap;

import java.util.Map;

/**

* 登记式单例实际上维护的是一组单例类的实例，将这些实例存储到一个Map(登记簿)

* 中，对于已经登记过的单例，则从工厂直接返回，对于没有登记的，则先登记，而后

* 返回

* @author pp

*

*/

public class RegSingleton {

/**

* 登记簿，用来存放所有登记的实例

*/

private static Map map = new HashMap();

//在类加载时添加一个实例到登记簿

static{

RegSingleton singleton = new RegSingleton();

map.put(singleton.getClass().getName(), singleton);//运用了反射

}

/**

* 受保护的默认构造方法

*/

protected RegSingleton() {

}

/**

* 静态工厂方法，返回指定登记对象的唯一实例

* 对于已经登记的直接取出返回，对于还未登记的先登记，然后取出返回

*

*/

public static RegSingleton getInstance(String name){

if(name==null){

name="RegSingleton";

}

if(map.get(name)==null){

try {

map.put(name, (RegSingleton) Class.forName(name).newInstance());

} catch (Exception e) {

e.printStackTrace();

}

}

return map.get(name);

}

/**

* 一個示意性的商业方法

*/

public String about(){

return "Hello,I am RegSingleton";

}

}


5、创建型-原型模式：
原型模式也是用于对象的创建，通过将一个对象作为原型，对其进行复制克隆，产生一个与源对象类似的新对象。
原型模式包含如下角色：
抽象原型类：规定了具体原型对象必须实现的的 clone() 方法。
具体原型类：实现抽象原型类的 clone() 方法，它是可被复制的对象。
访问类：使用具体原型类中的 clone() 方法来复制新的对象。


 在 Java 中，原型模式的核心是就是原型类 Prototype，Prototype 类需要具备以下两个条件：

实现 Cloneable 接口：
重写 Object 类中的 clone() 方法，用于返回对象的拷贝；
Object 类中的 clone() 方法默认是浅拷贝，如果想要深拷贝对象，则需要在 clone() 方法中自定义自己的复制逻辑。

@Data
@AllArgsConstructor
@NoArgsConstructor
public class Student implements Cloneable {
    private String name;
    private String sex;
    private Integer age;
    @Override
    protected Object clone() throws CloneNotSupportedException {
        return super.clone();
    }
 
    public static void main(String[] args) throws Exception{
        Student stu1 = new Student("张三", "男", 18);
        Student stu2 = (Student)stu1.clone();
        stu2.setName("李四");
        System.out.println(stu1);// Student(name=张三, sex=男, age=18)
        System.out.println(stu2);// Student(name=李四, sex=男, age=18)
    }
}

可以看到，把一个学生复制过来，只是改了姓名而已，其他属性完全一样没有改变，
需要注意的是，一定要在被拷贝的对象上实现Cloneable接口，否则会抛出CloneNotSupportedException异常。


浅复制：将一个对象复制后，基本数据类型的变量会重新创建，而引用类型指向的还是原对象所指向的内存地址。

@Data
public class Clazz implements Cloneable {
    private String name;
    private Student student;
    @Override
    protected Object clone() throws CloneNotSupportedException {
        return super.clone();
    }
}
@Data
@AllArgsConstructor
@NoArgsConstructor
public class Student implements Serializable {
    private String name;
    private String sex;
    private Integer age;
}
 
    public static void main(String[] args) throws Exception{
        Clazz clazz1 = new Clazz();
        clazz1.setName("高三一班");
        Student stu1 = new Student("张三", "男", 18);
        clazz1.setStudent(stu1);
        System.out.println(clazz1); // Clazz(name=高三一班, student=Student(name=张三, sex=男, age=18))
        Clazz clazz2 = (Clazz)clazz1.clone();
        Student stu2 = clazz2.getStudent();
        stu2.setName("李四");
        System.out.println(clazz1); // Clazz(name=高三一班, student=Student(name=李四, sex=男, age=18))
        System.out.println(clazz2); // Clazz(name=高三一班, student=Student(name=李四, sex=男, age=18))
    }
	
可以看到，当修改了stu2的姓名时，stu1的姓名同样也被修改了，这说明stu1和stu2是同一个对象，这就是浅克隆的特点，
对具体原型类中的引用类型的属性进行引用的复制。同时，这也可能是浅克隆所带来的弊端，因为结合该例子的原意，
显然是想在班级中新增一名叫李四的学生，而非让所有的学生都改名叫李四，于是我们这里就要使用深克隆。
	
深复制：将一个对象复制后，不论是基本数据类型还有引用类型，都是重新创建的。
        使用原型模式进行创建对象不仅简化对象的创建步骤，还比 new 方式创建对象的性能要好的多，
		因为 Object 类的 clone() 方法是一个本地方法，直接操作内存中的二进制流，特别是复制大对象时，性能的差别非常明显；

		@Data
public class Clazz implements Cloneable, Serializable {
    private String name;
    private Student student;
    @Override
    protected Object clone() throws CloneNotSupportedException {
        return super.clone();
    }
 
    protected Object deepClone() throws IOException, ClassNotFoundException {
        ByteArrayOutputStream bos = new ByteArrayOutputStream();
        ObjectOutputStream oos = new ObjectOutputStream(bos);
        oos.writeObject(this);
        ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray());
        ObjectInputStream ois = new ObjectInputStream(bis);
        return ois.readObject();
    }
}
 
    public static void main(String[] args) throws Exception{
        Clazz clazz1 = new Clazz();
        clazz1.setName("高三一班");
        Student stu1 = new Student("张三", "男", 18);
        clazz1.setStudent(stu1);
        Clazz clazz3 = (Clazz)clazz1.deepClone();
        Student stu3 = clazz3.getStudent();
        stu3.setName("王五");
        System.out.println(clazz1); // Clazz(name=高三一班, student=Student(name=张三, sex=男, age=18))
        System.out.println(clazz3); // Clazz(name=高三一班, student=Student(name=王五, sex=男, age=18))
    }

可以看到，当修改了stu3的姓名时，stu1的姓名并没有被修改了，这说明stu3和stu1已经是不同的对象了，
说明Clazz中的Student也被克隆了，不再指向原有对象地址，这就是深克隆。
这里需要注意的是，Clazz类和Student类都需要实现Serializable接口，否则会抛出NotSerializableException异常。
	        

6、结构型-适配器模式：
适配器模式主要用于将一个类或者接口转化成客户端希望的格式，使得原本不兼容的类可以在一起工作，
将目标类和适配者类解耦；同时也符合“开闭原则”，可以在不修改原代码的基础上增加新的适配器类；
将具体的实现封装在适配者类中，对于客户端类来说是透明的，而且提高了适配者的复用性，
但是缺点在于更换适配器的实现过程比较复杂。

所以，适配器模式比较适合以下场景：
（1）系统需要使用现有的类，而这些类的接口不符合系统的接口。
（2）使用第三方组件，组件接口定义和自己定义的不同，不希望修改自己的接口，但是要使用第三方组件接口的功能。
下面有个非常形象的例子很好地说明了什么是适配器模式：

适配器模式（Adapter）包含以下主要角色：

目标（Target）接口：当前系统业务所期待的接口，它可以是抽象类或接口。
适配者（Adaptee）类：它是被访问和适配的现存组件库中的组件接口。
适配器（Adapter）类：它是一个转换器，通过继承或引用适配者的对象，把适配者接口转换成目标接口，让客户按目标接口的格式访问适配者。

// 适配者 220V电压
public class AC220 {
    public int output() {
        System.out.println("输出220V交流电");
        return 220;
    }
}
// 目标 5V
public interface DC5 {
    public int output5();
}
// 适配器类（电源适配器）
public class PowerAdapter extends AC220 implements DC5 {
    @Override
    public int output5() {
        int output220 = super.output();
        int output5 = output220 / 44;
        System.out.println(output220 + "V适配转换成" + output5 + "V");
        return output5;
    }
}
    // 测试
    public static void main(String[] args) {
        PowerAdapter powerAdapter = new PowerAdapter();
        // 输出220V交流电
        powerAdapter.output();
        // 输出220V交流电
        // 220V适配转换成5V
        powerAdapter.output5();
    }

通过上面代码例子可以看出，类适配器有一个很明显的缺点，就是违背了合成复用原则。
结合上面的例子，假如我不是220V的电压了，是380V电压呢？那就要多建一个380V电压的适配器了。
同理，由于Java是单继承的原因，如果不断的新增适配者，那么就要无限的新增适配器，于是就有了对象适配器。

对象适配器：
// 电源接口
public interface Power {
    int output();
}
// 适配者 220V电压
public class AC220 implements Power {
    @Override
    public int output() {
        System.out.println("输出220V交流电");
        return 220;
    }
}
// 目标 5V
public interface DC5 {
    public int output5();
}
@AllArgsConstructor
public class PowerAdapter implements DC5 {
 
    // 适配者
    private Power power;
    @Override
    public int output5() {
        int output220 = power.output();
        int output5 = output220 / 44;
        System.out.println(output220 + "V适配转换成" + output5 + "V");
        return output5;
    }
}
    // 测试
    public static void main(String[] args) {
        DC5 powerAdapter = new PowerAdapter(new AC220());
        // 输出220V交流电
        // 220V适配转换成5V
        powerAdapter.output5();
    }
	
可以看到，上面代码中，只实现了目标接口，并没有继承适配者，而是将适配者类实现适配者接口，
在适配器中引入适配者接口，当我们需要使用不同的适配者通过适配器进行转换时，就无需再新建适配器类了，
如上面例子，假如我需要380V的电源转换成5V的，那么客户端只需要调用适配器时传入380V电源的类即可，
就无需再新建一个380V电源的适配器了
（PS：上述逻辑代码中output220 / 44请忽略，可以根据实际情况编写实际的通用逻辑代码）。

接口适配器：
接口适配器主要是解决类臃肿的问题，我们可以把所有相近的适配模式的方法都放到同一个接口里面，去实现所有方法，
当客户端需要哪个方法直接调用哪个方法即可。如上面例子所示，我们只是转换成了5V电压，
那假如我要转换成12V，24V，30V...呢？那按照上面的写法就需要新建12V，24V，30V...的接口，这样就会导致类过于多了。
那么我们就可以把5V，12V，24V，30V...这些转换方法，通通都写到一个接口里去，
这样当我们需要转换哪种就直接调用哪种即可。

// 这里例子 输出不同直流电接口
public interface DC {
    int output5();
    int output12();
    int output24();
    int output30();
}
// 适配器类（电源适配器）
@AllArgsConstructor
public class PowerAdapter implements DC {
    private Power power;
    @Override
    public int output5() {
        // 具体实现逻辑
        return 5;
    }
    @Override
    public int output12() {
        // 具体实现逻辑
        return 12;
    }
    @Override
    public int output24() {
        // 具体实现逻辑
        return 24;
    }
    @Override
    public int output30() {
        // 具体实现逻辑
        return 30;
    }
}

7、结构型-装饰器模式：
装饰器模式可以动态给对象添加一些额外的职责从而实现功能的拓展，在运行时选择不同的装饰器，从而实现不同的行为；
比使用继承更加灵活，通过对不同的装饰类进行排列组合，创造出很多不同行为，得到功能更为强大的对象；
符合“开闭原则”，被装饰类与装饰类独立变化，用户可以根据需要增加新的装饰类和被装饰类，在使用时再对其进行组合，原有代码无须改变。
但是装饰器模式也存在缺点，首先会产生很多的小对象，增加了系统的复杂性，
第二是排错比较困难，对于多次装饰的对象，调试时寻找错误可能需要逐级排查，较为烦琐。

装饰（Decorator）模式中的角色：

抽象构件（Component）角色 ：定义一个抽象接口以规范准备接收附加责任的对象。
具体构件（Concrete Component）角色 ：实现抽象构件，通过装饰角色为其添加一些职责。
抽象装饰（Decorator）角色 ： 继承或实现抽象构件，并包含具体构件的实例，可以通过其子类扩展具体构件的功能。
具体装饰（ConcreteDecorator）角色 ：实现抽象装饰的相关方法，并给具体构件对象添加附加的责任。

// 炒饭类
public class FriedRice {
    String getDesc() {
        return "炒饭";
    }
    Integer getPrice() {
        return 5;
    }
}
// 配料表
public abstract class Ingredients extends FriedRice{
    private FriedRice friedRice;
    public Ingredients(FriedRice friedRice) {
        this.friedRice = friedRice;
    }
    String getDesc() {
        return this.friedRice.getDesc();
    }
    Integer getPrice() {
        return this.friedRice.getPrice();
    }
}
// 鸡蛋配料
public class Egg extends Ingredients {
    public Egg(FriedRice friedRice) {
        super(friedRice);
    }
    String getDesc() {
        return super.getDesc() + "+鸡蛋";
    }
    Integer getPrice() {
        return super.getPrice() + 2;
    }
}
// 火腿配料
public class Ham extends Ingredients {
    public Ham(FriedRice friedRice){
        super(friedRice);
    }
    String getDesc() {
        return super.getDesc() + "+火腿";
    }
    Integer getPrice() {
        return super.getPrice() + 3;
    }
}
    // 测试方法
    public static void main(String[] args) {
        FriedRice friedRice = new FriedRice();
        System.out.println(friedRice.getDesc() + friedRice.getPrice() + "元"); // 炒饭5元
        friedRice = new Egg(friedRice);
        System.out.println(friedRice.getDesc() + friedRice.getPrice() + "元"); // 炒饭+鸡蛋7元
        friedRice = new Egg(friedRice);
        System.out.println(friedRice.getDesc() + friedRice.getPrice() + "元");// 炒饭+鸡蛋+鸡蛋9元
        friedRice = new Ham(friedRice);
        System.out.println(friedRice.getDesc() + friedRice.getPrice() + "元");// 炒饭+鸡蛋+鸡蛋+火腿12元
    }

装饰器模式与代理模式对比：
装饰器模式就是一种特殊的代理模式。
装饰器模式强调自身的功能扩展，用自己说了算的透明扩展，可动态定制的扩展；代理模式强调代理过程的控制。
获取目标对象构建的地方不同，装饰者是从外界传递进来的，可以通过构造方法传递；静态代理是在代理类内部创建，以此来隐藏目标对象。

适用场景：
用于扩展一个类的功能或者给一个类添加附加职责。
动态的给一个对象添加功能，这些功能同样也可以再动态的撤销。

优点：
装饰器是继承的有力补充，比继承灵活，不改变原有对象的情况下动态地给一个对象扩展功能，即插即用。
通过使用不同装饰类以及这些装饰类的排列组合，可实现不同效果。
装饰器完全遵守开闭原则。

缺点：
会出现更多的代码，更多的类，增加程序的复杂性。
动态装饰时，多层装饰会更复杂。
	
8、结构型-代理模式：
代理模式的设计动机是通过代理对象来访问真实对象，通过建立一个对象代理类，
由代理对象控制原对象的引用，从而实现对真实对象的操作。在代理模式中，代理对象主要起到一个中介的作用，
用于协调与连接调用者(即客户端)和被调用者(即目标对象)，在一定程度上降低了系统的耦合度，同时也保护了目标对象。
但缺点是在调用者与被调用者之间增加了代理对象，可能会造成请求的处理速度变慢。

静态代理：静态代理就是指我们在给一个类扩展功能的时候，我们需要去书写一个静态的类，
相当于在之前的类上套了一层，这样我们就可以在不改变之前的类的前提下去对原有功能进行扩展，
静态代理需要代理对象和目标对象实现一样的接口。

// 火车站接口，有卖票功能
public interface TrainStation {
    void sellTickets();
}
// 广州火车站卖票
public class GuangzhouTrainStation implements TrainStation {
    @Override
    public void sellTickets() {
        System.out.println("广州火车站卖票啦");
    }
}
// 代售点卖票（代理类）
public class ProxyPoint implements TrainStation {
    // 目标对象（代理火车站售票）
    private GuangzhouTrainStation station = new GuangzhouTrainStation();
    @Override
    public void sellTickets() {
        System.out.println("代售加收5%手续费");
        station.sellTickets();
    }
    public static void main(String[] args) {
        ProxyPoint proxyPoint = new ProxyPoint();
        // 代售加收5%手续费
        // 广州火车站卖票啦
        proxyPoint.sellTickets();
    }
}
    // 测试
    public static void main(String[] args) {
        ProxyPoint proxyPoint = new ProxyPoint();
        // 代售加收5%手续费
        // 火车站卖票啦
        proxyPoint.sellTickets();
    }
	
动态代理：
代理类在代码运行时创建的代理称之为动态代理。
动态代理中代理类并不是预先在Java代码中定义好的，而是运行时由JVM动态生成，并且可以代理多个目标对象。	
// 火车站接口，有卖票功能
public interface TrainStation {
    void sellTickets();
}
// 广州火车站卖票
public class GuangzhouTrainStation implements TrainStation {
    @Override
    public void sellTickets() {
        System.out.println("广州火车站卖票啦");
    }
}
// 深圳火车站卖票
public class ShenzhenTrainStation implements TrainStation {
    @Override
    public void sellTickets() {
        System.out.println("深圳火车站卖票啦");
    }
}
// 代售点卖票（代理类）
public class ProxyPoint implements InvocationHandler {
    private TrainStation trainStation;
    public TrainStation getProxyObject(TrainStation trainStation) {
        this.trainStation = trainStation;
        Class<? extends TrainStation> clazz = trainStation.getClass();
        return (TrainStation) Proxy.newProxyInstance(clazz.getClassLoader(), clazz.getInterfaces(), this);
    }
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println("代售火车票收取5%手续费");
        return method.invoke(this.trainStation, args);
    }
}
    // 测试
    public static void main(String[] args) {
        ProxyPoint proxy = new ProxyPoint();
        TrainStation guangzhouTrainStation = proxy.getProxyObject(new GuangzhouTrainStation());
        // 代售火车票收取5%手续费
        // 广州火车站卖票啦
        guangzhouTrainStation.sellTickets();
        TrainStation shenzhenTrainStation = proxy.getProxyObject(new ShenzhenTrainStation());
        // 代售火车票收取5%手续费
        // 深圳火车站卖票啦
        shenzhenTrainStation.sellTickets();
    }

9、结构型-桥接模式：
桥接模式也称为桥梁模式、接口模式或者柄体（Handle and Body）模式，是将抽象部分与他的具体实现部分分离，
使它们都可以独立地变化，通过组合的方式建立两个类之间的联系，而不是继承。
桥接（Bridge）模式包含以下主要角色：
抽象化（Abstraction）角色 ：定义抽象类，并包含一个对实现化对象的引用。
扩展抽象化（Refined Abstraction）角色 ：是抽象化角色的子类，实现父类中的业务方法，并通过组合关系调用实现化角色中的业务方法。
实现化（Implementor）角色 ：定义实现化角色的接口，供扩展抽象化角色调用。
具体实现化（Concrete Implementor）角色 ：给出实现化角色接口的具体实现。

// 视频接口
public interface Video {
    void decode(String fileName);
}
 
// MP4格式类
public class Mp4 implements Video{
    @Override
    public void decode(String fileName) {
        System.out.println("MP4视频文件："+ fileName);
    }
}
// RMVB格式类
public class Rmvb implements Video{
    @Override
    public void decode(String fileName) {
        System.out.println("rmvb文件：" + fileName);
    }
}
// 操作系统抽象类
@AllArgsConstructor
public abstract class OperatingSystem {
    Video video;
    public abstract void play(String fileName);
 
}
// iOS系统
public class Ios extends OperatingSystem {
    public Ios(Video video){
        super(video);
    }
    @Override
    public void play(String fileName) {
        video.decode(fileName);
    }
}
// windows系统
public class Windows extends OperatingSystem {
    public Windows(Video video){
        super(video);
    }
    @Override
    public void play(String fileName) {
        video.decode(fileName);
    }
}
视频类和操作系统类之间通过OperatingSystem类桥接关联起来。

在JDBC中使用桥接模式：
在Java中我们使用 JDBC 连接数据库时，在各个数据库之间进行切换，基本不需要动太多的代码，
原因就是使用了桥接模式，JDBC 提供统一接口，每个数据库提供各自的实现，
然后由桥接类创建一个连接数据库的驱动，使用某一个数据库的时候只需要切换一下就行。

在 JDBC 中，桥接模式的实现化角色 (Implementor) 为的 Driver 接口，
具体实现化 (Concrete Implementor) 角色对应 MysqlDriver、OracleDriver 和 MariadbDriver，
扩展抽象化 (Refined Abstraction) 角色对应 DriverManager，不具有抽象化 (Abstraction) 角色作为扩展抽象化角色的父类。

适用场景：
在抽象和具体实现之间需要增加更多的灵活性的场景。
一个类存在两个（或多个）独立变化的维度，而这两个（或多个）维度都需要独立进行扩展。
不希望使用继承，或因为多层继承导致系统类的个数剧增。

优点：
分离抽象部分及其具体实现部分。
提高了系统的扩展性。
符合开闭原型。
符合合成复用原则。

缺点：
增加了系统的理解与设计难度。
需要正确地识别系统中两个独立变化的维度。


10、结构型-外观模式：
外观模式又称门面模式，提供了一个统一的接口，用来访问子系统中的一群接口。

特征：门面模式定义了一个高层接口，让子系统更容易使用。

外观（Facade）模式包含以下主要角色：
外观（Facade）角色：为多个子系统对外提供一个共同的接口。
子系统（Sub System）角色：实现系统的部分功能，客户可以通过外观角色访问它。

public class Light {
    public void on() {
        System.out.println("开灯");
    }
    public void off() {
        System.out.println("关灯");
    }
}
public class Tv {
    public void on() {
        System.out.println("开电视");
    }
    public void off() {
        System.out.println("关电视");
    }
}
public class Fan {
    public void on() {
        System.out.println("开风扇");
    }
    public void off() {
        System.out.println("关风扇");
    }
}

public class SmartSpeaker {
    private Light light;
    private Tv tv;
    private Fan fan;
    public SmartSpeaker() {
        light = new Light();
        tv = new Tv();
        fan = new Fan();
    }
    public void say(String order) {
        if (order.contains("起床")) {
            getUp();
        } else if (order.contains("睡觉")) {
            sleep();
        } else {
            System.out.println("我还听不懂你说的啥！");
        }
    }
    public void getUp() {
        System.out.println("起床");
        light.on();
        tv.on();
        fan.off();
    }
    public void sleep() {
        System.out.println("睡觉");
        light.off();
        tv.off();
        fan.on();
    }
}
    public static void main(String[] args) {
        SmartSpeaker smartSpeaker = new SmartSpeaker();
        //睡觉
        //关灯
        //关电视
        //开风扇
        smartSpeaker.say("我要睡觉了!");
        //起床
        //开灯
        //开电视
        //关风扇
        smartSpeaker.say("我起床了!");
        //我还听不懂你说的啥！
        smartSpeaker.say("Emmm");
    }


适用场景：
对分层结构系统构建时，使用外观模式定义子系统中每层的入口点可以简化子系统之间的依赖关系。
当一个复杂系统的子系统很多时，外观模式可以为系统设计一个简单的接口供外界访问。
当客户端与多个子系统之间存在很大的联系时，引入外观模式可将它们分离，从而提高子系统的独立性和可移植性。

优点：
简化了调用过程，无需深入了解子系统，以防给子系统带来风险。
减少系统依赖、松散耦合。
更好地划分访问层次，提高了安全性。
遵循迪米特法则，即最少知道原则。

缺点：
当增加子系统和扩展子系统行为时，可能容易带来未知风险。
不符合开闭原则。
某些情况下可能违背单一职责原则。


11、结构型-组合模式：
组合模式也称为整体-部分（Part-Whole）模式，它的宗旨是通过将单个对象（叶子结点）和组合对象（树枝节点）用相同的接口进行表示。
作用：使客户端对单个对象和组合对象保持一致的方式处理。

组合模式主要包含三种角色：
抽象根节点（Component）：定义系统各层次对象的共有方法和属性，可以预先定义一些默认行为和属性。
树枝节点（Composite）：定义树枝节点的行为，存储子节点，组合树枝节点和叶子节点形成一个树形结构。
叶子节点（Leaf）：叶子节点对象，其下再无分支，是系统层次遍历的最小单位。

// 菜单组件
public abstract class MenuComponent {
    String name;
    Integer level;
    public void add(MenuComponent menuComponent) {
        throw new UnsupportedOperationException("不支持添加操作!");
    }
    public void remove(MenuComponent menuComponent) {
        throw new UnsupportedOperationException("不支持删除操作!");
    }
    public MenuComponent getChild(Integer i) {
        throw new UnsupportedOperationException("不支持获取子菜单操作!");
    }
    public String getName() {
        throw new UnsupportedOperationException("不支持获取名字操作!");
    }
    public void print() {
        throw new UnsupportedOperationException("不支持打印操作!");
    }
}
// 菜单类
public class Menu extends MenuComponent {
    private List<MenuComponent> menuComponentList = new ArrayList<>();
    public Menu(String name,int level){
        this.level = level;
        this.name = name;
    }
    @Override
    public void add(MenuComponent menuComponent) {
        menuComponentList.add(menuComponent);
    }
    @Override
    public void remove(MenuComponent menuComponent) {
        menuComponentList.remove(menuComponent);
    }
    @Override
    public MenuComponent getChild(Integer i) {
        return menuComponentList.get(i);
    }
    @Override
    public void print() {
        for (int i = 1; i < level; i++) {
            System.out.print("--");
        }
        System.out.println(name);
        for (MenuComponent menuComponent : menuComponentList) {
            menuComponent.print();
        }
    }
}
// 子菜单类
public class MenuItem extends MenuComponent {
    public MenuItem(String name,int level) {
        this.name = name;
        this.level = level;
    }
    @Override
    public void print() {
        for (int i = 1; i < level; i++) {
            System.out.print("--");
        }
        System.out.println(name);
    }
}
    // 测试方法
    public static void main(String[] args) {
        //创建一级菜单
        MenuComponent component = new Menu("系统管理",1);
 
        MenuComponent menu1 = new Menu("用户管理",2);
        menu1.add(new MenuItem("新增用户",3));
        menu1.add(new MenuItem("修改用户",3));
        menu1.add(new MenuItem("删除用户",3));
 
        MenuComponent menu2 = new Menu("角色管理",2);
        menu2.add(new MenuItem("新增角色",3));
        menu2.add(new MenuItem("修改角色",3));
        menu2.add(new MenuItem("删除角色",3));
        menu2.add(new MenuItem("绑定用户",3));
 
        //将二级菜单添加到一级菜单中
        component.add(menu1);
        component.add(menu2);
 
        //打印菜单名称(如果有子菜单一块打印)
        component.print();
    }
// 测试结果
系统管理
--用户管理
----新增用户
----修改用户
----删除用户
--角色管理
----新增角色
----修改角色
----删除角色
----绑定用户
 

12、结构型-享元模式：
享元模式又称为轻量级模式，是对象池的一种实现，类似于线程池，线程池可以避免不停的创建和销毁多个对象，消耗性能。
提供了减少对象数量从而改善应用所需的对象结构的方式。宗旨：共享细粒度对象，将多个对同一对象的访问集中起来。

享元（Flyweight ）模式中存在以下两种状态：
内部状态，即不会随着环境的改变而改变的可共享部分。
外部状态，指随环境改变而改变的不可以共享的部分。享元模式的实现要领就是区分应用中的这两种状态，并将外部状态外部化。

享元模式的主要有以下角色：

抽象享元角色（Flyweight）：通常是一个接口或抽象类，在抽象享元类中声明了具体享元类公共的方法，
这些方法可以向外界提供享元对象的内部数据（内部状态），同时也可以通过这些方法来设置外部数据（外部状态）。

具体享元（Concrete Flyweight）角色 ：它实现了抽象享元类，称为享元对象；
在具体享元类中为内部状态提供了存储空间。通常我们可以结合单例模式来设计具体享元类，
为每一个具体享元类提供唯一的享元对象。

非享元（Unsharable Flyweight)角色 ：并不是所有的抽象享元类的子类都需要被共享，
不能被共享的子类可设计为非共享具体享元类；当需要一个非共享具体享元类的对象时可以直接通过实例化创建。

享元工厂（Flyweight Factory）角色 ：负责创建和管理享元角色。当客户对象请求一个享元对象时，
享元工厂检査系统中是否存在符合要求的享元对象，如果存在则提供给客户；如果不存在的话，则创建一个新的享元对象。

// 抽象接口
public interface ITicket {
    void show(String seat);
}
public class TrainTicket implements ITicket {
    private String from;
    private String to;
    private Integer price;
    public TrainTicket(String from, String to) {
        this.from = from;
        this.to = to;
    }
    @Override
    public void show(String seat) {
        this.price = new Random().nextInt(500);
        System.out.println(from + "->" + to + ":" + seat + "价格:" + this.price);
    }
}
// 工厂类
public class TicketFactory {
    private static Map<String, ITicket> pool = new ConcurrentHashMap<>();
    public static ITicket getTicket(String from, String to) {
        String key = from + "->" + to;
        if (pool.containsKey(key)) {
            System.out.println("使用缓存获取火车票:" + key);
            return pool.get(key);
        }
        System.out.println("使用数据库获取火车票:" + key);
        ITicket ticket = new TrainTicket(from, to);
        pool.put(key, ticket);
        return ticket;
    }
}
    // 测试
    public static void main(String[] args) {
        ITicket ticket = getTicket("北京", "上海");
        //使用数据库获取火车票:北京->上海
        //北京->上海:二等座价格:20
        ticket.show("二等座");
        ITicket ticket1 = getTicket("北京", "上海");
        //使用缓存获取火车票:北京->上海
        //北京->上海:商务座价格:69
        ticket1.show("商务座");
        ITicket ticket2 = getTicket("上海", "北京");
        //使用数据库获取火车票:上海->北京
        //上海->北京:一等座价格:406
        ticket2.show("一等座");
        System.out.println(ticket == ticket1);//true
        System.out.println(ticket == ticket2);//false
    }
	
注意：
可以看到ticket和ticket2是使用数据库查询的，而ticket1是使用缓存查询的，
同时ticket == ticket1返回的是true，ticket == ticket2返回的是false，证明ticket和ticket1是共享的对象。

适用场景：
一个系统有大量相同或者相似的对象，造成内存的大量耗费。
对象的大部分状态都可以外部化，可以将这些外部状态传入对象中。
在使用享元模式时需要维护一个存储享元对象的享元池，而这需要耗费一定的系统资源，因此，应当在需要多次重复使用享元对象时才值得使用享元模式。

优点：
减少对象的创建，降低内存中对象的数量，降低系统的内存，提高效率。
减少内存之外的其他资源占用。

缺点：
关注内、外部状态。
关注线程安全问题。
使系统、程序的逻辑复杂化。

Java 中，String 类型就是使用享元模式，String 对象是 final 类型，对象一旦创建就不可改变。
而 Java 的字符串常量都是存在字符串常量池中的，JVM 会确保一个字符串常量在常量池中只有一个拷贝。
而且提到共享池，我们也很容易联想到 Java 里面的JDBC连接池，通过连接池的管理，实现了数据库连接的共享，
不需要每一次都重新创建连接，节省了数据库重新创建的开销，提升了系统的性能！


 13、行为型-策略模式：
策略模式又叫政策模式（Policy Pattern），它是将定义的算法家族分别封装起来，让它们之间可以互相替换，从而让算法的变化不会影响到使用算法的用户。可以避免多重分支的if......else和switch语句。

策略模式的主要角色如下：

抽象策略（Strategy）类：这是一个抽象角色，通常由一个接口或抽象类实现。此角色给出所有的具体策略类所需的接口。
具体策略（Concrete Strategy）类：实现了抽象策略定义的接口，提供具体的算法实现或行为。
环境（Context）类：持有一个策略类的引用，最终给客户端调用。

策略模式适用用于以下几种场景：
（1）应用程序需要实现特定的功能服务，而该程序有多种实现方式使用，所以需要动态地在几种算法中选择一种
（2）一个类定义了多种行为算法，并且这些行为在类的操作中以多个条件语句的形式出现，
就可以将相关的条件分支移入它们各自的Strategy类中以代替这些条件语句。

// 会员卡接口
public interface VipCard {
    public void discount();
}
public class GoldCard implements VipCard {
    @Override
    public void discount() {
        System.out.println("金卡打7折");
    }
}
public class SilverCard implements VipCard {
    @Override
    public void discount() {
        System.out.println("银卡打8折");
    }
}
public class CopperCard implements VipCard {
    @Override
    public void discount() {
        System.out.println("铜卡打9折");
    }
}
public class Normal implements VipCard {
    @Override
    public void discount() {
        System.out.println("普通会员没有折扣");
    }
}
// 会员卡容器类
public class VipCardFactory {
    private static Map<String, VipCard> map = new ConcurrentHashMap<>();
    static {
        map.put("gold", new GoldCard());
        map.put("silver", new SilverCard());
        map.put("copper", new CopperCard());
    }
    public static VipCard getVIPCard(String level) {
        return map.get(level) != null ? map.get(level) : new Normal();
    }
 
}
    // 测试方法
    public static void main(String[] args) {
        //金卡打7折
        VipCardFactory.getVIPCard("gold").discount();
        //银卡打8折
        VipCardFactory.getVIPCard("silver").discount();
        //普通会员没有折扣
        VipCardFactory.getVIPCard("other").discount();
    }
	
总结：
适用场景：
系统中有很多类，而它们的区别仅仅在于它们的行为不同。
系统需要动态地在几种算法中选择一种。
需要屏蔽算法规则。

优点：
符合开闭原则。
避免使用多重条件语句。
可以提高算法的保密性和安全性。
易于扩展。

缺点：
客户端必须知道所有的策略，并且自行决定使用哪一个策略类。
代码中会产生非常多的策略类，增加维护难度。
	
14、行为型-模板方法：
模板方法模式通常又叫模板模式，是指定义一个算法的骨架，并允许之类为其中的一个或者多个步骤提供实现。模板方法模式使得子类可以在不改变算法结构的情况下，重新定义算法的某些步骤。

模板方法（Template Method）模式包含以下主要角色：

抽象类（Abstract Class）：负责给出一个算法的轮廓和骨架。它由一个模板方法和若干个基本方法构成。
模板方法：定义了算法的骨架，按某种顺序调用其包含的基本方法。
基本方法：是实现算法各个步骤的方法，是模板方法的组成部分。基本方法又可以分为三种：
抽象方法(Abstract Method) ：一个抽象方法由抽象类声明、由其具体子类实现。
具体方法(Concrete Method) ：一个具体方法由一个抽象类或具体类声明并实现，其子类可以进行覆盖也可以直接继承。
钩子方法(Hook Method) ：在抽象类中已经实现，包括用于判断的逻辑方法和需要子类重写的空方法两种。一般钩子方法是用于判断的逻辑方法，这类方法名一般为isXxx，返回值类型为boolean类型。
具体子类（Concrete Class）：实现抽象类中所定义的抽象方法和钩子方法，它们是一个顶级逻辑的组成步骤。

public abstract class DayOffProcess {
    // 请假模板
    public final void dayOffProcess() {
        // 领取申请表
        this.pickUpForm();
        // 填写申请信息
        this.writeInfo();
        // 签名
        this.signUp();
        // 提交到不同部门审批
        this.summit();
        // 行政部备案
        this.filing();
    }
    private void filing() {
        System.out.println("行政部备案");
    }
    protected abstract void summit();
    protected abstract void signUp();
    private void writeInfo() {
        System.out.println("填写申请信息");
    }
    private void pickUpForm() {
        System.out.println("领取申请表");
    }
}
public class ZhangSan extends DayOffProcess {
    @Override
    protected void summit() {
        System.out.println("张三签名");
    }
    @Override
    protected void signUp() {
        System.out.println("提交到技术部审批");
    }
}
public class Lisi extends DayOffProcess {
    @Override
    protected void summit() {
        System.out.println("李四签名");
    }
    @Override
    protected void signUp() {
        System.out.println("提交到市场部审批");
    }
}
    // 测试方法
    public static void main(String[] args) {
        DayOffProcess zhangsan = new ZhangSan();
        //领取申请表
        //填写申请信息
        //提交到技术部审批
        //张三签名
        //行政部备案
        zhangsan.dayOffProcess();
        DayOffProcess lisi = new Lisi();
        //领取申请表
        //填写申请信息
        //提交到市场部审批
        //李四签名
        //行政部备案
        lisi.dayOffProcess();
    }


适用场景：
一次性实现一个算法不变的部分，并将可变的行为留给子类来实现。
各子类中公共的行为被提取出来并集中到一个公共的父类中，从而避免代码重复。

优点：
利用模板方法将相同处理逻辑的代码放到抽象父类中，可以提高代码的复用性。
将不同的代码不同的子类中，通过对子类的扩展增加新的行为，提高代码的扩展性。
把不变的行为写在父类上，去除子类的重复代码，提供了一个很好的代码复用平台，符合开闭原则。

缺点：
类数目的增加，每一个抽象类都需要一个子类来实现，这样导致类的个数增加。
类数量的增加，间接地增加了系统实现的复杂度。
继承关系自身缺点，如果父类添加新的抽象方法，所有子类都要改一遍。


15、行为型-责任链模式：
职责链可以将请求的处理者组织成一条链，并将请求沿着链传递，如果某个处理者能够处理请求则处理，否则将该请求交由上级处理。客户端只需将请求发送到职责链上，无须关注请求的处理细节，通过职责链将请求的发送者和处理者解耦了，这也是职责链的设计动机。        

职责链模式可以简化对象间的相互连接，因为客户端和处理者都没有对方明确的信息，同时处理者也不知道职责链中的结构，处理者只需保存一个指向后续者的引用，而不需要保存所有候选者的引用。

另外职责链模式增加了系统的灵活性，我们可以任意增加或更改处理者，甚至更改处理者的顺序，不过有可能会导致一个请求无论如何也得不到处理，因为它可能被放置在链末端。

所以责任链模式有以下几个优点：

（1）降低耦合度，将请求的发送者和接收者解耦。反映在代码上就是不需要在类中写很多丑陋的 if….else 语句，如果用了职责链，相当于我们面对一个黑箱，只需将请求递交给其中一个处理者，然后让黑箱内部去负责传递就可以了。
（2）简化了对象，使得对象不需要链的结构。
（3）增加系统的灵活性，通过改变链内的成员或者调动他们的次序，允许动态地新增或者删除处理者
（4）增加新的请求处理类很方便。
但是责任链模式也存在一些缺点：

（1）不能保证请求一定被成功处理
（2）系统性能将受到一定影响，并且可能会造成循环调用。
（3）可能不容易观察运行时的特征，而且在进行代码调试时不太方便，有碍于除错。
 

// 用户实体类
@Data
public class User {
    private String username;
    private String password;
    private String role;
}
// handler抽象类
public abstract class Handler {
    protected Handler next;
    // 返回handler方便链式操作
    public void next(Handler next) {
        this.next = next;
    }
    // 流程开始的方法
    public abstract void doHandler(User user);
}
// 校验用户名或者密码是否为空
public class ValidateHandler extends Handler {
    @Override
    public void doHandler(User user) {
        if (StringUtils.isBlank(user.getUsername()) || StringUtils.isBlank(user.getPassword())) {
            System.out.println("用户名或者密码为空!");
            return;
        }
        System.out.println("校验通过");
        next.doHandler(user);
    }
}
// 登录校验，校验用户名是否匹配密码
public class LoginHandler extends Handler {
    @Override
    public void doHandler(User user) {
        if (!"pyy52hz".equals(user.getUsername()) || !"123456".equals(user.getPassword())) {
            System.out.println("用户名或者密码不正确!请检查!");
            return;
        }
        user.setRole("admin");
        System.out.println("登陆成功!角色为管理员!");
        next.doHandler(user);
    }
}
// 权限校验
public class AuthHandler extends Handler {
    @Override
    public void doHandler(User user) {
        if (!"admin".equals(user.getRole())) {
            System.out.println("无权限操作!");
            return;
        }
        System.out.println("角色为管理员,可以进行下一步操作!");
    }
}
// 登录流程
public class LoginService {
    public void login(User user) {
        Handler validateHandler = new ValidateHandler();
        Handler loginHandler = new LoginHandler();
        Handler authHandler = new AuthHandler();
        validateHandler.next(loginHandler);
        loginHandler.next(authHandler);
        validateHandler.doHandler(user);
    }
}
    // 测试方法
    public static void main(String[] args){
      User user = new User();
      //校验通过
      //用户名或者密码不正确!请检查!
      user.setUsername("pyy52hz");
      user.setPassword("1234567");
      LoginService loginService = new LoginService();
      loginService.login(user);
      //校验通过
      //登陆成功!角色为管理员!
      //角色为管理员,可以进行下一步操作!
      user.setUsername("pyy52hz");
      user.setPassword("123456");
      loginService.login(user);
    }


       
16、行为型-观察者模式：
观察者模式又称为 发布-订阅模式，定义了对象之间一对多依赖关系，当目标对象(被观察者)的状态发生改变时，它的所有依赖者(观察者)都会收到通知。
一个观察目标可以对应多个观察者，而这些观察者之间没有相互联系，所以能够根据需要增加和删除观察者，使得系统更易于扩展，符合开闭原则；
并且观察者模式让目标对象和观察者松耦合，虽然彼此不清楚对方的细节，但依然可以交互，目标对象只知道一个具体的观察者列表，
但并不认识任何一个具体的观察者，它只知道他们都有一个共同的接口。

但观察者模式的缺点在于如果存在很多个被观察者的话，那么将需要花费一定时间通知所有的观察者，如果观察者与被观察者之间存在循环依赖的话，那么可能导致系统崩溃，并且观察者模式没有相应的机制让观察者知道被观察对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。

// 抽象观察者接口
public interface Observer {
    void update(String message);
}
// 微信用户类 具体的观察者
@AllArgsConstructor
public class WeixinUser implements Observer {
    private String name;
    @Override
    public void update(String message) {
        System.out.println(name + "接收到了消息(观察到了):" + message);
    }
}
// 被观察者接口
public interface Observable {
    // 新增用户(新增观察者)
    void add(Observer observer);
    // 移除用户,或者说用户取消订阅(移除观察者)
    void del(Observer observer);
    // 发布 推送消息
    void notify(String message);
}
// 具体的被观察者(公众号)
public class Subject implements Observable {
    // 观察者列表(订阅用户)
    private List<Observer> list = new ArrayList<>();
    @Override
    public void add(Observer observer) {
        list.add(observer);
    }
    @Override
    public void del(Observer observer) {
        list.remove(observer);
    }
    // 给每一个观察者(订阅者)推送消息
    @Override
    public void notify(String message) {
        list.forEach(observer -> observer.update(message));
    }
 
}
    // 测试
    public static void main(String[] args){
      Observable o = new Subject();
      WeixinUser user1 = new WeixinUser("张三");
      WeixinUser user2 = new WeixinUser("李四");
      WeixinUser user3 = new WeixinUser("王五");
      o.add(user1);
      o.add(user2);
      o.add(user3);
      o.notify("薛之谦演唱会要来到广州啦!");
      // 运行结果
      // 张三接收到了消息(观察到了):薛之谦演唱会要来到广州啦!
      // 李四接收到了消息(观察到了):薛之谦演唱会要来到广州啦!
      // 王五接收到了消息(观察到了):薛之谦演唱会要来到广州啦!
    }
 
JDK实现
在 Java 中，通过java.util.Observable类和 java.util.Observer接口定义了观察者模式，只要实现它们的子类就可以编写观察者模式实例。

1 Observable类
Observable类是抽象目标类（被观察者），它有一个Vector集合成员变量，用于保存所有要通知的观察者对象，下面是它最重要的 3 个方法：
void addObserver(Observer o) 方法：用于将新的观察者对象添加到集合中。
void notifyObservers(Object arg) 方法：调用集合中的所有观察者对象的update方法，通知它们数据发生改变。通常越晚加入集合的观察者越先得到通知。
void setChange() 方法：用来设置一个boolean类型的内部标志，注明目标对象发生了变化。当它为true时，notifyObservers() 才会通知观察者。

2 Observer 接口
Observer 接口是抽象观察者，它监视目标对象的变化，当目标对象发生变化时，观察者得到通知，并调用 update 方法，进行相应的工作。

3 代码实现
// 具体的被观察者(公众号)
@Data
@AllArgsConstructor
public class Subject extends Observable {
    // 公众号的名字
    private String name;
    // 公众号发布消息
    public void notifyMessage(String message) {
        System.out.println(this.name + "公众号发布消息:" + message + "请关注用户留意接收!");
        super.setChanged();
        super.notifyObservers(message);
    }
}
@AllArgsConstructor
public class WeixinUser implements Observer {
    private String name;
    /**
     * @param o 被观察者
     * @param arg 被观察者带过来的参数，此例子中是公众号发布的消息
     */
    @Override
    public void update(Observable o, Object arg) {
        System.out.println(name + "关注了公众号(被观察者):" + ((Subject)o).getName() + ",接收到消息:" + arg);
    }
}
    // 测试
    public static void main(String[] args){
        WeixinUser user1 = new WeixinUser("张三");
        WeixinUser user2 = new WeixinUser("李四");
        WeixinUser user3 = new WeixinUser("王五");
        Subject subject = new Subject("演唱会消息发布");
        subject.addObserver(user1);
        subject.addObserver(user2);
        subject.addObserver(user3);
        subject.notifyMessage("薛之谦演唱会要来到广州啦!");
        // 返回结果
        // 演唱会消息发布公众号发布消息:薛之谦演唱会要来到广州啦!请关注用户留意接收!
        // 王五关注了公众号(被观察者):演唱会消息发布,接收到消息:薛之谦演唱会要来到广州啦!
        // 李四关注了公众号(被观察者):演唱会消息发布,接收到消息:薛之谦演唱会要来到广州啦!
        // 张三关注了公众号(被观察者):演唱会消息发布,接收到消息:薛之谦演唱会要来到广州啦!
    }

适用场景：
当一个抽象模型包含两个方面内容，其中一个方面依赖于另一个方面。
其他一个或多个对象的变化依赖于另一个对象的变化。
实现类似广播机制的功能，无需知道具体收听者，只需分发广播，系统中感兴趣的对象会自动接收该广播。
多层级嵌套使用，形成一种链式触发机制，使得事件具备跨域（跨越两种观察者类型）通知。

优点：
观察者和被观察者是松耦合（抽象耦合）的，符合依赖倒置原则。
分离了表示层（观察者）和数据逻辑层（被观察者），并且建立了一套触发机制，使得数据的变化可以相应到多个表示层上。
实现了一对多的通讯机制，支持事件注册机制，支持兴趣分发机制，当被观察者触发事件时，只有感兴趣的观察者可以接收到通知。

缺点：
如果观察者数量过多，则事件通知会耗时较长。
事件通知呈线性关系，如果其中一个观察者处理事件卡壳，会影响后续的观察者接收该事件。
如果观察者和被观察者之间存在循环依赖，则可能造成两者之间的循环调用，导致系统崩溃。

17、行为型-访问者模式：
访问者模式是一种将数据结构与数据操作分离的设计模式。是指封装一些作用于某种数据结构中的各元素的操作。

特征：可以在不改变数据结构的前提下定义作用于这些元素的新的操作。

访问者模式包含以下主要角色:

抽象访问者（Visitor）角色：定义了对每一个元素 （Element） 访问的行为，它的参数就是可以访问的元素，它的方法个数理论上来讲与元素类个数（Element的实现类个数）是一样的，从这点不难看出，访问者模式要求元素类的个数不能改变。
具体访问者（ConcreteVisitor）角色：给出对每一个元素类访问时所产生的具体行为。
抽象元素（Element）角色：定义了一个接受访问者的方法（ accept ），其意义是指，每一个元素都要可以被访问者访问。
具体元素（ConcreteElement）角色： 提供接受访问方法的具体实现，而这个具体的实现，通常情况下是使用访问者提供的访问该元素类的方法。
对象结构（Object Structure）角色：定义当中所提到的对象结构，对象结构是一个抽象表述，具体点可以理解为一个具有容器性质或者复合对象特性的类，它会含有一组元素（ Element ），并且可以迭代这些元素，供访问者访问。


// 访问者接口
public interface IVisitor {
    void visit(Engineer engineer);
    void visit(Pm pm);
}
// 具体的访问者类,访问者角色(CEO)
public class CeoVisitor implements IVisitor {
    @Override
    public void visit(Engineer engineer) {
        System.out.println(engineer.getName() + "KPI为:" + engineer.getKpi());
    }
    @Override
    public void visit(Pm pm) {
        System.out.println(pm.getName() + "KPI为:" + pm.getKpi());
    }
}
// 具体的访问者类,访问者角色(CTO)
public class CtoVisitor implements IVisitor {
    @Override
    public void visit(Engineer engineer) {
        System.out.println(engineer.getName() + "工作内容:" + engineer.getCodeLine() + "行代码");
    }
    @Override
    public void visit(Pm pm) {
        System.out.println(pm.getName() + "工作内容:" + pm.getProject() + "个项目");
    }
}
@Data
// 抽象元素(员工)
public abstract class Employee {
    private String name;
    private Integer kpi;
    public Employee(String name) {
        this.name = name;
        this.kpi = new Random().nextInt(10);
    }
    public abstract void accept(IVisitor visitor);
}
// 具体元素(程序员)
public class Engineer extends Employee {
    public Engineer(String name) {
        super(name);
    }
    @Override
    public void accept(IVisitor visitor) {
        visitor.visit(this);
    }
    public Integer getCodeLine() {
        return new Random().nextInt(10000);
    }
}
// 具体元素(项目经理)
public class Pm extends Employee {
    public Pm(String name) {
        super(name);
    }
    @Override
    public void accept(IVisitor visitor) {
        visitor.visit(this);
    }
    public Integer getProject() {
        return new Random().nextInt(10);
    }
}
@AllArgsConstructor
public class Report {
    private List<Employee> employeeList;
    public void showReport(IVisitor visitor) {
        for (Employee employee : employeeList) {
            employee.accept(visitor);
        }
    }
}
    // 测试
    public static void main(String[] args){
      List<Employee> employeeList = new ArrayList<>();
      employeeList.add(new Engineer("工程师A"));
      employeeList.add(new Engineer("工程师B"));
      employeeList.add(new Engineer("项目经理A"));
      employeeList.add(new Engineer("工程师C"));
      employeeList.add(new Engineer("工程师D"));
      employeeList.add(new Engineer("项目经理B"));
      Report report = new Report(employeeList);
      System.out.println("=============CEO==============");
      report.showReport(new CeoVisitor());
      System.out.println("=============CTO==============");
      report.showReport(new CtoVisitor());
      // =============CEO==============
      // 工程师AKPI为:2
      // 工程师BKPI为:4
      // 项目经理AKPI为:4
      // 工程师CKPI为:2
      // 工程师DKPI为:0
      // 项目经理BKPI为:0
      // =============CTO==============
      // 工程师A工作内容:5811行代码
      // 工程师B工作内容:9930行代码
      // 项目经理A工作内容:2163行代码
      // 工程师C工作内容:4591行代码
      // 工程师D工作内容:333行代码
      // 项目经理B工作内容:3940行代码
    }



在访问者模式使用了双分派技术，所谓双分派技术就是在选择方法的时候，不仅仅要根据消息接收者的运行时区别，还要根据参数的运行时区别。
在访问者模式中，客户端将具体状态当做参数传递给具体访问者，这里完成第一次分派，然后具体访问者作为参数的“具体状态”中的方法，同时也将自己this作为参数传递进去，
这里就完成了第二次分派。双分派意味着得到的执行操作决定于请求的种类和接受者的类型。

适用场景：

数据结构稳定，作用于数据结构的操作经常变化的场景。
需要数据结构与数据操作分离的场景。
需要对不同数据类型（元素）进行操作，而不使用分支判断具体类型的场景。
优点：

解耦了数据结构与数据操作，使得操作集合可以独立变化。
扩展性好：可以通过扩展访问者角色，实现对数据集的不同操作。
元素具体类型并非单一，访问者均可操作。
各角色职责分离，符合单一职责原则。
缺点：

无法增加元素类型：若系统数据结构对象易于变化，经常有新的数据对象增加进来，则访问者类必须增加对应元素类型的操作，违背了开闭原则。
具体元素变更困难：具体元素增加属性，删除属性等操作会导致对应的访问者类需要进行相应的修改，尤其当有大量访问者类时，修改访问太大。
违背依赖倒置原则：为了达到“区别对待”，访问者依赖的是具体元素类型，而不是抽象。


18、行为型-中介者模式：
中介者模式又称为调解者模式或调停者模式。用一个中介对象封装一系列的对象交互，中介者使各对象不需要显示地相互作用，从而使其耦合松散，而且可以独立地改变它们之间的交互。

核心：通过中介者解耦系统各层次对象的直接耦合，层次对象的对外依赖通信统统交由中介者转发。

中介者模式包含以下主要角色：

抽象中介者（Mediator）角色：它是中介者的接口，提供了同事对象注册与转发同事对象信息的抽象方法。
具体中介者（ConcreteMediator）角色：实现中介者接口，定义一个 List 来管理同事对象，协调各个同事角色之间的交互关系，因此它依赖于同事角色。
抽象同事类（Colleague）角色：定义同事类的接口，保存中介者对象，提供同事对象交互的抽象方法，实现所有相互影响的同事类的公共功能。
具体同事类（Concrete Colleague）角色：是抽象同事类的实现者，当需要与其他同事对象交互时，由中介者对象负责后续的交互。

// 抽象同事类
@AllArgsConstructor
public class Person {
    protected String name;
    protected MediatorCompany mediatorCompany;
}
// 房主
public class HouseOwner extends Person {
    public HouseOwner(String name, MediatorCompany mediatorCompany) {
        super(name, mediatorCompany);
    }
    // 联络方法
    public void connection(String message) {
        mediatorCompany.connection(this, message);
    }
    // 获取消息
    public void getMessage(String message) {
        System.out.println("房主" + name + "获取到的信息:" + message);
    }
}
// 租客
public class Tenant extends Person {
    public Tenant(String name, MediatorCompany mediatorCompany) {
        super(name, mediatorCompany);
    }
    public void connection(String message) {
        mediatorCompany.connection(this, message);
    }
    public void getMessage(String message) {
        System.out.println("租客" + name + "获取到的信息:" + message);
    }
}
// 中介公司(中介者)
@Data
public class MediatorCompany {
    private HouseOwner houseOwner;
    private Tenant tenant;
    public void connection(Person person, String message) {
        // 房主需要通过中介获取租客信息
        if (person.equals(houseOwner)) {
            this.tenant.getMessage(message);
        } else { // 反之租客通过中介获取房主信息
            this.houseOwner.getMessage(message);
        }
    }
}
    // 测试
    public static void main(String[] args){
        // 先创建三个角色，中介公司，房主，租客
        MediatorCompany mediatorCompany = new MediatorCompany();
        // 房主和租客都在同一家中介公司
        HouseOwner houseOwner = new HouseOwner("张三", mediatorCompany);
        Tenant tenant = new Tenant("李四", mediatorCompany);
        // 中介公司获取房主和租客的信息
        mediatorCompany.setHouseOwner(houseOwner);
        mediatorCompany.setTenant(tenant);
        // 房主和租客都在这家中介公司发布消息，获取到对应的消息
        tenant.connection(tenant.name + "想租一房一厅!");
        houseOwner.connection(houseOwner.name + "这里有!来看看呗!");
        // 测试结果
        // 房主张三获取到的信息:李四想租一房一厅!
        // 租客李四获取到的信息:张三这里有!来看看呗!
    }


但是，中介者对象封装了对象之间的关联关系，导致中介者对象变得比较庞大复杂，所承担的责任也比较多，维护起来也比较困难，
它需要知道每个对象和他们之间的交互细节，如果它出问题，将会导致整个系统都会出问题。

适用场景：
系统中对象之间存在复杂的引用关系，产生的我相互依赖关系结构混乱且难以理解。
交互的公共行为，如果需要改变行为则可以增加新的中介者类。

优点：
减少类间的依赖，将多对多依赖转化成了一对多，降低了类间耦合。
类间各司其职，符合迪米特法则。

缺点：
中介者模式中将原本多个对象直接的相互依赖变成了中介者和多个同事类的依赖关系。当同事类越多时，中介者就会越臃肿，变得复杂且难以维护。


19、行为型-命令模式：
        命令模式的本质是将请求封装成对象，将发出命令与执行命令的责任分开，命令的发送者和接收者完全解耦，发送者只需知道如何发送命令，不需要关心命令是如何实现的，甚至是否执行成功都不需要理会。命令模式的关键在于引入了抽象命令接口，发送者针对抽象命令接口编程，只有实现了抽象命令接口的具体命令才能与接收者相关联。

        使用命令模式的优势在于降低了系统的耦合度，而且新命令可以很方便添加到系统中，也容易设计一个组合命令。但缺点在于会导致某些系统有过多的具体命令类，因为针对每一个命令都需要设计一个具体命令类。

        命令模式的UML结构图如下：



命令模式详情： Java设计模式之行为型：命令模式

20、行为型-状态模式：
命令模式是对命令的封装，每一个命令都是一个操作：请求的一方发出请求要求执行一个操作；接收的一方收到请求，并执行操作。命令模式解耦了请求方和接收方，请求方只需请求执行命令，不用关心命令是怎样被接收，怎样被操作以及是否被执行等。本质：解耦命令的请求与处理。

命令模式包含以下主要角色：

抽象命令类（Command）角色： 定义命令的接口，声明执行的方法。
具体命令（Concrete Command）角色：具体的命令，实现命令接口；通常会持有接收者，并调用接收者的功能来完成命令要执行的操作。
实现者/接收者（Receiver）角色： 接收者，真正执行命令的对象。任何类都可能成为一个接收者，只要它能够实现命令要求实现的相应功能。
调用者/请求者（Invoker）角色： 要求命令对象执行请求，通常会持有命令对象，可以持有很多的命令对象。这个是客户端真正触发命令并要求命令执行相应操作的地方，也就是说相当于使用命令对象的入口。

// 播放器类
public class Player {
    public void play() {
        System.out.println("正常播放");
    }
    public void pause() {
        System.out.println("暂停播放");
    }
    public void stop() {
        System.out.println("停止播放");
    }
}
// 命令接口
public interface IAction {
    void excuse();
}
// 播放命令类
@AllArgsConstructor
public class PlayAction implements IAction {
    private Player player;
    @Override
    public void excuse() {
        this.player.play();
    }
}
// 暂停命令类
@AllArgsConstructor
public class PauseAction implements IAction {
    private Player player;
    @Override
    public void excuse() {
        this.player.pause();
    }
}
// 停止命令类
@AllArgsConstructor
public class StopAction implements IAction{
    private Player player;
    @Override
    public void excuse() {
        this.player.stop();
    }
}
// 控制器
public class Controller {
    public void excuse(IAction action) {
        action.excuse();
    }
}
   // 测试方法
   public static void main(String[] args) {
        // 正常播放
        new Controller().excuse(new PlayAction(new Player()));
        // 暂停播放
        new Controller().excuse(new PauseAction(new Player()));
        // 停止播放
        new Controller().excuse(new StopAction(new Player()));
    }


适用场景：
现实语义中具备“命令”的操作（如命令菜单，shell命令...）。
请求调用者和请求接收者需要解耦，使得调用者和接收者不直接交互。
需要抽象出等待执行的行为，比如撤销操作和恢复操作等。
需要支持命令宏（即命令组合操作）。

优点：
通过引入中间件（抽象接口），解耦了命令的请求与实现。
扩展性良好，可以很容易地增加新命令。
支持组合命令，支持命令队列。
可以在现有的命令的基础上，增加额外功能。

缺点：
具体命令类可能过多。
增加 了程序的复杂度，理解更加困难。


21、行为型-备忘录模式：
备忘录模式又称为快照模式（Snapshot Pattern）或令牌模式（Token Pattern），是指在不破坏封装的前提下，
捕获一个对象的内部状态，并在对象之外保存这个状态，这样以后就可将该对象恢复到原先保存的状态。
特征：“后悔药”

备忘录模式的主要角色如下：
发起人（Originator）角色：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，它可以访问备忘录里的所有信息。
备忘录（Memento）角色：负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人。
管理者（Caretaker）角色：对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改。
备忘录有两个等效的接口：

窄接口：管理者(Caretaker)对象（和其他发起人对象之外的任何对象）看到的是备忘录的窄接口(narror Interface)，这个窄接口只允许他把备忘录对象传给其他的对象。
宽接口：与管理者看到的窄接口相反，发起人对象可以看到一个宽接口(wide Interface)，这个宽接口允许它读取所有的数据，以便根据这些数据恢复这个发起人对象的内部状态。

“白箱”备忘录模式：
下面就以游戏打怪为简单的例子进行代码实现（下面“黑箱”同这个例子）：
备忘录角色对任何对象都提供一个宽接口，备忘录角色的内部所存储的状态就对所有对象公开。


// 游戏角色类
@Data
public class GameRole {
    private Integer vit; // 生命力
    private Integer atk; // 攻击力
    private Integer def; // 防御力
    // 初始化状态
    public void init() {
        this.vit = 100;
        this.atk = 100;
        this.def = 100;
    }
    // 战斗到0
    public void fight() {
        this.vit = 0;
        this.atk = 0;
        this.def = 0;
    }
    // 保存角色状态
    public RoleStateMemento saveState() {
        return new RoleStateMemento(this.vit, this.atk, this.def);
    }
    // 回复角色状态
    public void recoverState(RoleStateMemento roleStateMemento) {
        this.vit = roleStateMemento.getVit();
        this.atk = roleStateMemento.getAtk();
        this.def = roleStateMemento.getDef();
    }
    // 展示状态
    public void showState() {
        System.out.println("角色生命力:" + this.vit);
        System.out.println("角色攻击力:" + this.atk);
        System.out.println("角色防御力:" + this.def);
    }
}
// 游戏状态存储类(备忘录类)
@Data
@AllArgsConstructor
public class RoleStateMemento {
    private Integer vit; // 生命力
    private Integer atk; // 攻击力
    private Integer def; // 防御力
}
// 角色状态管理者类
@Data
public class RoleStateCaretaker {
    private RoleStateMemento roleStateMemento;
}
    // 测试结果
    public static void main(String[] args){
      System.out.println("===========打boss前状态===========");
      GameRole gameRole = new GameRole();
      gameRole.init();
      gameRole.showState();
      // 保存进度
      RoleStateCaretaker roleStateCaretaker = new RoleStateCaretaker();
      roleStateCaretaker.setRoleStateMemento(gameRole.saveState());
      System.out.println("===========打boss后状态===========");
      gameRole.fight();
      gameRole.showState();
      System.out.println("===========恢复状态===========");
      gameRole.recoverState(roleStateCaretaker.getRoleStateMemento());
      gameRole.showState();
      // ===========打boss前状态===========
      // 角色生命力:100
      // 角色攻击力:100
      // 角色防御力:100
      // ===========打boss后状态===========
      // 角色生命力:0
      // 角色攻击力:0
      // 角色防御力:0
      // ===========恢复状态===========
      // 角色生命力:100
      // 角色攻击力:100
      // 角色防御力:100
    }
 
"白箱"备忘录模式是破坏封装性的，但是通过程序员自律，同样可以在一定程度上实现大部分的用意。

“黑箱”备忘录模式:
备忘录角色对发起人对象提供了一个宽接口，而为其他对象提供一个窄接口，
在Java语言中，实现双重接口的办法就是将备忘录类设计成发起人类的内部成员类。
将RoleStateMemento设为GameRole的内部类，从而将RoleStateMemento对象封装在GameRole 里面；
在外面提供一个标识接口Memento给RoleStateCaretaker及其他对象使用。
这样GameRole类看到的是RoleStateMemento所有的接口，
而RoleStateCaretaker及其他对象看到的仅仅是标识接口Memento所暴露出来的接口，从而维护了封装型。


// 窄接口,标识接口
public interface Memento {
}
// 角色状态管理者类
@Data
public class RoleStateCaretaker {
    private Memento memento;
}
// 游戏角色类
@Data
public class GameRole {
    private Integer vit; // 生命力
    private Integer atk; // 攻击力
    private Integer def; // 防御力
    // 初始化状态
    public void init() {
        this.vit = 100;
        this.atk = 100;
        this.def = 100;
    }
    // 战斗到0
    public void fight() {
        this.vit = 0;
        this.atk = 0;
        this.def = 0;
    }
    // 保存角色状态
    public RoleStateMemento saveState() {
        return new RoleStateMemento(this.vit, this.atk, this.def);
    }
    // 回复角色状态
    public void recoverState(Memento memento) {
        RoleStateMemento roleStateMemento = (RoleStateMemento) memento;
        this.vit = roleStateMemento.getVit();
        this.atk = roleStateMemento.getAtk();
        this.def = roleStateMemento.getDef();
    }
    // 展示状态
    public void showState() {
        System.out.println("角色生命力:" + this.vit);
        System.out.println("角色攻击力:" + this.atk);
        System.out.println("角色防御力:" + this.def);
    }
    // 备忘录内部类
    @Data
    @AllArgsConstructor
    private class RoleStateMemento implements Memento {
        private Integer vit; // 生命力
        private Integer atk; // 攻击力
        private Integer def; // 防御力
    }
}
    // 测试结果
    public static void main(String[] args){
      System.out.println("===========打boss前状态===========");
      GameRole gameRole = new GameRole();
      gameRole.init();
      gameRole.showState();
      // 保存进度
      RoleStateCaretaker roleStateCaretaker = new RoleStateCaretaker();
      roleStateCaretaker.setMemento(gameRole.saveState());
      System.out.println("===========打boss后状态===========");
      gameRole.fight();
      gameRole.showState();
      System.out.println("===========恢复状态===========");
      gameRole.recoverState(roleStateCaretaker.getMemento());
      gameRole.showState();
      // ===========打boss前状态===========
      // 角色生命力:100
      // 角色攻击力:100
      // 角色防御力:100
      // ===========打boss后状态===========
      // 角色生命力:0
      // 角色攻击力:0
      // 角色防御力:0
      // ===========恢复状态===========
      // 角色生命力:100
      // 角色攻击力:100
      // 角色防御力:100
    }

适用场景：
需要保存历史快照的场景。
希望在对象之外保存状态，且除了自己其他类对象无法访问状态保存具体内容。

优点：
简化发起人实体类职责，隔离状态存储与获取，实现了信息的封装，客户端无需关心状态的保存细节。
提供状态回滚功能。

缺点：
消耗资源：如果需要保存的状态过多时，每一次保存都会消耗很多内存。

	
22、行为型-迭代器模式：
迭代器模式又称为游标模式（Cursor Pattern），它提供一种顺序访问集合/容器对象元素的方法，而又无须暴露结合内部表示。
本质：抽离集合对象迭代行为到迭代器中，提供一致访问接口。

迭代器模式主要包含以下角色：
抽象聚合（Aggregate）角色：定义存储、添加、删除聚合元素以及创建迭代器对象的接口。
具体聚合（ConcreteAggregate）角色：实现抽象聚合类，返回一个具体迭代器的实例。
抽象迭代器（Iterator）角色：定义访问和遍历聚合元素的接口，通常包含 hasNext()、next() 等方法。
具体迭代器（Concretelterator）角色：实现抽象迭代器接口中所定义的方法，完成对聚合对象的遍历，记录遍历的当前位置。

// 迭代器接口
public interface Iterator<T> {
    Boolean hasNext();
    T next();
}
// 迭代器接口实现类
public class IteratorImpl<T> implements Iterator<T> {
    private List<T> list;
    private Integer cursor;
    private T element;
 
    public IteratorImpl(List<T> list) {
        this.list = list;
    }
    @Override
    public Boolean hasNext() {
        return cursor < list.size();
    }
    @Override
    public T next() {
        element = list.get(cursor);
        cursor++;
        return element;
    }
}
// 容器接口
public interface Aggregate<T> {
    void add(T t);
    void remove(T t);
    Iterator<T> iterator();
}
// 容器接口实现类
public class AggregateImpl<T> implements Aggregate<T> {
    private List<T> list = new ArrayList<>();
    @Override
    public void add(T t) {
        list.add(t);
    }
    @Override
    public void remove(T t) {
        list.remove(t);
    }
    @Override
    public Iterator<T> iterator() {
        return new IteratorImpl<>(list);
    }
}

适用场景：
访问一个集合对象的内容而无需暴露它的内部表示。
为遍历不同的集合结构提供一个统一的访问接口。

优点：
多态迭代：为不同的聚合结构提供一致的遍历接口，即一个迭代接口可以访问不同的聚集对象。
简化集合对象接口：迭代器模式将集合对象本身应该提供的元素迭代接口抽取到了迭代器中，使集合对象无须关心具体迭代行为。
元素迭代功能多样化：每个集合对象都可以提供一个或多个不同的迭代器，使的同种元素聚合结构可以有不同的迭代行为。
解耦迭代与集合：迭代器模式封装了具体的迭代算法，迭代算法的变化，不会影响到集合对象的架构。

缺点：
对于比较简单的遍历（像数组或者有序列表），使用迭代器方式遍历较为繁琐。
增加了类的个数，在一定程度上增加了系统的复杂性。


23、行为型-解释器模式：
解释器模式给定一个语言，定义它的文法的一种表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。
特征：为了解释一种语言，而为语言创建的解释器。

解释器模式包含以下主要角色：
抽象表达式（Abstract Expression）角色：定义解释器的接口，约定解释器的解释操作，主要包含解释方法 interpret()。
终结符表达式（Terminal Expression）角色：是抽象表达式的子类，用来实现文法中与终结符相关的操作，文法中的每一个终结符都有一个具体终结表达式与之相对应。
非终结符表达式（Nonterminal Expression）角色：也是抽象表达式的子类，用来实现文法中与非终结符相关的操作，文法中的每条规则都对应于一个非终结符表达式。
环境（Context）角色：通常包含各个解释器需要的数据或是公共的功能，一般用来传递被所有解释器共享的数据，后面的解释器可以从这里获取这些值。
客户端（Client）：主要任务是将需要分析的句子或表达式转换成使用解释器对象描述的抽象语法树，然后调用解释器的解释方法，当然也可以通过环境角色间接访问解释器的解释方法。


// 抽象角色 定义解释器
public interface Expression {
    int interpret();
}
@AllArgsConstructor
public class NumberTerminal implements Expression {
    private int number;
    @Override
    public int interpret() {
        return this.number;
    }
}
// 非终结表达式（抽象类）
@AllArgsConstructor
public abstract class NonTerminal implements Expression {
    protected Expression left;
    protected Expression right;
}
// 非终结表达式（加法）
public class PlusNonTerminal extends NonTerminal implements Expression {
    public PlusNonTerminal(Expression left, Expression right) {
        super(left, right);
    }
    @Override
    public int interpret() {
        return left.interpret() + right.interpret();
    }
}
// 非终结表达式（减法）
public class MinusNonTerminal extends NonTerminal implements Expression {
    public MinusNonTerminal(Expression left, Expression right) {
        super(left, right);
    }
    @Override
    public int interpret() {
        return left.interpret() - right.interpret();
    }
}
// 非终结表达式（乘法）
public class MclNonTerminal extends NonTerminal implements Expression {
    public MclNonTerminal(Expression left, Expression right) {
        super(left, right);
    }
    @Override
    public int interpret() {
        return left.interpret() * right.interpret();
    }
}
// 非终结表达式（除法）
public class DivisionNonTerminal extends NonTerminal implements Expression {
    public DivisionNonTerminal(Expression left, Expression right) {
        super(left, right);
    }
    @Override
    public int interpret() {
        return left.interpret() / right.interpret();
    }
}
// 计算器类（实现运算逻辑）
public class Cal {
    private Expression left;
    private Expression right;
    private Integer result;
    public Cal(String expression) {
        this.parse(expression);
    }
    private Integer parse(String expression) {
        // 获取表达式元素
        String [] elements = expression.split(" ");
        for (int i = 0; i < elements.length; i++) {
            String element = elements[i];
            // 判断是否是运算符号
            if (OperatorUtils.isOperator(element)) {
                // 运算符号的右边就是右终结符
                right = new NumberTerminal(Integer.valueOf(elements[++i]));
                //计算结果
                result = OperatorUtils.getNonTerminal(left, right, element).interpret();
                // 计算结果重新成为左终结符
                left = new NumberTerminal(result);
            } else {
                left = new NumberTerminal(Integer.valueOf(element));
            }
        }
        return result;
    }
    public Integer cal() {
        return result;
    }
 
}
// 操作工具类
public class OperatorUtils {
    // 判断是不是非终结符
    public static boolean isOperator(String symbol) {
        return symbol.equals("+") || symbol.equals("-") || symbol.equals("*")|| symbol.equals("/");
    }
    // 简单工厂
    public static NonTerminal getNonTerminal(Expression left, Expression right, String symbol) {
        if (symbol.equals("+")) {
            return new PlusNonTerminal(left, right);
        } else if (symbol.equals("-")) {
            return new MinusNonTerminal(left, right);
        } else if (symbol.equals("*")) {
            return new MclNonTerminal(left, right);
        } else if (symbol.equals("/")) {
            return new DivisionNonTerminal(left, right);
        }
        return null;
    }
}
    // 测试
    // PS：此处进行的逻辑仅仅实现从左到右运算，并没有先乘除后加减的逻辑
    public static void main(String[] args) {
        System.out.println(new Cal("10 + 20 - 40 * 60").cal()); // -600
        System.out.println(new Cal("20 + 50 - 60 * 2").cal()); // 20
    }
	
Spring中的解释器模式：

public static void main(String[] args) {
        ExpressionParser expressionParser = new SpelExpressionParser();
        org.springframework.expression.Expression expression = expressionParser.parseExpression("10 + 20 + 30 * 4");
        Integer value = expression.getValue(Integer.class);
        System.out.println(value); // 150
        expression = expressionParser.parseExpression("(10+20+30)*4");
        value = expression.getValue(Integer.class);
        System.out.println(value); // 240
    }

可以看到Spring中解释器写的是比较完善的，不仅有先乘除后加减和先括号进行运算的日常计算规则，
而且对于空格也并没有要求，仅需要写出完整的表达式即可运算出来。

适用场景：
一些重复出现的问题可以用一种简单的语言来进行表述。
一个简单语法需要解释的场景。

优点：
扩展性强：在解释器模式中由于语法是由很多类表示的，当语法规则更改时，只需修改相应的非终结符表达式即可；若扩展语法时，只需添加相应非终结符类即可。
增加了新的解释表达式的方式。
易于实现文法：解释器模式对应的文法应当是比较简单且易于实现的，过于复杂的语法并不适合使用解释器模式。

缺点：
语法规则较复杂时，会引起类膨胀。
执行效率比较低


数据结构与算法：
数据结构与算法相辅相成，不会孤立存在；数据结构是为算法服务的，
算法是作用在特定的数据结构之上（如数组具有随机访问的特点，二分查找算法需要用数组来存储数据）。
数据结构是静态的，只是组织数据的一种形式，若不在它的基础上操作、构建算法、孤立存在的数据结构是没有意义的。

数据结构与算法之数组：
数组是一种线性表数据结构，它用一组连续的内存空间，来存储一组具有相同类型的数据。

无序数组：
public class MyArray {
	//声明一个数组
	private long[] arr;
	
	//有效数据的长度
	private int elements;
	
	//无参构造函数，默认长度为50
	public MyArray(){
		arr = new long[50];
	}
	
	public MyArray(int maxsize){
		arr = new long[maxsize];
	}
	
	
	//添加数据
	public void insert(long value){
		arr[elements] = value;
		elements++;
	}
	
	//显示数据
	public void display(){
		System.out.print("[");
		for(int i = 0;i < elements;i++){
			System.out.print(arr[i] + " ");
		}
		System.out.println("]");
	}
	
	//根据下标查找数据
	public long get(int index){
		if(index >= elements || index < 0){
			throw new ArrayIndexOutOfBoundsException();
		}else{
			return arr[index];
		}
	}
	
	/**
	 * 根据值查询
	 * @param value 需要被查询的值
	 * @return 被查询值的下标
	 */
	public int search(int value){
		//声明一个变量i用来记录该数据的下标值
		int i ;
		for(i = 0;i < elements;i++){
			if(value == arr[i]){
				break;
			}
		}
		//如果查询到最后一个元素依然没有找到
		if(i == elements){
			return -1;
		}else{
			return i;
		}
	}
	
	//根据下标删除数据
	public void delete(int index){
		if(index >= elements || index < 0){
			throw new ArrayIndexOutOfBoundsException();
		}else{
			//删除该元素后，后面所有元素前移一位
			for(int i = index; i < elements;i++){
				arr[i] = arr[i+1];
			}
			elements--;
		}
		
	}
	/**
	 * 替换数据
	 * @param index 被替换的下标
	 * @param newvalue 新的数据
	 */
	public void change(int index,int newvalue){
		if(index >= elements || index < 0){
			throw new ArrayIndexOutOfBoundsException();
		}else{
			arr[index] = newvalue;
		}
	} 
}

有序数组：
public class MyOrderArray { 
	private long[] arr;
	
	private int elements;
	
	public MyOrderArray(){
		arr = new long[50];
	}
	
	public MyOrderArray(int maxsize){
		arr = new long[maxsize];
	}
	
	//添加数据
	public void insert(int value){
		int i;
		for(i = 0;i < elements;i++){
			if(arr[i] > value){
				break;
			}
		}
		for(int j = elements;j > i;j--){
			arr[j] = arr[j -1];
		}
		arr[i] = value;
		elements++;
	}
	
	
	//删除数据
	public void delete(int index){
		if(index >=elements || index <0){
			throw new ArrayIndexOutOfBoundsException();
		}else{
			for(int i = index;i < elements; i++){
				arr[i] = arr[i+1];
			}
			elements--;
		}
	}
	
	//修改数据
	public void change(int index,int value){
		if(index >= elements || index < 0){
			throw new IndexOutOfBoundsException();
		}else{
			arr[index] = value;
		}
	}
	
	//根据下标查询数据
	public long get(int index){
		if(index >= elements || index < 0){
			throw new IndexOutOfBoundsException();
		}else{
			return arr[index];
		}
	}
	
	//展示数据
	public void display(){
		System.out.print("[");
		for(int i = 0; i < elements;i++){
			System.out.print(arr[i] + " ");
		}
		System.out.println("]");
	}
	
	
	//二分法查找数据
	public int binarySearch(long value){
			//声明三个指针分别指向数组的头，尾，中间
			int low = 0;
			int pow = elements;
			int middle = 0;
			
			while(true){
				middle = (low + pow) / 2;
				//如果中指针所指的值等于带查询数
				if(arr[middle] == value){
					return middle;
				}else if(low > pow){
					return -1;
				}else{
					if(arr[middle] > value){
						//待查询的数在左边,右指针重新改变指向
						pow = middle-1;
					}else{
						//带查询的数在右边，左指针重新改变指向
						low = middle +1;
					}
				}
			}
	}
}


数据结构与算法之栈：
栈（stack）是一种容器，可存入数据元素、访问元素、删除元素，它的特点在于只能允许在容器的一端（称为栈顶端指标，英语：top）
进行加入数据（英语：push）和输出数据（英语：pop）的运算。

1.由于栈数据结构只允许在一端进行操作，因而按照后进先出的原理运作。
2.栈可以用顺序表实现，也可以用链表实现。

package mystack;

public class MyStack {

    //栈的底层使用数组来存储数据
    //private int[] elements;
    int[] elements; //测试时使用

    public MyStack() {
        elements = new int[0];
    }

    //添加元素
    public void push(int element) {
        //创建一个新的数组
        int[] newArr = new int[elements.length + 1];
        //把原数组中的元素复制到新数组中
        for (int i = 0; i < elements.length; i++) {
            newArr[i] = elements[i];
        }
        //把添加的元素放入新数组中
        newArr[elements.length] = element;
        //使用新数组替换旧数组
        elements = newArr;
    }

    //取出栈顶元素
    public int pop() {
        //当栈中没有元素
        if (is_empty()) {
            throw new RuntimeException("栈空");
        }
        //取出数组的最后一个元素
        int element = elements[elements.length - 1];
        //创建一个新数组
        int[] newArr = new int[elements.length - 1];
        //原数组中除了最后一个元素其他元素放入新数组
        for (int i = 0; i < elements.length - 1; i++) {
            newArr[i] = elements[i];
        }
        elements = newArr;
        return element;
    }

    //查看栈顶元素
    public int peek() {
        return elements[elements.length - 1];
    }

    //判断栈是否为空
    public boolean is_empty() {
        return elements.length == 0;
    }

    //查看栈的元素个数
    public int size() {
        return elements.length;
    }
}
	

数据结构与算法之队列：
队列（Queue）是只允许在一端进行插入操作，而在另一端进行删除操作的线性表。
队列是一种先进先出的（First In First Out）的线性表，简称FIFO。允许插入的一端为队尾，允许删除的一端为队头。
1.队列不允许在中间部位进行操作！
2.同栈一样，队列也可以用顺序表或者链表实现。

public class MyQueue {

    int[] elements;

    public MyQueue() {
        elements = new int[0];
    }

    //入队
    public void enqueue(int element) {
        //创建一个新的数组
        int[] newArr = new int[elements.length + 1];
        //把原数组中的元素复制到新数组中
        for (int i = 0; i < elements.length; i++) {
            newArr[i] = elements[i];
        }
        //把添加的元素放入新数组中
        newArr[elements.length] = element;
        //使用新数组替换旧数组
        elements = newArr;
    }

    //出队
    public int dequeue() {
        if (isEmpty()) {
            throw new RuntimeException("队空，无数据");
        }
        //把数组中第1个元素取出来
        int element = elements[0];
        //创建一个新数组
        int[] newArr = new int[elements.length - 1];
        //把原数组除了第一个数据，其他存入新数组
        for (int i = 0; i < newArr.length; i++) {
            newArr[i] = elements[i + 1];
        }
        //新数组替换旧数组
        elements = newArr;

        return element;
    }

    //判断是否队空
    public boolean isEmpty() {
        return elements.length==0;
    }

    //获取队列长度
    public int size() {
        return elements.length;
    }
}

数据结构与算法之链表：
单链表：
单链表也叫单向链表，是链表中最简单的一种形式，它的每个节点包含两个域，一个信息域（元素域）和一个链接域。
这个链接指向链表中的下一个节点，而最后一个节点的链接域则指向一个空值。	
1.表元素域data用来存放具体的数据。
2.链接域next用来存放下一个节点的位置。

//一个节点
public class Node {

    //节点内容
    int data;
    //下一个节点
    Node next;

    public Node(int data) {
        this.data = data;
    }

    //为节点追加节点
    public Node append(Node node) {
        //当前节点
        Node currentNode = this;
        //循环向后找
        while (true) {
            //取出下一个节点
            Node nextNode = currentNode.next();
            //如果下一个节点为null，当前节点已经是最后一个节点
            if (nextNode == null) {
                break;
            }
            //赋给当前节点，无线向后找
            currentNode = nextNode;
        }
        //把需要追加的节点，追加为找到的当前节点（最后一个节点）的下一个节点
        currentNode.next = node;
        return this;
    }

    //显示所有节点信息
    public void show() {
        Node currentNode = this;
        while (true) {
            System.out.print(currentNode.data + " ");
            //取出下一个节点
            currentNode = currentNode.next;
            //如果是最后一个节点
            if (currentNode == null) {
                break;
            }
        }
        System.out.println();
    }

    //插入一个节点作为当前节点的下一个节点
    public void after(Node node) {
        //取出下一个节点，作为下下一个节点
        Node nextNext = next;
        //把新节点作为当前节点的下一个节点
        this.next = node;
        //把下下一个节点设置为新节点的下一个节点
        node.next = nextNext;

    }

    //删除下一个节点
    public void removeNode() {
        //取出下下一个节点
        Node newNext = next.next;
        //把下下一个节点设置为当前节点的下一个节点
        this.next = newNext;
    }

    //获取下一个节点
    public Node next() {
        return this.next;
    }

    //获取节点中的数据
    public int getData() {
        return this.data;
    }

    //判断节点是否为最后一个节点
    public boolean isLast() {
        return next == null;
    }

}

双向链表：
在双向链表中有两个指针域，一个是指向前驱结点的prev，一个是指向后继结点的next指针。

public class DoubleNode {
    //上一个节点
    DoubleNode pre = this;
    //下一个节点
    DoubleNode next = this;
    //节点数据
    int data;

    public DoubleNode(int data) {
        this.data = data;
    }

    //增加节点
    public void after(DoubleNode node) {
        //原来的下一个节点
        DoubleNode nextNext = next;
        //新节点作为当前节点的下一个节点
        this.next = node;
        //当前节点作为新节点的前一个节点
        node.pre = this;
        //原来的下一个节点作为新节点的下一个节点
        node.next = nextNext;
        //原来的下一个节点的上一个节点为新节点
        nextNext.pre = node;
    }

    //获取下一个节点
    public DoubleNode getNext() {
        return this.next;
    }

    //获取上一个节点
    public DoubleNode getPre() {
        return this.pre;
    }

    //获取数据
    public int getData() {
        return this.data;
    }
}

数据结构与算法之树：
树是一种非线性数据结构，它是由一个或多个结点组成的。

树的结构：
1、根节点：最顶上的唯一的一个；
2、双亲节点：子节点的父节点就叫做双亲节点；
3、子节点：双亲节点所产生的节点就是子节点
4、路径：从根节点到目标节点所走的路程叫做路径；
5、节点的度：有多少个子节点就有多少的度（最下面的度一定为0，所以是叶子节点）
6、节点的权：在节点中所存的数字
7、叶子节点：没有子节点的节点，就是没有下一代的节点；
8、子树：在整棵树中将一部分看成也是一棵树，即使只有一个节点也是一棵树，不过这个树是在整个大树职中的，包含的关系
9、层：就是族谱中有多少代的人；
10、树的高度：树的最大的层数：就是层数中的最大值
11、森林：多个树组成的集合

树结构的优点：
1.空间利用率比较高
2.可以非常快速地查找到最大值和最小值

树的种类：
无序树：树中任意节点的子节点之间没有顺序关系，这种树称为无序树，也称为自由树；

有序树：树中任意节点的子节点之间有顺序关系，这种树称为有序树；

二叉树：每个节点最多含有两个子树的树称为二叉树；
完全二叉树：对于一颗二叉树，假设其深度为d(d>1)。除了第d层外，其它各层的节点数目均已达最大值，且第d层所有节点从左向右连续地紧密排列，这样的二叉树被称为完全二叉树，其中满二叉树的定义是所有叶节点都在最底层的完全二叉树;
平衡二叉树（AVL树）：当且仅当任何节点的两棵子树的高度差不大于1的二叉树；
排序二叉树（二叉查找树（英语：Binary Search Tree），也称二叉搜索树、有序二叉树）；
霍夫曼树（用于信息编码）：带权路径最短的二叉树称为哈夫曼树或最优二叉树；
B树：一种对读写操作进行优化的自平衡的二叉查找树，能够保持数据有序，拥有多余两个子树。

数据结构与算法之排序算法：

直接插入排序：

算法思想：
直接插入排序的核心思想就是：将数组中的所有元素依次跟前面已经排好的元素相比较，
如果选择的元素比已排序的元素小，则交换，直到全部元素都比较过。
因此，从上面的描述中我们可以发现，直接插入排序可以用两个循环完成：

第一层循环：遍历待比较的所有数组元素
第二层循环：将本轮选择的元素(selected)与已经排好序的元素(ordered)相比较。
如果：selected > ordered，那么将二者交换

代码实现：
#直接插入排序
def insert_sort(L):
    #遍历数组中的所有元素，其中0号索引元素默认已排序，因此从1开始
    for x in range(1,len(L)):
    #将该元素与已排序好的前序数组依次比较，如果该元素小，则交换
    #range(x-1,-1,-1):从x-1倒序循环到0
        for i in range(x-1,-1,-1):
    #判断：如果符合条件则交换
            if L[i] > L[i+1]:
                temp = L[i+1]
                L[i+1] = L[i]
                L[i] = temp

希尔排序
算法思想：
希尔排序的算法思想：将待排序数组按照步长gap进行分组，然后将每组的元素利用直接插入排序的方法进行排序；
每次将gap折半减小，循环上述操作；当gap=1时，利用直接插入，完成排序。
同样的：从上面的描述中我们可以发现：希尔排序的总体实现应该由三个循环完成：

第一层循环：将gap依次折半，对序列进行分组，直到gap=1
第二、三层循环：也即直接插入排序所需要的两次循环。具体描述见上。

代码实现：
#希尔排序
def insert_shell(L):
    #初始化gap值，此处利用序列长度的一般为其赋值
    gap = (int)(len(L)/2)
    #第一层循环：依次改变gap值对列表进行分组
    while (gap >= 1):
    #下面：利用直接插入排序的思想对分组数据进行排序
    #range(gap,len(L)):从gap开始
        for x in range(gap,len(L)):
    #range(x-gap,-1,-gap):从x-gap开始与选定元素开始倒序比较，每个比较元素之间间隔gap
            for i in range(x-gap,-1,-gap):
    #如果该组当中两个元素满足交换条件，则进行交换
                if L[i] > L[i+gap]:
                    temp = L[i+gap]
                    L[i+gap] = L[i]
                    L[i] =temp
    #while循环条件折半
        gap = (int)(gap/2)


简单选择排序
算法思想：
简单选择排序的基本思想：比较+交换。

从待排序序列中，找到关键字最小的元素；
如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换；
从余下的 N - 1 个元素中，找出关键字最小的元素，重复(1)、(2)步，直到排序结束。
因此我们可以发现，简单选择排序也是通过两层循环实现。
第一层循环：依次遍历序列当中的每一个元素
第二层循环：将遍历得到的当前元素依次与余下的元素进行比较，符合最小元素的条件，则交换。

代码实现：
# 简单选择排序
def select_sort(L):
#依次遍历序列中的每一个元素
    for x in range(0,len(L)):
#将当前位置的元素定义此轮循环当中的最小值
        minimum = L[x]
#将该元素与剩下的元素依次比较寻找最小元素
        for i in range(x+1,len(L)):
            if L[i] < minimum:
                temp = L[i];
                L[i] = minimum;
                minimum = temp
#将比较后得到的真正的最小值赋值给当前位置
        L[x] = minimum	

堆排序
堆的概念
堆：本质是一种数组对象。特别重要的一点性质：<b>任意的叶子节点小于（或大于）它所有的父节点</b>。对此，又分为大顶堆和小顶堆，大顶堆要求节点的元素都要大于其孩子，小顶堆要求节点元素都小于其左右孩子，两者对左右孩子的大小关系不做任何要求。
利用堆排序，就是基于大顶堆或者小顶堆的一种排序方法。下面，我们通过大顶堆来实现。

基本思想：
堆排序可以按照以下步骤来完成：

1.首先将序列构建称为大顶堆；
（这样满足了大顶堆那条性质：位于根节点的元素一定是当前序列的最大值）

2.取出当前大顶堆的根节点，将其与序列末尾元素进行交换；
（此时：序列末尾的元素为已排序的最大值；由于交换了元素，当前位于根节点的堆并不一定满足大顶堆的性质）
对交换后的n-1个序列元素进行调整，使其满足大顶堆的性质；

3.重复2.3步骤，直至堆中只有1个元素为止
	
#-------------------------堆排序--------------------------------
#**********获取左右叶子节点**********
def LEFT(i):
    return 2*i + 1
def RIGHT(i):
    return 2*i + 2
#********** 调整大顶堆 **********
#L:待调整序列 length: 序列长度 i:需要调整的结点
def adjust_max_heap(L,length,i):
#定义一个int值保存当前序列最大值的下标
    largest = i
#执行循环操作：两个任务：1 寻找最大值的下标；2.最大值与父节点交换
    while (1):
#获得序列左右叶子节点的下标
        left,right = LEFT(i),RIGHT(i)
#当左叶子节点的下标小于序列长度 并且 左叶子节点的值大于父节点时，将左叶子节点的下标赋值给largest
        if (left < length) and (L[left] > L[i]):
            largest = left
            print('左叶子节点')
        else:
            largest = i
#当右叶子节点的下标小于序列长度 并且 右叶子节点的值大于父节点时，将右叶子节点的下标值赋值给largest
        if (right < length) and (L[right] > L[largest]):
            largest = right
            print('右叶子节点')
#如果largest不等于i 说明当前的父节点不是最大值，需要交换值
        if (largest != i):
            temp = L[i]
            L[i] = L[largest]
            L[largest] = temp
            i = largest
            print(largest)
            continue
        else:
            break
#********** 建立大顶堆 **********
def build_max_heap(L):
    length = len(L)
    for x in range((int)((length-1)/2),-1,-1):
        adjust_max_heap(L,length,x)
#********** 堆排序 **********
def heap_sort(L):
#先建立大顶堆，保证最大值位于根节点；并且父节点的值大于叶子结点
    build_max_heap(L)
#i：当前堆中序列的长度.初始化为序列的长度
    i = len(L)
#执行循环：1. 每次取出堆顶元素置于序列的最后(len-1,len-2,len-3...)
#         2. 调整堆，使其继续满足大顶堆的性质，注意实时修改堆中序列的长度
    while (i > 0):
        temp = L[i-1]
        L[i-1] = L[0]
        L[0] = temp
#堆中序列长度减1
        i = i-1
#调整大顶堆
        adjust_max_heap(L,i,0)

冒泡排序
基本思想:
冒泡排序思路比较简单：

将序列当中的左右元素，依次比较，保证右边的元素始终大于左边的元素；
（ 第一轮结束后，序列最后一个元素一定是当前序列的最大值；）
对序列当中剩下的n-1个元素再次执行步骤1。
对于长度为n的序列，一共需要执行n-1轮比较
（利用while循环可以减少执行次数）

#冒泡排序
def bubble_sort(L):
    length = len(L)
#序列长度为length，需要执行length-1轮交换
    for x in range(1,length):
#对于每一轮交换，都将序列当中的左右元素进行比较
#每轮交换当中，由于序列最后的元素一定是最大的，因此每轮循环到序列未排序的位置即可
        for i in range(0,length-x):
            if L[i] > L[i+1]:
                temp = L[i]
                L[i] = L[i+1]
                L[i+1] = temp

快速排序
算法思想：
快速排序的基本思想：挖坑填数+分治法
从序列当中选择一个基准数(pivot)
在这里我们选择序列当中第一个数最为基准数
将序列当中的所有数依次遍历，比基准数大的位于其右侧，比基准数小的位于其左侧
重复步骤1.2，直到所有子集当中只有一个元素为止。
用伪代码描述如下：
1．i =L; j = R; 将基准数挖出形成第一个坑a[i]。
2．j--由后向前找比它小的数，找到后挖出此数填前一个坑a[i]中。
3．i++由前向后找比它大的数，找到后也挖出此数填到前一个坑a[j]中。
4．再重复执行2，3二步，直到i==j，将基准数填入a[i]中

代码实现：
#快速排序
#L：待排序的序列；start排序的开始index,end序列末尾的index
#对于长度为length的序列：start = 0;end = length-1
def quick_sort(L,start,end):
    if start < end:
        i , j , pivot = start , end , L[start]
        while i < j:
#从右开始向左寻找第一个小于pivot的值
            while (i < j) and (L[j] >= pivot):
                j = j-1
#将小于pivot的值移到左边
            if (i < j):
                L[i] = L[j]
                i = i+1 
#从左开始向右寻找第一个大于pivot的值
            while (i < j) and (L[i] < pivot):
                i = i+1
#将大于pivot的值移到右边
            if (i < j):
                L[j] = L[i]
                j = j-1
#循环结束后，说明 i=j，此时左边的值全都小于pivot,右边的值全都大于pivot
#pivot的位置移动正确，那么此时只需对左右两侧的序列调用此函数进一步排序即可
#递归调用函数：依次对左侧序列：从0 ~ i-1//右侧序列：从i+1 ~ end
        L[i] = pivot
#左侧序列继续排序
        quick_sort(L,start,i-1)
#右侧序列继续排序
        quick_sort(L,i+1,end)

归并排序
算法思想：
1.归并排序是建立在归并操作上的一种有效的排序算法，该算法是采用分治法的一个典型的应用。
它的基本操作是：将已有的子序列合并，达到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。
2.归并排序其实要做两件事：
分解----将序列每次折半拆分
合并----将划分后的序列段两两排序合并
因此，归并排序实际上就是两个操作，拆分+合并
3.如何合并？
L[first...mid]为第一段，L[mid+1...last]为第二段，并且两端已经有序，现在我们要将两端合成达到L[first...last]并且也有序。
首先依次从第一段与第二段中取出元素比较，将较小的元素赋值给temp[]
重复执行上一步，当某一段赋值结束，则将另一段剩下的元素赋值给temp[]
此时将temp[]中的元素复制给L[]，则得到的L[first...last]有序
4.如何分解？
在这里，我们采用递归的方法，首先将待排序列分成A,B两组；然后重复对A、B序列分组；
直到分组后组内只有一个元素，此时我们认为组内所有元素有序，则分组结束。

代码实现:

# 归并排序
#这是合并的函数
# 将序列L[first...mid]与序列L[mid+1...last]进行合并
def mergearray(L,first,mid,last,temp):
#对i,j,k分别进行赋值
    i,j,k = first,mid+1,0
#当左右两边都有数时进行比较，取较小的数
    while (i <= mid) and (j <= last):
        if L[i] <= L[j]:
            temp[k] = L[i]
            i = i+1
            k = k+1
        else:
            temp[k] = L[j]
            j = j+1
            k = k+1
#如果左边序列还有数
    while (i <= mid):
        temp[k] = L[i]
        i = i+1
        k = k+1
#如果右边序列还有数
    while (j <= last):
        temp[k] = L[j]
        j = j+1
        k = k+1
#将temp当中该段有序元素赋值给L待排序列使之部分有序
    for x in range(0,k):
        L[first+x] = temp[x]
# 这是分组的函数
def merge_sort(L,first,last,temp):
    if first < last:
        mid = (int)((first + last) / 2)
#使左边序列有序
        merge_sort(L,first,mid,temp)
#使右边序列有序
        merge_sort(L,mid+1,last,temp)
#将两个有序序列合并
        mergearray(L,first,mid,last,temp)
# 归并排序的函数
def merge_sort_array(L):
#声明一个长度为len(L)的空列表
    temp = len(L)*[None]
#调用归并排序
    merge_sort(L,0,len(L)-1,temp)	


基数排序
算法思想:
基数排序：通过序列中各个元素的值，对排序的N个元素进行若干趟的“分配”与“收集”来实现排序。
分配：我们将L[i]中的元素取出，首先确定其个位上的数字，根据该数字分配到与之序号相同的桶中
收集：当序列中所有的元素都分配到对应的桶中，再按照顺序依次将桶中的元素收集形成新的一个待排序列L[ ]
对新形成的序列L[]重复执行分配和收集元素中的十位、百位...直到分配完该序列中的最高位，则排序结束
根据上述“基数排序”的展示，我们可以清楚的看到整个实现的过程

代码实现:
#************************基数排序****************************
#确定排序的次数
#排序的顺序跟序列中最大数的位数相关
def radix_sort_nums(L):
    maxNum = L[0]
#寻找序列中的最大数
    for x in L:
        if maxNum < x:
            maxNum = x
#确定序列中的最大元素的位数
    times = 0
    while (maxNum > 0):
        maxNum = (int)(maxNum/10)
        times = times+1
    return times
#找到num从低到高第pos位的数据
def get_num_pos(num,pos):
    return ((int)(num/(10**(pos-1))))%10
#基数排序
def radix_sort(L):
    count = 10*[None]       #存放各个桶的数据统计个数
    bucket = len(L)*[None]  #暂时存放排序结果
#从低位到高位依次执行循环
    for pos in range(1,radix_sort_nums(L)+1):
        #置空各个桶的数据统计
        for x in range(0,10):
            count[x] = 0
        #统计当前该位(个位，十位，百位....)的元素数目
        for x in range(0,len(L)):
            #统计各个桶将要装进去的元素个数
            j = get_num_pos(int(L[x]),pos)
            count[j] = count[j]+1
        #count[i]表示第i个桶的右边界索引
        for x in range(1,10):
            count[x] = count[x] + count[x-1]
        #将数据依次装入桶中
        for x in range(len(L)-1,-1,-1):
            #求出元素第K位的数字
            j = get_num_pos(L[x],pos)
            #放入对应的桶中，count[j]-1是第j个桶的右边界索引
            bucket[count[j]-1] = L[x]
            #对应桶的装入数据索引-1
            count[j] = count[j]-1
        # 将已分配好的桶中数据再倒出来，此时已是对应当前位数有序的表
        for x in range(0,len(L)):
            L[x] = bucket[x]

				
注解、反射、动态代理→ Java Spring  
JavaBean:JavaBean 是一种JAVA语言写成的可重用组件。为写成JavaBean，类必须是具体的和公共的，并且具有无参数的构造器。
JavaBean 通过提供符合一致性设计模式的公共方法将内部域暴露成员属性，set和get方法获取。

作用：JavaBean是一种可重用的Java组件，它可以被Applet、Servlet、JSP等Java应用程序调用。
也可以可视化地被Java开发工具使用。它包含属性(Properties)、方法(Methods)、事件(Events)等特性。

Java注解：
生成文档，通过代码里标识的元数据生成javadoc文档。
编译检查，通过代码里标识的元数据让编译器在编译期间进行检查验证。
编译时动态处理，编译时通过代码里标识的元数据动态处理，例如动态生成代码。
运行时动态处理，运行时通过代码里标识的元数据动态处理，例如使用反射注入实例。

四种元注解：
 ▷ Retention：指定注解的作用范围，三种 SOURCE,CLASS,RUNTIME
 ▷ Target：指定注解可以在哪些地方使用
 ▷ Documented ：指定该注解是否会在 javadoc 体现
 ▷ Inherited：子类会继承父类注解

注解的注意事项：
▷ 注解仅存在于源码中，在class字节码文件中不包含
▷ 默认的保留策略，注解会在class字节码文件中存在，但运行时无法获得，
▷ 注解会在class字节码文件中存在，在运行时可以通过反射获取到
▷ 首先要明确生命周期长度 SOURCE < CLASS < RUNTIME ，前者能作用的地方后者一定也能作用。
        ①：一般如果需要在 运行时去动态获取注解信息，那只能用 RUNTIME 注解；
        ②：如果要在 编译时进行一些预处理操作，比如生成一些辅助代码（如 ButterKnife），就用 CLASS注解；
        ③：如果只是做一些 检查性的操作如 @Override 和 @SuppressWarnings，则可选用 SOURCE 注解。

		
Retention注解：
只能用于修饰一个 Annotation 定义, 用于指定该 Annotation 可以保留多长时间,
@Rentention 包含一个 RetentionPolicy 类型的成员变量, 使用 @Rentention 时必须为该 value 成员变量指定值（值有三种）。
▲ 三种值：
▷ RetentionPolicy.SOURCE: 编译器使用后，直接丢弃这种策略的注释。
▷ RetentionPolicy.CLASS: 编译器将把注解记录在 class 文件中。当运行 Java 程序时 , JVM 不会保留注解。 这是默认值。
▷ RetentionPolicy.RUNTIME: 编译器将把注解记录在 class 文件中。当运行 Java 程序时 , JVM 会保留注解。程序可以通过反射获取该注解。

3、Target 注解
用于修饰 Annotation 定义，指定被修饰的 Annotation 能用于修饰哪些程序元素。@Target 也包含一个名为 value 的成员变量。

​​​​​​4、Documented 注解
@Documented: 用于指定被该元注解修饰的 Annotation 类将被javadoc 工具提取成文档，即在生成文档时，可以看到该注解。
注意：
定义为@Documented 的注解必须设置Retention值为RUNTIME。

5、Inherited 注解
被@Inherited 修饰的注解 将具有继承性，如果某个类使用了被 @Inherited修饰的注解，则其子类将自动具有该注解
	
Java动态代理：
代理类在程序运行时创建的代理方式被成为动态代理。在静态代理中，代理类（RenterProxy）是自己已经定义好了的，在程序运行之前就已经编译完成。
而动态代理是在运行时根据我们在Java代码中的“指示”动态生成的。Java运用了反射实现了动态代理。
动态代理相较于静态代理的优势在于可以很方便的对代理类的所有函数进行统一管理，如果我们想在每个代理方法前都加一个方法，如果代理方法很多，我们需要在每个代理方法都要写一遍，很麻烦。而动态代理则不需要。
代码实现：创建RenterInvocationHandler类，这个类实现了InvocationHandler接口，并持有一个被代理类的对象，InvocationHandler中有一个invoke方法，所有执行代理对象的方法都会被替换成执行invoke方法。
然后通过反射在invoke方法中执行代理类的方法。在代理过程中，在执行代理类的方法前或者后可以执行自己的操作，这就是spring aop的主要原理。

动态代理之Cglib代理：
动态代理需要被代理类实现接口，如果被代理类没有实现接口，那么这么实现动态代理？这时候就需要用到CGLib了。这种代理方式就叫做CGlib代理。
Cglib代理也叫作子类代理，他是通过在内存中构建一个子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，然后加入自己需要的操作。因为使用的是继承的方式，所以不能代理final 类
动态代理与CGLib动态代理都是实现Spring AOP的基础。如果加入容器的目标对象有实现接口,用动态代理，如果目标对象没有实现接口,用Cglib代理。

动态代理的运用：Spring
Spring框架：Spring→SpringMVC→SpringBoot 
Spring 框架就像一个家族，有众多衍生产品例如 boot、security、jpa等等。但他们的基础都是Spring 的 ioc和 aop ioc 提供了依赖注入的容器 aop ，解决了面向横切面的编程，然后在此两者的基础上实现了其他延伸产品的高级功能。Spring MVC是基于 Servlet 的一个 MVC 框架 主要解决 WEB 开发的问题，因为 Spring 的配置非常复杂，各种XML、 JavaConfig、hin处理起来比较繁琐。于是为了简化开发者的使用，从而创造性地推出了Spring boot，约定优于配置，简化了spring的配置流程。
Spring的工作原理其实是，Spring在启动时读取bean配置信息，这里bean配置信息包括xml文件、Java类#Configuration、注解#AutoWired，
存放到Bean注册表，并根据Bean注册表实例化Bean，实际上就是实例化Bean的实现类，然后将Bean实例放到Spring容器中。

Spring的IOC是通过反射来实现的：
在Spring中，通过IOC可以将实现类、参数信息等配置在其对应的配置文件中，当需要更改实现类或参数信息时，只需要修改配置文件即可。
Spring的IOC实现原理利用的就是Java的反射机制，Spring的工厂类会帮我们完成配置文件的读取、利用反射机制注入对象等工作，
我们可以通过bean的名称获取对应的对象。

Spring AOP（Aspect-Oriented Programming）是面向切面编程的一种实现技术，主要用于实现程序功能的统一维护。
Spring AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。
Spring AOP的三种使用方式：

注解方式：通过注解的方式配置切入点，然后定义增强处理。
XML方式：通过XML配置文件的方式配置切入点，然后定义增强处理。
Java方式：通过Java配置类的方式配置切入点，然后定义增强处理。


Spring AOP是运用反射来实现的：
Spring AOP即面向切面编程，是Spring核心之一，其可以快速横向扩展。在Spring中，每一个代理实例都有一个关联的调用处理程序对象，
它实现了接口InvocationHandler，该接口的invoke方法用于处理代理实例上的方法调用。
在Spring中，当需要使用该Service时，Spring会自动将对应的Bean注入到需要它的地方，这个过程是自动的，
对于开发人员来说是透明的，无需手动进行配置。


Spring IOC举例————IOC操作Bean管理（基于XML方式）
1、基于 xml 方式创建对象
（1）在 spring 配置文件中，使用 bean 标签，标签里面添加对应属性，就可以实现对象创建
（2）在 bean 标签有很多属性，介绍常用的属性
* id 属性：唯一标识
* class 属性：类全路径（包类路径）
（3）创建对象时候，默认也是执行无参数构造方法完成对象创建
<bean id = "user" class = "Spring.User"></bean>

2、基于 xml 方式注入属性
（1）DI：依赖注入，就是注入属性

3、第一种注入方式：使用 set 方法进行注入
（1）创建类，定义属性和对应的 set 方法
/**
* 演示使用 set 方法进行注入属性
*/
public class Book {
 //创建属性
 private String bname;
 private String bauthor;
 //创建属性对应的 set 方法
 public void setBname(String bname) {
 this.bname = bname;
 }
 public void setBauthor(String bauthor) {
 this.bauthor = bauthor;
 }
}
（2）在 spring 配置文件配置对象创建，配置属性注入
<!--2 set 方法注入属性-->
<bean id="book" class="com.atguigu.spring5.Book">
 <!--使用 property 完成属性注入
 name：类里面属性名称
 value：向属性注入的值
 -->
 <property name="bname" value="易筋经"></property>
 <property name="bauthor" value="达摩老祖"></property>
</bean>
4、第二种注入方式：使用有参数构造进行注入
（1）创建类，定义属性，创建属性对应有参数构造方法
public class Orders {
 //属性
 private String oname;
 private String address;
 //有参数构造
 public Orders(String oname,String address) {
 this.oname = oname;
 this.address = address;
 }
}
（2）在 spring 配置文件中进行配置
<!--3 有参数构造注入属性-->
<bean id="orders" class="com.atguigu.spring5.Orders">
 <constructor-arg name="oname" value="电脑"></constructor-arg>
 <constructor-arg name="address" value="China"></constructor-arg>
</bean>

Spring AOP举例
1、创建类，在类里面定义方法
public class User {
 public void add() {
 System.out.println("add.......");
 }
}
2、创建增强类（编写增强逻辑）
（1）在增强类里面，创建方法，让不同方法代表不同通知类型
//增强的类
public class UserProxy {
 public void before() {//前置通知
 System.out.println("before......");
 }
}

3、进行通知的配置
（1）在 spring 配置文件中，开启注解扫描
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans" 
 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
 xmlns:context="http://www.springframework.org/schema/context" 
 xmlns:aop="http://www.springframework.org/schema/aop" 
 xsi:schemaLocation="http://www.springframework.org/schema/beans 
http://www.springframework.org/schema/beans/spring-beans.xsd 
 http://www.springframework.org/schema/context 
http://www.springframework.org/schema/context/spring-context.xsd 
 http://www.springframework.org/schema/aop 
http://www.springframework.org/schema/aop/spring-aop.xsd">
 <!-- 开启注解扫描 -->
 <context:component-scan basepackage="com.atguigu.spring5.aopanno"></context:component-scan>

 （2）使用注解创建 User 和 UserProxy 对象
//被增强的类
@Component
public class User{
//代码部分
}

//增强的类
@Component
public class UserProxy{
//代码部分
}

（3）在增强类上面添加注解 @Aspect
//增强的类
@Component
@Aspect //生成代理对象
public class UserProxy {

（4）在 spring 配置文件中开启生成代理对象
<!-- 开启 Aspect 生成代理对象-->
<aop:aspectj-autoproxy></aop:aspectj-autoproxy>

4、配置不同类型的通知
（1）在增强类的里面，在作为通知方法上面添加通知类型注解，使用切入点表达式配置
//增强的类
@Component
@Aspect //生成代理对象
public class UserProxy {
 //前置通知
 //@Before 注解表示作为前置通知
 @Before(value = "execution(* com.atguigu.spring5.aopanno.User.add(..))")
 public void before() {
 System.out.println("before.........");
 }
 //后置通知（返回通知）
 @AfterReturning(value = "execution(* 
com.atguigu.spring5.aopanno.User.add(..))")
 public void afterReturning() {
 System.out.println("afterReturning.........");
 }
 //最终通知
 @After(value = "execution(* com.atguigu.spring5.aopanno.User.add(..))")
 public void after() {
 System.out.println("after.........");
 }
 //异常通知
 @AfterThrowing(value = "execution(* 
com.atguigu.spring5.aopanno.User.add(..))")
 public void afterThrowing() {
 System.out.println("afterThrowing.........");
 }
 //环绕通知
 @Around(value = "execution(* com.atguigu.spring5.aopanno.User.add(..))")
 public void around(ProceedingJoinPoint proceedingJoinPoint) throws 
Throwable {
 System.out.println("环绕之前.........");
 //被增强的方法执行
 proceedingJoinPoint.proceed();
 System.out.println("环绕之后.........");
 }
}
5、相同的切入点抽取
//相同切入点抽取
@Pointcut(value = "execution(* com.atguigu.spring5.aopanno.User.add(..))")
public void pointdemo() {
}
//前置通知
//@Before 注解表示作为前置通知
@Before(value = "pointdemo()")
public void before() {
 System.out.println("before.........");
}
6、有多个增强类多同一个方法进行增强，设置增强类优先级
（1）在增强类上面添加注解 @Order(数字类型值)，数字类型值越小优先级越高
@Component
@Aspect
@Order(1)
public class PersonProxy

SpringMVC：
SpringMVC是一个基于Java的Web应用开发框架，用于构建灵活、可扩展的Web应用程序。它是Spring框架的一部分，提供了一种模型-视图-控制器（MVC）的架构模式，用于将应用程序的不同方面分离开来。
SpringMVC使用了前端控制器（Front Controller）设计模式，其中DispatcherServlet充当中央调度器，负责接收所有的客户端请求并将其分派给相应的处理程序（Controller）。
它还提供了丰富的功能，如请求映射、数据绑定、数据验证、视图解析和国际化支持等，以简化Web应用程序的开发过程。
通过使用SpringMVC，开发人员可以轻松地构建可维护和可扩展的Web应用程序，实现松耦合和高度可测试性。它还与其他Spring框架模块（如Spring IoC和Spring AOP）紧密集成，提供了全面的企业级开发解决方案。

Spring MVC的功能
Spring MVC提供了一种轻度耦合的方式来开发web应用。
Spring MVC是Spring的一个模块，是一个web框架。通过Dispatcher Servlet, ModelAndView 和 View Resolver，开发web应用变得很容易。
解决的问题领域是网站应用程序或者服务开发——URL路由、Session、模板引擎、静态Web资源等等。

Spring MVC获取请求参数的过程：
1、通过ServletAPI获取
将HttpServletRequest作为控制器方法的形参，此时HttpServletRequest类型的参数表示封装了当前请
求的请求报文的对象
@RequestMapping("/testParam")
public String testParam(HttpServletRequest request){
String username = request.getParameter("username");
String password = request.getParameter("password");
System.out.println("username:"+username+",password:"+password);
return "success";
}

2、通过控制器方法的形参获取请求参数
在控制器方法的形参位置，设置和请求参数同名的形参，当浏览器发送请求，匹配到请求映射时，在
DispatcherServlet中就会将请求参数赋值给相应的形参

<a th:href="@{/testRest/1/admin}">测试路径中的占位符-->/testRest</a><br>
@RequestMapping("/testRest/{id}/{username}")

@RequestMapping("/testParam")
public String testParam(String username, String password){
System.out.println("username:"+username+",password:"+password);
return "success";
}


注：
若请求所传输的请求参数中有多个同名的请求参数，此时可以在控制器方法的形参中设置字符串
数组或者字符串类型的形参接收此请求参数
若使用字符串数组类型的形参，此参数的数组中包含了每一个数据
若使用字符串类型的形参，此参数的值为每个数据中间使用逗号拼接的结果

3、@RequestParam
@RequestParam是将请求参数和控制器方法的形参创建映射关系
@RequestParam注解一共有三个属性：
value：指定为形参赋值的请求参数的参数名
required：设置是否必须传输此请求参数，默认值为true
若设置为true时，则当前请求必须传输value所指定的请求参数，若没有传输该请求参数，且没有设置
defaultValue属性，则页面报错400：Required String parameter 'xxx' is not present；若设置为
false，则当前请求不是必须传输value所指定的请求参数，若没有传输，则注解所标识的形参的值为
null
defaultValue：不管required属性值为true或false，当value所指定的请求参数没有传输或传输的值
为""时，则使用默认值为形参赋值

4、@RequestHeader
@RequestHeader是将请求头信息和控制器方法的形参创建映射关系
@RequestHeader注解一共有三个属性：value、required、defaultValue，用法同@RequestParam

5、@CookieValue
@CookieValue是将cookie数据和控制器方法的形参创建映射关系
@CookieValue注解一共有三个属性：value、required、defaultValue，用法同@RequestParam

6、通过POJO获取请求参数
可以在控制器方法的形参位置设置一个实体类类型的形参，此时若浏览器传输的请求参数的参数名和实
体类中的属性名一致，那么请求参数就会为此属性赋值

Spring MVC的工作流程：
用户通过视图层发送请求到服务器，在服务器中请求被Controller接收，
Controller调用相应的Model层处理请求，处理完毕将结果返回到Controller，
Controller再根据请求处理的结果找到相应的View视图，渲染数据后最终响应给浏览器。

<form th:action="@{/testpojo}" method="post">
用户名：<input type="text" name="username"><br>
密码：<input type="password" name="password"><br>
性别：<input type="radio" name="sex" value="男">男<input type="radio"
name="sex" value="女">女<br>
年龄：<input type="text" name="age"><br>
邮箱：<input type="text" name="email"><br>
<input type="submit">
</form>
@RequestMapping("/testpojo")
public String testPOJO(User user){
System.out.println(user);
return "success";
}
//最终结果-->User{id=null, username='张三', password='123', age=23, sex='男',
email='123@qq.com'}

7、解决获取请求参数的乱码问题
解决获取请求参数的乱码问题，可以使用SpringMVC提供的编码过滤器CharacterEncodingFilter，但是
必须在web.xml中进行注册
注：
SpringMVC中处理编码的过滤器一定要配置到其他过滤器之前，否则无效


SpringMVC流程
1、用户发送请求至前端控制器DispatcherServlet。
2、DispatcherServlet收到请求调用HandlerMapping处理器映射器。
3、处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。
4、DispatcherServlet调用HandlerAdapter处理器适配器。
5、HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。
6、Controller执行完成返回ModelAndView。
7、HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。
8、DispatcherServlet将ModelAndView传给ViewReslover视图解析器。
9、ViewReslover解析后返回具体View。
10、DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。
11、DispatcherServlet响应用户。

以下组件通常使用框架提供实现：

DispatcherServlet：作为前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。
HandlerMapping：通过扩展处理器映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。
HandlAdapter：通过扩展处理器适配器，支持更多类型的处理器。
ViewResolver：通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。


域对象共享数据
1、使用ServletAPI向request域对象共享数据
<form th:action="@{/testpojo}" method="post">
用户名：<input type="text" name="username"><br>
密码：<input type="password" name="password"><br>
性别：<input type="radio" name="sex" value="男">男<input type="radio"
name="sex" value="女">女<br>
年龄：<input type="text" name="age"><br>
邮箱：<input type="text" name="email"><br>
<input type="submit">
</form>
@RequestMapping("/testpojo")
public String testPOJO(User user){
System.out.println(user);
return "success";
}
//最终结果-->User{id=null, username='张三', password='123', age=23, sex='男',
email='123@qq.com'}
<!--配置springMVC的编码过滤器-->
<filter>
<filter-name>CharacterEncodingFilter</filter-name>
<filterclass>org.springframework.web.filter.CharacterEncodingFilter</filter-class>
<init-param>
<param-name>encoding</param-name>
<param-value>UTF-8</param-value>
</init-param>
<init-param>
<param-name>forceResponseEncoding</param-name>
<param-value>true</param-value>
</init-param>
</filter>
<filter-mapping>
<filter-name>CharacterEncodingFilter</filter-name>
<url-pattern>/*</url-pattern>
</filter-mapping>
注：
SpringMVC中处理编码的过滤器一定要配置到其他过滤器之前，否则无效

总结：
SpringMVC本质上是对Java Web Servlet的封装，使得开发Java Web项目没有那么臃肿。
Spring MVC是后端渲染式的后台开发框架，没有做到前后端分离，对前端开发人员也要求有Java Web的开发环境。
前端人员作出的静态Html页面，也需要进行整合，改为Spring MVC里的View。


SSH：
SSH框架是Struts、Spring、Hibernate的一个合成框架，目前市场上比较流行的框架中也有它的身影。Struts是一个基于MVC模式的应用框架，如果学过Servlet。
那么其本质和Servlet差不多，MVC模式主要包括模型(Model)，视图(View)，控制器(Controller)，而Struts主要作为控制器来建立模型和视图的数据交互。
本文介绍的Struts以Struts2为主。它通过拦截器处理客户的各种请求。Spring使用基本的JavaBean来完成以前只可能由EJB完成的事情，Spring的核-fl,主要控制翻转(IOC)和面向切面(AOP)，
简单的说Spring是一种分层的轻量级开源框架。Spring更像是一个容器，将所有配置的Struts和Hibernate中的东西都放置进来，只要能够做好配置，它就会找到相应的位置，进行处理。
Hibernate是一个开源代码的对象映射框架，是根据JDBC技术基础衍生而来的，它将直接操作原来的数据库变为直接操作数据表后生成的Java类，实现了对象编程思维来操纵数据库。SSH框架中的各种技术相互协调、配合。实现了这一强大的框架。


SSM：SSM（Spring+SpringMVC+MyBatis）框架集由Spring、MyBatis两个开源框架整合而成（SpringMVC是Spring中的部分内容），常作为数据源较简单的web项目的框架。

1.spring MVC ＋ spring +mybatis，是标准的MVC设计模式，将整个系统划分为显示层，Controller层，Service层，DAO层四层

使用Spring MVC负责请求的转发和视图管理

spring实现业务对象管理，mybatis作为数据对象的持久化引擎。

2、Spring是一个开源框架，Spring是一个轻量级的控制反转（IoC）和面向切面（AOP）的容器框架，还能更好的让其他框架整合。
3、Spring MVC框架是有一个MVC框架，通过实现Model-View-Controller模式来很好地将数据、业务与展现进行分离。
4、MyBatis 是一个基于Java的持久层框架


关于GET请求的安全性：
Get是不安全的，因为在传输过程，数据被放在请求的URL中，
而如今现有的很多服务器、代理服务器或者用户代理都会将请求URL记录到日志文件中，然后放在某个地方，
这样就可能会有一些隐私的信息被第三方看到。另外，用户也可以在浏览器上直接看到提交的数据，
一些系统内部消息将会一同显示在用户面前。Post的所有操作对用户来说都是不可见的。

关于servlet：
Servlet（Server Applet）是Java Servlet的简称，称为小服务程序或服务连接器，用Java编写的服务器端程序，具有独立于平台和协议的特性，主要功能在于交互式地浏览和生成数据，生成动态Web内容。
狭义的Servlet是指Java语言实现的一个接口，广义的Servlet是指任何实现了这个Servlet接口的类，一般情况下，人们将Servlet理解为后者。Servlet运行于支持Java的应用服务器中。
从原理上讲，Servlet可以响应任何类型的请求，但绝大多数情况下Servlet只用来扩展基于HTTP协议的Web服务器。
最早支持Servlet标准的是JavaSoft的Java Web Server，此后，一些其它的基于Java的Web服务器开始支持标准的Servlet。

Servlet的工作原理：
Servlet接口定义了Servlet与servlet容器之间的契约。这个契约是：Servlet容器将Servlet类载入内存，并产生Servlet实例和调用它具体的方法。但是要注意的是，在一个应用程序中，每种Servlet类型只能有一个实例。
用户请求致使Servlet容器调用Servlet的Service（）方法，并传入一个ServletRequest对象和一个ServletResponse对象。ServletRequest对象和ServletResponse对象都是由Servlet容器（例如TomCat）封装好的，
并不需要程序员去实现，程序员可以直接使用这两个对象。
ServletRequest中封装了当前的Http请求，因此，开发人员不必解析和操作原始的Http数据。
ServletResponse表示当前用户的Http响应，程序员只需直接操作ServletResponse对象就能把响应轻松的发回给用户。
对于每一个应用程序，Servlet容器还会创建一个ServletContext对象。这个对象中封装了上下文（应用程序）的环境详情。
每个应用程序只有一个ServletContext。每个Servlet对象也都有一个封装Servlet配置的ServletConfig对象。

Servlet的生命周期：
init( ),service( ),destroy( )是Servlet生命周期的方法，代表了Servlet的生命周期，即Servlet从“出生”到“工作”再到“死亡 ”的过程。
Servlet容器（例如TomCat）会根据下面的规则来调用这三个方法：
1.init( ),当Servlet第一次被请求时，Servlet容器就会开始调用这个方法来初始化一个Servlet对象出来，
但是这个方法在后续请求中不会在被Servlet容器调用，就像人只能“出生”一次一样。我们可以利用init（ ）方法来执行相应的初始化工作。
调用这个方法时，Servlet容器会传入一个ServletConfig对象进来从而对Servlet对象进行初始化。

2.service( )方法，每当请求Servlet时，Servlet容器就会调用这个方法。就像人一样，需要不停的接受老板的指令并且“工作”。
第一次请求时，Servlet容器会先调用init( )方法初始化一个Servlet对象出来，然后会调用它的service( )方法进行工作，
但在后续的请求中，Servlet容器只会调用service方法了。

3.destory,当要销毁Servlet时，Servlet容器就会调用这个方法，就如人一样，到时期了就得死亡。
在卸载应用程序或者关闭Servlet容器时，就会发生这种情况，一般在这个方法中会写一些清除代码。


关于转发和重定向的区别：

1.重定向访问服务器两次，转发只访问服务器一次。
2.转发页面的URL不会改变，而重定向地址会改变
3.转发只能转发到自己的web应用内，重定向可以重定义到任意资源路径。
4.转发相当于服务器跳转，相当于方法调用，在执行当前文件的过程中转向执行目标文件，两个文件(当前文件和目标文件)属于同一次请求，前后页共用一个request，
可以通过此来传递一些数据或者session信息，request.setAttribute()和 request.getAttribute()。而重定向会产生一个新的request，不能共享request域信息与请求参数
5.由于转发相当于服务器内部方法调用，所以转发后面的代码仍然会执行(转发之后记得return)；重定向代码执行之后是方法执行完成之后进行重定向操作，也就是访问第二个请求，如果是方法的最后一行进行重定向那就会马上进行重定向(重定向也需要return)。
6.无论是RequestDispatcher.forward方法，还是HttpServletResponse.sendRedirect方法，在调用它们之前，都不能有内容已经被实际输出到了客户端。如果缓冲区中已经有了一些内容，这些内容将被从缓冲区中移除。


关于JSP和Servlet的区别：
1.  不同之处在哪？
Servlet在Java代码中通过HttpServletResponse对象动态输出HTML内容
JSP在静态HTML内容中嵌入Java代码，Java代码被动态执行后生成HTML内容

2.  各自的特点
Servlet能够很好地组织业务逻辑代码，但是在Java源文件中通过字符串拼接的方式生成动态HTML内容会导致代码维护困难、可读性差
JSP虽然规避了Servlet在生成HTML内容方面的劣势，但是在HTML中混入大量、复杂的业务逻辑同样也是不可取的

关于浏览器渲染数据：
前端渲染:
前端渲染就是指后端返回JSON数据或者JSONP数据，在前端利用预先写的html模板，循环读取JSON数据或者JSONP数据，进行选取，拼接，并且将这些数据插入页面来达到渲染效果。
后端渲染：
前端进行数据请求，后端用后台模板引擎直接生成html，前端接受到数据之后，直接插入页面。

前端渲染和后端渲染两者的好处和坏处:
1.前端渲染:
好处：网络传输数据量小。不占用服务端运算资源（解析模板），模板在前端（很有可能仅部分在前端），改结构变交互都前端自己来了，改完自己调就行。
坏处：前端耗时较多，对前端工作人员水平要求相对较高。前端代码较多，因为部分以前在后台处理的交互逻辑交给了前端处理。占用少部分客户端运算资源用于解析模板。
2.后端渲染
好处：前端耗时少，即减少了首屏时间，模板统一在后端。前端（相对）省事，不占用客户端运算资源（解析模板）
坏处：占用服务器资源。

前端渲染与后端渲染对比：
    
前端渲染：
页面呈现速度：主要受限于带宽和客户端机器的好坏，优化效果好，可以逐步动态展开内容，感觉上会更快一点。
可维护性强，前后端分离，各施其职，代码一目明了。
SEO友好度(seo=Search(搜索) Engine(引擎) Optimization(优化),即搜索引擎优化)：差，大量使用ajax，多数浏览器不能抓取ajax数据。
编码效率：高，前后端各自只做自己擅长的东西，后端最后只输出接口，不用管页面呈现，只要前后端人员能力不错，效率不会低。
    
后端渲染：
页面呈现速度：快，受限于用户的带宽
可维护性：差（前后端不分离）
SEO友好度：好,后端的数据一步搞定,直接生成相对应的模板网页
编码效率：低（有时候可能手忙脚乱,找不到数据对应的位置或者数据）

Spring Boot的功能及实现原理:

众所周知Spring框架需要进行大量的配置，Spring Boot引入自动配置的概念，让项目设置变得很容易。
Spring Boot本身并不提供Spring框架的核心特性以及扩展功能，只是用于快速、敏捷地开发新一代基于Spring框架的应用程序。也就是说，它并不是用来替代Spring的解决方案，而是和Spring框架紧密结合用于提升Spring开发者体验的工具。同时它集成了大量常用的第三方库配置(例如Jackson, JDBC, Mongo, Redis, Mail等等)，Spring Boot应用中这些第三方库几乎可以零配置的开箱即用(out-of-the-box)，大部分的Spring Boot应用都只需要非常少量的配置代码，开发者能够更加专注于业务逻辑。
Spring Boot只是承载者，辅助你简化项目搭建过程的。如果承载的是WEB项目，使用Spring MVC作为MVC框架，那么工作流程和你上面描述的是完全一样的，因为这部分工作是Spring MVC做的而不是Spring Boot。
对使用者来说，换用Spring Boot以后，项目初始化方法变了，配置文件变了，另外就是不需要单独安装Tomcat这类容器服务器了，maven打出jar包直接跑起来就是个网站，但你最核心的业务逻辑实现与业务流程实现没有任何变化。
所以，用最简练的语言概括就是：
Spring 是一个“引擎”；
Spring MVC 是基于Spring的一个 MVC 框架 ；
Spring Boot 是基于Spring4的条件注册的一套快速开发整合包。

SpringBoot中定制Web扩展配置：WebMvcConfigurerAdapter接口
这是一个接口，里边声明了很多的方法，例如拦截器，视图解析器，格式转化器。
如果想在webmvc中添加自己的功能，只需要去WebMvcConfigurer看看想增加什么功能，然后按照源码去写。

在SpringBoot中创建Servlet：
方式一： 通过注解扫描方式实现
创建一个servlet类

package com.liuhaiyang.springboot.servlet;
 
import javax.servlet.ServletException;
import javax.servlet.annotation.WebServlet;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import java.io.IOException;
 
//servlet第一种方式
@WebServlet(urlPatterns = "/myservlet")  //定义请求路径，通过该路径能访问到这个servlet
public class MyServlet extends HttpServlet {
 
    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        resp.getWriter().println("My Springboot-servlet-1");
        resp.getWriter().flush();
        resp.getWriter().close();
    }
 
    @Override
    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        super.doPost(req, resp);
    }
}

在SpringBoot项目的入口类上方使用注解 @ServletComponentScan 注解来扫描Servlet中的注解即可。

package com.liuhaiyang.springboot;
 
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.boot.web.servlet.ServletComponentScan;
 
@SpringBootApplication
@ServletComponentScan(basePackages = "com.liuhaiyang.springboot.servlet")   //第一种的注解
public class SpringbootTest13Application {
 
    public static void main(String[] args) {
        SpringApplication.run(SpringbootTest13Application.class, args);
    }
 
}

方式二：通过 SpringBoot 的配置类实现（组件注册）

再次创建一个Servlet类。

package com.liuhaiyang.springboot.servlet2;
 
import javax.servlet.ServletException;
import javax.servlet.annotation.WebServlet;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import java.io.IOException;
 
 
//servlet第二种方式
public class MyServlet extends HttpServlet {
 
    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        resp.getWriter().println("My Springboot-servlet-2");
        resp.getWriter().flush();
        resp.getWriter().close();
    }
 
    @Override
    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        super.doPost(req, resp);
    }
}

编写一个 Spring Boot 的配置类，在该类中注册 Servlet
创建 ServletConfig 配置类

package com.liuhaiyang.springboot.config;
 
import com.liuhaiyang.springboot.servlet2.MyServlet;
import org.springframework.boot.web.servlet.ServletRegistrationBean;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
 
@Configuration //该注解将此类定义为配置类（相当于一个xml文件）
public class ServletConfig {
    //@Bean是一个方法级别上的注解，主要用于配置类里 相当于<beans> <bean id="" class="" > </beans>
    @Bean
    public ServletRegistrationBean myServletRegistrationBean(){
        ServletRegistrationBean servletRegistrationBean=new ServletRegistrationBean(new MyServlet(),"/myservlet");
        return servletRegistrationBean;
    }
}


什么是过滤器（Filter）
过滤器，是在java web中将你传入的request、response提前过滤掉一些信息，或者提前设置一些参数。
然后再传入Servlet或Struts2的 action进行业务逻辑处理。比如过滤掉非法url（不是login.do的地址请求，如果用户没有登陆都过滤掉），
或者在传入Servlet或Struts2的action前统一设置字符集，或者去除掉一些非法字符。
过滤器处于客户端与Web资源（Servlet、JSP、HTML）之间，客户端与Web资源之间的请求和响应都要通过过滤器进行过滤。

什么是拦截器（Interceptor）
拦截器是一种面向方面/切面编程（AOP Aspect-Oriented Programming），而面向切面就是将多个模块的通用服务进行分离，
如权限管理、日志服务，他们在多个模块中都会用到，就可以将其各自封装为一个可重用模块。
而这些通用服务的具体实现是通过拦截器来完成，比如用户客户端访问一些保密模块都应先通过权限审查的拦截器来进行权限审查，
确定用户是否具有该项操作的权限后方能向下执行。在面向切面编程的就是在你的service或者一个方法前调用一个方法，
或者在方法后调用一个方法，比如动态代理就是拦截器的简单实现，在你调用方法前打印出字符串（或者做其它业务逻辑的操作），
也可以在你调用方法后打印出字符串，甚至在你抛出异常的时候做业务逻辑的操作。

二者区别
1、拦截器是基于java的反射机制的，而过滤器是基于函数回调（职责链）
2、过滤器依赖与servlet容器，而拦截器不依赖与servlet容器
3、拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用
4、拦截器可以访问action上下文、值栈里的对象，而过滤器不能
5、在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次
6、拦截器可以获取IOC容器中的各个bean，而过滤器不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。

通俗理解：
（1）过滤器（Filter）：当你有一堆东西的时候，你只希望选择符合你要求的某一些东西。定义这些要求的工具，就是过滤器。（理解：就是一堆字母中取一个B）
（2）拦截器（Interceptor）：在一个流程正在进行的时候，你希望干预它的进展，甚至终止它进行，这是拦截器做的事情。（理解：就是一堆字母中，干预它，通过验证的少点，顺便干点别的东西

触发时机与执行顺序
触发时机：
拦截器与过滤器触发时机不一样
过滤器是在请求进入容器后，但请求进入servlet之前进行预处理的。请求结束返回也是，是在servlet处理完后，返回给前端之前。

过滤器包裹servlet，servlet包裹住拦截器。

执行顺序 ：
过滤前 - 拦截前 - Action处理 - 拦截后 - 过滤后。个人认为过滤是一个横向的过程，首先把客户端提交的内容进行过滤(例如未登录用户不能访问内部页面的处理)；过滤通过后，拦截器将检查用户提交数据的验证，做一些前期的数据处理，接着把处理后的数据发给对应的Action；Action处理完成返回后，拦截器还可以做其他过程(还没想到要做啥)，再向上返回到过滤器的后续操作。

例子：自定义拦截器
@Component
public class MyInterceptor implements HandlerInterceptor {
  @Override
  public boolean preHandle(HttpServletRequest request, HttpServletResponse response,
                           Object handler) throws Exception {
		return true;
		}
		
需要再写一个自己的配置类：
@Configuration
public class MyConfiguration implements WebMvcConfigurer {
	 @Override
	 public void addInterceptors(InterceptorRegistry registry) {
		  //将我们自定义的拦截器加入配置
	 	 InterceptorRegistration interceptor = registry.addInterceptor(new MyInterceptor());
		  //设置拦截的url
		  interceptor.addPathPatterns("/user/**");
	 }
}

SpringBoot配置嵌入式Servlet容器：
1、找到接口ConfigurableEmbeddedServletContainer
2、找到接口EmbeddedServletContainerCustomizer
3、注册Servlet、Filter、Listener
	>ServletRegistrationBean
	>FilterRegistrationBean
	>ServletListenerRegistrationBean

配置Servlet:
@WebServlet(urlPatterns = "/portal/*")
public class HelloServlet extends HttpServlet {
    public HelloServlet() {
        super();
    }
 
    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        String name = req.getParameter("name");
        System.out.println("=====================Hello "+ name +", this is doGet Filter===================");
        PrintWriter writer = resp.getWriter();
        writer.write("Your request parameter is " + name);
        writer.flush();
        writer.close();
    }
 
    @Override
    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        System.out.println("=====================Hello doPost Filter===================");
        super.doPost(req, resp);
    }
 
    @Override
    protected void doPut(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        System.out.println("=====================Hello doPut Filter===================");
        super.doPut(req, resp);
    }
}

配置Filter：
@WebFilter(urlPatterns = "/*", filterName = "helloFilter")
public class HelloFilter implements Filter {
 
    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
        System.out.println("================init filter===================");
    }
 
    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
        System.out.println("=================this is filer method====================");
        filterChain.doFilter(servletRequest, servletResponse);
    }
 
    @Override
    public void destroy() {
        System.out.println("==========================destroy method===================");
    }
}

配置Listener：
package com.learn.listener;
 
import javax.servlet.ServletContextEvent;
import javax.servlet.ServletContextListener;
import javax.servlet.annotation.WebListener;
 
/**
 * springBoot整合Listener
 *
 *<listener>
 *	<listener-class>com.learn.listener.FirstListener</listener-class>
 *</listener>
 */
@WebListener
public class MyListener implements ServletContextListener {
 
	@Override
	public void contextDestroyed(ServletContextEvent arg0) {
		// TODO Auto-generated method stub
 
	}
 
	@Override
	public void contextInitialized(ServletContextEvent arg0) {
		System.out.println("Listener...init......");
 
	}
 
}

Spring与SpringBoot常用注解：
@SpringBootApplication：实现自动化装配，启动SpringBoot，包含@Configuration、@EnableAutoConfiguration、@ComponentScan通常用在主类上
@Component：普通pojo注入spring容器
@Service：Service注入Spring容器
@Controller：Controller注入容器
@Repository：Dao注入容器
@ResponseBody：将java对象转为json格式的数据
@RestController：该注解是@Controller和@ResponseBody的结合体，一般用于类，作用等于在类上面添加了@ResponseBody和@Controller
@AutoWired：默认按类型装配，如果发现找到多个bean，则按照name方式比对，如果还有多个，则报出异常
@Qualifier：spring的注解，按名字注入 一般当出现两个及以上bean时,不知道要注入哪个，结合@AutoWired使用
@Resource：默认按名称注入例如@Resource(name = “zhaozhao”)则根据name属性注入找不到则报错，
若无name属性则根据属性名称注入，如果匹配不成功则按照类型匹配匹配不成功则报错。
@RequestMapping：@RequestMapping（url），通过该注解就可以通过配置的url进行访问，方式可以是get或post请求，两种方式均可
@GetMapping：只是这个限定了只能是Get请求
@PostMapping：只是这个限定了只能是Post请求
@Value：用于获取bean的属性，一般用于读取配置文件的数据，作用在变量上 
@ConfigurationProperties：用于注入Bean属性，然后再通过当前Bean获取注入值，作用在类上 
@PropertySource：用于指定要读取的配置文件，可以和@Value或@ConfigurationProperties配合使用
@Configuration：作用于类上表示这是一个配置类，可理解为用spring的时候xml里面的< beans>标签 
@Bean：产生bean对象加入容器，作用于方法，可理解为用spring的时候xml里面的标签
@RequestParam：获取查询参数。即url?name=这种形式
@RequestBody：获取Body的参数，一般用于post获取参数 
@PathVariable：获取路径参数。即url/{id}这种形式 
@RequestHeader：获取请求头的信息 
@CookieValue：获取Cookie的信息

Spring Boot的启动类实现方式：
1、程序从main方法开始运行
2、使用SpringApplication.run()加载主程序类
3、主程序类需要标注@SpringBootApplication
4、@EnableAutoConfiguration是核心注解；
5、@Import导入所有的自动配置场景
6、@AutoConfigurationPackage定义默认的包扫描规则
7、程序启动扫描加载主程序类所在的包以及下面所有子包的组件；

Spring Boot使用的全局配置文件：
>application.properties
>application.yml

配置文件放在src/main/resources目录或者类路径/config下
.yml是YAML(YAML Aint Markup Language)编写的文件格式，YAML是一种直观的能够被电脑识别的的数据数据序列化格式，
比json、xml等更适合做配置文件

转载：https://www.zhihu.com/question/64671972/answer/223383505
作者：zhonghd
链接：https://www.jianshu.com/p/1d4d57a4db51
来源：简书
-------------------------------------------------------------------------------


J2EE应用程序开发技术：
前端技术：
HTML：
HTML 指的是超文本标记语言: HyperText Markup Language
HTML 允许你格式化文本，添加图片，创建链接、输入表单、框架和表格等等，并可将之存为文本文件，浏览器即可读取和显示。

HTML标签：
<!DOCTYPE html> 声明为 HTML5 文档
<html> 元素是 HTML 页面的根元素
<head> 元素包含了文档的元（meta）数据，如 <meta charset="utf-8"> 定义网页编码格式为 utf-8（由于在大部分浏览器中直接输出中文会出现乱码，所以要在头部将字符声明为UTF-8）
<title> 元素描述了文档的标题
<body> 元素包含了可见的页面内容
<h1> 元素定义一个大标题
<p> 元素定义一个段落

CSS：Cascading Style Sheet 层叠样式表
是一组样式设置的规则，用于控制页面的外观样式

CSS语法：
<head>
	<style>
		选择器{
			属性名：属性值;
			属性名：属性值;
		}
	</style>
</head>

JavaScript：JavaScript诞生于1995年，它的出现主要是用于处理网页中的前端验证。
所谓的前端验证，就是指检查用户输入的内容是否符合一定的规则。比如：用户名的长度，密码的长度，邮箱的格式等。

DOM概述：
当网页被加载时，浏览器会创建页面的文档对象模型（Document Object Model）。

通过DOM对象模型，JavaScript 获得创建动态 HTML ：

JavaScript 能改变页面中的所有 HTML 元素
JavaScript 能改变页面中的所有 HTML 属性
JavaScript 能改变页面中的所有 CSS 样式
JavaScript 能删除已有的 HTML 元素和属性
JavaScript 能添加新的 HTML 元素和属性
JavaScript 能对页面中所有已有的 HTML 事件作出反应
JavaScript 能在页面中创建新的 HTML 事件
换言之：HTML DOM 是关于如何获取、更改、添加或删除 HTML 元素的标准。


JSON：
JavaScript Object Notation（JavaScript 对象标记法），它是一种存储和交换数据的语法。
当数据在浏览器与服务器之间进行交换时，这些数据只能是文本，
JSON 属于文本并且我们能够把任何 JavaScript 对象转换为 JSON，然后将 JSON 发送到服务器。
我们也能把从服务器接收到的任何 JSON 转换为 JavaScript 对象。
以这样的方式，我们能够把数据作为 JavaScript 对象来处理，无需复杂的解析和转译。

JSON语法：
在json中，每一个数据项，都是由一个键值对（或者说是名值对）组成的，但是键必须是字符串，
且由双引号包围，而值必须是以下数据类型之一：

字符串（在 JSON 中，字符串值必须由双引号编写）
数字
对象（JSON 对象）
数组
布尔
null

数组（Array）用方括号(“[]”)表示。
对象（0bject）用大括号(“{}”)表示。
名称/值对(name/value）组合成数组和对象。
名称(name）置于双引号中，值（value）有字符串、数值、布尔值、null、对象和数组。
并列的数据之间用逗号(“,”）分隔

JSONArray可以添加JSONObject对象。
JSON 的值不可以是以下数据类型之一：

函数
日期
undefined

AJAX：
传统的web交互是用户触发一个http请求服务器，然后服务器收到之后，在做出响应到用户，并且返回一个新的页面，
每当服务器处理客户端提交的请求时，客户都只能空闲等待，并且哪怕只是一次很小的交互、
只需从服务器端得到很简单的一个数据，都要返回一个完整的HTML页，而用户每次都要浪费时间和带宽去重新读取整个页面。
这个做法浪费了许多带宽，由于每次应用的交互都需要向服务器发送请求，应用的响应时间就依赖于服务器的响应时间，
这导致了用户界面的响应比本地应用慢得多。

AJAX 的出现,刚好解决了传统方法的缺陷，AJAX 是一种用于创建快速动态网页的技术，通过在后台与服务器进行少量数据交换，
AJAX 可以使网页实现异步更新，这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。

AJAX的XMLHttpRequest对象：
AJAX 的核心是 XMLHttpRequest 对象。 所有现代浏览器都支持 XMLHttpRequest 对象。
XMLHttpRequest 对象用于幕后同服务器交换数据，这意味着可以更新网页的部分，而不需要重新加载整个页面。
所有现代浏览器（Chrom、IE7+、Firefox、Safari 以及 Opera）都有内建的 XMLHttpRequest 对象。

创建 XMLHttpRequest 的语法是：
variable = new XMLHttpRequest();

为了应对所有浏览器，包括 IE5 和 IE6，请检查浏览器是否支持 XMLHttpRequest 对象。
如果支持，创建 XMLHttpRequest 对象，如果不支持，则创建 ActiveX 对象：
var xhttp;
if (window.XMLHttpRequest) {
    xhttp = new XMLHttpRequest();
} else {
    // code for IE6, IE5
    xhttp = new ActiveXObject("Microsoft.XMLHTTP");
}

AJAX的请求整合：
JSON：
[
  {"name":"孙悟空","age":18,"gender":"男"},
  {"name":"猪八戒","age":19,"gender":"男"},
  {"name":"唐僧","age":20,"gender":"男"},
  {"name":"沙和尚","age":21,"gender":"男"}
]

index.html:
var Ajax = {
    get: function (url, fn) {
        var xhr = new XMLHttpRequest();
        xhr.open('GET', url, true);
        xhr.onreadystatechange = function () {
            if (xhr.readyState == 4 && xhr.status == 200 || xhr.status == 304) {
                fn.call(this, xhr.responseText);
            }
        };
        xhr.send();
    },
    post: function (url, data, fn) {
        var xhr = new XMLHttpRequest();
        xhr.open("POST", url, true);
        xhr.setRequestHeader("Content-Type", "application/x-www-form-urlencoded");
        xhr.onreadystatechange = function () {
            if (xhr.readyState == 4 && (xhr.status == 200 || xhr.status == 304)) {
                fn.call(this, xhr.responseText);
            }
        };
        xhr.send(data);
    }
};

// 演示GET请求
Ajax.get("users.json", function (response) {
    console.log(response);
});

// 演示POST请求
Ajax.post("users.json", "", function (response) {
    console.log(response);
});

Cookie:
Cookie 是一些数据，存储于你电脑上的文本文件中，当 web 服务器向浏览器发送 web 页面时，在连接关闭后，服务端不会记录用户的信息，Cookie 的作用就是用于解决 “如何记录客户端的用户信息”：

当用户访问 web 页面时，它的名字可以记录在 cookie 中。
在用户下一次访问该页面时，可以在 cookie 中读取用户访问记录。

一个的Cookie创建，添加了过期时间和路径：
document.cookie = "username=zhangsan; expires=Thu, 18 Dec 2043 12:00:00 GMT; path=/";

VUE：动态构建用户界面的渐进式JavaScript框架

Vue的特点：
遵循MVVM模式
编码简洁，体积小，运行效率高，适合移动/PC端开发
它本身只关注UI，可以引入其它第三方库开发项目

与其他JS框架的关联：
借鉴 Angular 的模板和数据绑定技术
借鉴 React 的组件化和虚拟DOM技术

Vue周边库：
vue-cli：vue脚手架
vue-resource
axios
vue-router：路由
vuex：状态管理
element-ui：基于vue的UI组件库（PC端）

VUE简单实现：

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>初识vue</title>
    <!-- 引入Vue -->
    <script src="../js/vue.js"></script>
</head>
<body>
    <!-- 准备好一个容器 -->
    <div id="root">
        <h1>Hello！{{name}}!</h1>
    </div>

    <script>
        Vue.config.productionTip = false // 阻止vue在启动时生成生产提示
        new Vue({
            el:'#root', //el用于指定当前Vue实例为哪个容器服务，值通常为css选择器字符串
            data:{ //data用于存储数据，数据共el所指定的容器去使用
                name:'JOJO'
            }
        })
    </script>
</body>
</html>

注意：

想让Vue工作，就必须创建一个Vue实例，且要传入一个配置对象
root容器里的代码依然符合html规范，只不过混入了一些特殊的Vue语法
root容器里的代码被称为Vue模板
Vue实例与容器是一一对应的
真实开发中只有一个Vue实例，并且会配合着组件一起使用
{{xxx}}中的xxx要写js表达式，且xxx可以自动读取到data中的所有属性
一旦data中的数据发生变化，那么模板中用到该数据的地方也会自动更新



后端技术：
Servlet → Java spring → springMVC
以前：J2EE应用框架 J2EE开发框架主要有Hibernate，Spring，Struts2，EXTJS，Json。

Hibernate：
Hibernate是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装，
它将POJO与数据库表建立映射关系，是一个全自动的orm框架，hibernate可以自动生成SQL语句，自动执行，
使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库。Hibernate可以应用在任何使用JDBC的场合，
既可以在Java的客户端程序使用，也可以在Servlet/JSP的Web应用中使用，
最具革命意义的是，Hibernate可以在应用EJB的JavaEE架构中取代CMP，完成数据持久化的重任。

创建映射配置文件：
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE hibernate-mapping PUBLIC 
    "-//Hibernate/Hibernate Mapping DTD 3.0//EN"
    "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd">
    
<hibernate-mapping>
	<!-- 建立类与表的映射 -->
	<class name="com.meimeixia.hibernate.demo01.Customer" table="cst_customer">
		<!-- 建立类中的属性与表中的主键相对应 -->
		<id name="cust_id" column="cust_id">
			<!-- 主键的生成策略，后面会讲，现在使用的是本地生成策略 -->
			<generator class="native" />
		</id>
		
		<!-- 建立类中的普通属性和表中的字段相对应 -->
		<property name="cust_name" column="cust_name" />
		<property name="cust_source" column="cust_source" />
		<property name="cust_industry" column="cust_industry" />
		<property name="cust_level" column="cust_level" />
		<property name="cust_phone" column="cust_phone" />
		<property name="cust_mobile" column="cust_mobile" />
	</class>
</hibernate-mapping>

创建核心配置文件：
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE hibernate-configuration PUBLIC
	"-//Hibernate/Hibernate Configuration DTD 3.0//EN"
	"http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd">
	
<hibernate-configuration>
	<session-factory>
		<!-- 下面是三个必须要有的配置 -->
		<!-- 配置连接MySQL数据库的基本参数 -->
		<property name="hibernate.connection.driver_class">com.mysql.jdbc.Driver</property>
		<property name="hibernate.connection.url">jdbc:mysql:///hibernate_demo01</property>
		<property name="hibernate.connection.username">root</property>
		<property name="hibernate.connection.password">liayun</property>
		
		<!-- 配置Hibernate的方言 -->
		<property name="hibernate.dialect">org.hibernate.dialect.MySQLDialect</property>
		
		<!-- 下面两个是可选的配置！ -->
		<!-- 打印sql语句 -->
		<property name="hibernate.show_sql">true</property>
		<!-- 格式化sql语句 -->
		<property name="hibernate.format_sql">true</property>
		
		<!-- 告诉Hibernate的核心配置文件加载哪个映射文件 -->
		<mapping resource="com/meimeixia/hibernate/demo01/Customer.hbm.xml"/>
	</session-factory>
</hibernate-configuration>

创建单元测试类：
package com.meimeixia.hibernate.demo01;

import org.hibernate.Session;
import org.hibernate.SessionFactory;
import org.hibernate.Transaction;
import org.hibernate.cfg.Configuration;
import org.junit.Test;

/**
 * Hibernate的入门案例
 * @author 
 *
 */
public class HibernateDemo1 {
	
	//保存用户的案例
	@Test
	public void demo1() {
		//1. 加载Hibernate的核心配置文件
		Configuration configuration = new Configuration().configure();
		//如果在Hibernate的核心配置文件没有设置加载哪个映射文件，则可手动加载映射文件
		//configuration.addResource("com/meimeixia/hibernate/demo01/Customer.hbm.xml");
		
		//2. 创建SessionFactory对象，类似于JDBC中的连接池
		SessionFactory sessionFactory = configuration.buildSessionFactory();
		
		//3. 通过SessionFactory获取到Session对象，类似于JDBC中的Connection
		Session session = sessionFactory.openSession();
		
		//4. 手动开启事务，（最好是手动开启事务）
		Transaction transaction = session.beginTransaction();
		
		//5. 编写代码
		Customer customer = new Customer();
		customer.setCust_name("张小敬aaa");
		
		session.save(customer);//保存一个用户
		
		//6. 事务提交
		transaction.commit();
		
		//7. 释放资源
		session.close();
		sessionFactory.close();
	}
	
}

Struts2：
Struts2框架是一个用于开发Java EE网络应用程序的开放源代码网页应用程序架构。它利用并延伸了Java Servlet API，鼓励开发者采用MVC架构。
Struts2以WebWork优秀的设计思想为核心，吸收了Struts框架的部分优点，提供了一个更加整洁的MVC设计模式实现的Web应用程序框架。

Strut2核心过滤器：web.xml
<?xml version="1.0" encoding="UTF-8"?>
<web-app version="2.5" 
	xmlns="http://java.sun.com/xml/ns/javaee" 
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
	xsi:schemaLocation="http://java.sun.com/xml/ns/javaee 
	http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd">
  <display-name></display-name>	
  <welcome-file-list>
    <welcome-file>index.jsp</welcome-file>
  </welcome-file-list>
  
  <!-- 配置struts2的核心过滤器 -->
  <!-- 所有请求都要通过核心过滤器 -->
  <filter>
  	<filter-name>struts2</filter-name>
  	<filter-class>org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter</filter-class>
  </filter>
  
  <filter-mapping>
  	<filter-name>struts2</filter-name>
  	<url-pattern>/*</url-pattern>
  </filter-mapping>
  
</web-app>

编写启动类：
package com.banana.struts.demo1;
/*
 * Struts2的Action类
 */
public class HelloAction {
	public String execute(){
		System.out.print("HelloAction执行了......");
		return "success";
	}
}

编写struts.xml来控制转向：
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE struts PUBLIC
	"-//Apache Software Foundation//DTD Struts Configuration 2.3//EN"
	"http://struts.apache.org/dtds/struts-2.3.dtd">

<struts>
	<!-- Struts2为了管理Action的配置，通过包进行管理 -->
	<!-- 配置Struts2的包 -->
	<package name="hello" extends="struts-default" namespace="/">
		<!-- 配置Action -->
		<action name="hello" class="com.banana.struts.demo1.HelloAction">
		<!-- 页面的跳转 -->
			<result name="success">/demo1/success.jsp</result>
		</action>
	</package>
</struts>

添加页面：
<%@ page language="java" import="java.util.*" pageEncoding="UTF-8"%>
<%
String path = request.getContextPath();
String basePath = request.getScheme()+"://"+request.getServerName()+":"+request.getServerPort()+path+"/";
%>

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <base href="<%=basePath%>">
    <title>My JSP 'demo1' starting page</title>
  </head>
  
  <body>
    <h1>Struts2的入门</h1>
    <h3><a href="${ pageContext.request.contextPath }/hello.action">Struts2的入门</a></h3>
  </body>
  
</html>


MVC设计模式：MVC指MVC模式的某种框架，它强制性地使应用程序的输入、处理和输出分开。
使用MVC应用程序被分成三个核心部件：模型、视图、控制器。

>M即model模型是指模型表示业务规则。在MVC的三个部件中，模型拥有最多的处理任务。即Bean层、mapper层和service层。
被模型返回的数据是中立的，模型与数据格式无关，这样一个模型能为多个视图提供数据，由于应用于模型的代码只需写一次就可以被多个视图重用，所以减少了代码的重复性。

>V即View视图是指用户看到并与之交互的界面。比如由html元素组成的网页界面，或者软件的客户端界面。
MVC的好处之一在于它能为应用程序处理很多不同的视图。在视图中其实没有真正的处理发生，它只是作为一种输出数据并允许用户操作的方式。

>C即controller控制器是指控制器接受用户的输入并调用模型和视图去完成用户的需求，控制器本身不输出任何东西和做任何处理。
它只是接收请求并决定调用哪个模型构件去处理请求，然后再确定用哪个视图来显式返回的数据。

MVC(Model模型、View视图、Control控制层)，将软件进行分层达到松耦合的效果。
通用的软件编程思想, 在MVC设计模式中认为, 任何软件都可以分三层：
控制层（Controller）、数据处理模型（Model）、负责展示数据的视图（View）。
在MVC设计思想中要求一个符合MVC设计思想的软件应该保证上面这三部分相互独立，互不干扰，每一个部分只负责自己擅长的部分。
如果某一个模块发生变化，应该尽量做到不影响其他两个模块。提高代码的可读性，实现程序间的松耦合、提高代码复用性。

Web开发中前后端分离和前后端不分离的对比：
https://www.cnblogs.com/liruilong/p/12244925.html

路由控制:前后端分离的情况后端在任何都会返回一个json数据，不涉及路由处理，即页面跳转全是由前端自己完成。
不分离的情况，路由跳转一般由后端完成，而且携带数据，通过重定向或请求转发实现，依赖Servlet中的内置对象。
返回数据:前后端分离的情况后端返回的整体划分上只有执行逻辑响应的消息实体类和对应的需要展示的数据分页类对应的JSON。
不分离后端返回的是经过视图解析器处理前的字符串。

请求方式:前后端分离的情况以Rest风格的方式处理为主,当执行增删改查对应http请求方法POST,DELEE,PUT,GET,
一般以异步请求为主,不分离情况一般同步异步结合。请求上以GET和POST为主。

注解使用：前后端分离，接收的数据是Json时需要@RequestBody作用在方法参数上。
用于将POST请求数据转化为实体类。返回数据时使用@ResponseBody用于将POST请求数据转化为实体类。
返回数据时使用@ResponseBody,作用在方法上,当然对于全局的也可以使用@RespController注解。
前后端不分离一般使用@RequestMapping，请求方式不用管。前后端不分离一般使用@RequestMapping，请求方式不用管。

数据库及持久层技术以及多种数据库的应用：
关系型数据库及其底层工作原理：
MYSQL体系结构：
Client Connectors
接入方。支持很多协议(JDBC、ODBC、.NET、PHP、Python、PERL、C 等)
Management Serveices & Utilities
系统管理和控制工具，mysqldump、 mysql复制集群、分区管理等
Connection Pool
连接池：管理缓冲用户连接、用户名、密码、权限校验、线程处理等需要缓存的需求
SQL Interface
SQL接口：接受用户的SQL命令，并且返回用户需要查询的结果
Parser
解析器，SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的
Optimizer
查询优化器，SQL语句在查询之前会使用查询优化器对查询进行优化
Cache和Buffer（高速缓存区）
查询缓存，如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据
pluggable storage Engines
插件式存储引擎。存储引擎是MySql中具体的与文件打交道的子系统
File System
文件系统，数据、日志（redo，undo）、索引、错误日志、查询记录、慢查询等

MYSQL架构：
连接层：最上层是一些客户端和连接服务。主要完成一些类似于连接处理、授权认证、及相关的安全方案。
在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。
服务器也会为安全接入的每个客户端验证它所具有的操作权限。

服务层：第二层服务层，主要完成大部分的核心服务功能， 包括查询解析、分析、优化、缓存、以及所有的内置函数，所有跨存储引擎的功能也都在这一层实现，
包括触发器、存储过程、视图等

引擎层：第三层存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信。
不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取。

存储层：第四层为数据存储层，主要是将数据存储在运行于该设备的文件系统之上，并完成与存储引擎的交互

关于SQL语句
SQL语言包括以下几个部分：
1.数据定义语言（Data-Definition Language，DDL）：创建、删除、修改关系模式的命令
2.数据操纵语言（Data-Manipulation Language，DML）：对数据库其中的对象和数据运行访问工作的编程语句，包括查询、修改、插入、添加
3.完整性（integrity）：SQL DDL包括定义完整性约束的命令
4.视图定义（view definition）：SQL DDL包括定义视图的命令
5.事务控制（transaction control）：SQL 包括定义事务的开始点和结束点的命令
6.嵌入式SQL（embedded SQL）和动态SQL（dynamic SQL）：定义如何嵌入诸如C、C++和Java这样的编程语言中
7.授权（authorization）：SQL DCL用来定义访问权限和安全级别。

SQL的基本数据类型：
SQL的基本数据类型由13个基本数据类型组成，它们是由 Microsoft Jet 数据库引擎和几个验证过的有效同义字定义的。常见的有：

整形（Integer）。
单精度（Single）。
双精度（Double）。
可变长度字符（VarChar）。
固定长度字符（Char）。
长型（Long）。
日期（Date）。

此外，还有货币、文本、时间、位串、UI格式化类型等。
       

关于SQL语句在MySQL中执行过程详解
一、SQL语句执行原理：
第一步:客户端把语句发给服务器端执行
当我们在客户端执行 select 语句时,客户端会把这条 SQL 语句发送给服务器端,让服务器端的
进程来处理这语句。也就是说,Oracle 客户端是不会做任何的操作,他的主要任务就是把客户端产生
的一些 SQL 语句发送给服务器端。虽然在客户端也有一个数据库进程,但是,这个进程的作用跟服务器
上的进程作用是不相同的。服务器上的数据库进程才会对SQL语句进行相关的处理。不过,有个问题需
要说明,就是客户端的进程跟服务器的进程是一一对应的。也就是说,在客户端连接上服务器后,在客户
端与服务器端都会形成一个进程,客户端上的我们叫做客户端进程;而服务器上的我们叫做服务器进程。
第二步:语句解析
当客户端把 SQL 语句传送到服务器后,服务器进程会对该语句进行解析。同理,这个解析的工作,
也是在服务器端所进行的。虽然这只是一个解析的动作,但是,其会做很多“小动作”。
1. 查询高速缓存(library cache)。服务器进程在接到客户端传送过来的 SQL 语句时,不
会直接去数据库查询。而是会先在数据库的高速缓存中去查找,是否存在相同语句的执行计划。如果在
数据高速缓存中,则服务器进程就会直接执行这个 SQL 语句,省去后续的工作。所以,采用高速数据缓
存的话,可以提高 SQL 语句的查询效率。一方面是从内存中读取数据要比从硬盘中的数据文件中读取
数据效率要高,另一方面,也是因为这个语句解析的原因。
大多数情况下查询缓存不管用。因为①只有相同的查询操作才会命中查询缓存②如果该表使用了DML、DCL
语句，那么该表的所有高速缓存查询就会失效。③使用了每次查询都返回不一样结果的函数（例如NOW（）），
不会命中查询缓存
不过这里要注意一点,这个数据缓存跟有些客户端软件的数据缓存是两码事。有些客户端软件为了
提高查询效率,会在应用软件的客户端设置数据缓存。由于这些数据缓存的存在,可以提高客户端应用软
件的查询效率。但是,若其他人在服务器进行了相关的修改,由于应用软件数据缓存的存在,导致修改的
数据不能及时反映到客户端上。从这也可以看出,应用软件的数据缓存跟数据库服务器的高速数据缓存
不是一码事。
2. 语句合法性检查(data dict cache)。当在高速缓存中找不到对应的 SQL 语句时,则服
务器进程就会开始检查这条语句的合法性。这里主要是对 SQL 语句的语法进行检查,看看其是否合乎
语法规则。如果服务器进程认为这条 SQL 语句不符合语法规则的时候,就会把这个错误信息,反馈给客
户端。在这个语法检查的过程中,不会对 SQL 语句中所包含的表名、列名等等进行 SQL 他只是语法
上的检查。
3. 语言含义检查(data dict cache)。若 SQL 语句符合语法上的定义的话,则服务器进程
接下去会对语句中的字段、表等内容进行检查。看看这些字段、表是否在数据库中。如果表名与列名不
准确的话,则数据库会就会反馈错误信息给客户端。所以,有时候我们写 select 语句的时候,若语法
与表名或者列名同时写错的话,则系统是先提示说语法错误,等到语法完全正确后,再提示说列名或表名
错误。
4. 获得对象解析锁(control structer)。当语法、语义都正确后,系统就会对我们需要查询
的对象加锁。这主要是为了保障数据的一致性,防止我们在查询的过程中,其他用户对这个对象的结构发
生改变。
5. 数据访问权限的核对(data dict cache)。当语法、语义通过检查之后,客户端还不一定
能够取得数据。服务器进程还会检查,你所连接的用户是否有这个数据访问的权限。若你连接上服务器
的用户不具有数据访问权限的话,则客户端就不能够取得这些数据。有时候我们查询数据的时候,辛辛苦
苦地把 SQL 语句写好、编译通过,但是,最后系统返回个 “没有权限访问数据”的错误信息,让我们气
半死。这在前端应用软件开发调试的过程中,可能会碰到。所以,要注意这个问题,数据库服务器进程先
检查语法与语义,然后才会检查访问权限。
6. 确定最佳执行计划 。当语句与语法都没有问题,权限也匹配的话,服务器进程还是不会直接对
数据库文件进行查询。服务器进程会根据一定的规则,对这条语句进行优化。不过要注意,这个优化是有
限的。一般在应用软件开发的过程中,需要对数据库的 sql 语言进行优化,这个优化的作用要大大地大
于服务器进程的自我优化。所以,一般在应用软件开发的时候,数据库的优化是少不了的。当服务器进程
的优化器确定这条查询语句的最佳执行计划后,就会将这条 SQL 语句与执行计划保存到数据高速缓存
(library cache)。如此的话,等以后还有这个查询时,就会省略以上的语法、语义与权限检查的步骤,
而直接执行 SQL 语句,提高 SQL 语句处理效率。
第三步:语句执行
语句解析只是对 SQL 语句的语法进行解析,以确保服务器能够知道这条语句到底表达的是什么意
思。等到语句解析完成之后,数据库服务器进程才会真正的执行这条 SQL 语句。这个语句执行也分两
种情况。
一是若被选择行所在的数据块已经被读取到数据缓冲区的话,则服务器进程会直接把这个数据传递
给客户端,而不是从数据库文件中去查询数据。
若数据不在缓冲区中,则服务器进程将从数据库文件中查询相关数据,并把这些数据放入到数据缓冲
区中(buffer cache)。
第四步:提取数据
当语句执行完成之后,查询到的数据还是在服务器进程中,还没有被传送到客户端的用户进程。所以,
在服务器端的进程中,有一个专门负责数据提取的一段代码。他的作用就是把查询到的数据结果返回给
用户端进程,从而完成整个查询动作。从这整个查询处理过程中,我们在数据库开发或者应用软件开发过
程中,需要注意以下几点:
一是要了解数据库缓存跟应用软件缓存是两码事情。数据库缓存只有在数据库服务器端才存在,在
客户端是不存在的。只有如此,才能够保证数据库缓存中的内容跟数据库文件的内容一致。才能够根据
相关的规则,防止数据脏读、错读的发生。而应用软件所涉及的数据缓存,由于跟数据库缓存不是一码事
情,所以,应用软件的数据缓存虽然可以提高数据的查询效率,但是,却打破了数据一致性的要求,有时候
会发生脏读、错读等情况的发生。所以,有时候,在应用软件上有专门一个功能,用来在必要的时候清除
数据缓存。不过,这个数据缓存的清除,也只是清除本机上的数据缓存,或者说,只是清除这个应用程序
的数据缓存,而不会清除数据库的数据缓存。
二是绝大部分 SQL 语句都是按照这个处理过程处理的。我们 DBA 或者基于 Oracle 数据库的
开发人员了解这些语句的处理过程,对于我们进行涉及到 SQL 语句的开发与调试,是非常有帮助的。有
时候,掌握这些处理原则,可以减少我们排错的时间。特别要注意,数据库是把数据查询权限的审查放在
语法语义的后面进行检查的。所以,有时会若光用数据库的权限控制原则,可能还不能满足应用软件权限
控制的需要。此时,就需要应用软件的前台设置,实现权限管理的要求。而且,有时应用数据库的权限管
理,也有点显得繁琐,会增加服务器处理的工作量。因此,对于记录、字段等的查询权限控制,大部分程
序涉及人员喜欢在应用程序中实现,而不是在数据库上实现。

SQL语句中的函数、关键字、排序等执行顺序:
1. FROM 子句返回初始结果集。
2. WHERE 子句排除不满足搜索条件的行。
3. GROUP BY 子句将选定的行收集到 GROUP BY 子句中各个唯一值的组中。
4. 选择列表中指定的聚合函数可以计算各组的汇总值。
5. 此外,HAVING 子句排除不满足搜索条件的行。
6. 计算所有的表达式;
7. 使用 order by 对结果集进行排序。
8. 查找你要搜索的字段。

MYSQL存储引擎：
MySQL 提供了多个不同的存储引擎，包括处理事务安全表的引擎和处理非事务安全表的引擎。
在 MySQL 中，不需要在整个服务器中使用同一种存储引擎，针对具体的要求，可以对每一个表使用不同的存储引擎。
MySQL 5.7 支持的存储引擎有 InnoDB、MyISAM、Memory、Merge、Archive、CSV、BLACKHOLE 等。
可以使用SHOW ENGINES;语句查看系统所支持的引擎类型

InnoDB：
在 MySQL 5.5 及以后版本后，MySQL 选择使用 InnoDB为默认存储引擎。
在创建数据库表时，不指定存储引擎时，使用的就是 InnoDB。如需使用其他存储引擎，可以手动来指定。
 
特点：
InnoDB 支持事务操作；（每一条SQL都默认封装成事务，自动提交，会影响速度）
InnoDB 支持外键；
InnoDB 是聚集索引（聚簇索引）；
InnoDB 不保存表的总条数；
InnoDB 5.7版本之前不支持全文检索；
InnoDB 支持表级锁、行级锁，默认为行级锁；
InnoDB 表必须有主键（如果我们没有明确去指定创建主键索引。它会帮我们隐藏的生成一个 6 byte 的 int 型的索引作为主键索引）；
InnoDB 文件存储方式为.frm文件存储表结构，ibd文件存储数据内容。

名词解释：
什么是聚集(簇)索引？
聚簇索引的特点是叶子节点包含了完整的记录行，而非聚簇索引的叶子节点只有所以字段和主键ID。
MySQL 索引采用 B+Tree（不熟悉？来跳转链接了解：MySQL 索引底层为什么选择B+Tree）。
InnoDB 和 MyISAM 作为 MySQL 中 B+Tree 索引的两种重要体现形式。 
InnoDB 推荐以主键作为索引来组织数据进行存储，它认为主键是一个非常重要的属性。
InnoDB 表数据文件本身就是按B+Tree组织的一个索引结构，聚簇索引就是按照每张表的主键来构造一个B+树，
叶子节点中存放的就是整张表的数据。
 
一般建表会用一个自增主键做聚簇索引，没有的话MySQL会默认创建，
但是这个主键如果更改代价较高，故建表时要考虑自增ID不能频繁 update 这一点。
MySQL一张表，比如有id(主键)，name，age等字段。我们可以建很多个索引，MySQL除了主键索引外，都是非聚簇索引。
即只有我们创建的主键id索引，我们可以叫他id索引，它别名又叫做聚簇索引，
（因为只有id索引，叶子节点包含了完整的记录行）理解成一个别名的即可。
如果我们再创建一个name索引，它就叫做非聚簇索引，或者辅助索引。）
 
我们日常工作中，根据实际情况自行添加的索引都是辅助索引，辅助索引就是一个为了需找主键索引的二级索引，
现在找到主键索引再通过主键索引找数据；

MyISAM存储引擎：
MyISAM 作为 MySQL 中 B+Tree 索引的另一种重要体现形式。
 
特点：

MyISAM 是非聚集索引；
MyISAM 有一个变量专门来保存整个表的行数，查询count很快(注意不能加任何 where 条件)
MyISAM 支持全文索引；
MyISAM 可以被压缩后进行查询操作，节省空间容量；
MyISAM 支持表级锁，不支持行级锁；
MyISAM 中主键不是必须的；
MyISAM 文件存储方式为.frm文件存储表结构，.MYD文件存储数据内容，.MYI文件存储索引文件。

MySQL主从复制（数据库的主数据库复制到从数据库）
读写分离：主（master）实现写请求，从（slave）实现读请求，从而减轻数据库的压力。
redis可以实现读写分离，elasticsearch没有主从同步，kafka用的是主读主写

MySQL分库分表：
分库分表的方式有四种，它们分别是：垂直分表、垂直分库、水平分库和水平分表。

垂直分表：可以把一个宽表的字段按照访问频率、是否是大字段的原则拆分为多个表，这样既能使业务清晰，还能提高部分性能。
拆分后，尽量从业务角度避免联查，否则性能方面将得不偿失。

垂直分库：可以把多个表按照业务的耦合性来进行分类，分别存放在不同的数据库中，
这些库可以分布在不同的服务器，从而使访问压力被分摊在多个服务器，大大提高性能，同时能提高整体架构的业务清晰度，
不同的业务库可根据自身情况定制优化方案。但是它需要解决跨库带来的所有复杂问题。

水平分库：可以把一个表的数据(按数据行)分到多个不同的库，每个库只有这个表的部分数据，
这些库可以分布在不同的服务器，从而使访问压力被多服务器负载，提升性能。
它不仅需要解决跨库带来的问题，还需要解决数据路由的问题。

水平分表：可以把一个表的数据(按数据行)分到多个同一个数据库的多张表中，每个表的数据只有这个表的部分数据，
这样做能小幅提升性能，它仅仅作为水平分库的一个补充优化。

最后，一般来说，在系统设计阶段就应该根据业务耦合程度来确定用哪种分库分表的方式(方案)，
在数据量及访问压力不是特别大的情况，首先考虑缓存、读写分离、索引技术等方案。
若数据量极大，且连续增长，再考虑水平分库水平分表的方案。


MySQL索引：
1.索引列的数据长度能少则少；
2.索引一定不是越多越好，越全越好，一定是建合适的；
3.匹配列前缀可用到索引 like 9999%，like %9999%、like %9999用不到索引；
注意： like 9999% 并不会一定用到索引（离散型太差，就不会用到索引）
    like %9999%、like %9999 是绝对不会用到索引的

4.Where 条件中 not in 和 <>操作无法使用索引；
5.匹配范围值，order by 也可用到索引；
6.多用指定列查询，只返回自己想到的数据列，少用select *；
7.联合索引中如果不是按照索引最左列开始查找，无法使用索引；
8.联合索引中精确匹配最左前列并范围匹配另外一列可以用到索引；
比如说：有个[name,phone]联合索引
    where name=‘abc’ and phone>‘136xxxxxxxx’ 这种是可以用到索引的

9.联合索引中，如果查询中有某个列的范围查询，则其右边的所有列都无法使用索引；
比如说：有个[age,name]联合索引
    where age>18 and name='abc’这是用不到索引的
它只会age使用索引，name不会使用索引。还是基于最左匹配原则

Mysql索引数据结构:
首先，数据库索引使用树来存储，因为树的查询效率高，而且二叉查找树还可以保持数据的有序。
那么索引为什么没有使用二叉树来实现呢？
其实从算法逻辑上讲，二叉查找树的查找速度和比较次数都是最小的，但是从Mysql的角度讲，我们不得不考虑一个现实问题：磁盘IO。
查找都是索引操作，一般来说索引非常大，尤其是关系型数据库这种，当数据量比较大的时候，索引的大小有可能几个G甚至更多，数据量大的索引能达到亿级别，所以为了减少内存的占用，数据库索引是存储在外部磁盘上的。
当我们利用索引查询的时候，不可能把整个索引全部加载到内存，只能逐一加载每个磁盘页，磁盘页对应索引树的节点。
那么Mysql衡量查询效率的标准就是磁盘IO次数。
如果我们利用二叉树作为索引结构，那么磁盘的IO次数和索引树的高度是相关的。
那么为了提高查询效率，就需要减少磁盘IO数。为了减少磁盘IO的次数，就需要尽量降低树的高度，需要把原来“瘦高”的树结构变的“矮胖”，树的每层的分叉越多越好，因此B树正好符合我们的要求，这也是B-树的特征之一。
原来的二叉树一个节点只存储一个数据，要想把它变“矮胖”，就需要在一个节点存储多个数据，同时为了查找必须保持节点结构的有序，这样B树就应运而生了。

B-树（B类树）的特点就是每层节点数目非常多，层数很少，目的就是为了就少磁盘IO次数。
B-树是一种多路平衡查找树，它的每一个节点最多包含K个孩子，k称为B树的阶。k的大小取决于磁盘页的大小。
一个m阶的B树具有如下几个特征：

1.根结点至少有两个子女。
2.每个中间节点都包含k-1个元素和k个孩子，其中 m/2 <= k <= m。
3.每一个叶子节点都包含k-1个元素，其中 m/2 <= k <= m。
4.所有的叶子结点都位于同一层。
5.每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。
一个B树结构的具体例子。


在B-树中进行查询时，在查询的中的比较次数其实不比二叉查找树少，尤其当单一节点中的元素数量很多时。
可是相比磁盘IO的速度，内存中的耗时几乎可以忽略，所以只要树的高度足够低，IO次数足够少，就可以提高查询性能。
相比之下节点内部元素多一点也没有关系，仅仅是多了几次内存交互，只要不超过磁盘页的大小即可。这就是B-树的优势之一。
B树在插入和删除节点的时候如果导致树不平衡，就通过自动调整节点的位置来保持树的自平衡。
非关系型数据库MongoDB使用B树作为数据库索引。
大部分关系型数据库，比如Mysql，则使用B+树作为索引。
B+树是基于B-树的一种变体，有着比B-树更高的查询性能。
B+树和B-树有一些共同点，但是B+树也具备一些新的特征。

一个m阶的B+树具有如下几个特征：
1.有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。
2.所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
3.所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。


从B+树的结构可以看出，B+树中的节点之间不但含有重复元素，而且叶子节点还用指针连在一起。
在B+树中，每一个父节点的中的元素都出现在子节点中，是子节点的最大（或最小元素）。
由于父节点的所有元素都出现在子节点，因此所有叶子节点包含了全量元素信息。
并且每个叶子节点都有指向下一个叶子节点的指针，形成了有序链表。
在B+树中，只有叶子节点才真正存储数据，非叶子节点不存储数据。
使用B+树做索引的好处主要体现在查询性能上。
在单元素查询的时候，B+树会自顶向下逐层查找节点，最终找到匹配的叶子节点。
对于范围查询，比如查询范围为3~11的元素，B-树只能依靠繁琐的中序遍历，首先自顶向下查找范围的下限，然后中序遍历找到上限。
B+树的范围查询则要简单的多，首先自顶向下查找范围的下限，然后只需要在叶子节点所在的链表上做遍历即可。

B+树和B-树的区别： 
B+树中间节点没有存储数据，只有叶节点存放数据，其余节点用来索引，所以同样大小的磁盘页可以容纳更多的节点元素，而B-树是每个索引节点都会有Data域。这就意味着，数据量相同的情况下，B+树的结构比B-树更加“矮胖”，因此查询是IO次数也更少。这就决定了B+树更适合用来存储外部数据，也就是所谓的磁盘数据。
其次，B+树的查询必须最终查询到叶子节点，而B-树只要找到匹配元素即可，无论匹配元素处于中间节点还是叶子节点。
因此，B-树的查询性能并不稳定（最好情况是只查根节点，最坏情况是查到叶子节点）。而B+树每一次查找都是稳定的。

综合起来，B+树相比B-树的优势有三个：
1.单一节点存储更多的元素，使得查询的IO次数更少。
2.所有查询都要查找到叶子节点，查询性能稳定。
3.所有叶子节点形成有序链表，便于范围查询。

最后总结一下：

数据库索引为什么不用AVL（平衡二叉树）？
数据库索引是存储在磁盘上，磁盘IO操作比较耗时，为了提高查询效率就需要减少磁盘IO的次数。而磁盘IO次数和树的高度有关，所以为了减少磁盘IO就需要降低树的高度，这时查找的结构就可以把二叉树变成B类的树。
数据库索引为什么用B+树而不用B-树？
数据库索引采用B+树的主要原因是B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。正是为了解决这个问题，B+树应运而生。B+树只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作（或者说效率太低）。

那么MongoDB为什么使用B-树而不是B+树？
至于MongoDB为什么使用B-树而不是B+树，可以从它的设计角度来考虑，它并不是传统的关系性数据库，而是以Json格式作为存储的nosql，目的就是高性能，高可用，易扩展。首先它摆脱了关系模型，上面所述的范围查询的优点就没那么强烈了，其次Mysql由于使用B+树，数据都在叶节点上，每次查询都需要访问到叶节点，而MongoDB使用B-树，所有节点都有Data域，只要找到指定索引就可以进行访问，无疑单次查询平均快于Mysql（但侧面来看Mysql至少平均查询耗时差不多）。
总体来说，Mysql选用B+树和MongoDB选用B-树还是以自己的需求来选择的。

数据库索引为什么不用红黑树？
首先看一下红黑树的特点：
红黑树是一种自平衡的二叉查找树，除了符合二叉查找树的基本特征外，它还具有下列的附加特征。
1.节点是红色或黑色。
2.根节点是黑色。
3.每个叶子节点都是黑色的空节点（NIL节点）。
4 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)
5.从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。


这是因为这些规则限制，才保证了红黑树的自平衡。红黑树从根到叶子的最长路径不会超过最短路径的2倍。
当插入或删除节点的时候，红黑树的规则可能被打破。这时候就需要做出一些调整， 来继续维持我们的规则。
那么在大规模数据存储的时候，红黑树往往出现由于树的深度过大而造成磁盘IO读写过于频繁，进而导致效率低下的情况。磁盘查找存取的次数往往由树的高度所决定，所以，只要我们通过某种较好的树结构尽量减少树的高度，就可以提高查询性能。B树可以有多个子女，从几十到上千，可以降低树的高度。
归结起来，使用B+树而不是用其他结构的原因就是为了减少磁盘IO的次数，减少数的高度，而B+树就很好的做到了这一点。
那么什么情况下使用红黑树?红黑树和B树使用场合有什么不同？两者都是有序的数据结构，可用作数据容器。

红黑树多用在内部排序，即全放在内存中的，微软STL的map和set的内部实现就是红黑树。
B树多用在内存里放不下，大部分数据存储在外存上时。因为B树层数少，因此可以确保每次操作，读取磁盘的次数尽可能的少。
在数据较小，可以完全放到内存中时，红黑树的时间复杂度比B树低。
反之，数据量较大，外存中占主要部分时，B树因其读磁盘次数少，而具有更快的速度。

MySQL事务机制：
事务（Transaction），是指作为单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行。 
事务处理可以确保除非事务性单元内的所有操作都成功完成，否则不会永久更新面向数据的资源。
简单理解事务，即：当前操作要么全部成功，要么全部失败。这样可以简化错误恢复并使应用程序更加可靠。

事务 4 大特性：原子性、一致性、隔离性、持久性。通常称为 ACID 特性。

原子性(Atomicity)：指一个事务是一个不可分割的工作单元，事务中包括的所有操作要么都完成，要么都不完成。
一致性(Consistency)：指事务必须是使数据库从一个一致性状态变到另一个一致性状态，是否一致性与原子性是密切相关的。
隔离性(Isolation)：指一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对 并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。
持久性(Durability)：指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的，接下来的其他操作或故障不应该对这些数据有任何影响。

事务并发带来的问题：
1.脏读 ：一个事务对数据进行了增删改，但未提交，另一事务可以读取到未提交的数据。
如果第一个事务这时候回滚了，那么第二个事务就读到了脏数据。
2.不可重复读：一个事务中发生了两次读操作，第一次读操作和第二次读操作之间，
另外一个事务对数据进行了修改，这就会导致两次读取的数据是不一致的。
3.幻读：第一个事务对一定范围的数据进行批量查询，第二个事务在这个范围增加一条数据，
这时候第一个事务就会丢失对新增数据的内容。

MySQL锁：
锁的出现，就是用于解决不同事务对共享资源并发访问所引起的脏读、不可重复读、幻读问题。
MySQL InnoDB 锁类型，分别是：共享锁(Shard Lock)、排它锁(Exclusive Lock)、
意向共享锁(Intention Shared Lock)、意向排它锁(Intention Exclusive Lock)、自增锁(AUTO-INC Lock)、
临键锁(Next-key Lock)、间隙锁(Gap Lock)、记录锁(Record Lock) 八种。
(记录锁、间隙锁、临键锁这三种锁，都是行锁的具体实现算法。
我们可以将其理解为锁的类型，也可以理解为行锁的具体实现算法)

MySQL行级锁：行级锁，每次操作锁住对应的行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。
应用在InnoDB存储引擎中,MyISAM不支持行级锁。

MySQL表级锁：表级锁，每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。
应用在MyISAM、InnoDB、BDB等存储引擎中。
对于表级锁，主要分为以下三类：
表锁
元数据锁（meta data lock，MDL）
意向锁

共享锁（S锁）：
添加共享锁之后，如果查询未命中索引，则不会使用行锁，会退变为表锁。
所以在没有创建name索引时，修改徐勇数据时，会被阻塞；
>当创建name索引后，由于查询命中索引，所以行锁将曹茜这条数据锁住，并不会影响表中其他数据的操作。此时修改徐勇这条数据能够成功。
>由于行锁、表锁的原因，其他事务会处于等待状态。锁超时等待，默认为 50 s。
我们可通过命令：show variables like ‘innodb_lock_wait_timeout’;来查看(CSDN原因，将引号修改为英文状态单引号)。
锁超时时间也分会话/全局级别，我们可通过set session innodb_lock_wait_timeout = 20; 
或 set global innodb_lock_wait_timeout = 20; 来进行修改设置。

排他锁（X锁）：
添加排他锁之后，如果 name 字段查询未命中索引，则不会使用行锁，会退变为表锁。
所以在没有创建name索引时，修改徐勇数据时，会被阻塞；
>当创建name索引后，由于 name 字段查询命中索引，所以行锁会将曹茜这条数据锁住（其他会话无法获取该条数据的共享锁、
排它锁），并不会影响表中其他数据的操作。此时修改徐勇这条数据能够成功。
>此时查询数据是可以正常进行的。是因为 InnoDB 还有一个"一致性的非锁定读"的概念，
就是说行锁未释放之前，其他事务读取该行数据读取的是它的快照数据，并不会与行锁冲突
>由于行锁、表锁的原因，其他事务会处于等待状态。锁超时等待，默认为 50 s。

意向锁：
1 意向共享锁（IS锁）
表锁。表示事务准备给数据行加入共享锁时，即一个数据行加共享锁前必须先取得该表的 IS 锁， 意向共享锁之间是可以相互兼容的

2 意向排他锁（IX锁）
表锁。表示事务准备给数据行加入排他锁时，即一个数据行加排他锁前必须先取得该表的 IX 锁， 意向排它锁之间是可以相互兼容的

意向锁(IS锁、IX锁)是 InnoDB 数据操作之前自动加的，不需要用户干预。所以此处不做介绍，有个概念即可。当事务想去进行锁表时，可以先判断意向锁是否存在，存在时则可快速返回该表不能启用表锁。

自增锁：
当我们插入数据时，自增锁会 +1，但是此时如果事务执行了 rollback 等其他操作，导致数据并没有插入成功，
此时自增锁 id 并不会随之回退，会永久丢失，从而导致的自增 id 列不连续。

临键锁：
临键锁（Next-key Lock），作为 InnoDB 引擎默认行锁算法。就是解决 幻读 问题。
当 SQL 执行按照索引进行数据查询时，查询条件为范围查找(between and 、< 、> 等)并有数据命中时，
此时 SQL 语句加上的锁为 Next-key Lock，锁住的是索引的记录+下一个区间（左开右闭）。

临键锁，为什么要锁住下一个区间？
这和索引底层 B+Tree 有关系。MySQL 索引底层选择 B+Tree。B+Tree 数据都保存在叶子节点，并且具有顺序性，
从左到右依次增大。临键锁锁住相邻区间，此时 insert 插入数据时，我们并不能够将数据成功的插入到该区间，
就能够满足每次查询的数据一致，从而解决幻读问题。

示例解释：还是select * from orders where id > 5 and id < 9 for update;这个查询，
事务A 第一次查询出来一条 id = 7 的数据。如果不锁住相邻区间，此时事务B 插入了一条 id = 8 的数据。
那么事务A 在接下来就会查询出 2 条数据。如果锁住相邻区间，那么只要在事务 A 没结束期间，
查询到的都会只有 id = 7 这1条数据。这就解决了幻读问题。

间隙锁：
间隙锁（Gap Lock）。当 SQL 执行按照索引进行数据查询时，查询条件的数据不存在，
此时 SQL 语句加上的锁即为 Gap Lock，锁住的是数据不存在的区间（左开右开）。

因为只有在 RR 事务隔离级别下，InnoDB 引擎才能够解决数据幻读的问题。
临键锁(Next-key Lock) = 间隙锁(Gap Lock) + 记录锁(Record Lock)，所以 Gap 锁只有在 RR 级别下存在。

记录锁：
记录锁（Record Lock）。当 SQL 执行按照唯一性（Primary key、Unique key）索引进行数据查询时，查询条件等值匹配且查询的数据存在，
此时 SQL 语句加上的锁即为 Record Lock，锁住的是具体的索引项。

MySQL MVCC：
MVCC 多版本并发控制
MySQL的大多数事务型存储引擎实现都不是简单的行级锁。基于提升并发性考虑，一般都同时实现了多版本并发控制（MVCC），包括Oracle、PostgreSQL。只是实现机制各不相同。
可以认为 MVCC 是行级锁的一个变种，但它在很多情况下避免了加锁操作，因此开销更低。
虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只是锁定必要的行。
MVCC 的实现是通过保存数据在某个时间点的快照来实现的。也就是说不管需要执行多长时间，每个事物看到的数据都是一致的。
典型的MVCC实现方式，分为乐观（optimistic）并发控制和悲观（pressimistic）并发控制。
下边通过 InnoDB的简化版行为来说明 MVCC 是如何工作的。
InnoDB 的 MVCC，是通过在每行记录后面保存两个隐藏的列来实现。这两个列，一个保存了行的创建时间，一个保存行的过期时间（删除时间）。
当然存储的并不是真实的时间，而是系统版本号（system version number）。
每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。

REPEATABLE READ（可重读）隔离级别下MVCC如何工作：

SELECT：
InnoDB会根据以下两个条件检查每行记录：
①InnoDB只查找版本早于当前事务版本的数据行，这样可以确保事务读取的行，要么是在开始事务之前已经存在要么是事务自身插入或者修改过的
②行的删除版本号要么未定义，要么大于当前事务版本号，这样可以确保事务读取到的行在事务开始之前未被删除

只有符合上述两个条件的才会被查询出来

INSERT：InnoDB为新插入的每一行保存当前系统版本号作为行版本号

DELETE：InnoDB为删除的每一行保存当前系统版本号作为行删除标识

UPDATE：InnoDB为插入的一行新纪录保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为删除标识

保存这两个额外系统版本号，使大多数操作都不用加锁。使数据操作简单，性能很好，并且也能保证只会读取到符合要求的行。
不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作和一些额外的维护工作。
MVCC 只在 COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作。

Oracle:
SQL语句在Oracle中执行过程详解
Oracle采用了共享池来判断SQL语句是否存在缓存和执行计划。
1.语法检查
2.语义检查
3.权限检查
4.共享池检查：最主要的作用是缓存SQL语句和该语句的执行计划→ 软解析
5.优化器→硬解析


数据库连接技术：
JDBC：传统连接数据库的方法，容易产生硬编码问题，难以保证SQL注入安全性
//步骤一:定义连接数据库的相关信息
static String driver = "com.mysql.jdbc.Driver";
连接数据库
    static String url = "jdbc:mysql://localhost:3306/school?useSSL=false";
    static String username = "root";
    static String password = "root";

public static void main(String[] args) {
//步骤二:加载jdbc驱动
 Class.forName(driver);

//步骤三:通过驱动管理器获得和数据的连接
Connection conn = DriverManager.getConnection(url,username,password);
System.out.println("数据库的连接:"+conn);

//步骤四:定义查询的sql语句

//步骤五:创建一个PreparedStatement对象(可以用来执行sql,来操作数据库)
PreparedStatement pstmt = conn.prepareStatement(sql);

//步骤六:执行sql,得到结果集
ResultSet rs = pstmt.executeQuery();

//步骤七:关闭资源
}

数据库连接池Druid：
1.数据库连接池是个容器，负责分配、管理数据库连接(Connection)；
2.它允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个；
3.释放空闲时间超过最大空闲时间的数据库连接来避免因为没有释放数据库连接而引起的数据库连接遗漏；
public class Druid_ {
    @Test
    public void testDruid() throws Exception {
        //1.加入Druid jar包
        //2.加入配置文件，将该文件拷贝到项目的src目录下
        //3.创建Properties对象，读取配置文件
        Properties properties = new Properties();
        properties.load(new FileInputStream("src\\druid.properties"));

        //4.创建一个指定参数的数据库连接池
        DataSource dataSource = DruidDataSourceFactory.createDataSource(properties);
        long start =System.currentTimeMillis();
        for (int i = 0; i < 5000; i++) {
            Connection connection = dataSource.getConnection();
            connection.close();
        }
        long end =System.currentTimeMillis();
        System.out.println("Druid 5000次连接mysql耗时：" + (end - start));//Druid 5000次连接mysql耗时：3608
    }
}

Mybatis：
MyBatis是一个优秀的持久层框架，它对jdbc的操作数据库的过程进行封装，
使开发者只需要关注 SQL 本身，而不需要花费精力去处理例如注册驱动、创建connection、创建statement、手动设置参数、
结果集检索等jdbc繁杂的过程代码。
Mybatis通过xml或注解的方式将要执行的各种statement（statement、preparedStatemnt、CallableStatement）配置起来，
并通过java对象和statement中的sql进行映射生成最终执行的sql语句，
最后由mybatis框架执行sql并将结果映射成java对象并返回。
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org/DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="com.mybitis.mapper.UserMapper">
    <resultMap id="result" type="com.mybitis.entity.User">
        <result column="userid" jdbcType="INTEGER" property="userid" />
        <result column="username" jdbcType="VARCHAR" property="username" />
        <result column="password" jdbcType="VARCHAR" property="password" />
    </resultMap>

    <select id="findAllUser" resultType="com.mybitis.entity.User">
        select  * from user;
    </select>

    <select id="findUserByUserId" resultType="com.mybitis.entity.User">
        select * from user where userid=#{userid};
    </select>
    <select id="findUserByUsername" resultType="com.mybitis.entity.User">
        select * from user where username=#{username};
    </select>

    <insert id="insertUser" parameterType="com.mybitis.entity.User" keyProperty="userid" useGeneratedKeys="true">
        insert into user(userid,username,password) values (#{userid},#{username},#{password});
    </insert>

    <update id="updateUser" parameterType="com.mybitis.entity.User">
        update user set username=#{username},password=#{password} where userid=#{userid};
    </update>

    <delete id="deleteUser" parameterType="com.mybitis.entity.User">
        delete from user where userid=#{userid};
    </delete>
</mapper>

MyBatis获取参数值的两种方式：${}和#{}
${}的本质就是字符串拼接，#{}的本质就是占位符赋值
${}使用字符串拼接的方式拼接sql，若为字符串类型或日期类型的字段进行赋值时，需要手动加单引
号；但是#{}使用占位符赋值的方式拼接sql，此时为字符串类型或日期类型的字段进行赋值时，可以自动添加单引号
使用#{}可以防止SQL注入

1、单个字面量类型的参数
若mapper接口中的方法参数为单个的字面量类型
此时可以使用${}和#{}以任意的名称获取参数的值，注意${}需要手动加单引号

2、多个字面量类型的参数
若mapper接口中的方法参数为多个时
此时MyBatis会自动将这些参数放在一个map集合中，以arg0,arg1...为键，以参数为值；
以param1,param2...为键，以参数为值；因此只需要通过${}和#{}访问map集合的键就可以获取相对应的值，注意${}需要手动加单引号

3、map集合类型的参数
若mapper接口中的方法需要的参数为多个时，此时可以手动创建map集合，将这些数据放在map中
只需要通过${}和#{}访问map集合的键就可以获取相对应的值，注意${}需要手动加单引号

4、实体类类型的参数
若mapper接口中的方法参数为实体类对象时
此时可以使用${}和#{}，通过访问实体类对象中的属性名获取属性值，注意${}需要手动加单引号

5、使用@Param标识参数
可以通过@Param注解标识mapper接口中的方法参数
此时，会将这些参数放在map集合中，以@Param注解的value属性值为键，以参数为值；
以param1,param2...为键，以参数为值；只需要通过${}和#{}访问map集合的键就可以获取相对应的值，注意${}需要手动加单引号

MyBatis的缓存：

1、MyBatis的一级缓存
一级缓存是SqlSession级别的，通过同一个SqlSession查询的数据会被缓存，下次查询相同的数据，
就会从缓存中直接获取，不会从数据库重新访问

使一级缓存失效的四种情况：
1) 不同的SqlSession对应不同的一级缓存
2) 同一个SqlSession但是查询条件不同
3) 同一个SqlSession两次查询期间执行了任何一次增删改操作
4) 同一个SqlSession两次查询期间手动清空了缓存

2、MyBatis的二级缓存
二级缓存是SqlSessionFactory级别，通过同一个SqlSessionFactory创建的SqlSession查询的结果会被缓存；
此后若再次执行相同的查询语句，结果就会从缓存中获取。

二级缓存开启的条件：
a>在核心配置文件中，设置全局配置属性cacheEnabled="true"，默认为true，不需要设置
b>在映射文件中设置标签<cache />
c>二级缓存必须在SqlSession关闭或提交之后有效
d>查询的数据所转换的实体类类型必须实现序列化的接口
使二级缓存失效的情况：
两次查询之间执行了任意的增删改，会使一级和二级缓存同时失效


列式存储数据库：
列存储不同于传统的关系型数据库，其数据在表中是按行存储的，列方式所带来的重要好处之一就是，由于查询中的选择规则是通过列来定义的，因此整个数据库是自动索引化的。
列式数据库是以列相关存储架构进行数据存储的数据库，主要适合于批量数据处理和即时查询。相对应的是行式数据库，数据以行相关的存储体系架构进行空间分配，主要适合于大批量的数据处理，常用于联机事务型数据处理。
列存储数据库使用一个称为 keyspace 的概念。keyspace 有点像关系模型中的模式。keyspace 包含所有列族(有点像关系模型中的表)，其中包含行，包含列。
列式存储多用于OLAP(Online analytical processing)联机分析处理系统

>列族由多行组成。
>每一行可以包含与其他行不同数量的列。而且这些列不必与其他行的列匹配(例如，它们可以有不同的列名、数据类型、数量等)。
>每行包含一列。它不像关系数据库那样跨所有行。每个列包含一个名称/值对，以及一个时间戳。

		  Column 		Column 		   Column
		  Name 			Name		   Name 
Row Key   Value 		Value 		   Value
		  Timestamp   	Timestamp	   Timestamp

每一行的结构：
Row Key：每一行都有一个惟一的键，这是该行的惟一标识符。
Column：每个列包含名称、值和时间戳。
Name：KV 对的 K
Value：KV 对的 V
Timestamp：这提供了插入数据的日期和时间。这可以用来确定数据的最新版本。

特点/优点
高效的压缩效率，节省磁盘空间和计算CPU和内存
基于 CPU L2 缓存高效的数据迭代
压缩算法：列式数据库由于其每一列都是分开储存的。所以很容易针对每一列的特征运用不同的压缩算法。常见的列式数据库压缩算法有Run Length Encoding ， Data Dictionary ， Delta Compression ， BitMap Index ， LZO ， Null Compression 等等。根据不同的特征进行的压缩效率从10W:1 到10:1 不等。而且数据越大其压缩效率的提升越为明显。
延迟物化：列式数据库由于其特殊的执行引擎，在数据中间过程运算的时候一般不需要解压数据而是以指针代替运算，直到最后需要输出完整的数据时。
聚合查询：由于它们的结构，柱状数据库在聚合查询(如SUM、COUNT、AVG等)方面表现得特别好。
可扩展性：列式存储数据库是可伸缩的。它们非常适合大规模并行处理(MPP)，这涉及到将数据分散到一个大的机器集群中——通常是数千台机器。
快速查询和写入：可以非常快地加载。可以在几秒钟内加载十亿行表。几乎可以立即开始查询和分析。

列式存储数据库有：1.HBase；2.ClickHouse；3.Druid；4.HP Vertica（也支持行式存储）。

非关系型数据库(nosql)：
redis：
redis是一个开源的、使用C语言编写的、支持网络交互的、可基于内存也可持久化的nosql数据库

redis五大数据类型：
1.String字符串
2.List
3.Set
4.Hash
5.ZSet

SpringBoot整合Redis：SpringBoot配置Redis工具类
@Configuration
public class RedisConfig {
    @Bean
    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {
        RedisTemplate<String, Object> template = new RedisTemplate<String, Object>();
        template.setConnectionFactory(factory);
        // key采用String的序列化方式
        template.setKeySerializer(new StringRedisSerializer());
        // hash的key也采用String的序列化方式
        template.setHashKeySerializer(new StringRedisSerializer());
        // value序列化方式采用jackson
        template.setValueSerializer(new GenericJackson2JsonRedisSerializer());
        // hash的value序列化方式采用jackson
        template.setHashValueSerializer(new GenericJackson2JsonRedisSerializer());
        template.afterPropertiesSet();
        return template;
    }

}

自动注入redisTemplate
@Autowired
private RedisTemplate redisTemplate;


Memcache:
memcache是一个高性能的分布式的内存对象缓存系统，用于动态Web应用以减轻数据库负担。它通过在内存中缓存数据和对象，来减少读取数据库的次数。从而提高动态、数据库驱动网站速度。
memcache通过在内存里维护一个统一的巨大的hash表，它能够用来存储各种格式的数据，包括图像、视频、文件以及数据库检索的结果等。memcache主要用于分担数据库负的压力，memcache将数据调用到内存中，然后从内存中读取，从而大大提高读取速度。

优点：
1.Memcached可以利用多核优势，单实例吞吐量极高，可以达到几十万QPS（取决于key、value的字节大小以及服务器硬件性能，日常环境中QPS高峰大约在4-6w左右）。适用于最大程度扛量。
2.支持直接配置为session handle。

缺点：
1只支持简单的key/value数据结构，不像Redis可以支持丰富的数据类型。
2.无法进行持久化，数据不能备份，只能用于缓存使用，且重启后数据全部丢失。
3.无法进行数据同步，不能将MC中的数据迁移到其他MC实例中。
4.Memcached内存分配采用Slab Allocation机制管理内存，value大小分布差异较大时会造成内存利用率降低，并引发低利用率时依然出现踢出等问题。需要用户注重value设计。


MongoDB:
MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。
在高负载的情况下，添加更多的节点，可以保证服务器性能。
MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。
MongoDB 将数据存储为一个文档，数据结构由键值(key=>value)对组成。
MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。

优点：
1.更高的写负载，MongoDB拥有更高的插入速度。
2.处理很大的规模的单表，当数据表太大的时候可以很容易的分割表。
3.高可用性，设置M-S不仅方便而且很快，MongoDB还可以快速、安全及自动化的实现节点（数据中心）故障转移。
4.快速的查询，MongoDB支持二维空间索引，比如管道，因此可以快速及精确的从指定位置获取数据。MongoDB在启动后会将数据库中的数据以文件映射的方式加载到内存中。如果内存资源相当丰富的话，这将极大地提高数据库的查询速度。
5.非结构化数据的爆发增长，增加列在有些情况下可能锁定整个数据库，或者增加负载从而导致性能下降，由于MongoDB的弱数据结构模式，添加1个新字段不会对旧表格有任何影响，整个过程会非常快速。

缺点：
1.不支持事务。
2.MongoDB占用空间过大 。
3.MongoDB没有成熟的维护工具。

Java容器技术：
容器技术是一种软件开发和部署技术，允许开发人员在虚拟环境中将应用程序与其依赖关系封装在一起，以实现在不同的环境中的一致性。
容器技术通过使用容器映像来管理应用程序，并在系统上运行容器实例。容器映像是包含所有应用程序代码和依赖关系的可执行文件。容器实例则是运行在特定环境中的应用程序副本。

容器技术的优势在于：
避免了环境问题：应用程序在容器中与其依赖关系一起运行，因此可以避免环境问题导致的故障。
提高了部署效率：容器可以快速部署，并且可以方便地进行版本管理和回滚。
支持微服务架构：容器可以作为微服务架构的基础设施，帮助开发人员快速构建、部署和管理复杂的分布式系统。
目前，Docker是最常用的容器技术，它提供了一个开放的生态系统，可以方便地管理容器。

镜像技术：
镜像技术是一种软件开发和部署技术，它允许开发人员将一个完整的软件环境打包为一个可重复使用的镜像文件。
镜像文件包含了所有应用程序和系统所需的文件，以及它们的配置。

镜像技术的优势在于：
简化部署：使用镜像可以快速地将应用程序部署到任何环境中。
提高一致性：镜像文件包含了所有所需的文件和配置，因此可以保证在不同的环境中的一致性。
方便回滚：如果一个镜像不能正常工作，可以方便地回滚到以前的版本。
镜像技术是虚拟化、容器化和云计算等计算机领域的重要技术，在微服务架构、云部署等场景中被广泛使用。常见的镜像技术有Docker镜像、Kubernetes镜像、OpenShift镜像等。

Docker：
Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。
Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。
容器是完全使用沙箱机制，相互之间不会有任何接口,更重要的是容器性能开销极低。
Docker支持将软件编译成一个镜像；然后在镜像中各种软件做好配置，将镜像发布出去，其他使用者可以直接使用这个镜像。
运行中的这个镜像称为容器，容器启动是非常快速的。类似windows里面的ghost操作系统，安装好后什么都有了；

Docker核心概念：
docker镜像(Images)：Docker 镜像是用于创建 Docker 容器的模板。
docker容器(Container)：容器是独立运行的一个或一组应用。
docker客户端(Client)：客户端通过命令行或者其他工具使用
Docker API(https://docs.docker.com/reference/api/docker_remote_api) 与 Docker 的守护进程通信
docker主机(Host)：一个物理或者虚拟的机器用于执行Docker 守护进程和容器。
docker仓库(Registry)：Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。Docker 
Hub(https://hub.docker.com) 提供了庞大的镜像集合供使用。

为什么Docker比Vm快
1、docker有着比虚拟机更少的抽象层。由于docker不需要Hypervisor实现硬件资源虚拟化,运行在docker容器上的程序直接使用的都是实际物理机的硬件资源。
因此在CPU、内存利用率上docker将会在效率上有明显优势。
2、docker利用的是宿主机的内核,而不需要Guest OS。
因此,当新建一个 容器时,docker不需要和虚拟机一样重新加载一个操作系统内核。
仍而避免引导、加载操作系统内核返个比较费时费资源的过程,当新建一个虚拟机时,虚拟机软件需要加载GuestOS,返个新建过程是分钟级别的。
而docker由于直接利用宿主机的操作系统,则省略了这个复杂的过程,因此新建一个docker容器只需要几秒钟。

kernel：Linux系统内核

boot file system （bootfs）：包含boot loader和kernel。用户不会修改这个文件系统。Linux系统刚启动时会加载bootfs文件系统；
而在启动完成后，整个内核都会被加载进内存，此时bootfs会被卸载掉从而释放出所占用的内存。
对于同样内核版本的不同的Linux发行版的bootfs都是一致的。

root file system （rootfs）：包含典型的目录结构，包括/dev, /proc, /bin, /etc, /lib, /usr, and /tmp等，
再加上要运行用户应用所需要的所有配置文件，二进制文件和库文件。这个文件系统在不同的Linux发行版中是不同的，
且用户可以对这个文件进行修改。

k8s：
k8s可以更快的更新新版本，打包应用，更新的时候可以做到不用中断服务，服务器故障不用停机，
从开发环境到测试环境到生产环境的迁移极其方便，一个配置文件搞定，一次生成image，到处运行。
在k8s进行管理应用的时候，基本步骤是：创建集群，部署应用，发布应用，扩展应用，更新应用。


分布式中间件：
中间件技术是计算机系统中的一个软件层，位于客户端和服务端之间，负责处理两者之间的通信和数据交换。
它可以通过转换格式、路由消息、管理连接等方式支持多种应用场景，并具有提高系统可靠性、安全性、扩展性等优势。
常见的中间件技术包括消息队列、缓存、负载均衡、API网关、数据库代理和文件存储代理等。
它们各具特点，可以应用于分布式系统、微服务架构、大数据系统等不同场景。

中间件技术包括：
消息队列：如RabbitMQ、ActiveMQ、Kafka等。
缓存：如Redis、Memcached等。
负载均衡：如Nginx、HAProxy、F5等。
API网关：如Kong、Zuul、Tyk等。
数据库代理：如MySQL Proxy、PgBouncer等。
文件存储代理：如Ceph、GlusterFS等。

消息队列：
消息队列中间件是分布式系统中重要的组件，主要实现异步消息，应用解耦，流量削峰及消息通讯等功能。

RocketMQ:
RocketMQ作为一款纯java、分布式、队列模型的开源消息中间件，支持事务消息、顺序消息、批量消息、定时消息、消息回溯等。

RocketMQ 特点：
>支持发布/订阅（Pub/Sub）和点对点（P2P）消息模型
>在一个队列中可靠的先进先出（FIFO）和严格的顺序传递 （RocketMQ可以保证严格的消息顺序，而ActiveMQ无法保证）
>支持拉（pull）和推（push）两种消息模式
pull其实就是消费者主动从MQ中去拉消息，而push则像rabbit MQ一样，是MQ给消费者推送消息。但是RocketMQ的push其实是基于pull来实现的。
它会先由一个业务代码从MQ中pull消息，然后再由业务代码push给特定的应用/消费者。其实底层就是一个pull模式
>单一队列百万消息的堆积能力 （RocketMQ提供亿级消息的堆积能力，这不是重点，重点是堆积了亿级的消息后，依然保持写入低延迟）
>支持多种消息协议，如 JMS、MQTT 等
>分布式高可用的部署架构,满足至少一次消息传递语义（RocketMQ原生就是支持分布式的，而ActiveMQ原生存在单点性）
>提供 docker 镜像用于隔离测试和云集群部署
>提供配置、指标和监控等功能丰富的 Dashboard

Java创建RocketMQ生产者:
package com.wn.producer;

import com.alibaba.rocketmq.client.exception.MQClientException;
import com.alibaba.rocketmq.client.producer.DefaultMQProducer;
import com.alibaba.rocketmq.client.producer.SendResult;
import com.alibaba.rocketmq.common.message.Message;
public class MQProducer {
public static void main(String[] args) throws MQClientException {
DefaultMQProducer producer=new DefaultMQProducer("rmq-group");
producer.setNamesrvAddr("192.168.138.187:9876;192.168.138.188:9876");
producer.setInstanceName("producer");
producer.start();
try {

for (int i=0;i<10;i++){
Thread.sleep(1000); //每秒发送一次
Message msg = new Message("itmayiedu-topic", // topic 主题名称
"TagA", // tag 临时值
("itmayiedu-"+i).getBytes()// body 内容
);
SendResult sendResult=producer.send(msg);
System.out.println(sendResult.toString());
}

} catch (Exception e) {
e.printStackTrace();
}
producer.shutdown();
}
}



Java创建RocketMQ消费者:

package com.wn.consumer;

import com.alibaba.rocketmq.client.consumer.DefaultMQPushConsumer;
import com.alibaba.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;
import com.alibaba.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;
import com.alibaba.rocketmq.client.consumer.listener.MessageListenerConcurrently;
import com.alibaba.rocketmq.client.exception.MQClientException;
import com.alibaba.rocketmq.common.message.MessageExt;
import java.util.List;

public class MQConsumer {
public static void main(String[] args) throws MQClientException {
DefaultMQPushConsumer consumer=new DefaultMQPushConsumer("rmq-group");
consumer.setNamesrvAddr("192.168.138.187:9876;192.168.138.188:9876");
consumer.setInstanceName("consumer");
consumer.subscribe("itmayiedu-topic","TagA");
consumer.registerMessageListener(new MessageListenerConcurrently() {
@Override
public ConsumeConcurrentlyStatus consumeMessage(List list, ConsumeConcurrentlyContext consumeConcurrentlyContext) {
for (MessageExt msg:list){
System.out.println(msg.getMsgId()+"---"+new String(msg.getBody()));
}
return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
}
});

consumer.start();
System.out.println("Consumer Started...");
}
}

RabbitMQ:
RabbitMQ是由erlang语言开发，基于AMQP（Advanced Message Queue 高级消息队列协议）协议实现的消息队列，
它是一种应用程序之间的通信方法，消息队列在分布式系统开发中应用非常广泛。

RabbitMQ特点：
>RabbitMQ是使用Erlang语言开发的开源消息队列系统，基于AMQP协议来实现。
>AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。
>AMQP协议更多用在企业系统内，对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量的要求还在其次。
>RabbitMQ的可靠性是非常好的，数据能够保证百分之百的不丢失。可以使用镜像队列，它的稳定性非常好。所以说在我们互联网的金融行业。对数据的稳定性和可靠性要求都非常高的情况下，我们都会选择RabbitMQ。当然没有kafka性能好，但是要比AvtiveMQ性能要好很多。也可以自己做一些性能的优化。
>RabbitMQ可以构建异地双活架构，包括每一个节点存储方式可以采用磁盘或者内存的方式。

RabbitMQ创建直连交换机：
import org.springframework.amqp.core.Binding;
import org.springframework.amqp.core.BindingBuilder;
import org.springframework.amqp.core.DirectExchange;
import org.springframework.amqp.core.Queue;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
 
@Configuration
public class DirectRabbitConfig {
 
    //队列 起名：TestDirectQueue
    @Bean
    public Queue TestDirectQueue() {
        // durable:是否持久化,默认是false,持久化队列：会被存储在磁盘上，当消息代理重启时仍然存在，暂存队列：当前连接有效
        // exclusive:默认也是false，只能被当前创建的连接使用，而且当连接关闭后队列即被删除。此参考优先级高于durable
        // autoDelete:是否自动删除，当没有生产者或者消费者使用此队列，该队列会自动删除。
        // return new Queue("TestDirectQueue",true,true,false);
 
        //一般设置一下队列的持久化就好,其余两个就是默认false
        return new Queue("TestDirectQueue",true);
    }
 
    //Direct交换机 起名：TestDirectExchange
    @Bean
    DirectExchange TestDirectExchange() {
      //  return new DirectExchange("TestDirectExchange",true,true);
        return new DirectExchange("TestDirectExchange",true,false);
    }
 
    //绑定  
    //将队列和交换机绑定, 并设置用于匹配键：TestDirectRouting
    @Bean
    Binding bindingDirect() {
        return BindingBuilder.bind(TestDirectQueue()).to(TestDirectExchange()).with("TestDirectRouting");
    }
     
    @Bean
    DirectExchange lonelyDirectExchange() {
        return new DirectExchange("lonelyDirectExchange");
    }
}

写个接口实现消息推送：
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;
import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.util.HashMap;
import java.util.Map;
import java.util.UUID;

@RestController
public class SendMessageController {

    //使用RabbitTemplate,这提供了接收/发送等等方法
    @Autowired
    RabbitTemplate rabbitTemplate;  
 
    @GetMapping("/sendDirectMessage")
    public String sendDirectMessage() {
        String messageId = String.valueOf(UUID.randomUUID());
        String messageData = "test message, hello!";
        String createTime = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss"));
        Map<String,Object> map=new HashMap<>();
        map.put("messageId",messageId);
        map.put("messageData",messageData);
        map.put("createTime",createTime);
        //将消息携带绑定键值：TestDirectRouting 发送到交换机TestDirectExchange
        rabbitTemplate.convertAndSend("TestDirectExchange", "TestDirectRouting", map);
        return "ok";
    }
}



缓存中间件：Redis
Redis是一个使用C语言开发的数据库，与数据库不同，Redis的数据库存在内存中，它是内存数据库。正因为如此他的读写速度非常快，因此Redis作为nosql被广泛应用于缓存方向。
Redis除了做缓存之外，Redis也经常用来做分布式锁，甚至是消息队列。
Redis提供了多种数据类型来支持不同的业务场景。Redis还支持事务、持久化、Lua脚本、多种集群方案。

优点：
读写性能极高
支持数据持久化
支持事务
数据结构丰富
支持主从复制
丰富的特性

缺点：
数据库容量收到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。
主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。

redis可以在分布式系统中当缓存，也可以在分布式系统中用来做分布式锁。
redis用作分布式锁：为了解决分布式系统中的缓存击穿问题，需要分布式锁。
String uuid = UUID.randomUUID().toString();
lock = redisTemplate.opsForValue().setIfAbsent("lock","111"，300，TimeOut.SECONDS); //加锁并设置过期时间，保证了原子性
if(lock){
//加锁成功... 执行业务
Map<String，List<Catelog2Vo>> dataFromDb = getDataFromDb();
//删除锁脚本
String script = "if redis.ca11("get",KEYS[1]) == ARGV[1]then
return redis.ca11("de1",KEYS[1])else return 0 end";
//删除锁
Integer lock1 = redisTemplate.execute(new DefaultRedisScript<INTEGER>(script,Integer.class)
										,Array.asList("lock"),uuid);


return getDataFromDb();
}else {
//加锁失败...重试。
synchronized ()
return getCatalogJsonFromDbwithRedisLock();//自旋的方式
}

可以使用redisson完成分布式锁功能：

一、创建redisson工具类
@Bean(destroyMethod="shutdown")
public RedissonClient redisson() throws IOException {
//1、创建配置
//Redis url should start with redis:// or rediss://
Config config = new Config();
config.useSingleServer().setAddress("redis://192.168,5610:6379");
//2、根据Config创建出RedissonClient示例RedissonClient redissonClient = Redisson.create(config);
return redissonClient;
}

二、redisson创建分布式锁
@ResponseBody
@GetMapping("/he1lo")
public String hello(){

//1、获取一把锁，只要锁的名字一样，就是同一把锁
RLock lock = redisson .getLock( name: "my-lock");

//2、加锁
lock.lock(10,TimeUnit.SECONDS);//10秒自动解锁,自动解锁时间一定要大于业务的执行时间。
//Lock.Lock(10,TimeUnit.SECONDS); 在锁时间到了以后，不会自动续期。
//1、如果我们传递了锁的超时时间，就发送给redis执行脚本，进行占锁，默认超时就是我们指定的时间
//2、如果我们未指定锁的超时时间，就使用30 * 1000[LockWatchdogTimeout看门狗的默认时间];只要占锁成功，
就会启动一个定时任务[重新给锁设置过期时间，新的过期时间就是看门狗的默认时间],每隔10s都会自动续期
//internalLockLeaseTime[看门狗时间] / 3,10s
//1)、锁的自动续期，如果业务超长，运行期间自动给锁续上新的305。不用担心业务时间长，锁自动过期被删掉
//2)加锁的业务只要运行完成，就不会给当前锁续期，即使不手动解锁，锁默认在305以后自动删除。
try{
System.out.println("加锁成功，执行业务..."+Thread.currentThread().getId());
Thread.sleep( millis: 300e0);
}catch (Exception e){

}finally {

//3、解锁 将设解锁代码没有运行，redisson会不会出现死锁
System.out.println("释放锁..."+Thread.currentThread().getId());lock.unlock();
return "hello";
}

Spring缓存：SpringCache
Spring Cache利用了AOP，实现了基于注解的缓存功能，
并且进行了合理的抽象，业务代码不用关心底层是使用了什么缓存框架，只需要简单地加一个注解，就能实现缓存功能了。
@Cacheable({"category"})
public List<CategoryEntity> getLevel1Categorys() {
	......
}

SpringCache自定义缓存：
指定生成的缓存使用的key， key属性指定，接受一个SpEL
@Cacheable(value = {"category"},key = "#root.method.name")
public List<CategoryEntity> getLevel1Categorys() {
    return this.baseMapper.selectList(
            new QueryWrapper<CategoryEntity>().eq("parent_cid",0));
}

将数据保存为json格式，自定义RedisCacheConfiguration即可
@Configuration
@EnableCaching
public class MyCacheConfig {
    @Bean
    RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties){
        RedisCacheConfiguration config  = RedisCacheConfiguration.defaultCacheConfig();
        //修改key和value的序列化机制
        config = config .serializeKeysWith(
                RedisSerializationContext.SerializationPair.fromSerializer(
                        new StringRedisSerializer()));
        config = config.serializeValuesWith(
                RedisSerializationContext.SerializationPair.fromSerializer(
                        new GenericJackson2JsonRedisSerializer()));

        CacheProperties.Redis redisProperties = cacheProperties.getRedis();
        //将配置文件中的所有配置都生效
        if (redisProperties.getTimeToLive() != null) {
            config = config.entryTtl(redisProperties.getTimeToLive());
        }
        if (redisProperties.getKeyPrefix() != null) {
            config = config.prefixKeysWith(redisProperties.getKeyPrefix());
        }
        if (!redisProperties.isCacheNullValues()) {
            config = config.disableCachingNullValues();
        }
        if (!redisProperties.isUseKeyPrefix()) {
            config = config.disableKeyPrefix();
        }
        return config;
    }
}


数据库中间件Mycat：
从定义和分类来看，它是一个开源的分布式数据库系统，Mycat是一个实现了MySQL协议的服务器，
前端用户可以把它看作是一个数据库代理，用MySQL客户端工具和命令行访问，
而其后端可以用MySQL原生协议与多个MySQL服务器通信，也可以用JDBC协议与大多数主流数据库服务器通信，
其核心功能是分表分库，即将一个大表水平分割为N个小表，存储在后端MySQL服务器里或者其他数据库里。

为什么要使用Mycat?
Java与数据库的紧耦合
高访问量高并发对数据库的压力
读写请求数据不一致

分布式系统：
分布式系统是计算机程序的集合，这些程序利用跨多个独立计算节点的计算资源来实现共同的目标。
它也被称为分布式计算或分布式数据库，并依靠不同的节点通过公共网络进行通信和同步。
这些节点通常代表独立的物理硬件设备，但也可代表单独的软件进程或其他递归封装的系统。
分布式系统旨在消除系统的瓶颈或中心故障点。

分布式框架通常使用以下技术：
1.分布式系统的基本架构，包括节点、通信、一致性、数据分布等。
2.分布式资源管理，如负载均衡、任务调度、数据复制等。
3.分布式通信技术，如RPC、消息队列等。
4.集群管理和监控技术，如ZooKeeper、Nagios等。
5.分布式数据存储技术，如分布式文件系统、NoSQL数据库等。
这些技术与其他技术，如容错、可扩展性、数据一致性等结合使用，以构建一个完整的分布式系统。

分布式系统模式发展阶段：
1.单一应用框架(ORM)
当网站流量很小时，只需一个应用，将所有功能如下单支付等都部署在一起，以减少部署节点和成本。
2.垂直应用框架(MVC)
垂直应用架构解决了单一应用架构所面临的扩容问题，流量能够分散到各个子系统当中，且系统的体积可控，一定程度上降低了开发人员之间协同以及维护的成本，提升了开发效率。
MVC架构将网络交互层和数据交互层区分开，实现了业务读取和数据的分离。
3.分布式应用架构(RPC)
当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心。
不同业务场景的模块之间互相调用、通信。
4.流动计算架构(SOA)
随着服务化的进一步发展，服务越来越多，服务之间的调用和依赖关系也越来越复杂，诞生了面向服务的架构体系(SOA)，
也因此衍生出了一系列相应的技术，如对服务提供、服务调用、连接处理、通信协议、序列化方式、服务发现、服务路由、日志输出等行为进行封装的服务框架。
在分布式架构的基础上，延申出的架构。


RPC框架：远程过程调用，是一种通过网络从远程计算机程序上请求服务的程序。

RPC框架调用的过程：（客户端和服务端网络传输的过程）
(1) 客户端（client）以本地调用方式（即以接口的方式）调用服务；
(2) 客户端存根（client stub）接收到调用后，负责将方法、参数等组装成能够进行网络传输的消息体（将消息体对象序列化为二进制）；
(3) 客户端通过sockets将消息发送到服务端；
(4) 服务端存根( server stub)收到消息后进行解码（将消息对象反序列化）；
(5) 服务端存根( server stub)根据解码结果调用本地的服务；
(6) 本地服务执行并将结果返回给服务端存根（server stub）；
(7) 服务端存根( server stub)将返回结果打包成消息（将结果消息对象序列化）；
(8) 服务端(server)通过sockets将消息发送到客户端；
(9) 客户端存根(client stub)接收到结果消息，并进行解码（将结果消息发序列化）；
(10) 客户端(client)得到最终结果。

RPC的目标是要把2、3、4、7、8、9这些步骤都封装起来。

分布式系统的CAP理论：
Consistency：一致性，在分布式系统中，更新操作执行成功后所有的用户的读操作必须返回最新值；
client写入，server同步至整个系统；
Availability：可用性，只要收到用户的请求，在一定的时间内服务器就必须给出回应，回应的结果可以是成功或是失败；
Partition tolerance：分区容错，即区间通信可能失败，在网络中断，消息丢失的情况下，仍对外提供服务；
一般无法避免，可以认为CAP中的P总是成立

在一个分布式计算机系统中，一致性C，可用性A，分区容错性P这三种保证无法同时得到满足，最多满足两个：
1.放弃P
为了避免分区容错性问题的发生，一种做法是将所有与事务相关的数据都放在一台服务器上，虽然不能保证100%系统不会出错，
但是不会碰到由分区带来的负面效果，这样的做法会严重影响系统的扩展性。

2.放弃A
放弃可用性，一旦遇到分区容错故障，受到影响的服务器需要等待一定的时间，因此会导致在等待期间系统无法对外提供服务。

3.放弃C
这儿说的放弃一致性，并不是完全放弃数据的一致性，而是放弃数据的强一致性，而保留数据的最终一致性。
以网络购物为例，对只剩下一件库存的商品，如果同时接受到了两份订单，那么较晚的订单将被告知商品告罄。

分布式系统的通信方式：
分布式通信是指在分布式系统中，不同节点之间进行消息传递和交互的方式。
以下是常见的分布式通信方式：

消息队列（Message Queue）
使用消息队列作为中间件，节点之间通过发送和接收消息来实现通信。消息队列提供了异步、解耦和可靠性的通信机制，常见的消息队列系统包括RabbitMQ、Apache Kafka和ActiveMQ等。

实现方式
消息队列底层的实现可以有多种方式，具体取决于所使用的消息队列系统。以下是一些常见的底层实现方式：

基于内存：某些消息队列系统使用内存作为底层实现，以实现高吞吐量和低延迟。消息在内存中进行存储和传递，因此速度非常快。然而，这种实现方式通常会面临数据持久性和可靠性的挑战，因为内存是易失性存储。

基于文件系统：一些消息队列系统使用文件系统作为底层实现。消息被写入到文件中，并通过文件进行传递。这种实现方式可以提供较好的数据持久性，因为文件可以在系统重启后仍然存在。然而，相对于内存实现，文件系统实现的吞吐量和延迟可能较低。

基于数据库：部分消息队列系统使用数据库作为底层实现。消息被存储在数据库表中，并通过数据库进行传递。这种实现方式可以提供较好的数据持久性和可靠性，因为数据库通常具有事务支持和持久化机制。但是，数据库的读写开销可能较大，从而影响性能。

基于网络协议：一些消息队列系统使用网络协议作为底层实现，如TCP/IP协议栈。消息通过网络进行传输，可以在不同的计算节点之间进行通信。这种实现方式提供了跨网络的分布式消息传递，但可能受限于网络延迟和可靠性。

需要注意的是，不同的消息队列系统可能使用不同的底层实现方式，并且可以结合多种技术来实现不同的特性和性能。例如，一些消息队列系统可能会将内存和文件系统结合使用，
以在内存中提供高性能的消息传递，并在需要持久性时将消息写入文件系统。选择适当的底层实现方式取决于应用程序的需求，包括性能、可靠性和持久性等方面的考虑。

优缺点及适用场景
优点：异步通信、解耦性高、支持可靠性消息传递、支持消息持久化、可扩展性好。
缺点：引入中间件，增加了系统复杂性；消息顺序性可能受到影响；需要额外的管理和维护。
适用场景：分布式系统解耦、异步任务处理、实时数据流处理、事件驱动架构。

远程过程调用（Remote Procedure Call，RPC）
  使用RPC技术进行分布式通信，允许节点之间像调用本地函数一样进行远程调用。RPC提供了一种透明的通信方式，常见的RPC框架包括gRPC、Apache Thrift和Spring Cloud等。

优缺点及适用场景
优点：简化分布式通信过程；透明的远程调用；支持多种编程语言；高性能。
缺点：服务依赖性高；通信过程对网络要求较高；对系统的管理和维护较为复杂。
适用场景：微服务架构、跨语言通信、高性能计算、分布式计算。

RESTful API
  使用基于HTTP协议的RESTful API进行通信，节点之间通过HTTP请求和响应进行数据交换。RESTful API提供了一种简单和标准化的通信方式，常用于构建分布式Web服务和微服务架构。

优缺点及适用场景
优点：简单易用、基于标准的HTTP协议、良好的可扩展性、松耦合。
缺点：同步通信方式、无状态性可能导致性能问题；数据传输较为冗余。
适用场景：Web服务、前后端分离架构、微服务架构。

分布式共享内存（Distributed Shared Memory，DSM）
  通过共享内存的方式实现分布式通信，允许多个节点共享内存空间，从而实现数据共享和交互。DSM提供了高性能的通信方式，常见的DSM系统包括Apache Ignite和Hazelcast等。

优缺点及适用场景
优点：高性能的数据共享和交互；简化编程模型；可扩展性好。
缺点：一致性和同步性问题；需要复杂的内存管理和同步机制；依赖于底层网络。
适用场景：分布式缓存、分布式计算、分布式数据库。

网络套接字（Socket）
  使用底层的网络套接字进行直接的节点间通信，可以基于TCP或UDP协议实现点对点的数据传输。网络套接字提供了最底层的通信方式，常用于构建自定义的分布式通信协议和框架。

优缺点及适用场景
优点：最底层的通信方式；灵活性高；适用于定制化通信需求。
缺点：需要自行处理通信协议和数据格式；可靠性和一致性问题需要自行解决。
适用场景：定制化分布式通信协议、低级别的网络通信、特定的性能优化需求。

总结
需要根据具体的系统要求、性能需求、可靠性需求、开发团队技术栈和经验等因素，综合考虑选择合适的分布式通信方式。
有时候，系统可能会结合多种方式来满足不同的需求，例如使用消息队列进行异步通信，结合RESTful API进行同步交互。


分布式文件系统：
分布式文件系统可以有效解决数据的存储和管理难题：将固定于某个地点的某个文件系统，扩展到任意多个地点/多个文件系统，众多的节点组成一个文件系统网络。
每个节点可以分布在不同的地点，通过网络进行节点间的通信和数据传输。人们在使用分布式文件系统时，无需关心数据是存储在哪个节点上、或者是从哪个节点从获取的，
只需要像使用本地文件系统一样管理和存储文件系统中的数据。分布式文件系统是建立在客户机/服务器技术基础之上的，一个或多个文件服务器与客户机文件系统协同操作，
这样客户机就能够访问由服务器管理的文件。分布式文件系统的发展大体上经历子三个阶段：第一阶段是网络文件系统，第二阶段是共享SAN文件系统，第三阶段是面向对象的并行文件系统。


Spring Cloud：
Spring Cloud是一个为构建分布式系统的微服务框架。
准确的说，它不是一个框架，而是一个大的容器，将各个微服务通过接口调用，从而简化了开发者的代码量。
Spring Cloud和普通RPC有很大区别，Spring Cloud使用的是http协议的RPC框架，传统RPC框架使用内部调用的方式。

Spring Cloud常用组件：
SpringCloud的五大核心组件为Eureka、Fegin、Ribbon、Hystrix、Zull

1.Eureka（注册中心）
SpringCloud提供了多种注册中心的支持，这其中就包括Eureka、ZooKeeper等，我们平时常用的也是这两种
Eureka主要就是用来注册服务的，其中包括两部分：Eureka Client、Eureka Server
Eureka Client：包含服务提供者、服务消费者，主要负责服务注册、心跳续约与健康状况查询
Eureka Server：提供注册服务，各个节点启动后，都会在Eureka Server中注册，可用的节点信息可以在Eureka Server中的服务注册表中找到（Eureka Server之间通过复制的方式来完成数据的同步）
应用启动后，Eureka Client会向Eureka Server发送心跳，一般默认周期为30秒，如果Eureka在多个心跳周期内（一般为90秒）没有接受到某个节点的心跳，Eureka就会进入自我保护机制

2.Feign
Feign是一个HTTP请求的轻量级客户端框架。
通过 接口+注解 的方式发起HTTP请求的调用，而不是像Java中通过封装HTTP请求报文的方式直接调用。

Feign执行流程：
在主程序上添加@EnableFeignClients注解开启对已经加@FeignClient注解的接口进行扫描加载。
调用接口中的方法时，基于JDK动态代理的方式，通过InvokeHandler调用处理器分发远程调用，生成具体的RequestTemplate
RequestTemplate生成Request请求，结合Ribbon实现服务调用负载均衡策略
Feign最核心的就是动态代理，同时整合了Ribbon和Hystrix，具备负载均衡、隔离、熔断和降级功能

3.Ribbon（负载均衡）
Ribbon是一个客户端的负载均衡器，他提供对大量的HTTP和TCP客户端的访问控制
Ribbon负载均衡策略：简单轮询、权重、随机、重试等多种策略

4.Hystrix（服务熔断）
Hystrix提供两个命令，分别是HystrixCommand、HystrixObservableCommand，通常是在Spring中通过注解和AOP来实现对象的构造
熔断：简单来说，就是我们生活中的“保险丝”。如果熔断器打开，就会执行短路，直接进行降级；如果熔断器关闭，就会进入隔离逻辑。默认触发熔断器的条件为：最近一个时间窗口（默认为10秒），总请求次数大于等于circuitBreakerRequestVolume Threshold（默认为20次）并且异常请求比例大于circuitBreakerError ThresholdPercentage（默认为50%），此时熔断器触发
隔离：一般分为两种：线程池隔离和信号量隔离。线程池隔离指的是每个服务对应一个线程池，线程池满了就会降级；信号量隔离是基于tomcat线程池来控制的，当线程达到某个百分比，走降级流程
降级：作为Hystrix中兜底的策略，当出现业务异常、线程池已满、执行超时等情况，调用fallback方法返回一个错误提示

5.Zull（网关）
网关相当于一个网络服务架构的入口，所有网络请求必须通过网关转发到具体的服务。

主要功能：统一管理微服务请求、负载均衡、动态路由、权限控制、监控、静态资源处理等

负载均衡：为每一种负载类型分配对应的容量，并弃用超出限定值的请求
动态路由：根据需要动态的将路由请求到后台不同的集群
权限控制：可以识别认证需要的信息和拒绝不满足条件的请求
监控：追踪有意义的数据和统计结果
静态资源处理：直接在Zull中处理静态资源，从而避免其转发到内部集群

Dubbo：
一款分布式服务框架
高性能和透明化的RPC远程服务调用方案
SOA服务治理方案

Dubbo架构：
Provider: 暴露服务的服务提供方。
Consumer: 调用远程服务的服务消费方。
Registry: 服务注册与发现的注册中心。
Monitor: 统计服务的调用次数和调用时间的监控中心。

调用流程
0.服务容器负责启动，加载，运行服务提供者。
1.服务提供者在启动时，向注册中心注册自己提供的服务。
2.服务消费者在启动时，向注册中心订阅自己所需的服务。
3.注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。
4.服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。
5.服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心

Dubbo注册中心
对于服务提供方，它需要发布服务，而且由于应用系统的复杂性，服务的数量、类型也不断膨胀；
对于服务消费方，它最关心如何获取到它所需要的服务，而面对复杂的应用系统，需要管理大量的服务调用。
而且，对于服务提供方和服务消费方来说，他们还有可能兼具这两种角色，即既需要提供服务，有需要消费服务。

通过将服务统一管理起来，可以有效地优化内部应用对服务发布/使用的流程和管理。服务注册中心可以通过特定协议来完成服务对外的统一。
Dubbo提供的注册中心有如下几种类型可供选择：
Multicast注册中心
Zookeeper注册中心
Redis注册中心
Simple注册中心

Dubbo优缺点
优点：
透明化的远程方法调用
- 像调用本地方法一样调用远程方法；只需简单配置，没有任何API侵入。
软负载均衡及容错机制
可在内网替代nginx lvs等硬件负载均衡器。
服务注册中心自动注册 & 配置管理
-不需要写死服务提供者地址，注册中心基于接口名自动查询提供者ip。
使用类似zookeeper等分布式协调服务作为服务注册中心，可以将绝大部分项目配置移入zookeeper集群。
服务接口监控与治理
-Dubbo-admin与Dubbo-monitor提供了完善的服务接口管理与监控功能，针对不同应用的不同接口，可以进行 多版本，多协议，多注册中心管理。

缺点：
只支持JAVA语言

分布式应用程序协调服务：
什么是注册中心？
注册中心是微服务架构中的纽带，类似于“通讯录”，它记录了服务和服务地址的映射关系。
在分布式架构中，服务会注册到这里，当服务需要调用其它服务时，就到这里找到服务的地址并进行调用。
注册中心本质上是为了解耦服务提供者和服务消费者。对于任何一个微服务，原则上都应存在或者支持多个提供者，这是由微服务的分布式属性决定的，
更进一步，为了支持弹性扩缩容特性，一个微服务的提供者的数量和分布往往是动态变化的，也是无法预先确定的。
因此，原本在单体应用阶段常用的静态LB机制就不再适用了，需要引入额外的组件来管理微服务提供者的注册与发现，
而这个组件就是服务注册中心。

注册中心的核心功能：
服务注册：服务实例将自身服务信息注册到注册中心
服务发现：服务实例通过注册中心，获取到注册到其中的服务实例的信息，通过这些信息去请求它们提供的服务
服务剔除：服务注册中心将出问题的服务自动剔除到可用列表之外，使其不会被调用到

什么是负载均衡？
负载均衡建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、
加强网络数据处理能力、提高网络的灵活性和可用性。
负载均衡（Load Balance）其意思就是分摊到多个操作单元上进行执行，
例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。

Zookeeper：注册中心
eureka：注册中心
nacos: 注册中心
Ribbon：负载均衡组件
Hystrix：断路器
Zuul：网关服务组件
SpringCloud Config：配置中心

zookeeper和eureka有什么区别？
1：zookeeper保证cp原则（一致性）而Eureka保证的是ap原则（可用性）
2：zookeeper在选举期间注册服务瘫痪不可用，而Eureka各个节点平等，只要一台就能保证服务可以，但查询到的数据不一定是最新的，可以很好的应对网络故障导致的部分节点失联
3：zookeeper有header和follower角色（当header挂掉，会从剩下的follower里面选举一个header），Eureka各个节点平等
4：zookeeper采用半数存活原则（避免脑裂），Eureka采用自我保护机制来解决分区问题
5：kafka就是使用的zookeeper作为注册中心，理论上Eureka更适合作为注册中心

分布式服务跟踪ELK：
ELK 是elastic公司提供的一套完整的日志收集、展示解决方案，是三个产品的首字母缩写，分别是ElasticSearch、Logstash 和 Kibana：

ElasticSearch简称ES，由Java 语言编写，它是一个建立在全文搜索引擎Apache Lucene基础上的、实时的、分布式的搜索和分析引擎，
它可以用于全文搜索，结构化搜索以及分析；
Logstash是一个具有实时传输能力的数据收集引擎，用来进行数据收集（如：读取文本文件）、解析，并将数据发送给ES；
Kibana为Elasticsearch提供了分析和可视化的Web平台。
它可以在Elasticsearch的索引中查找，交互数据，并生成各种维度表格、图形；
在ELK中beats是用于数据采集的工具，相较于logstash，beats是更轻量级的工具。Beats 平台集合了多种单一用途数据采集器，这些采集器安装后可用作轻量型代理，从成百上千或成千上万台机器向 Logstash 或 Elasticsearch 发送数据。

1、elasticSearch
是一个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。
2、logstash
主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式（支持以TCP/UDP/HTTP多种方式收集数据）。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作，再一并发往elasticSearch上去。
3、kibana
是一个开源工具，kibana可以为logstash和elasticSearch提供的日志分析友好的web界面，可以帮助汇总、分析和搜索重要数据日志。
4、filebeat
filebeat隶属于beats。目前beats包含四种工具：
（1）packetbeat（搜索网络流量数据）
（2）topbeat（搜索系统、进程和文件系统级别的CPU和内存使用情况等数据）
（3）filebeat（搜集文件数据）
（4）winlogbeat（搜集windows事件日志数据）

登录-安全框架Spring security：
Spring Security是一个能够为基于Spring的企业应用系统提供声明式的安全访问控制解决方案的安全框架。
它提供了一组可以在Spring应用上下文中配置的Bean，充分利用了Spring IoC，
DI（控制反转Inversion of Control ,DI:Dependency Injection 依赖注入）
和AOP（面向切面编程）功能，为应用系统提供声明式的安全访问控制功能，减少了为企业系统安全控制编写大量重复代码的工作。

Spring Security一般流程为：

1.当用户登录时，前端将用户输入的用户名、密码信息传输到后台，后台用一个类对象将其封装起来，
通常使用的是UsernamePasswordAuthenticationToken这个类。
2.程序负责验证这个类对象。验证方法是调用Service根据username从数据库中取用户信息到实体类的实例中，
比较两者的密码，如果密码正确就成功登陆，同时把包含着用户的用户名、密码、所具有的权限等信息的类对象放到
SecurityContextHolder（安全上下文容器，类似Session）中去。
3.用户访问一个资源的时候，首先判断是否是受限资源。如果是的话还要判断当前是否未登录，没有的话就跳到登录页面。
如果用户已经登录，访问一个受限资源的时候，程序要根据url去数据库中取出该资源所对应的所有可以访问的角色，
然后拿着当前用户的所有角色一一对比，判断用户是否可以访问（这里就是和权限相关）。

Java在处理敏感数据的时候如何实现数据的安全性？

使用加密算法：Java提供了多种加密算法，如AES、DES、RSA等，可以对敏感数据进行加密，保护数据不被非法获取。
使用安全协议：Java提供了SSL/TLS协议，可以用于实现加密通信，保证数据在传输过程中的安全性。
使用安全容器：Java提供了安全容器，如Java KeyStore、Java CredentialStore等，可以用于存储密钥和凭据，保护敏感数据不被非法访问。
权限控制：Java可以通过权限控制机制，如Java安全管理器（Security Manager），对敏感数据进行访问控制，防止非法访问和操作。
数据备份：对于重要的敏感数据，应该定期备份，并存储到安全的地方，以防止数据丢失或损坏。

分布式搜索引擎Elasticsearch：
Elasticsearch 是一个分布式、高扩展、高实时的搜索与数据分析引擎。
它能很方便的使大量数据具有搜索、分析和探索的能力。
Elasticsearch 的实现原理主要分为以下几个步骤，首先用户将数据提交到Elasticsearch 数据库中，
再通过分词控制器去将对应的语句分词，将其权重和分词结果一并存入数据，
当用户搜索数据时候，再根据权重将结果排名，打分，再将返回结果呈现给用户。

1.首先要存储数据，必须要建立索引。在es中索引实际仅仅是一个逻辑上的命名空间，这个命名空间指向的是一个或多个的分片shard，其中分片的出先可以实现水平扩容，副本分片的出现作用于高可用。
2.一个分片是一个仅仅保存了索引中所有数据中一部分分片数据的低级别的工作单元
3.一个分片就是一个Lucene实例，对于他本身而言就是一个完整的查询搜索引擎。
4.我们的文档是被存储索引在分片中的，但是客户端并不直接和分片交互，而是和index索引进行交互
5.众多分片是ES集群分布式存储数据的方式，可以简单把分片当作存储数据的容器。文档存储在分片中，分片被分配到集群中的节点Node中。
6.当集群扩容、缩容时，es能够自动的对集群节点中分片上的数据进行迁移，最终仍能保证数据均衡分布
7.分片分为主分片和副本分片
8.每个分片从技术实现上来讲，最大可以索引Integer.MAX_VALUE-128个文档；实际上存储的上限取决于你的硬件资源、文档结构的复杂度等

primary shard 主分片
每个文档都只会存储在一个主分片中，不会分散存储在多个主分片中，并且每个分片所存储的容量是有上限的，因此我们配置的每个索引的主分片数量，就决定了该索引最大的容量。
主分片的数量是在创建索引时就确定的，不能再修改

replica shard 副本分片
副本分片是主分片的一个copy，有两个目的一是：解决单点问题，用于冗余数据，应对硬件故障，实现高可用；
二是：大流量支撑，每个副本都可以提供查询、检索请求。
副本数量在任何时刻都可以变更
每个主分片的副本分片，不会被和他的主分片分配在同一个Node节点上，
因为在同一个节点上的主、副本分配上没有任何意义的，一旦该Node挂掉，这个Node节点上的主、副本副片都会丢失。


分布式实时数据分析Clickhouse：
ClickHouse 是 Yandex（俄罗斯最大的搜索引擎）开源的一个用于实时数据分析的基于列存储的数据库，其处理数据的速度比传统方法快 100-1000 倍。
ClickHouse 的性能超过了目前市场上可比的面向列的 DBMS，每秒钟每台服务器每秒处理数亿至十亿多行和数十千兆字节的数据。

分布式版本控制系统Git：
Git是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。

从一般开发者的角度来看，git有以下功能：
1、从服务器上克隆完整的Git仓库（包括代码和版本信息）到单机上。(指令 git clone)
2、在自己的机器上根据不同的开发目的，创建分支，修改代码。	(指令 git branch xxx )
3、在单机上自己创建的分支上提交代码。	(指令 git add .)
4、在单机上合并分支。 (指令 git merge xxx(分支名字))
5、把服务器上最新版的代码fetch下来，然后跟自己的主分支合并。
6、生成补丁（patch），把补丁发送给主开发者。
7、看主开发者的反馈，如果主开发者发现两个一般开发者之间有冲突（他们之间可以合作解决的冲突），就会要求他们先解决冲突，然后再由其中一个人提交。如果主开发者可以自己解决，或者没有冲突，就通过。
8、一般开发者之间解决冲突的方法，开发者之间可以使用pull 命令解决冲突，解决完冲突之后再向主开发者提交补丁。

从主开发者的角度（假设主开发者不用开发代码）看，git有以下功能：
1、查看邮件或者通过其它方式查看一般开发者的提交状态。
2、打上补丁，解决冲突（可以自己解决，也可以要求开发者之间解决以后再重新提交，如果是开源项目，还要决定哪些补丁有用，哪些不用）。
3、向公共服务器提交结果，然后通知所有开发人员。

Java大数据：
从业务层面来说，"大数据" 指的是由企业、组织和个人生成的大量和复杂的数据集。
这些数据集太大、太快或太复杂，它们无法用传统的数据处理工具进行处理和分析，它们通常来自多种来源，
包括但不限于社交媒体、电子商务交易、移动设备、传感器和日志文件渠道获取数据。
大数据既给社会带来机会，也给行业带来挑战。一方面，企业可以利用大数据获得有价值的洞察力、改进决策和优化运营。
另一方面，管理、存储和处理大数据需要专门的工具和技术，例如分布式系统、并行处理和机器学习算法。
为了处理大数据，企业通常使用一系列技术，包括 Hadoop、Spark、NoSQL 数据库和云计算平台。
这些技术使企业能够实时存储、处理和分析大量数据，并根据数据派生的洞察力做出明智的决策。
总之，大数据是一个快速发展的领域，涉及从多种来源收集、管理和分析大量数据。
从数据的多方面收集，再到企业的大数据系统，最后再根据数据的应用、数据的分析，来达到影响企业决策的目的，
这才是大数据的终极目标，它有可能通过为组织提供新的洞察力和创新机会，来改变企业和行业。

从技术层面来说，大数据的技术主要是基于Hadoop为底层实现，由hive、spark实现分布式批计算，
spark streaming、flink实现分布式流式传输，由kafka实现消息队列，由Flume实现数据抽取，
zookeeper实现分布式注册中心，clickhouse、hbase实现列式存储，有些系统架构时需要元数据管理、
调度系统、监控系统的一整套处理海量数据的数据处理系统。
大数据的框架众多，大数据技术也在不断进步，处理批数据的pig和流式传输storm已经被淘汰。

Hadoop 的三大主要组件是：
Hadoop 分布式文件系统 (HDFS)：一个分布式文件系统，可以在一组商业化硬件节点上存储大量数据集。
HDFS 旨在具有高度可扩展性和容错性，并提供数据复制以确保数据在硬件故障的情况下可用。
MapReduce：一种在计算机集群上并行处理大数据集的编程模型。
MapReduce 将处理逻辑与数据存储分离，并自动处理数据分布、容错性和负载平衡。
YARN (Yet Another Resource Negotiator)：一个资源管理系统，
可协调在 Hadoop 集群上运行的各种应用程序之间的资源（如 CPU、内存和存储）的分配。
YARN 提供了一个灵活且可扩展的平台，用于运行各种大数据应用，例如批处理、实时流处理和机器学习算法。

总之，这三个组件组成了 Hadoop 生态系统的核心，并提供了一个强大的平台，用于存储、处理和分析大量复杂数据集。。

MapReduce 是一个分布式运算程序的编程框架，是用户开发"基于 Hadoop 的数据分析应用"的核心框架。
MapReduce 核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上。
1.MapReduce运算程序一般需要分成2个阶段：Map阶段和Reduce阶段
2.Map阶段的并发MapTask，完全并行运行，互不相干
3.Reduce阶段的并发ReduceTask，完全互不相干，但是他们的数据依赖于上一个阶段的所有MapTask并发实例的输出
4.MapReduce编程模型只能包含一个Map阶段和一个Reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个MapReduce程序，串行运行

用户编写的程序分成三个部分：Mapper、Reducer 和 Driver。
1．Mapper阶段
（1）用户自定义的Mapper要继承自己的父类
（2）Mapper的输入数据是KV对的形式（KV的类型可自定义）
（3）Mapper中的业务逻辑写在map()方法中
（4）Mapper的输出数据是KV对的形式（KV的类型可自定义）
（5）map()方法（MapTask进程）对每一个<K,V>调用一次

2．Reducer阶段
（1）用户自定义的Reducer要继承自己的父类
（2）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV
（3）Reducer的业务逻辑写在reduce()方法中
（4）ReduceTask进程对每一组相同k的<k,v>组调用一次reduce()方法

3．Driver阶段
相当于YARN集群的客户端，用于提交我们整个程序到YARN集群，提交的是
封装了MapReduce程序相关运行参数的job对象

大数据资源管理系统YARN：
Yarn是Hadoop的分布式资源调度平台，负责为集群的运算提供运算资源。
如果把分布式计算机和单个计算机相对应的话，HDFS就相当于计算机的文件系统，
Yarn就是计算机的操作系统，MapReduce就是计算机上的应用程序。

Yarn主要由三个组件组成：
ResourceManager：他是整个集群资源的老大，负责整个集群系统的资源分配与调度。
NodeManager：他是单个节点的老大，管理本节点的用户作业和工作流。
ApplicationMaster：他是单个应用程序的老大，负责单个应用的监控运行。

1. ResourceManager
ResourceManager 负责整个集群的资源管理和分配，是一个全局的资源管理系统。
NodeManager 以心跳的方式向 ResourceManager 汇报资源使用情况（目前主要是 CPU 和内存的使用情况）。
RM 只接受 NM 的资源回报信息，对于具体的资源处理则交给 NM 自己处理。
YARN Scheduler 根据 application 的请求为其分配资源，不负责application job 的监控、追踪、运行状态反馈、启动等工作。

2. NodeManager
NodeManager 是每个节点上的资源和任务管理器，它是管理这台机器的代理，负责该节点程序的运行，以及该节点资源的管理和监控。YARN 集群每个节点都运行一个NodeManager。
NodeManager 定时向 ResourceManager 汇报本节点资源（CPU、内存）的使用情况和Container 的运行状态。当 ResourceManager 宕机时 NodeManager 自动连接 RM 备用节点。
NodeManager 接收并处理来自 ApplicationMaster 的 Container 启动、停止等各种请求。

3. ApplicationMaster
用户提交的每个应用程序均包含一个 ApplicationMaster ， 它可以运行在ResourceManager 以外的机器上。
负责与 RM 调度器协商以获取资源（用 Container 表示）。
将得到的任务进一步分配给内部的任务(资源的二次分配)。
与 NM 通信以启动/停止任务。
监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务。
当前 YARN 自带了两个 ApplicationMaster 实现，一个是用于演示AM 编写方法的实例程序 DistributedShell，
它可以申请一定数目的Container 以并行运行一个 Shell 命令或者 Shell 脚本；
另一个是运行 MapReduce 应用程序的 AM—MRAppMaster。

YARN工作机制：
1.客户端程序向ResourceManager提交应用并请求一个ApplicationMaster实例。
2.ResourceManager找到可以运行一个Container的NodeManager，并在这个Container中启动ApplicationMaster实例。
3.ApplicationMaster向ResourceManager进行注册，注册之后客户端就可以查询ResourceManager获得自己ApplicationMaster的详细信息，
以后就可以和自己的ApplicationMaster直接交互了。
4.在平常的操作过程中，ApplicationMaster根据resource-request协议向ResourceManager发送resource-request请求。
5.当Container被成功分配之后，ApplicationMaster通过向NodeManager发送container-launch-specification信息来启动
Container，container-launch-specification信息包含了能够让Container和ApplicationMaster交流所需要的资料。
6.应用程序的代码在启动的Container中运行，并把运行的进度、状态等信息通过application-specific协议发送给ApplicationMaster。
7.在应用程序运行期间，提交应用的客户端主动和ApplicationMaster交流获得应用的运行状态、进度更新等信息，
交流的协议也是application-specific协议。
8.一但应用程序执行完成并且所有相关工作也已经完成，ApplicationMaster向ResourceManager取消注册然后关闭，
用到所有的Container也归还给系统。

数据仓库工具Hive：
Hive是由 Facebook 开源用于解决海量结构化日志的数据统计工具，Hive 是基于 Hadoop 的一个数据仓库工具，
可以将结构化的数据文件映射为一张表，并提供类 SQL 查询功能。

Hive的本质是将HQL转化成MapReduce程序：
Hive 通过给用户提供的一系列交互接口，接收到用户的指令(SQL)，使用自己的 Driver，结合元数据(MetaStore)，
将这些指令翻译成 MapReduce，提交到 Hadoop 中执行，最后，将执行返回的结果输出到用户交互接口。

Hive的优缺点：
优点：
（1）操作接口采用类 SQL 语法，提供快速开发的能力（简单、容易上手）。
（2）避免了去写 MapReduce，减少开发人员的学习成本。
（3）Hive 的执行延迟比较高，因此 Hive 常用于数据分析，对实时性要求不高的场合。
（4）Hive 优势在于处理大数据，对于处理小数据没有优势，因为 Hive 的执行延迟比较
高。
（5）Hive 支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。

缺点：
1、Hive 的 HQL 表达能力有限
①迭代式算法无法表达
②数据挖掘方面不擅长，由于 MapReduce 数据处理流程的限制，效率更高的算法却无法实现。

2、Hive 的效率比较低
①Hive 自动生成的 MapReduce 作业，通常情况下不够智能化
②Hive 调优比较困难，粒度较粗

Hive的底层原理：
（1）解析器（SQL Parser）：将 SQL 字符串转换成抽象语法树 AST，
这一步一般都用第三方工具库完成，比如 antlr；对 AST 进行语法分析，
比如表是否存在、字段是否存在、SQL语义是否有误。
（2）编译器（Physical Plan）：将 AST 编译生成逻辑执行计划。
（3）优化器（Query Optimizer）：对逻辑执行计划进行优化。
（4）执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于 Hive 来说，就是 MR/Spark。


Spark 批处理运算：
Spark 是一个分布式数据快速分析项目。它的核心技术是弹性分布式数据集（Resilient Distributed Datasets），
提供了比 MapReduce 丰富的模型，可以快速在内存中对数据集进行多次迭代，来支持复杂的数据挖掘算法和图形计算算法。
Spark底层是由Hadoop实现，但是和Hadoop有明显不同。

Spark和MapReduce对比:
1.MapReduce多个作业间的数据通信是基于磁盘, 而Sparke多个作业间的数据通信是基于内存
2.一个MapReduce程序只有map+reduce, 而Spark程序可以有多个算子
3.MapReduce是批处理, 而Spark是批处理 & 微批准实时处理
4.Shuffle中Spark不用落盘, 而MapReduce要磁盘
5.Spark有丰富的RDD算子, SQL操作, Streaming流处理, 还可以处理机器学习, 而MapReduce只有Mapper和Reducer
6.Spark有容错机制可以切断血缘, 避免失败后从源头数据开始全部重新计算

Spark Core:Spark Core 中提供了 Spark 最基础与最核心的功能，
Spark 其他的功能如：Spark SQL，Spark Streaming，GraphX, MLlib 都是在 Spark Core 的基础上进行扩展。
MapReduce 框架采用非循环式的数据流模型，把中间结果写入到 HDFS 中，带来了大量的数据复制、磁盘 IO 和序列化开销。
且这些框架只能支持一些特定的计算模式(map/reduce)，并没有提供一种通用的数据抽象。因此Spark发展出了RDD这个概念。

RDD(Resilient Distributed Dataset)叫做弹性分布式数据集，
是 Spark 中最基本的数据抽象，代表一个不可变、可分区、里面的元素可并行计算的集合。

RDD单词拆解：
Resilient ：它是弹性的，RDD 里面的中的数据可以保存在内存中或者磁盘里面；
Distributed ： 它里面的元素是分布式存储的，可以用于分布式计算；
Dataset: 它是一个集合，可以存放很多元素。

RDD 的算子分为两类:
Transformation转换操作:返回一个新的 RDD
Action动作操作:返回值不是 RDD(无返回值或返回其他的)

注意:
RDD 不实际存储真正要计算的数据，而是记录了数据的位置在哪里，数据的转换关系(调用了什么方法，传入什么函数)。
RDD 中的所有转换都是惰性求值/延迟执行的，也就是说并不会直接计算。
只有当发生一个要求返回结果给 Driver 的 Action动作时，这些转换才会真正运行。
之所以使用惰性求值/延迟执行，是因为这样可以在 Action 时对 RDD 操作形成 DAG有向无环图进行 Stage 的划分和并行优化，
这种设计让 Spark 更加有效率地运行。

存储级别
默认的存储级别都是仅在内存存储一份，Spark 的存储级别还有好多种，存储级别在 object StorageLevel 中定义的。
>RDD 持久化/缓存的目的是为了提高后续操作的速度
>缓存的级别有很多，默认只存在内存中,开发中使用 memory_and_disk
>只有执行 action 操作的时候才会真正将 RDD 数据进行持久化/缓存
>实际开发中如果某一个 RDD 后续会被频繁的使用，可以将该 RDD 进行持久化/缓存

RDD 容错机制Checkpoint
持久化的局限：

持久化/缓存可以把数据放在内存中，虽然是快速的，但是也是最不可靠的；
也可以把数据放在磁盘上，也不是完全可靠的！例如磁盘会损坏等。
问题解决：
Checkpoint 的产生就是为了更加可靠的数据持久化，在Checkpoint的时候一般把数据放在在 HDFS 上，
这就天然的借助了 HDFS 天生的高容错、高可靠来实现数据最大程度上的安全，实现了 RDD 的容错和高可用。

SparkContext.setCheckpointDir("目录") //HDFS的目录
RDD.checkpoint

持久化和 Checkpoint 的区别：
位置：Persist 和 Cache 只能保存在本地的磁盘和内存中(或者堆外内存–实验中) Checkpoint 可以保存数据到 HDFS 这类可靠的存储上。
生命周期：Cache 和 Persist 的 RDD 会在程序结束后会被清除或者手动调用 unpersist 方法 Checkpoint 的 RDD 在程序结束后依然存在，不会被删除。

RDD的依赖关系：宽依赖和窄依赖
对于窄依赖：
>窄依赖的多个分区可以并行计算；
>窄依赖的一个分区的数据如果丢失只需要重新计算对应的分区的数据就可以了。

对于宽依赖：
划分 Stage(阶段)的依据:对于宽依赖,必须等到上一阶段计算完成才能计算下一阶段。

DAG(Directed Acyclic Graph 有向无环图)：指的是数据转换执行的过程，有方向，无闭环(其实就是 RDD 执行的流程)；
原始的 RDD 通过一系列的转换操作就形成了 DAG 有向无环图，任务执行时，可以按照 DAG 的描述，执行真正的计算(数据被操作的一个过程)。
DAG 的边界:
开始：通过 SparkContext 创建的 RDD；
结束：触发 Action，一旦触发 Action 就形成了一个完整的 DAG。

划分stage可以运用在并行计算。一个复杂的业务逻辑如果有 shuffle，那么就意味着前面阶段产生结果后，
才能执行下一个阶段，即下一个阶段的计算要依赖上一个阶段的数据。
那么我们按照 shuffle 进行划分(也就是按照宽依赖就行划分)，就可以将一个 DAG 划分成多个 Stage/阶段，
在同一个 Stage 中，会有多个算子操作，可以形成一个 pipeline 流水线，流水线内的多个平行的分区可以并行执行。

总结：Spark 会根据 shuffle/宽依赖使用回溯算法来对 DAG 进行 Stage 划分，
从后往前，遇到宽依赖就断开，遇到窄依赖就把当前的 RDD 加入到当前的 stage/阶段中。

广播变量：广播变量用来把变量在所有节点的内存之间进行共享，
在每个机器上缓存一个只读的变量，而不是为机器上的每个任务都生成一个副本。

import org.apache.spark.broadcast.Broadcast
import org.apache.spark.rdd.RDD
import org.apache.spark.{SparkConf, SparkContext}

object BroadcastVariablesTest {
  def main(args: Array[String]): Unit = {
    val conf: SparkConf = new SparkConf().setAppName("wc").setMaster("local[*]")
    val sc: SparkContext = new SparkContext(conf)
    sc.setLogLevel("WARN")

    //不使用广播变量
    val kvFruit: RDD[(Int, String)] = sc.parallelize(List((1,"apple"),(2,"orange"),(3,"banana"),(4,"grape")))
    val fruitMap: collection.Map[Int, String] =kvFruit.collectAsMap
    //scala.collection.Map[Int,String] = Map(2 -> orange, 4 -> grape, 1 -> apple, 3 -> banana)
    val fruitIds: RDD[Int] = sc.parallelize(List(2,4,1,3))
    //根据水果编号取水果名称
    val fruitNames: RDD[String] = fruitIds.map(x=>fruitMap(x))
    fruitNames.foreach(println)
    //注意:以上代码看似一点问题没有,但是考虑到数据量如果较大,且Task数较多,
    //那么会导致,被各个Task共用到的fruitMap会被多次传输
    //应该要减少fruitMap的传输,一台机器上一个,被该台机器中的Task共用即可
    //如何做到?---使用广播变量
    //注意:广播变量的值不能被修改,如需修改可以将数据存到外部数据源,如MySQL、Redis
    println("=====================")
    val BroadcastFruitMap: Broadcast[collection.Map[Int, String]] = sc.broadcast(fruitMap)
    val fruitNames2: RDD[String] = fruitIds.map(x=>BroadcastFruitMap.value(x))
    fruitNames2.foreach(println)

  }
}

Spark SQL:Spark SQL 是 Spark 用来操作结构化数据的组件。
通过 Spark SQL，用户可以使用 SQL或者 Apache Hive 版本的 SQL 方言（HQL）来查询数据。

Spark SQL数据抽象可以分为两类：
① DataFrame：DataFrame 是一种以 RDD 为基础的分布式数据集，类似于传统数据库的二维表格，
带有 Schema 元信息(可以理解为数据库的列名和类型)。DataFrame = RDD ＋ 泛型 + SQL 的操作 + 优化
② DataSet：DataSet是DataFrame的进一步发展，它比RDD保存了更多的描述信息，概念上等同于关系型数据库中的二维表，
它保存了类型信息，是强类型的，提供了编译时类型检查。调用 Dataset 的方法先会生成逻辑计划，
然后被 spark 的优化器进行优化，最终生成物理计划，然后提交到集群中运行！DataFrame = Dateset[Row]

RDD[Person]：以 Person 为类型参数，但不了解其内部结构。
DataFrame：提供了详细的结构信息 schema 列的名称和类型。这样看起来就像一张表了。
DataFrame = RDD - 泛型 + Schema + SQL + 优化

DataSet[Person]：不光有 schema 信息，还有类型信息。
DataSet = DataFrame + 泛型
DataSet = RDD + Schema + SQL + 优化

Spark Streaming:Spark Streaming 是 Spark 平台上针对实时数据进行流式计算的组件，提供了丰富的处理数据流的API。
Spark Streaming 的特点：
易用：可以像编写离线批处理一样去编写流式程序，支持 java/scala/python 语言。
容错：SparkStreaming 在没有额外代码和配置的情况下可以恢复丢失的工作。
易整合到 Spark 体系：流式处理与批处理和交互式查询相结合。

Spark Streaming工作流程：
① Spark Streaming 中，会有一个接收器组件 Receiver，作为一个长期运行的 task 跑在一个 Executor 上，Receiver 接收外部的数据流形成 input DStream。
② DStream 会被按照时间间隔划分成一批一批的 RDD，当批处理间隔缩短到秒级时，便可以用于处理实时数据流（时间间隔的大小可以由参数指定，一般设在 500 毫秒到几秒之间）。
③ 对 DStream 进行操作就是对 RDD 进行操作，计算处理的结果可以传给外部系统。
④ 接受到实时数据后，给数据分批次，然后传给 Spark Engine 处理最后生成该批次的结果。

Spark Streaming的实时性：
Spark Streaming 将流式计算分解成多个 Spark Job，对于每一时间段数据的处理都会经过 Spark DAG 图分解
以及 Spark 的任务集的调度过程。
对于目前版本的 Spark Streaming 而言，其最小的 Batch Size 的选取在 0.5~5 秒钟之间。
所以 Spark Streaming 能够满足流式准实时计算场景，对实时性要求非常高的如高频实时交易场景则不太适合。

Structure Streaming：
Structured Streaming 是一个基于 Spark SQL 引擎的可扩展、容错的流处理引擎。
统一了流、批的编程模型，你可以使用静态数据批处理一样的方式来编写流式计算操作。
并且支持基于 event_time 的时间窗口的处理逻辑。
Structured Streaming 最核心的思想就是将实时到达的数据看作是一个不断追加的 unbound table 无界表，
到达流的每个数据项(RDD)就像是表中的一个新行被附加到无边界的表中，
这样用户就可以用静态结构化数据的批处理查询方式进行流计算，如可以使用 SQL 对到来的每一行数据进行实时查询处理。

Transform实时计算：
case class DeviceData(device: String, deviceType: String, signal: Double, time: DateTime)
val df: DataFrame = ... // streaming DataFrame with IOT device data with schema { device: string, deviceType: string, signal: double, time: string }
val ds: Dataset[DeviceData] = df.as[DeviceData]    // streaming Dataset with IOT device data
// Select the devices which have signal more than 10
df.select("device").where("signal > 10")      // using untyped APIs
ds.filter(_.signal > 10).map(_.device)         // using typed APIs
// Running count of the number of updates for each device type
df.groupBy("deviceType").count()                 // using untyped API
// Running average signal for each device type
import org.apache.spark.sql.expressions.scalalang.typed
ds.groupByKey(_.deviceType).agg(typed.avg(_.signal))    // using typed API

计算结果可以选择输出到多种设备并进行如下设定：
output mode：以哪种方式将 result table 的数据写入 sink,即是全部输出 complete 还是只输出新增数据；
format/output sink 的一些细节：数据格式、位置等。如 console；
query name：指定查询的标识。类似 tempview 的名字；
trigger interval：触发间隔，如果不指定，默认会尽可能快速地处理数据；
checkpointLocation：一般是 hdfs 上的目录。注意：Socket 不支持数据恢复，如果设置了，第二次启动会报错，Kafka 支持。

Spark MLlib:
MLlib 是 Spark 提供的一个机器学习算法库。MLlib 不仅提供了模型评估、数据导入等额外的功能，
还提供了一些更底层的机器学习原语。

Spark GraphX:GraphX 是 Spark 面向图计算提供的框架与算法库。
Spark 计算框架为了能够进行高并发和高吞吐的数据处理，封装了三大数据结构，用于处理不同的应用场景。

Spark运行流程：
1.SparkContext 向资源管理器注册并向资源管理器申请运行 Executor
2.资源管理器分配 Executor，然后资源管理器启动 Executor
3.Executor 发送心跳至资源管理器
4.SparkContext 构建 DAG 有向无环图
5.将 DAG 分解成 Stage（TaskSet）
6.把 Stage 发送给 TaskScheduler
7.Executor 向 SparkContext 申请 Task
8.TaskScheduler 将 Task 发送给 Executor 运行
9.同时 SparkContext 将应用程序代码发放给 Executor
10.Task 在 Executor 上运行，运行完毕释放所有资源


Flink 大数据批处理运算+流式运算：
Apache Flink 是一个开源的、分布式的大数据处理框架，可以处理批量数据和实时数据处理。
它被设计成快速、可扩展和可靠，并提供统一的批量和流数据处理编程模型。

Flink 的一些关键特性包括：
低延迟处理：Flink 提供了实时数据流的低延迟处理，适用于实时分析、欺诈检测和网络监测等场景。
容错性：Flink 提供了内置的容错性，确保数据处理即使在节点故障的情况下也可以继续。
可扩展性：Flink 可以水平扩展，添加额外的节点来处理不断增加的数据。
高效数据处理：Flink 通过其流水线数据处理架构提供高效的数据处理，减少了中间数据存储的需求。
易于使用：Flink 提供了一个用户友好的编程模型，支持 Java 和 Scala，并提供类似 SQL 的查询语言进行流数据处理。

Flink 应用程序结构：
Source: 数据源，Flink 在流处理和批处理上的 source 大概有 4 类：基于本地集合的 source、基于文件的 source、
基于网络套接字的 source、自定义的 source。自定义的 source 常见的有 Apache kafka、RabbitMQ 等，
当然你也可以定义自己的 source。

Transformation：数据转换的各种操作，有 Map / FlatMap / Filter / KeyBy / Reduce / Fold / Aggregations / Window 
/ WindowAll / Union / Window join / Split / Select等，操作很多，可以将数据转换计算成你想要的数据。

Sink：接收器，Flink 将转换计算后的数据发送的地点 ，你可能需要存储下来，Flink 常见的 Sink 大概有如下几类：
写入文件、打印出来、写入 socket 、自定义的 sink 。自定义的 sink 常见的有 
Apache kafka、RabbitMQ、MySQL、ElasticSearch、Apache Cassandra、Hadoop FileSystem 等，
同理你也可以定义自己的 sink。

2. Flink 并行数据流
Flink 程序在执行的时候，会被映射成一个 Streaming Dataflow，一个 Streaming Dataflow 是由一组 Stream 和 Transformation Operator 组成的。在启动时从一个或多个 Source Operator 开始，结束于一个或多个 Sink Operator。
Flink 程序本质上是并行的和分布式的，在执行过程中，一个流(stream)包含一个或多个流分区，而每一个 operator 包含一个或多个 operator 子任务。操作子任务间彼此独立，在不同的线程中执行，甚至是在不同的机器或不同的容器上。operator 子任务的数量是这一特定 operator 的并行度。相同程序中的不同 operator 有不同级别的并行度。

一个 Stream 可以被分成多个 Stream 的分区，也就是 Stream Partition。一个 Operator 也可以被分为多个 Operator Subtask。如上图中，Source 被分成 Source1 和 Source2，它们分别为 Source 的 Operator Subtask。
每一个 Operator Subtask 都是在不同的线程当中独立执行的。一个 Operator 的并行度，就等于 Operator Subtask 的个数。
上图 Source 的并行度为 2。而一个 Stream 的并行度就等于它生成的 Operator 的并行度。

数据在两个 operator 之间传递的时候有两种模式：
One to One 模式：两个 operator 用此模式传递的时候，会保持数据的分区数和数据的排序；如上图中的 Source1 到 Map1，它就保留的 Source 的分区特性，以及分区元素处理的有序性。
Redistributing （重新分配）模式：这种模式会改变数据的分区数；每个一个 operator subtask 会根据选择 transformation 把数据发送到不同的目标 subtasks,比如 keyBy()会通过 hashcode 重新分区,broadcast()和 rebalance()方法会随机重新分区；

3. Task 和 Operator chain
Flink的所有操作都称之为Operator，客户端在提交任务的时候会对Operator进行优化操作，
能进行合并的Operator会被合并为一个Operator，合并后的Operator称为Operator chain，实际上就是一个执行链，
每个执行链会在TaskManager上一个独立的线程中执行。


4. 任务调度与执行
当Flink执行executor会自动根据程序代码生成DAG数据流图；
ActorSystem创建Actor将数据流图发送给JobManager中的Actor；
JobManager会不断接收TaskManager的心跳消息，从而可以获取到有效的TaskManager；
JobManager通过调度器在TaskManager中调度执行Task（在Flink中，最小的调度单元就是task，对应就是一个线程）；
在程序运行过程中，task与task之间是可以进行数据传输的。

Job Client：
主要职责是提交任务, 提交后可以结束进程, 也可以等待结果返回；
Job Client 不是 Flink 程序执行的内部部分，但它是任务执行的起点；
Job Client 负责接受用户的程序代码，然后创建数据流，将数据流提交给 Job Manager 以便进一步执行。
执行完成后，Job Client 将结果返回给用户。

JobManager：
主要职责是调度工作并协调任务做检查点；
集群中至少要有一个 master，master 负责调度 task，协调checkpoints 和容错；
高可用设置的话可以有多个 master，但要保证一个是 leader, 其他是standby；
Job Manager 包含 Actor System、Scheduler、CheckPoint三个重要的组件；
JobManager从客户端接收到任务以后, 首先生成优化过的执行计划, 再调度到TaskManager中执行。

TaskManager：
主要职责是从JobManager处接收任务, 并部署和启动任务, 接收上游的数据并处理；
Task Manager 是在 JVM 中的一个或多个线程中执行任务的工作节点；
TaskManager在创建之初就设置好了Slot, 每个Slot可以执行一个任务。

5. 任务槽和槽共享
每个TaskManager是一个JVM的进程, 可以在不同的线程中执行一个或多个子任务。
为了控制一个worker能接收多少个task。worker通过task slot来进行控制（一个worker至少有一个task slot）。

1) 任务槽
每个task slot表示TaskManager拥有资源的一个固定大小的子集。
flink将进程的内存进行了划分到多个slot中。
图中有2个TaskManager，每个TaskManager有3个slot的，每个slot占有1/3的内存。
内存被划分到不同的slot之后可以获得如下好处:
TaskManager最多能同时并发执行的任务是可以控制的，那就是3个，因为不能超过slot的数量。
slot有独占的内存空间，这样在一个TaskManager中可以运行多个不同的作业，作业之间不受影响。

2) 槽共享
默认情况下，Flink允许子任务共享插槽，即使它们是不同任务的子任务，只要它们来自同一个作业。结果是一个槽可以保存作业的整个管道。允许插槽共享有两个主要好处：
只需计算Job中最高并行度（parallelism）的task slot,只要这个满足，其他的job也都能满足。
资源分配更加公平，如果有比较空闲的slot可以将更多的任务分配给它。图中若没有任务槽共享，负载不高的Source/Map等subtask将会占据许多资源，而负载较高的窗口subtask则会缺乏资源。
有了任务槽共享，可以将基本并行度（base parallelism）从2提升到6.提高了分槽资源的利用率。同时它还可以保障TaskManager给subtask的分配的slot方案更加公平。

FLink的Time和Window：
流式：就是数据源源不断的流进来，也就是数据没有边界，但是我们计算的时候必须在一个有边界的范围内进行，
所以这里面就有一个问题，边界怎么确定？无非就两种方式，根据时间段或者数据量进行确定，
根据时间段就是每隔多长时间就划分一个边界，根据数据量就是每来多少条数据划分一个边界，
Flink 中就是这么划分边界的，本文会详细讲解。

实时：就是数据发送过来之后立马就进行相关的计算，然后将结果输出。这里的计算有两种：
一种是只有边界内的数据进行计算，这种好理解，比如统计每个用户最近五分钟内浏览的新闻数量，
就可以取最近五分钟内的所有数据，然后根据每个用户分组，统计新闻的总数。
另一种是边界内数据与外部数据进行关联计算，比如：统计最近五分钟内浏览新闻的用户都是来自哪些地区，
这种就需要将五分钟内浏览新闻的用户信息与 hive 中的地区维表进行关联，然后在进行相关计算。

Time：
在Flink中，如果以时间段划分边界的话，那么时间就是一个极其重要的字段。

Flink中的时间有三种类型：

Event Time：是事件创建的时间。它通常由事件中的时间戳描述，例如采集的日志数据中，每一条日志都会记录自己的生成时间，Flink通过时间戳分配器访问事件时间戳。
Ingestion Time：是数据进入Flink的时间。
Processing Time：是每一个执行基于时间操作的算子的本地系统时间，与机器相关，默认的时间属性就是Processing Time。

例如，一条日志进入Flink的时间为2021-01-22 10:00:00.123，到达Window的系统时间为2021-01-22 10:00:01.234，
日志的内容：2021-01-06 18:37:15.624 INFO Fail over to rm2
对于业务来说，要统计1min内的故障日志个数，哪个时间是最有意义的？—— eventTime，因为我们要根据日志的生成时间进行统计。

Window：
Window，即窗口，我们前面一直提到的边界就是这里的Window(窗口)。
官方解释：流式计算是一种被设计用于处理无限数据集的数据处理引擎，而无限数据集是指一种不断增长的本质上无限的数据集，
而window是一种切割无限数据为有限块进行处理的手段。
所以Window是无限数据流处理的核心，Window将一个无限的stream拆分成有限大小的”buckets”桶，
我们可以在这些桶上做计算操作。

Window类型
本文刚开始提到，划分窗口就两种方式：
根据时间进行截取(time-driven-window)，比如每1分钟统计一次或每10分钟统计一次。
根据数据进行截取(data-driven-window)，比如每5个数据统计一次或每50个数据统计一次。

总之，Flink 是一个强大的大数据处理框架，适用于批量数据和实时数据处理。它提供了低延迟处理、容错性、可扩展性

ClickHouse 大数据列式存储：
ClickHouse是一个开源的，用于联机分析（OLAP）的列式数据库管理系统（DBMS-database manager system）, 它是面向列的，
并允许使用SQL查询，实时生成分析报告。ClickHouse最初是一款名为Yandex.Metrica的产品，主要用于WEB流量分析。
ClickHouse的全称是Click Stream，Data WareHouse，简称ClickHouse。

ClickHouse不是一个单一的数据库,它允许在运行时创建表和数据库，加载数据和运行查询，而无需重新配置和重新启动服务器。
ClickHouse同时支持列式存储和数据压缩，这是对于一款高性能数据库来说是必不可少的特性。
一个非常流行的观点认为，如果你想让查询变得更快，最简单且有效的方法是减少数据扫描范围和数据传输时的大小，
而列式存储和数据压缩就可以帮助我们实现上述两点，列式存储和数据压缩通常是伴生的，因为一般来说列式存储是数据压缩的前提。

Zookeeper 大数据分布式协调服务
Zookeeper从设计模式角度来理解：是一个基于观察者模式设计的分布式服务管理框架，
它负责存储和管理大家都关心的数据，然后接受观察者的注册，
一旦这些数据的状态发生变化，Zookeeper就将负责通知已经在Zookeeper上注册的那些观察者做出相应的反应。

特点：
1.Zookeeper：一个领导者（Leader），多个跟随者（Follower）组成的集群。
2.集群中只要有半数以上节点存活，Zookeeper集群就能正常服务。所 以Zookeeper适合安装奇数台服务器。
3.全局数据一致：每个Server保存一份相同的数据副本，Client无论连接到哪个Server，数据都是一致的。
4.更新请求顺序执行，来自同一个Client的更新请求按其发送顺序依次执行。
5.数据更新原子性，一次数据更新要么成功，要么失败。
6.实时性，在一定时间范围内，Client能读到最新数据。

zookeeper的选举机制：
半数机制，超过半数的投票通过，即通过。
（1）第一次启动选举规则：
投票过半数时，服务器 id 大的胜出
（2）第二次启动选举规则：
①EPOCH 大的直接胜出
②EPOCH 相同，事务 id 大的胜出
③事务 id 相同，服务器 id 大的胜出

zookeeper可以保证数据的一致性。底层采用Paxos算法，对分布式系统中某个数据达成一致。

Paxos算法流程：
（1）Prepare: Proposer生成全局唯一且递增的Proposal ID，向所有Acceptor发送Propose请求，这里无需携带提案内容，只携带Proposal ID即可。
（2）Promise: Acceptor收到Propose请求后，做出“两个承诺，一个应答”。
➢ 不再接受Proposal ID小于等于（注意：这里是<= ）当前请求的Propose请求。
➢ 不再接受Proposal ID小于（注意：这里是< ）当前请求的Accept请求。
➢ 不违背以前做出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值。
（3）Propose: Proposer收到多数Acceptor的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。
如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。
然后携带当前Proposal ID，向所有Acceptor发送Propose请求。
（4）Accept: Acceptor收到Propose请求后，在不违背自己之前做出的承诺下，接受并持久化当前Proposal ID和提案Value。
（5）Learn: Proposer收到多数Acceptor的Accept后，决议形成，将形成的决议发送给所有Learner。

PS：如果系统中有一个以上的 Proposer，多个 Proposers 相互争夺 Acceptor，针对这种情况，一种改进的 Paxos 算法被提出：从系统中选
出一个节点作为 Leader，只有 Leader 能够发起提案。这样能避免活锁的情况出现。改进后的算法被称作ZAB协议。
Zookeeper保证了CAP理论中的CP，即一致性和分区容错性。Zookeeper不能保证每次服务请求的可用性，进行leader选举时集群不可用。

ZAB过程：
（1）客户端发起一个写操作请求。
（2）Leader服务器将客户端的请求转化为事务Proposal 提案，同时为每个Proposal 分配一个全局的ID，即zxid。
（3）Leader服务器为每个Follower服务器分配一个单独的队列，然后将需要广播的 Proposal依次放到队列中去，并且根据FIFO策略进行消息发送。
（4）Follower接收到Proposal后，会首先将其以事务日志的方式写入本地磁盘中，写入成功后向Leader反馈一个Ack响应消息。
（5）Leader接收到超过半数以上Follower的Ack响应消息后，即认为消息发送成功，可以发送commit消息。
（6）Leader向所有Follower广播commit消息，同时自身也会完成事务提交。Follower 接收到commit消息后，会将上一条事务提交。
（7）Zookeeper采用Zab协议的核心，就是只要有一台服务器提交了Proposal，就要确保所有的服务器最终都能正确提交Proposal。


Flume 大数据数据采集：Flume 是 Cloudera 提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。
Flume最主要的作用是实时读取服务器本地的文件，将数据写入到HDFS。

Flume基础结构：
1 Agent
Agent 是一个 JVM 进程，它以事件的形式将数据从源头送至目的。
Agent 主要有 3 个部分组成，Source、Channel、Sink。

2 Source
Source 是负责接收数据到 Flume Agent 的组件。Source 组件可以处理各种类型、各种格式的日志数据，
包括 avro、thrift、exec、jms、spooling directory、netcat、taildir、sequence generator、syslog、http、legacy。

3 Sink
Sink 不断地轮询 Channel 中的事件且批量地移除它们，并将这些事件批量写入到存储或索引系统、或者被发送到另一个 Flume Agent。
Sink 组件目的地包括 hdfs、logger、avro、thrift、ipc、file、HBase、solr、自定义。

4 Channel
Channel 是位于 Source 和 Sink 之间的缓冲区。因此，Channel 允许 Source 和 Sink 运作在不同的速率上。
Channel 是线程安全的，可以同时处理几个 Source 的写入操作和几个Sink 的读取操作。
Flume 自带两种 Channel：Memory Channel 和 File Channel。
Memory Channel 是内存中的队列。Memory Channel 在不需要关心数据丢失的情景下适用。
如果需要关心数据丢失，那么 Memory Channel 就不应该使用，因为程序死亡、机器宕机或者重启都会导致数据丢失。
File Channel 将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数据。

5 Event
传输单元，Flume 数据传输的基本单元，以 Event 的形式将数据从源头送至目的地。
Event 由 Header 和 Body 两部分组成，Header 用来存放该 event 的一些属性，为 K-V 结构，Body 用来存放该条数据，形式为字节数组。

kafka 大数据消息队列

传统的消息队列的主要应用场景包括：缓存/消峰、解耦和异步通信。
两种模式：点对点模式（消费者主动拉取数据，消息收到后清除数据），发布/订阅模式（可以有多个主题，消费者通过主题消费数据，每个消费者互相独立，都可以消费的到数据）

kafka特点：
1.为方便扩展，并提高吞吐量，一个topic分为多个partition
2.配合分区的设计，提出消费者组的概念，组内每个消费者并行消费
3.为提高可用性，为每个partition增加若干副本，类似NameNode HA
4. ZK中记录谁是leader，Kafka2.8.0以后也可以配置不采用ZK

Azkaban 大数据任务调度
Azkaban是由Linkedin公司推出的一个批量工作流任务调度器，主要用于在一个工作流内以一个特定的顺序运行一组工作和流程，
它的配置是通过简单的<key, value>对的方式，通过配置中的dependencies来设置依赖关系。
Azkaban使用job配置文件建立任务之间的依赖关系，并提供一个易于使用的Web用户界面维护和跟踪你的工作流。


常见工作流调度系统:
1.简单的任务调度：直接使用 Linux 的 Crontab 来定义；
2.复杂的任务调度：开发调度平台或使用现成的开源调度系统，比如 Ooize、Azkaban、Airflow、DolphinScheduler 等。

Azkaban由三个关键组件构成：
元数据
AzkabanWebServer
AzkabanExecutorServer

元数据
Azkaban使用关系型数据库存储元数据和执行状态。

AzkabanWebServer
项目管理：项目、项目权限以及上传的文件。
作业状态：跟踪执行流程以及执行程序正在运行的流程。
以前的流程/作业：通过以前的作业和流程执行以及访问其日志文件进行搜索。
计划程序：保留计划作业的状态。
SLA：保持所有的SLA规则

AzkabanExecutorServer
访问项目：从数据库检索项目文件。
执行流程/作业：检索和更新正在执行的作业流的数据
日志：将作业和工作流的输出日志存储到数据库中。
交互依赖关系：如果一个工作流在不同的执行器上运行，它将从数据库中获取状态。

AzkabanWebServer
AzkabanWebServer是整个Azkaban工作流系统的主要管理者，它负责Project管理、用户登录认证、定时执行工作流、跟踪工作流执行进度等
一系列任务。同时，它还提供Web服务操作接口，利用该接口，用户可以使用curl或其他Ajax的方式，来执行Azkaban的相关操作。
操作包括：用户登录、创建Project、上传Workflow、执行Workflow、查询Workflow的执行进度、杀掉Workflow等一系列操作，
且这些操作的返回结果均是JSON格式。并且Azkaban使用方便，Azkaban使用以.job为后缀名的键值属性文件来定义工作流中的各个任务，
以及使用dependencies属性来定义作业间的依赖关系链。这些作业文件和关联的代码最终以*.zip的方式通过Azkaban UI上传到Web服务器上。

AzkabanExecutorServer
以前版本的Azkaban在单个服务中具有AzkabanWebServer和AzkabanExecutorServer功能，
目前Azkaban已将AzkabanExecutorServer分离成独立的服务器，拆分AzkabanExecutorServer的原因有如下几点：

某个任务流失败后，可以更方便将其重新执行
便于Azkaban升级
AzkabanExecutorServer主要负责具体的工作流提交、执行，可以启动多个执行服务器，它们通过关系型数据库来协调任务的执行。

作业流执行过程：
WebServer根据内存中缓存的各Executor的资源（WebServer有一个线程会遍历各个Active Executor，
去发送Http请求获取其资源状态信息缓存到内存中），按照选择策略（包括executor资源状态、最近执行流个数等）选择一个Executor下发作业流；
Executor判断是否设置作业粒度分配，如果未设置作业粒度分配，则在当前Executor执行所有作业；
如果设置了作业粒度分配，则当前节点会成为作业分配的决策者，即分配节点；
分配节点从Zookeeper获取各个Executor的资源状态信息，然后根据策略选择一个Executor分配作业；
被分配到作业的Executor即成为执行节点，执行作业，然后更新数据库。


Atlas 大数据元数据管理
Apache Atlas 为组织提供开放式元数据管理和治理功能，用以构建其数据资产目录，对
这些资产进行分类和管理，形成数据字典。并为数据分析师和数据治理团队，提供围绕这些
数据资产的协作功能。
注：数据字典：可以查到 hive 库的释义，表的介绍以及字段的解释和说明。
1.表与表之间的血缘依赖
2.字段与字段之间的血缘依赖

Atlas的使用：
Atlas 的使用相对简单，其主要工作是同步各服务（主要是 Hive）的元数据，
并构建元数据实体之间的关联关系，然后对所存储的元数据建立索引，最终未用户提供数据血缘查看。

Apache Atlas为Hadoop的元数据治理提供了以下特性：

数据分类
- 为元数据导入或定义业务导向的分类注释
- 定义，注释，以及自动捕获数据集和底层元素之间的关系
- 导出元数据到第三方系统

集中审计
- 捕获与所有应用，过程以及与数据交互的安全访问信息
- 捕获执行，步骤，活动等操作的信息

搜索与血缘
- 预定义的导航路径用来探索数据分类以及审计信息
- 基于文本的搜索特性来快速和准确的定位相关联的数据和审计事件
- 对数据集血缘关系的可视化浏览使用户可以下钻到操作，安全以及数据起源相关的信息

安全与策略引擎
- 基于数据分类模式，属性以及角色的运行时合理合规策略
- 基于分类-预测的高级策略定义以防止数据推导
- 基于cell的属性和值的行/列级别的masking

Core
- Type System: Atlas 允许用户为他们想要管理的元数据对象定义一个模型。该模型由称为 "类型" 的定义组成。
"类型" 的 实例被称为 "实体" 表示被管理的实际元数据对象。类型系统是一个组件，允许用户定义和管理类型和实体。
由 Atlas 管理的所有元数据对象（例如Hive表）都使用类型进行建模，并表示为实体。要在 Atlas 中存储新类型的元数据，
需要了解类型系统组件的概念。

- Ingest/Export：Ingest 组件允许将元数据添加到 Atlas。类似地，Export 组件暴露由 Atlas 检测到的元数据更改，
以作为事件引发，消费者可以使用这些更改事件来实时响应元数据更改。

- Graph Engine：在内部，Atlas 通过使用图形模型管理元数据对象。以实现元数据对象之间的巨大灵活性和丰富的关系。
图形引擎是负责在类型系统的类型和实体之间进行转换的组件，以及基础图形模型。除了管理图形对象之外，
图形引擎还为元数据对象创建适当的索引，以便有效地搜索它们。

- Titan：目前，Atlas 使用 Titan 图数据库来存储元数据对象。 Titan 使用两个存储：默认情况下元数据存储配置为 HBase ，
索引存储配置为 Solr。也可以通过构建相应的配置文件使用BerkeleyDB存储元数据存储 和使用ElasticSearch存储 Index。
元数据存储用于存储元数据对象本身，索引存储用于存储元数据属性的索引，其允许高效搜索。

Integration
用户可以使用两种方法管理 Atlas 中的元数据：
- API： Atlas 的所有功能都可以通过 REST API 提供给最终用户，允许创建，更新和删除类型和实体。
它也是查询和发现通过 Atlas 管理的类型和实体的主要方法。
- Messaging：除了 API 之外，用户还可以选择使用基于 Kafka 的消息接口与 Atlas 集成。
这对于将元数据对象传输到 Atlas 以及从 Atlas 使用可以构建应用程序的元数据更改事件都非常有用。
如果希望使用与 Atlas 更松散耦合的集成，这可以允许更好的可扩展性，可靠性等，消息传递接口是特别有用的。
Atlas 使用 Apache Kafka 作为通知服务器用于钩子和元数据通知事件的下游消费者之间的通信。
事件由钩子(hook)和 Atlas 写到不同的 Kafka 主题。
- ATLAS_HOOK: 来自各个组件的Hook 的元数据通知事件通过写入到名为 ATLAS_HOOK 的 Kafka topic 发送到 Atlas
- ATLAS_ENTITIES：从 Atlas 到其他集成组件（如Ranger）的事件写入到名为 ATLAS_ENTITIES 的 Kafka topic



Metadata source
- Hive：通过hive bridge， atlas可以接入Hive的元数据，包括hive_db/hive_table/hive_column/hive_process
- Sqoop：通过sqoop bridge，atlas可以接入关系型数据库的元数据，包括sqoop_operation_type/ sqoop_dbstore_usage/sqoop_process/sqoop_dbdatastore
- Falcon：通过falcon bridge，atlas可以接入Falcon的元数据，包括falcon_cluster/falcon_feed/falcon_feed_creation/falcon_feed_replication/ falcon_process
- Storm：通过storm bridge，atlas可以接入流式处理的元数据，包括storm_topology/storm_spout/storm_bolt
- HBase: 通过hbase bridge

Atlas集成大数据组件的元数据源需要实现以下两点：

- 首先，需要基于atlas的类型系统定义能够表达大数据组件元数据对象的元数据模型
(例如Hive的元数据模型实现在org.apache.atlas.hive.model.HiveDataModelGenerator)；

- 然后，需要提供hook组件去从大数据组件的元数据源中提取元数据对象，实时侦听元数据的变更并反馈给atlas；

Applications
- Atlas Admin UI: 该组件是一个基于 Web 的应用程序，允许数据管理员和科学家发现和注释元数据。
Admin UI提供了搜索界面和类SQL的查询语言，可以用来查询由 Atlas 管理的元数据类型和对象。
Admin UI 使用 Atlas 的 REST API 来构建其功能。

- Tag Based Policies: Apache Ranger 是针对 Hadoop 生态系统的高级安全管理解决方案，与各种 Hadoop 组件具有广泛的集成。
通过与 Atlas 集成，Ranger 允许安全管理员定义元数据驱动的安全策略，以实现有效的治理。 
Ranger 是由 Atlas 通知的元数据更改事件的消费者。

- Business Taxonomy:从元数据源获取到 Atlas 的元数据对象主要是一种技术形式的元数据。
为了增强可发现性和治理能力，Atlas 提供了一个业务分类界面，允许用户首先定义一组代表其业务域的业务术语，
并将其与 Atlas 管理的元数据实体相关联。业务分类法是一种 Web 应用程序，目前是 Atlas Admin UI 的一部分，
并且使用 REST API 与 Atlas 集成。

 
ATlas类型系统
Atlas 允许用户为他们想要管理的元数据对象定义一个模型。该模型由称为 “类型” (type)的定义组成。被称为 “实体” (entities)的 “类型” 实例表示被管理的实际元数据对象。由 Atlas 管理的所有元数据对象（例如Hive表）都使用类型进行建模，并表示为实体。

- Type：Atlas中的 “类型” 定义了如何存储和访问特定类型的元数据对象。类型表示了所定义元数据对象的一个或多个属性集合。
具有开发背景的用户可以将 “类型” 理解成面向对象的编程语言的 “类” 定义的或关系数据库的 “表模式”。
类型具有元类型，元类型表示 Atlas 中此模型的类型：

- 基本元类型： Int，String，Boolean等
- 集合元类型：例如Array，Map
- Class，Struct，Trait

- Entities：Atlas中的 “实体” 是类 “类型” 的特定值或实例，因此表示真实世界中的特定元数据对象。
  回顾我们的面向对象编程语言的类比，“实例” 是某个 “类” 的 “对象”。
- Attributes：Atlas中的属性还有一些属性，其定义了与类型系统相关的更多概念，包括：
- isComposite - 是否复合
- isIndexable - 是否索引
- isUnique - 是否唯一
- multiplicity - 指示此属性是（必需的／可选的／还是可以是多值）的

Atlas 提供了一些预定义的系统类型：

- Referenceable：此类型表示可使用名为 qualifiedName 的唯一属性搜索的所有实体

- Asset：此类型包含名称，说明和所有者等属性

- Infrastructure：此类型扩展了Referenceable和Asset ，通常可用于基础设施元数据对象（如群集，主机等）的常用超类型

- DataSet：此类型扩展了Referenceable和Asset 。在概念上，它可以用于表示存储数据的类型。在 Atlas 中，hive表，Sqoop RDBMS表等
都是从 DataSet 扩展的类型。扩展 DataSet 的类型可以期望具有模式，它们将具有定义该数据集的属性的属性。
例如， hive_table 中的 columns 属性。另外，扩展 DataSet 的实体类型的实体参与数据转换，
这种转换可以由 Atlas 通过 lineage（或 provenance）生成图形。

- Process：此类型扩展了Referenceable和Asset 。在概念上，它可以用于表示任何数据变换操作。
例如，将原始数据的 hive 表转换为存储某个聚合的另一个 hive 表的 ETL 过程可以是扩展过程类型的特定类型。
流程类型有两个特定的属性，输入和输出。
 
Prometheus 大数据监控系统	
Prometheus 是一个开源的完整监控解决方案，其对传统监控系统的测试和告警模型进行了彻底的颠覆，
形成了基于中央化的规则计算、统一分析和告警的新模型。相比于传统监控系统，Prometheus 具有以下优点：

1 易于管理
➢ Prometheus 核心部分只有一个单独的二进制文件，不存在任何的第三方依赖(数据库，缓存等等)。唯一需要的就是本地磁盘，因此不会有潜在级联故障的风险。
➢ Prometheus 基于 Pull 模型的架构方式，可以在任何地方（本地电脑，开发环境，测试环境）搭建我们的监控系统。
➢ 对于一些复杂的情况，还可以使用 Prometheus 服务发现(Service Discovery)的能力动态管理监控目标。

2 监控服务的内部运行状态
Pometheus 鼓励用户监控服务的内部状态，基于 Prometheus 丰富的 Client 库，
用户可以轻松的在应用程序中添加对 Prometheus 的支持，从而让用户可以获取服务和应用内部真正的运行状态。

3 强大的数据模型
所有采集的监控数据均以指标(metric)的形式保存在内置的时间序列数据库当中(TSDB)。
所有的样本除了基本的指标名称以外，还包含一组用于描述该样本特征的标签。
每一条时间序列由指标名称(Metrics Name)以及一组标签(Labels)唯一标识。每条时
间序列按照时间的先后顺序存储一系列的样本值。
➢ http_request_status：指标名称(Metrics Name)
➢ {code='200',content_path='/api/path',environment='produment'}：表示维度的
标签，基于这些 Labels 我们可以方便地对监控数据进行聚合，过滤，裁剪。
➢ [value1@timestamp1,value2@timestamp2...]：按照时间的先后顺序 存储的样本值。

4 强大的查询语言 PromQL
Prometheus 内置了一个强大的数据查询语言 PromQL。 通过 PromQL 可以实现对
监控数据的查询、聚合。同时 PromQL 也被应用于数据可视化(如 Grafana)以及告警当中。
通过 PromQL 可以轻松回答类似于以下问题：
➢ 在过去一段时间中 95%应用延迟时间的分布范围？
➢ 预测在 4 小时后，磁盘空间占用大致会是什么情况？
➢ CPU 占用率前 5 位的服务有哪些？(过滤)

5 高效
对于监控系统而言，大量的监控任务必然导致有大量的数据产生。
而 Prometheus 可以高效地处理这些数据，对于单一 Prometheus Server 实例而言它可以处理：
➢ 数以百万的监控指标
➢ 每秒处理数十万的数据点

6 可扩展
可以在每个数据中心、每个团队运行独立的 Prometheus Sevrer。
Prometheus 对于联邦集群的支持，可以让多个 Prometheus 实例产生一个逻辑集群，
当单实例 Prometheus Server 处理的任务量过大时，通过使用功能分区(sharding)+联邦集群(federation)可以对其进行扩展。

7 易于集成
使用 Prometheus 可以快速搭建监控服务，并且可以非常方便地在应用程序中进行集成。
目前支持：Java，JMX，Python，Go，Ruby，.Net，Node.js 等等语言的客户端 SDK，
基于这些 SDK 可以快速让应用程序纳入到 Prometheus 的监控当中，或者开发自己的监控数据收集程序。
同时这些客户端收集的监控数据，不仅仅支持 Prometheus，还能支持 Graphite 这些其他的监控工具。
同时 Prometheus 还支持与其他的监控系统进行集成：Graphite，Statsd，Collected，Scollector，muini，Nagios等。 
Prometheus 社区还提供了大量第三方实现的监控数据采集支持：
JMX，CloudWatch，EC2，MySQL，PostgresSQL，Haskell，Bash，SNMP，
Consul，Haproxy，Mesos，Bind，CouchDB，Django，Memcached，RabbitMQ，
Redis，RethinkDB，Rsyslog 等等。

8 可视化
➢ Prometheus Server 中自带的 Prometheus UI，可以方便地直接对数据进行查询，并且支持直接以图形化的形式展示数据。
同时 Prometheus 还提供了一个独立的基于Ruby On Rails 的 Dashboard 解决方案 Promdash。
➢ 最新的 Grafana 可视化工具也已经提供了完整的 Prometheus 支持，基于 Grafana 可以创建更加精美的监控图标。
➢ 基于 Prometheus 提供的 API 还可以实现自己的监控可视化 UI。

9 开放性
通常来说当我们需要监控一个应用程序时，一般需要该应用程序提供对相应监控系统协议的支持，
因此应用程序会与所选择的监控系统进行绑定。为了减少这种绑定所带来的限制，
对于决策者而言要么你就直接在应用中集成该监控系统的支持，要么就在外部创建单独的服务来适配不同的监控系统。
而对于 Prometheus 来说，使用 Prometheus 的 client library 的输出格式不止支持Prometheus 的格式化数据，
也可以输出支持其它监控系统的格式化数据，比如 Graphite。
因此你甚至可以在不使用 Prometheus 的情况下，采用 Prometheus 的 client library 来让你的应用程序支持监控数据采集。
