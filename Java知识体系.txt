Java:Java是一个面向对象高级编程语言，通过Java编译器生成字节码文件在计算机里运行。
与C++不同，Java运用Java Virtual Machine（JVM）执行Java字节码（二进制形式），并通过JVM在多台机器上运行。
正因为Java运用了JVM在计算机上运行，并弱化了指针，因此Java不适合操作系统层面的源码编写，Java的应用在应用程序和web层面比较广泛。

Java官方文档：https://www.w3cschool.cn/java/dict

基本语法：关键字和保留字、标识符、变量、运算符、程序流程控制 
关键字：Java关键字是电脑语言里事先定义的，有特别意义的标识符，有时又叫保留字，还有特别意义的变量。
Java的关键字对Java的编译器有特殊的意义，他们用来表示一种数据类型，或者表示程序的结构等，关键字不能用作变量名、方法名、类名、包名和参数。
1、48个关键字：
用于定义类、函数、变量修饰符的关键字：
abstract、final、static、synchronized
用于定义类与类之间关系的关键字：
extends、implements
用于定义建立实例及引用实例、判断实例的关键字：
new、this、super、instanceof
用于异常处理的关键字：
try catch finally throw throws
用于包的关键字：
package import
其他修饰符关键字：
native、assert、transient、volatile、strictfp 
*用于定义数据类型值的字面值：
true、false、null。

2、Java保留字是指现有Java版本尚未使用 但以后版本可能会作为关键字使用，是C语言里用到但是Java里没有用到的关键字。
goto、const。

3、3个特殊直接量：true、false、null。

4、标识符：Java标识符由数字，字母和下划线（_），美元符号（$）或人民币符号（￥）组成。
在Java中是区分大小写的，而且还要求首位不能是数字。最重要的是，Java关键字不能当作Java标识符。
简单来说就是，在Java中凡是可以自己起名字的地方都叫标识符。

4.1 Java中的名称命名规范：
包名：多单词组成时所有字母都小写：xxxyyyzzz
类名、接口名：多单词组成时，所有单词的首字母大写：XxxYyyZzz
变量名、方法名：多单词组成时，第一个单词首字母小写，
第二个单词开始每个单词首字母大写：xxxYyyZzz
常量名：所有字母都大写。多单词时每个单词用下划线连接：XXX_YYY_ZZZ

5、变量
概念：本质上来说变量是内存中的一小块区域，通过变量名来访问这块区域。因此，使用每一个变量前必须要先申请（声明）然后必须对其进行赋值，才能使用

按照数据类型来分：
基本数据类型（primitive type,在栈stack中）：
整数类型：byte（1字节）、short（2字节）、int（4字节）、long（8字节）
浮点类型：float（4字节）、double（8字节）
整数类型默认为int、浮点类型默认为double。
字符型： char（使用Unicode编码、每个字符占两个字节，8个bite一个字节）
布尔型： boolean（与C语言布尔类型取0和1不同，只能取true和false）
引用数据类型（reference type,在堆heap中）：
类（字符串定义在类里）
接口
数组
（ *若想让基础类型存放在堆中，可以将基础类型包装为一个对象。将会用到基础类型的包装类）

按照声明的位置来分：
局部变量：方法体内，或者语句块内部定义的变量（局部变量不会默认初始化、必须先声明并赋值）
成员变量：方法体之外，类体中（需要先声明、赋值，若没有先赋值、则默认初始化后再使用）

基本数据类型大小：
类型 占用存储空间     表数范围
byte  1字节 = 8bit位   -128~127
short 2字节            -2^15~2^15-1
int   4字节            -2^31~2^31-1
long  8字节            -2^63~2^63-1
float 4字节 		   -3.40E+38 ~ +3.40E+38
double 8字节		   -1.79E+308 ~ +1.79E+308
注意：
bit : 计算机最小存储单位    byte：计算机中基本存储单元
整数类型默认为int、浮点类型默认为double。

字符型数据类型：
char用单引号'',String用双引号"";
String类型是字符串数据类型，用来存储多个字符，char类型只能存储一个字符。
String可以和8种数据类型做运算，运算的结果仍为String类型。
String是一个引用数据类型，但同时是一个final类，可以用字面量的定义方式去赋值。
通过字面量的方式（区别于new）赋值，会声明在常量池中。而常量池中不会存在相同内容的字符串。
所以，用==去比较两个相同内容的字符串，会返回true。

String代表不可变的字符串序列，称作"不可变性"
>当对字符串重新赋值时，需要重新写内存区域
>当对现有的字符串进行连接操作时，需要重新写内存区域赋值，不能在原有的基础上赋值
>当调用String的replace方法时，也需要重新写内存区域赋值，不能在原有的基础上赋值
>String字符串拼接的方式，常量和常量拼接的结果在常量池；只要其中有一个是变量，结果就在堆中；
 如果拼接的结果使用intern()方法，返回值在常量池中

String的实例化方式：
1.通过字面量的方式，声明在方法区中，两个相同的字符串返回true（即使是在对象中通过字面量定义的两个相同的字符串，返回的也是true）
2.通过new的方式，声明在堆中，两个相同的对象对比返回false

String与char之间的转换：
String → char ：使用String中的toCharArray()
char → String ：调用String中的构造器

String与byte之间的转换：
String → char ：使用String中的getByte()
char → String ：调用String中的构造器

不同于String是不可变的字符串序列，StringBuffer和StringBuilder是可变的字符串序列。
String：不可变的字符串序列
StringBuffer ：可变的字符串序列，线程安全，效率低，多线程时用
StringBuilder ：可变的字符串序列，线程不安全，效率高

String可以直接赋值或者创建对象
String s1 = "Hello"; // 通过直接赋值创建String对象  
String s2 = new String("Hello"); // 通过new关键字创建String对象

StringBuffer是Java中的一个可变类，它允许我们在同一个对象上进行多次的字符串操作。
StringBuffer sb = new StringBuffer(); // 创建一个空的StringBuffer对象  
sb.append("Hello"); // 添加字符串  
sb.append(" World"); // 添加另一个字符串  
System.out.println(sb.toString()); // 输出 "Hello World"

StringBuilder：StringBuilder和StringBuffer类似，也是Java中的一个可变类，允许我们在同一个对象上进行多次的字符串操作。
StringBuilder sb = new StringBuilder(); // 创建一个空StringBuilder对象  
sb.append("Hello"); // 添加字符串  
sb.append(" World"); // 添加另一个字符串  
System.out.println(sb.toString()); // 输出 "Hello World"

创建StringBuffer时，底层创建了一个长度为16的字符串char型数组；
如果创建时传了参数，则在此基础上增加一个长度为16的字符串char型数组，
默认情况下，扩容为原来的2倍+2，同时将原有数组的元素复制到新的数组中

基础数据类型的转换：
容量小的数据类型与容量大的数据类型运算，结果自动转换为容量大的数据类型。
当byte,short,char做运算时，结果必须是int类型。
byte,short,char -> int -> long -> float -> double

容量大的转换为容量小的：强制类型转换
注意：强制类型转换，可能导致精度损失。
// Widening
// byte<short<int<long<float<double
int i = 10;
long l = i;               // 10
// Narrowing 
double d = 10.02;
long l = (long)d;         // 10
String.valueOf(10);       // "10"
Integer.parseInt("10");   // 10
Double.parseDouble("10"); // 10.0

6、在Java当中，运算符可以分为：算术运算符(+ - * /)、 关系运算符(< > ==)、逻辑运算符、位运算符、移位运算符以及条件运算符等。
一、算术运算符
1，基本的四则运算：加减乘除模(+ - * / %)
注意点：

（1）这些运算符都是二元运算符，使用时必须要有左右两个操作数。

int a = 20;
int b = 10;
System.out.println(a + b); // 30
System.out.println(a - b); // 10
System.out.println(a * b); // 200
System.out.println(a / b); // 2
System.out.println(a % b); // 0 --->模运算相当于数学中除法的余数

（2）同C语言一样，int / int的结果还是int，而且会向下取整。

要出现小数点，那就转成double类型或在最后*1.0。

（3）除法和取模操作时，右操作数不能为0，否则会报出异常。

（4）%在Java中不但可以对整数进行取模，还可以对double进行取模操作。

（5）两边操作数不相同的时候，会发生类型提升。看一个特例：

对两个short类型进行相加，在用short进行接受，发现报错，提示是从int到short可能会有损失。
这是因为为了计算的方便，Java在将小于4个字节的类型进行计算的时候，会将其隐形提升到int类型。
上面两个short均被提升到int，在用short接收，就会报错。解决办法是进行强制类型转换。

2，增量运算符 = += -= *= %=
不会改变变量本身的数据类型。该种类型运算符操作完成后，会将操纵的结果赋值给左操作数。要注意只有变量才可以使用该运算符，常量不允许被修改，不能使用。

3，自增/自减运算符 ++/--
不会改变变量本身的数据类型。这两种运算符有前置和后置之分。如果是单独使用，那么前置和后置是没有区别的，如果是混合使用：

int a = 1;
a++; // 后置++ 表示给a的值加1，此时a的值为2
System.out.println(a++); // 注意：后置++是先使用变量原来值，表示式结束时再给变量+1，因此输出2
System.out.println(a); // 输出3
++a; // 前置++ 表示给a的值加1
System.out.println(++a); // 注意：前置++是先给变量+1，然后使用变量中的值，再使用表达式，因此输出5
System.out.println(a); // 输出5

混合使用，【前置++】先+1，然后使用变量+1之后的值，【后置++】先使用变量原来的值，表达式结束时给变量+1 只有变量才能使用自增/自减运算符，常量不能使用，因为常量不允许被修改。

二、关系运算符
主要有六个: == != < > <= >=，其计算结果是 true 或者 false 。在Java中，只有true和false，不存在0表示假，非0表示真。

当需要多次判断时，不能连着写，比如：3 < a < 5，在C语言当中，是可以运行的，但是在Java当中会报错，需要写成3 < a &&  a < 5。

==和equals的区别？
==：运算符
如果比较的是基本数据类型：比较两个变量保存的数据是否相同（不一定类型要相同）
如果比较的是引用数据类型：比较两个变量的地址值是否相同，是否指向同一个对象实体
equals(): 方法
只能适用于引用数据类型
Object类中equals（）的定义：Object类中定义的equals()和==的作用是相同的，比较两个对象的地址值
public boolean equals(Object obj){
	return (this == obj)
}
像String、Date、File、包装类等都重写了Object类中的equals()方法，比较两个对象的实体内容

在Java8中String类重写的equals()方法：
public boolean equals(Object anObject) {  
    if (this == anObject) {  
        return true;  
    }  
    if (anObject instanceof String) {  
        String anotherString = (String)anObject;  
        int n = value.length;  
        if (n == anotherString.value.length) {  
            char v1[] = value;  
            char v2[] = anotherString.value;  
            int i = 0;  
            while (n-- != 0) {  
                if (v1[i] != v2[i])  
                    return false;  
                i++;  
            }  
            return true;  
        }  
    }  
    return false;  
}


通常情况下，自定义的类需要重写equals()方法
自定义类重写equals()方法的步骤一般如下：
1、先用“==”判断是否相等。

2、判断equals()方法的参数是否为null，如果为null，则返回false；因为当前对象不可能为null，如果为null，则不能调用其equals()方法，否则抛java.lang.NullPointerException异常。

3、当参数不为null，则如果两个对象的运行时类（通过getClass()获取）不相等，返回false，否则继续判断。

三、逻辑运算符
逻辑运算符主要有六个: &  &&  |  || ! ^，运算结果都是boolean类型。

1、逻辑与 & 短路与 &&
语法规则：表达式1 && 表达式2，左右表达式必须是boolean类型的结果。相当于数学中的且。
短路与遵守短路求值的规则。即表达式1为假，表达式2就不再执行。逻辑与继续执行表达式2。

2、逻辑或 | 短路或 ||
语法规则：表达式1 || 表达式2，左右表达式必须是boolean类型的结果。相当于数学中的或。
短路或遵守短路求值的规则。即表达式1为真，表达式2就不再执行。逻辑或继续执行表达式2。

|| 遵守短路求值的规则。即表达式1为真，表达式2就不在执行，否则，执行表达式2。

& 和 | 也可以进行逻辑运算。如果他们的表达式为boolean，也表示逻辑运算，但是和&& ||相比不支持短路求值。

3、逻辑非 !
语法规则：!表达式1，相当于数学中的非。

4、逻辑异或
语法规则：表达式1^表达式2，左右表达式必须是boolean类型的结果。当表达式1和表达式2相同时为true，不同时为false。


四、位运算符
数据存储的最小单位是字节，而数据操作的最小单位是比特位。
字节是最小的存储单位，每个字节是由8个二进制比特位组成的，多个字节组合在一起可以表示各种不同的数据。
位运算表示按照二进制的每一位进行运算。
位运算符的左右两边是数值类型。

1，按位与&
如果两个二进制位都是 1，则结果为 1，否则结果为 0。

int a = 10;
int b = 20;
System.out.println(a & b); // 0


2，按位或|
如果两个二进制位有一个是1，则结果是1，否则都是0，结果是0。 

int a = 10;
int b = 20;
System.out.println(a | b); //30

 3，按位异或^
如果两个二进制位相同，则结果是0，否则是1。

4，按位取反~
如果该二进制位是1，则变成0，是0，变成1。

五、移位运算
    Java和C语言不同的地方在于，Java多了一个>>>，表示无符号右移。但是没有无符号左移。Java的移位运算符有三个: <<，>>，>>> 。都是二元运算符，且都是按照二进制比特位来运算的。

（1）左移：<<最左侧位不要了N位，在最右侧补零。左移 1 位，相当于原数字 * 2。左移 N 位，相当于原数字 * 2 的N次方。

（2）右移：>>最右侧不要了N位，在最左侧如果是正数，补0，负数补1。右移 1 位，相当于原数字 / 2。右移 N 位，相当于原数字 / 2 的N次方。

（3）无符号右移：>>>最右侧位不要了，最左侧补0。被移位二进制最高位无论是0还是1，空缺位都拿0补。

（4）移动负数位或者移位位数过大都没有意义。

    计算机在进行运算的时候，实际上是按照二进制运算的。加减等在运算的时候被转化成二进制的形式进行运算。计算机计算移位效率高于计算乘除，比如当某个代码正好乘除 2 的N次方的时候可以用移位运算代替。有的时候，可以拿来装逼用用。

六、条件运算符
条件运算符只有一个：表达式1 ? 表达式2 : 表达式3。
当表达式1为true时，执行表达式2，表达式3不在执行，否则执行表达式2。这个是Java当中唯一的一个三目运算符。表达式2和表达式3的结果需要同类型的，表达式不能单独存在。
int a = 10;
int b = 20;
int max = (a > b) ? a : b;
// 输出: 20
System.out.println(max);

七、在Java程序中，JVM默认总是顺序执行以分号;结束的语句。但是，在实际的代码中，程序经常需要做条件判断、循环，因此，需要有多种流程控制语句，来实现程序的跳转和循环等功能。
流程控制语句是用来控制程序中各语句执行顺序的语句，可以把语句组合成能完成一定功能的小逻辑模块。

if..else if..else：条件判断语句。
int j = 10;
if (j == 10) {
  System.out.println("I get printed");
} else if (j > 10) {
  System.out.println("I don't");
} else {
  System.out.println("I also don't");
}

for：循环语句，限定循环体的执行次数
for (int i = 0; i < 10; i++) {
  System.out.print(i);
}
// 输出: 0123456789

//增强for循环
int[] numbers = {1,2,3,4,5};
for (int number: numbers) {
  System.out.print(number);
}
// 输出: 12345

while：循环语句，反复执行语句或代码块，直到条件不满足时跳出
int count = 0;
while (count < 5) {
  System.out.print(count);
  count++;
}
// 输出: 01234

//do while循环
int count = 0;
do {
  System.out.print(count);
  count++;
} while (count < 5);
// 输出: 01234

switch..case:根据switch表达式中的值，依次匹配各个case中的常量。
一旦匹配成功，进入case结构，调用其执行语句。如果没有break关键字，则继续执行其他case结构的表达式。
int month = 3;
String str;
switch (month) {
  case 1:
    str = "January";
    break;
  case 2:
    str = "February";
    break;
  case 3:
    str = "March";
    break;
  default:
    str = "Some other month";
    break;
}
// 输出: Result March
System.out.println("Result " + str);

break和continue关键字：
1、break用于跳出一个循环体或者完全结束一个循环，不仅可以结束其所在的循环，还可结束其外层循环。
注意：
（1）只能在循环体内和switch语句体内使用break。
（2）不管是哪种循环，一旦在循环体中遇到break，系统将完全结束循环，开始执行循环之后的代码。
（3）当break出现在循环体中的switch语句体内时，起作用只是跳出该switch语句体，并不能终止循环体的执行。若想强行终止循环体的执行，可以在循环体中，但并不在switch语句中设置break语句，满足某种条件则跳出本层循环体。
for (int i = 0; i < 5; i++) {
  System.out.print(i);
  if (i == 3) {
    break;
  }
}
// 输出: 0123

2、continue语句的作用是跳过本次循环体中剩下尚未执行的语句，立即进行下一次的循环条件判定，可以理解为只是中止(跳过)本次循环，接着开始下一次循环。
注意：
（1）continue语句并没有使整个循环终止。
（2）continue 只能在循环语句中使用，即只能在 for、while 和 do…while 语句中使用。
for (int i = 0; i < 5; i++) {
  if (i == 3) {
    continue;
  }
  System.out.print(i);
}
// 输出: 01245

7、注释、文档注释
注释的内容不参与编译。
文档注释：注释内容可以被jdk提供的工具javadoc解析，生成一套网页文件形式体现的该程序的说明文档。
注意：javadoc解析的类要加上public

// 我是单行注释！
 
/*
而我是一个
多行注释！
*/
/**
  * 这个
  * 是
  * 文档
  * 注释
 */

8、注解
Annotation(注解)也被称为元数据(Metadata)是JDK1.5及以后版本引入的，用于修饰解释 包、类、方法、属性、构造器、局部变量等数据信息。
它可以用于创建文档，跟踪代码中的依赖性，甚至执行基本编译时检查。
注解是以‘@注解名’在代码中存在的，根据注解参数的个数，我们可以将注解分为：标记注解、单值注解、完整注解三类。
和注释一样，注解不影响程序逻辑，但注解可以被编译或运行，相当于嵌入在代码中的补充信息。
另外，你可以在编译时选择代码里的注解是否只存在于源代码级，或者它也能在class文件、或者运行时中出现（SOURCE/CLASS/RUNTIME）。
在 JavaSE 中，注解的使用目的比较简单，例如标记过时的功能，忽略警告等。
在 JavaEE 中注解占据了更重要的角色，例如用来配置应用程序的任何切面，代替 java EE 旧版中所遗留的繁冗代码和 XML 配置等。
 
元注解：标注在一个注解上，用于定义一个注解的状态
@Documented - 一个简单的标记注解，它标识了是否将注解添加到 Javadoc 中。

@Retention - 定义应保留注解的时间。
RetentionPolicy.SOURCE 在编译期间丢弃。这些注解在编译完成后没有任何意义，因此它们不会被写入字节码。例子：@Override, @SuppressWarnings
RetentionPolicy.CLASS – 在类加载期间丢弃。应用在进行字节码级别的编译期间。有些令人惊讶的是，这是默认的。
RetentionPolicy.RUNTIME – 不会丢弃。该注解可以在运行时进行反射。这是我们通常用于自定义注解的内容。

@Target - 注解可以使用的地方。如果不指定这一属性，注解可以应用在任何地方。
以下是该注解的有效值。这里的一个要点，它只有包含的形式，这意味着如果您想要对7个属性进行注解，
并且只想排除一个属性，这时需要在定义目标时包含所有7个属性。 

@Documented: 用于指定被该元注解修饰的 Annotation 类将被javadoc 工具提取成文档，即在生成文档时，可以看到该注解。
注意：
定义为@Documented 的注解必须设置Retention值为RUNTIME。

@Inherited 
被@Inherited 修饰的注解 将具有继承性，如果某个类使用了被 @Inherited修饰的注解，则其子类将自动具有该注解

Java数组（Array）：数组是多个相同类型的数据按照一定顺序排列的集合，并使用一个名字命名，并通过编号的方式对这些数据进行统一处理。
数组的声明：数组的长度一旦确定，就不能修改。
数组有一维数组和二维数组。
//声明 Declare
int[] a1;
int[] a2 = {1, 2, 3};
int[] a3 = new int[]{1, 2, 3};
int[] a4 = new int[3];
a4[0] = 1;
a4[2] = 2;
a4[3] = 3;

数组的初始化：数组的初始化有两种形式，静态初始化和动态初始化。
静态初始化:数组的初始化和数组的元素赋值同时进行 
ids = new int[]{11,22,12,12,12,123};
ids = {11,22,12,12,12,123};
动态初始化：数组的初始化和数组的元素赋值分开进行
String[] names = new String[5];

注意：数组一旦初始化完成，数组长度就确定了

数组元素通过角标调用。从第一个角标0开始，一直到-1。
通过数组的属性length获取数组的长度。
数组元素的默认初始化值：
>数组元素是整型：0
>数组元素是浮点型：0.0
>数组元素是char型：0或'\u0000' 而非'0'
>数组元素是Boolean型：false
>数组元素是引用数据类型: null

二维数组的初始化：
静态初始化：
int [][] arr = new int [][]{{1,2,3},{4,5},{6,7,8}};
int []arr [] = new int [][]{{1,2,3},{4,5},{6,7,8}};
int [][] arr = {{1,2,3},{4,5},{6,7,8}};
动态初始化：
String [][] arr2 = new String[5][3]; 
String [][] arr2 = new String[5][];

Java比较器：比较对象的大小
Comparable 的使用举例：
1.像String、包装类等实现了Comparable接口，重写了CompareTo()方法，给出了比较两个对象大小的方法
2.像String、包装类重写CompareTo()方法以后，进行了从小到大的排列
3.重写CompareTo(obj)的规则：
	如果当前对象this大于形参对象obj，则返回正整数；
	如果当前对象this小于形参对象obj，则返回负整数；
	如果当前对象this等于形参对象obj，则返回零；

Comparator定制排序：
当元素的类型没有实现Comparable接口而又不方便修改代码，或者实现了Comparable
接口的排序规则不适合当前的操作，可以考虑使用Comparator的对象来排序

Java编程范式-面向对象：
"万事万物皆对象"
1.在Java语言中，我们把功能、结构等封装到类中，通过类的实例化，来调用具体的功能结构
2.涉及到Java语言与前端HTML或者后端数据库做交互时，都体现为用类、对象去做交互
面向对象特点：封装、继承、多态
面向对象包括：类、对象、属性、方法、成员变量、局部变量、修饰符、方法的重载、继承、方法的重写、多态、static关键字、abstract关键字、接口 → JVM调优，设计模式，web和大数据框架

类：是一组相关属性和行为的集合。可以看成是一类事物的模板，使用事物的属性特征和行为特征来描述该类事物；如：人类
实例对象：是一类事物的具体体现。对象是类的一个实例（对象并不是找个女朋友），必然具备该类事物的属性和行为；如：小红、小明、小南
Scanner scanner = new Scanner();
具有静态描述的特征称之为属性
具有动态动作的行为(做事情)称之为方法
创建类的对象 = 类的实例化 = 实例化类
匿名对象：创建的对象没有显式的赋给一个变量名。匿名对象只能调用一次。
new Phone().sendEmail();
匿名对象的使用：将匿名对象的值赋值给方法的形参
mall.show(new Phone())

成员变量（属性，非static的）：
位置：在方法外部，直接写在类当中
作用范围：整个类全都可以通用
默认值：根据其类型，有默认值
内存位置：位于堆内存
生命周期：随着对象创建而诞生，随着对象被垃圾回收而消失
可以使用权限修饰符

局部变量：
位置：在方法内部
作用范围：只有方法当中才可以使用，出了方法就不能再用
默认值：无默认值
内存位置：位于栈内存
生命周期：随着方法进栈而诞生，随着方法出栈而消失
不可以使用权限修饰符

public class MyClass {  
    // 成员变量  
    public String myMemberVariable;  
      
    public void myMethod() {  
        // 局部变量  
        String myLocalVariable = "Hello, World!";  
    }  
}

修饰符：private：同类下访问  → 缺省：同包下访问 → protected：子包下可以访问，同包也可以访问。不同包下的子类，访问protected修饰的，需要使用子类的对象访问，不能使用父类的对象访问  → public ：项目中所有类都可以访问
PS:修饰类的时候，只能用缺省和public。

方法的重载：在 Java 类中可以定义 多个名称相同的方法 ，若只是参数不同，功能类似，那么可以将这类方法称为同名方法，也可以叫做方法重载
例如：sort(byte[] a) 与 sort(char[] a) 构成了方法的重载
Java中可变个数的形参 jdk5.0以上 格式：public void show(String ... strs){}
可变个数的形参与相同的数组之间不构成重载，二者不能共存，编译器认为这两种方法没有区别。

Java里面值传递机制只有一种：值传递。即将实际参数值的副本（复制）传入方法内，而参数本身不受影响。
>形参是基本数据类型，将实参的数据值传递给形参；形参是引用数据类型，将实参的地址值（含变量的数据类型）传递给形参。

Java中的值传递机制是指在传递基本数据类型的参数时，实际是将参数的值复制一份传递给方法或函数，而不是传递参数本身。这意味着在方法或函数内部对参数的修改不会影响到原始变量的值。
具体来说，当我们将基本类型的变量传递给方法时，实际上是将变量的值复制一份传递给方法，而不是传递变量本身。这意味着在方法内部对参数的修改不会影响到原始变量的值。

例如，如果我们定义一个方法来交换两个整数的值：
public static void swap(int x, int y) {  
    int temp = x;  
    x = y;  
    y = temp;  
}
当我们调用swap(a, b)时，实际传递的是a和b的值，而不是a和b本身。这意味着在swap方法内部对x和y的修改不会影响到原始的a和b的值。因此，调用swap(a, b)后，a的值不会改变，而b的值会被交换。

PS：String很奇特，虽然是引用数据类型，但是采用的却是值传递！！！


封装（数据的隐藏）：
通常，应禁止直接访问一个对象中数据的实际表示，而是应该通过操作接口来访问，这叫信息隐藏。
程序设计中的“高内聚，低耦合”：我们在程序设计的过程中要追求“高内聚，低耦合”。
高内聚就是类的内部数据操作细节自己来完成，不允许外部干涉，低耦合：就是， 仅暴露少量的方法给外部使用

封装的体现：
①将类的属性私有化，同时提供公共的(public)方法来获取(get)和设置(set)
②将类的方法私有化，仅用于内部方法调用
③单例模式

以下是一个示例，展示如何在Java中编写一个私有类的get和set方法，体现Java的封装性：

public class Person {  
    private String name;  
    private int age;  
  
    public Person(String name, int age) {  
        this.name = name;  
        this.age = age;  
    }  
  
    // Getter方法  
    public String getName() {  
        return name;  
    }  
  
    public int getAge() {  
        return age;  
    }  
  
    // Setter方法  
    public void setName(String name) {  
        this.name = name;  
    }  
  
    public void setAge(int age) {  
        if (age > 0) {  
            this.age = age;  
        } else {  
            System.out.println("年龄必须大于0");  
        }  
    }  
}
在上面的示例中，我们定义了一个名为Person的类，其中包含两个私有属性：name和age。我们使用构造函数来初始化这两个属性。然后，我们提供了getter方法来获取属性的值，以及setter方法来设置属性的值。
注意，setter方法只允许我们设置年龄为大于0的值，否则会输出一条错误消息。这就是Java封装性的体现，我们将属性封装在类内部，并通过getter和setter方法来控制对属性的访问。

构造器（构造方法）：
1.如果没有显式的定义的构造器，则系统默认定义空参的构造器
2.定义构造器的格式：权限修饰符 类名（形参列表）{}
3.一个类中可以有多个形参构造器，彼此构成重载
4.一旦我们显式的定义了构造器之后，系统就不再提供默认的空参构造器
5.一个类中，至少要有一个构造器

构造器的作用：
1.创建对象
2.初始化对象的属性

空参构造器：Person person = new Person();

带参构造器：
public Person(String name, int age) {  
    this.name = name;  
    this.age = age;  
}  


Java属性赋值的先后顺序：
1.默认初始化
2.显式初始化
3.构造器中初始化
4.通过 "对象.方法" 或 "对象.属性" 的方式初始化

在Java中，new一个对象是给怎么样的一个过程？

在Java中，创建一个对象主要经历了以下几个步骤：

1.加载类：首先，Java虚拟机（JVM）需要加载类。这个过程包括解析类的字节码，确定类的字段和方法，并为类的静态变量分配内存。
为实例变量分配内存：在类被加载后，JVM会为实例变量（即非静态字段）分配内存。
2.初始化实例变量：这个步骤会为实例变量赋予默认值。所有的数值类型默认值为0，所有的引用类型默认值为null。
如果类中有实例变量的初始化语句，或者从父类或接口中继承的实例变量初始化，那么这些初始化语句会被执行。
3.创建对象：接下来，使用new关键字来创建对象。这个过程包括为对象分配内存，复制构造函数的参数值到相应的实例变量，
调用构造函数来初始化对象，最后返回新创建对象的引用。
4.使用对象：现在，你可以使用这个新创建的对象来进行各种操作，比如调用方法、访问字段等。

Java之this关键字：
1.this可以修饰属性、方法、构造器
2.this修饰属性和方法
>this可以理解为当前对象
>在类的方法或类的构造器中，this修饰属性或方法时，一般情况下省略。特殊情况下，如果方法的形参和类的属性同名时，
必须显式使用"this.属性"声明此变量是属性，而非形参。
>this可以修饰构造器，结构为"this.形参列表"
>构造器中，不能通过方式"this.形参列表"调用自己
>如果一个类中有n个构造器，最多有n-1个构造器使用了"this.形参列表"方式
>规定："this.形参列表"必须声明在构造器的首行
>构造器内部，只能声明一个"this.形参列表"调用其他构造器

public class MyClass {  
    private int x;  
    private int y;  
  
    public MyClass() {  
        this(0, 0); // 使用 this 调用另一个构造器  
    }  
  
    public MyClass(int x, int y) {  
        this.x = x;  
        this.y = y;  
    }  
}


public class MyClass {  
    private int x;  
  
    public void setX(int x) {  
        this.x = x; // 使用 this 引用当前对象  
    }  
}

Java之package关键字：
1.为了更好的实现类的管理，提供包的概念
2.声明在原文件的首行
3.每"."一次，就代表一层文件目录
注意：相同或不同包下，不能引入同名的类、接口

Java之import关键字：
1.在源文件中显式的使用import结构导入指定包下的类、接口
2.声明在包的声明和类的声明之间
3.使用"xxx.*"的形式，表示可以导入xxx包下的所有结构
4.如果使用的类或接口是Java.lang包下定义的，则可以省略import结构
5.如果使用的类或接口是本包下定义的，则可以省略import结构

Java面向对象之继承：继承的基本思想是，基于已有的类创造新的类。
继承已存在的类就是复用这些类的方法，而且可以增加一些新的方法和字段，使新类能够适应新的情况，
继承是Java程序设计中一项核心技术，它主要解决的问题是：共性的抽取，实现代码复用。

Java中表现继承的关系需要借助关键字extends，子类继承父类。Class A extends B(){} A:子类、派生类、subclass B：父类、超类、基类、superclass
注意：
· 子类将继承父类的成员变量和成员方法。特别的，父类中声明为private的属性或方法，子类继承后，仍然认为子类获取了父类中私有的结构。
· Java中只支持单继承和多继承，不允许多重继承（C++允许多重继承）
· 子类继承父类之后，需要添加自己特有的成员，体现出与基类的不同
· 如果访问的成员变量子类中有，则优先访问子类本身的
· 如果访问的成员变量子类中无，父类中有，则访问继承下来的
· 如果子类与父类中有同名的成员变量，则优先访问子类自己的，即子类将父类的同名变量隐藏
· 如果我们没有显式的声明一个类的父类，则该类继承于Object类。Object类是所有类的父类

// 基类（父类）  
public class Animal {  
    private String name;  
  
    public Animal(String name) {  
        this.name = name;  
    }  
  
    public void eat() {  
        System.out.println(name + " is eating...");  
    }  
}  
  
// 子类（狗类）  
public class Dog extends Animal {  
    private String breed;  
  
    public Dog(String name, String breed) {  
        super(name);  // 调用父类的构造方法  
        this.breed = breed;  
    }  
  
    public void bark() {  
        System.out.println(getName() + " is barking...");  
    }  
  
    public String getBreed() {  
        return breed;  
    }  
}

继承之super关键字：
1.super可以用来调用属性、方法、构造器。
2.通过使用"super.属性"或"super.方法"的形式在子类中显式的调用父类的属性和方法
>所有类都继承Object类，任何类用super都可以调用Object类。
3.如果子类重写了父类的方法，此时子类中想调用父类被重写的方法。必须显式的使用"super.方法"的形式调用父类被重写的方法
4.在子类中显式的使用"super(形参列表)"调用父类中声明的构造器
>在子类构造方法中，super(形参列表)调用父类构造时，必须是子类构造方法中的第一条语句
>super(形参列表)只能在子类的构造方法中出现一次，并不能和this同时出现
>在类的多个构造器中，至少有一个子类调用了父类的空参构造器
>若父类显式定义无参或者默认的构造方法，在子类构造方法的第一行默认有隐含的super调用，即调用基类的构造方法
 构造哪个类的对象，就调用哪个类的构造方法，调用构造方法时先调用基类，在调用子类(即在子类中隐藏super())
>如果父类的构造方法是带有参数的，此时编译器不会给子类生成默认的构造方法，此时需要用户在子类中显式定义构造方法，并在子类构造方法中选取合适的父类构造方法调用

// 父类  
public class Parent {  
    protected int num;  
  
    public Parent(int num) {  
        this.num = num;  
    }  
  
    public int getNum() {  
        return num;  
    }  
}  
  
// 子类  
public class Child extends Parent {  
    private int num;  
  
    public Child(int num) {  
        super(num); // 调用父类的构造器  
        this.num = num * 2;  
    }  
  
    public int getNum() {  
        return super.getNum() * 2; // 调用父类的方法  
    }  
}

继承之执行顺序：

无继承关系时的执行顺序：
静态代码块先执行，且只执行一次，在类加载阶段执行
当有对象创建时，才会执行实例代码块，实例代码块执行完后，再执行构造方法

有继承关系时的执行顺序：
· 父类静态代码块优先子类静态代码块执行，都是最早执行的
· 父类实例代码块和父类构造方法紧接着执行
· 子类的实例代码块和子类构造方法在接着执行
· 第二次实例化对象时，父类和子类的静态代码块都不会在执行 

继承方式：单继承、多继承、不同的类继承同一个类（不支持一个类继承不同的父类）
final关键字修饰类不能被继承。

Java中的object类：
Object类是Javajava.lang包下的核心类，Object类是所有类的父类，何一个类时候如果没有明确的继承一个父类的话，那么它就是Object的子类；

1. clone()
保护方法，实现对象的浅复制，只有实现了Cloneable接口才可以调用该方法，否则抛出CloneNotSupportedException异常。

2. getClass()
final方法，返回Class类型的对象，反射来获取对象。

3. toString()
该方法用得比较多，一般子类都有覆盖，来获取对象的信息。

4. finalize()
该方法用于释放资源。因为无法确定该方法什么时候被调用，很少使用。

5. equals()
比较对象的内容是否相等

6. hashCode()
该方法用于哈希查找，重写了equals方法一般都要重写hashCode方法。这个方法在一些具有哈希功能的Collection中用到。

7. wait()
wait方法就是使当前线程等待该对象的锁，当前线程必须是该对象的拥有者，也就是具有该对象的锁。wait()方法一直等待，直到获得锁或者被中断。wait(long timeout)设定一个超时间隔，如果在规定时间内没有获得锁就返回。

调用该方法后当前线程进入睡眠状态，直到以下事件发生。

其他线程调用了该对象的notify方法。
其他线程调用了该对象的notifyAll方法。
其他线程调用了interrupt中断该线程。
时间间隔到了。
此时该线程就可以被调度了，如果是被中断的话就抛出一个InterruptedException异常。

8. notify()
该方法唤醒在该对象上等待的某个线程。

9. notifyAll()
该方法唤醒在该对象上等待的所有线程。


方法的重写（Override）：
重写以后，当创建子类对象以后，通过子类对象调用子父类中，同名同参的方法时，实际执行的方法是子类重写父类的方法。

方法重写的规则：

1.参数列表必须完全与被重写方法相同；也就是说，在被重写的方法里，输入参数必须与父类的参数相同
>父类的成员方法只能被它的子类重写。
>构造方法不能被重写
>如果不能继承一个方法，则不能重写这个方法。

2.返回类型必须完全与被重写方法的返回类型相同

3.子类重写父类的方法，权限修饰符不能大于父类被重写的方法
>父类中的访问权限是protected，那么，重写的的权限不能为public
>父类中的访问权限是private，子类不能重写父类
>子类和父类在同一个包中，那么子类可以重写父类所有除了声明为private和final的方法。
 子类和父类不在同一个包中，那么子类只能够重写父类的声明为public和protect的非final方法。
 
4.重写方法不能抛出新的检查异常或者比被重写方法申明更加宽泛的异常。
例如：父类的一个方法声明了一个检查异常IOException,但是在重写这个方法的时候不能抛出Exception异常，
因为Exception是IOException的父类，只能抛出IOException的子类异常。

>重写的方法能够抛出任何非强制异常，无论被重写的方法是否抛出异常。
但是，重写方法不能抛出新的强制性异常，或者比被重写方法声明的更广泛的强制性异常，反之则可以。

5.声明为static的方法不能被重写，但是能够被再次声明（可以被继承）;声明为final的方法不能被重写。

// 父类  
public class Animal {  
    public void makeSound() {  
        System.out.println("The animal makes a sound");  
    }  
}  
  
// 子类（狗类）  
public class Dog extends Animal {  
    @Override  // 使用@Override注解表示该方法是一个重写方法  
    public void makeSound() {  
        System.out.println("The dog barks");  
    }  
}

Java多态：
父类的引用指向子类的对象。
多态的前提是两个对象（类）存在继承关系，多态是建立在封装和继承基础之上的。
在编译期，只能调用父类中声明的方法，但在执行期，实际执行的是子类中重写父类的方法。(编译，看左边；运行，看右边)
>多态性不适用于属性，只适用于方法。(属性的编译和运行都是谁声明，谁调用)
>多态性不能调用子类特有的方法，编译时，对象是父类类型

如何在内存的层面理解多态性？
在 Java 内存层面，多态性中子类对象指向父类对象的行为是通过类型转换实现的。
在内存中，子类对象是父类对象的一个实例，因此它们都存储在堆内存中。
子类对象是父类对象的完整副本，并且拥有自己的方法和属性。由于子类对象是父类对象的完整副本，因此它们都可以被转换为父类对象的引用。
因此，我们可以在程序中使用父类对象的引用指向子类对象，这种行为称为向上转型。

当向上转型时，我们仍然可以使用父类对象的引用访问子类对象中的方法和属性，
但是如果父类对象没有定义这些方法和属性，则不能访问。
多态性允许我们在编译时使用父类对象的引用，而在运行时实际访问的是子类对象中的方法和属性。
这种行为允许我们在不改变现有代码的情况下实现子类特定的功能。

实现多态的条件，缺一不可：
1.子类继承父类
2.子类必须要对父类中方法进行重写

对于重载而言，在方法调用之前，编译器就确定了要调用的方法，这是"早绑定";
对于多态，在方法调用之后，编译器才确定要调用的方法，这是"晚绑定"

Java instanceof 关键字：
判断对象a是否是类A的一个实例，如果是，返回true(如果是多态对象，也会返回true);如果不是，返回false
使用instanceof关键字避免多态对象强制转化出现ClassCastException异常。

// 父类  
public class Shape {  
    public void draw() {  
        System.out.println("Drawing a shape...");  
    }  
}  
  
// 子类（圆形类）  
public class Circle extends Shape {  
    @Override  // 使用@Override注解表示该方法是一个重写方法  
    public void draw() {  
        System.out.println("Drawing a circle...");  
    }  
}  
  
// 子类（矩形类）  
public class Rectangle extends Shape {  
    @Override  // 使用@Override注解表示该方法是一个重写方法  
    public void draw() {  
        System.out.println("Drawing a rectangle...");  
    }  
}  
  
// 主类  
public class Main {  
    public static void main(String[] args) {  
        Shape[] shapes = new Shape[2];  // 创建一个Shape类型的数组，并分配两个空间  
        shapes[0] = new Circle();  // 将第一个空间指向Circle类的对象  
        shapes[1] = new Rectangle();  // 将第二个空间指向Rectangle类的对象  
          
        for (Shape shape : shapes) {  // 循环遍历数组中的每一个对象，并调用它们的draw()方法  
            shape.draw();  // 由于多态的存在，这个方法将调用Circle类和Rectangle类各自的draw()方法，而不是Shape类的draw()方法  
        }  
    }  
}
在上面的例子中，Shape 类是一个父类，它有一个 draw() 方法。Circle 和 Rectangle 类是两个子类，它们分别继承了 Shape 类并重写了 draw() 方法。
在 Main 类的 main() 方法中，首先创建了一个 Shape 类型的数组，并分别将两个子类的对象赋值给数组中的两个空间。
然后，使用一个for-each循环遍历数组中的每一个对象，并调用它们的 draw() 方法。由于多态的存在，这个方法将调用每个子类自己的 draw() 方法，而不是父类的 draw() 方法。


Java 包装类：
针对八种基本数据类型定义相应的引用类型（具有类的特征）

基本数据类型和包装类的转换：
基本数据类型→包装类：调用包装类的构造器;自动装箱
包装类→基本数据类型：调用包装类的xxxValue();自动拆箱
(自动装箱和自动拆箱是jdk5.0以后的特性)

基本数据类型、包装类转换为String类型：
1.连接运算 String str1 = num1 + "";
2.调用String的valueOf()方法 String str2 = String.valueOf();

String类型转换为基本数据类型、包装类：
调用包装类的静态方法 parseXXX

Java static关键字：
static关键字可以用来修饰属性、方法、代码块、内部类

static方法：
static修饰的方法一般称作静态方法，由于静态方法不依赖于任何对象就可以进行访问，
因此对于静态方法来说，是没有this的，因为它不依附于任何对象，既然都没有对象，就谈不上this了。
并且由于这个特性，在静态方法中不能访问类的非静态成员变量和非静态成员方法，
因为非静态成员方法/变量都是必须依赖具体的对象才能够被调用。
但是要注意的是，虽然在静态方法中不能访问非静态成员方法和非静态成员变量，但是在非静态成员方法中是可以访问静态成员方法/变量的。

public class StaticMethodExample {  
    // 静态方法  
    public static int add(int a, int b) {  
        return a + b;  
    }  
  
    public static void main(String[] args) {  
        // 直接通过类名调用静态方法  
        int sum = StaticMethodExample.add(5, 3);  
        System.out.println("The sum is: " + sum);  
    }  
}

static变量：
static修饰的属性也称作静态变量，静态变量和非静态变量的区别是：
静态变量被所有的对象所共享，声明在方法区，在内存中只有一个副本，它当且仅当在类初次加载时会被初始化。
而非静态变量是对象所拥有的，在创建对象的时候被初始化，声明在堆中，存在多个副本，各个对象拥有的副本互不影响。
static成员变量的初始化顺序按照定义的顺序进行初始化。

public class SharedVariableExample {  
    // 静态变量  
    public static int sharedVariable;  
  
    public static void main(String[] args) {  
        // 创建两个实例  
        SharedVariableExample example1 = new SharedVariableExample();  
        SharedVariableExample example2 = new SharedVariableExample();  
  
        // 修改静态变量的值  
        example1.sharedVariable = 10;  
  
        // 打印静态变量的值，可以看到它在这两个实例中是相同的  
        System.out.println("example1.sharedVariable: " + example1.sharedVariable);  
        System.out.println("example2.sharedVariable: " + example2.sharedVariable);  
    }  
}

static代码块：
(代码块的作用：用来初始化类、对象）
static关键字还有一个比较关键的作用就是 用来形成静态代码块以优化程序性能。
static块可以置于类中的任何地方，类中可以有多个static块。
在类初次被加载的时候，会按照static块的顺序来执行每个static块，并且只会执行一次。
因此，很多时候会将一些只需要进行一次的初始化操作都放在static代码块中进行。
静态代码块的执行顺序按照声明的前后顺序执行。
静态代码块的执行要优于非静态代码块的执行，而且静态代码块只能调用静态的属性、方法，不能调用非静态的结构。

public class StaticBlockExample {  
    // 静态变量  
    public static int staticVariable;  
  
    // 静态代码块  
    static {  
        System.out.println("This is a static block.");  
        staticVariable = 10;  
    }  
  
    public static void main(String[] args) {  
        // 创建两个实例  
        StaticBlockExample example1 = new StaticBlockExample();  
        StaticBlockExample example2 = new StaticBlockExample();  
  
        // 打印静态变量的值，可以看到它在这两个实例中是相同的  
        System.out.println("example1.staticVariable: " + example1.staticVariable);  
        System.out.println("example2.staticVariable: " + example2.staticVariable);  
    }  
}

PS：开发中，如何确定一个属性是否要声明为static？
①属性是可以被多个对象所共享的
②操作静态属性的方法，通常设计成static的
③工具类中的方法，习惯上声明为static的

Java final关键字
1.用来修饰类
>此类不能被其他类继承

2.用来修饰方法
>方法不能被重写

3.final用来修饰变量
>此时修饰的"变量"被称为常量
>final修饰属性，可以考虑修饰的位置有：显示初始化、代码块中初始化、构造器中初始化
>final修饰局部变量，修饰形参时，表示此形参是一个常量。一旦赋值此形参，不能重新赋值
>final修饰属性，用来当作全局常量

4.final用来修饰类

>不能被继承：如果一个类被final修饰，那么这个类不能被其他类继承。即，没有子类可以继承这个final类。
>不能被扩展：如果一个类被final修饰，那么这个类的所有子类都不能被其他类继承。
>所有成员变量、方法和内部类默认也是final：当一个类被final修饰时，它的所有成员变量、方法和内部类默认也是final的。
这意味着这些成员不能被覆盖或重写。
>用于安全和性能优化：由于final类的不可变性，它常用于创建工具类或驱动程序，比如驱动器接口或一些不需要修改的基础类。
这样就可以防止其他人更改类的行为或结构，同时也可以提高程序的性能，因为编译器可以对其进行更多优化。

PS:被final修饰的类不允许被继承，但是可以实例化

        final class Foo {
            private final int value;

            public Foo(int value) {
                this.value = value;
            }

            public int getValue() {
                return value;
            }
        }
        Foo foo = new Foo(10);
        System.out.println(foo.getValue()); //输出10


Java abstract关键字
1.用来修饰类:被修饰的类称为抽象类,可能包含抽象方法,也可能不包含抽象方法
>此类不能被实例化,即不能创建对象(因为其中包含抽象方法),其他功能与类相同
>抽象类中一定有构造器,便于子类实例化时调用
>开发中,提供抽象类的子类,让子类对象实例化,完成相关操作
>抽象类一般位于体系结构的上层,用来定义功能

注意:如果一个类继承了抽象类,那么这个类要么重写抽象类中所有的抽象方法,要么将此类也抽象化
abstract class Animal {  
    // 抽象方法  
    abstract void makeSound();  
  
    // 非抽象方法  
    void eat() {  
        System.out.println("The animal eats.");  
    }  
}

PS:在Java中被abstract修饰的类不能被final修饰
在Java中，如果一个类被abstract修饰，那么这个类就是一个抽象类。而如果一个类被final修饰，那么这个类就是一个最终类，不能被继承。
由于抽象类被设计为不能被实例化的类，因此它不能同时被final修饰，因为final意味着这个类不能被继承，这与抽象类的设计初衷相矛盾。因此，在Java中，一个类不能同时被abstract和final修饰。


2.用来修饰方法: 被修饰的方法称为抽象方法
>抽象方法只有方法的声明,没有方法体(在一些比较顶层的类中,它的方法实现与子类大多不同,此时没必要在顶层实现具体的方法,只需声明功能即可)
>包含抽象方法的类一定是一个抽象类;反之,抽象类中可无方法体
>若子类重写父类中所有的抽象方法,则子类才可实例化
>若未重写父类抽象类所有的方法,则此子类也是一个抽象类,需要用abstract修饰

abstract class Animal {  
    public abstract void makeSound();  
}
在这个例子中，Animal是一个抽象类，它有一个抽象方法makeSound()。由于该方法没有具体的实现代码，因此它只能被声明而不能被实现。任何继承自Animal的类都必须提供makeSound()方法的具体实现。


注意:
abstract不能用来修饰属性,方法
abstract不能用来修饰: 私有方法,静态方法,final修饰的方法,final修饰的类

//抽象类的匿名子类
Worker worker = new Worker();
//非匿名类的非匿名对象
method1(worker);
//非匿名类的匿名对象
method1(new Worker());
//匿名类的匿名对象
//person类是抽象类
Person p = new Person(){

    @Override
    public void eat();

    @Override
    public void breath();

}

Java接口：
接口（英文：Interface），在JAVA编程语言中是一个抽象类型，是抽象方法的集合，接口通常以interface来声明。一个类通过继承接口的方式，从而来继承接口的抽象方法。
接口并不是类，编写接口的方式和类很相似，但是它们属于不同的概念。类描述对象的属性和方法。接口则包含类要实现的方法。
除非实现接口的类是抽象类，否则该类要定义接口中的所有方法。
接口无法被实例化，但是可以被实现。一个实现接口的类，必须实现接口内所描述的所有方法，否则就必须声明为抽象类。另外，在 Java 中，接口类型可用来声明一个变量，他们可以成为一个空指针，或是被绑定在一个以此接口实现的对象。

public interface MyInterface {  
    void method1();  
  
    int method2(String str);  
}

抽象类和接口的对比：
1、抽象类和接口都不能直接实例化。如果要实例化，抽象类变量必须指向实现所有抽象方法的子类对象，接口变量必须指向实现所有接口方法的类对象。
2、抽象类要被子类继承，接口要被类实现。
3、接口只能做方法申明，抽象类中可以做方法申明，也可以做方法实现。
4、接口里定义的变量只能是公共的静态的常量，抽象类中的变量是普通变量。
5、抽象类里的抽象方法必须全部被子类所实现，如果子类不能全部实现父类抽象方法，那么该子类只能是抽象类。同样，实现接口的时候，如不能全部实现接口方法，那么该类也只能为抽象类。
6、抽象方法只能申明，不能实现。
7、抽象类里可以没有抽象方法
8、如果—个类里有抽象方法，那么这个类只能是抽象类
9、抽象方法要被实现，所以不能是静态的，也不能是私有的。
10、接口可以继承接口，并且可多继承接口，但类只能单—继承。
11.接口可以通过匿名内部类实例化。接口是对动作的抽象，抽象类是对根源的抽象。抽象类表示的是，这个对象是什么。而接口表示的是，这个对象能做什么。

接口和抽象类的区别？
1.抽象类是对事物的抽象，即对类抽象；接口是对行为抽象，即局部抽象。抽象类对整体形为进行抽象，包括形为和属性。接口只对行为进行抽象。
2.抽象类是多个子类的像类，是一种模板式设计；接口是一种形为规范，是一种辐射式设计。



Java高级应用：
异步、多线程、集合、泛型、序列化、IO、网络编程、反射、动态代理、jdk8.0以及以后新特性

Java多线程：Java多线程实现的原理是基于Java虚拟机（JVM）的线程调度。JVM通过线程调度器负责分配CPU时间，实现多线程的并发执行。
Java多线程编程需要注意以下几点：

1.同步问题，如果不同步可能导致线程安全问题；
2.线程间通信，如果不能有效的沟通，线程的任务可能无法完成；
3.线程上下文切换，如果频繁的切换，可能导致性能问题；
4.防止死锁，如果两个线程互相等待对方释放资源，可能造成死锁。
5.线程生命周期的管理，线程不能永久存在，需要正确的关闭和管理。

Java多线程生命周期：
就绪状态：就绪状态的线程又叫做可运行状态，表示当前线程具有抢夺CPU时间片的权力（CPU时间片就是执行权）。当一个线程抢夺到CPU时间片之后，就开始执行run方法，run方法的开始执行标志着线程进入运行状态。
运行状态：run方法的开始执行标志着这个线程进入运行状态，当之前占有的CPU时间片用完之后，会重新回到就绪状态继续抢夺CPU时间片，当再次抢到CPU时间之后，会重新进入run方法接着上一次的代码继续往下执行。
阻塞状态：当一个线程遇到阻塞事件，例如接收用户键盘输入，或者sleep方法等，此时线程会进入阻塞状态，阻塞状态的线程会放弃之前占有的CPU时间片。之前的时间片没了需要再次回到就绪状态抢夺CPU时间片。
锁池：在这里找共享对象的对象锁线程进入锁池找共享对象的对象锁的时候，会释放之前占有CPU时间片，有可能找到了，有可能没找到，没找到则在锁池中等待，如果找到了会进入就绪状态继续抢夺CPU时间片。（这个进入锁池，可以理解为一种阻塞状态）

多线程的实现方式（一）
继承Thread类
1、自定义一个类MyThread类，用来继承与Thread类
2、在MyThread类中重写run（）方法
3、在测试类中创建MyThread类的对象
4、启动线程
PS:调用start()方法启动线程后，线程会从run()方法开始执行。

public class Demo01 {
    public static void main(String[] args) {
        //创建线程
        MyThread t01 = new MyThread();
        MyThread t02 = new MyThread();
        MyThread t03 = new MyThread("线程03");
 
        //开启线程
//        t01.run();
//        t02.run();
//        t03.run();
        // 不会启动线程，不会分配新的分支栈。（这种方式就是单线程。）
        // start()方法的作用是：启动一个分支线程，在JVM中开辟一个新的栈空间，这段代码任务完成之后，瞬间就结束了。
        // 这段代码的任务只是为了开启一个新的栈空间，只要新的栈空间开出来，start()方法就结束了。线程就启动成功了。
        // 启动成功的线程会自动调用run方法，并且run方法在分支栈的栈底部（压栈）。
        // run方法在分支栈的栈底部，main方法在主栈的栈底部。run和main是平级的。
        t01.start();
        t02.start();
        t03.start();
        //设置线程名（补救的设置线程名的方式）
        t01.setName("线程01");
        t02.setName("线程02");
        //设置主线程名称
        Thread.currentThread().setName("主线程");
        for (int i = 0; i < 50; i++) {
            //Thread.currentThread() 获取当前正在执行线程的对象
            System.out.println(Thread.currentThread().getName() + ":" + i);
        }
    }
}
class MyThread extends Thread{
    public MyThread() {
    }
 
    public MyThread(String name) {
        super(name);
    }
 
    //run方法是每个线程运行过程中都必须执行的方法
    @Override
    public void run() {
        for (int i = 0; i < 50; i++) {
            System.out.println(this.getName() + ":" + i);
        }
    }
}

此处最重要的为start()方法。单纯调用run()方法不会启动线程，不会分配新的分支栈。
start()方法的作用是：启动一个分支线程，在JVM中开辟一个新的栈空间，这段代码任务完成之后，瞬间就结束了。线程就启动成功了。
启动成功的线程会自动调用run方法（由JVM线程调度机制来运作的），并且run方法在分支栈的栈底部（压栈）。
run方法在分支栈的栈底部，main方法在主栈的栈底部。run和main是平级的。
单纯使用run()方法是不能多线程并发的。

多线程的实现方式（二）
实现Runnable接口
1、自定义一个MyRunnable类来实现Runnable接口
2、在MyRunnable类中重写run（）方法
3、创建Thread对象，并把MyRunnable对象作为Tread类构造方法的参数传递进去
4、启动线程
开发中使用这种方式创建多线程，而不是继承Thread类
PS:调用start()方法启动线程后，线程会从run()方法开始执行。

public class Demo02 {
    public static void main(String[] args) {
        MyRunnable myRun = new MyRunnable();//将一个任务提取出来，让多个线程共同去执行
        //封装线程对象
        Thread t01 = new Thread(myRun, "线程01");
        Thread t02 = new Thread(myRun, "线程02");
        Thread t03 = new Thread(myRun, "线程03");
        //开启线程
        t01.start();
        t02.start();
        t03.start();
        //通过匿名内部类的方式创建线程
        new Thread(new Runnable() {
            @Override
            public void run() {
                for (int i = 0; i < 20; i++) {
                    System.out.println(Thread.currentThread().getName() + " - " + i);
                }
            }
        },"线程04").start();
    }
}
//自定义线程类，实现Runnable接口
//这并不是一个线程类，是一个可运行的类，它还不是一个线程。
class MyRunnable implements Runnable{
    @Override
    public void run() {
        for (int i = 0; i < 50; i++) {
            System.out.println(Thread.currentThread().getName() + " - " + i);
        }
    }
}

多线程的实现方式（三）
实现Callable接口（ java.util.concurrent.FutureTask; /JUC包下的，属于java的并发包，老JDK中没有这个包。新特性。）
1、自定义一个MyCallable类来实现Callable接口
2、在MyCallable类中重写call()方法
3、创建FutureTask，Thread对象，并把MyCallable对象作为FutureTask类构造方法的参数传递进去，把FutureTask对象传递给Thread对象。
4、启动线程

        这种方式的优点：可以获取到线程的执行结果；方法可以抛出异常；返回结果支持泛型的返回值

        这种方式的缺点：效率比较低，在获取t线程执行结果的时候，当前线程受阻塞，效率较低。

		
package com.lmw.thread3;

import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.FutureTask;

public class ThreadCallableTest {
    public static void main(String[] args) {
        //3.创建callable接口实现类的对象
        Number number = new Number();
        //4.将callable实现接口实现类的对象作为参数传递到FutureTask构造器中，创建FutureTask的对象
        FutureTask futureTask = new FutureTask(number);
        //5.将FutureTask的对象作为参数传递到Thread类的构造器中，创建Thread对象，并调用start()
        new Thread(futureTask).start();

        try {
            // get方法的返回值即为futureTask构造器的参数Callable实现类重写的call方法的返回值
            //6.获取callable中call方法的返回值
            Object sum = futureTask.get();
            System.out.println("总和为:" + sum);
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();
        }


    }
}

// 1.创建一个实现callable接口的实现类
class Number implements Callable {
    // 2.实现call方法，将此线程需要执行的操作写在call方法中
    @Override
    public Object call() throws Exception {
        int sum = 0;
        for (int i = 1; i <= 100; i++) {
            if(i % 2 == 0) {
                sum  = sum + i;
            }
        }
        return sum;
    }
}

多线程的实现方式（四）
创建线程池		
优点：1.提高响应速度 2.降低资源消耗 3.便于线程管理

import java.util.ArrayList;
import java.util.Date;
import java.util.List;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
​
public class ThreadDemo {
    
    @SuppressWarnings({ "rawtypes", "unchecked" })
    public static void main(String[] args) throws ExecutionException, InterruptedException {
        System.out.println("---- 主程序开始运行 ----");
        Date startTime = new Date();
        
        int taskSize = 5;
        // 创建一个线程池,Executors提供了创建各种类型线程池的方法，具体详情请自行查阅
        ExecutorService executorService = Executors.newFixedThreadPool(taskSize);
        
        // 创建多个有返回值的任务
        List<Future> futureList = new ArrayList<Future>();
        for (int i = 0; i < taskSize; i++) {
            Callable callable = new MyCallable(i);
            // 执行任务并获取Future对象
            Future future = executorService.submit(callable);
            futureList.add(future);
        }
        
        // 关闭线程池
        executorService.shutdown();
​
        // 获取所有并发任务的运行结果
        for (Future future : futureList) {
            // 从Future对象上获取任务的返回值，并输出到控制台
            System.out.println(">>> " + future.get().toString());
        }
​
        Date endTime = new Date();
        System.out.println("---- 主程序结束运行 ----，程序运行耗时【" + (endTime.getTime() - startTime.getTime()) + "毫秒】");
    }
}
​
class MyCallable implements Callable<Object> {
    private int taskNum;
​
    MyCallable(int taskNum) {
        this.taskNum = taskNum;
    }
​	@Override
    public Object call() throws Exception {
        System.out.println(">>> " + taskNum + " 线程任务启动");
        Date startTime = new Date();
        Thread.sleep(1000);
        Date endTime = new Date();
        long time = endTime.getTime() - startTime.getTime();
        System.out.println(">>> " + taskNum + " 线程任务终止");
        return taskNum + "线程任务返回运行结果, 当前任务耗时【" + time + "毫秒】";
    }
}


Java synchronized 关键字：同步代码块，解决线程安全问题，解决多线程上下文冲突问题，保证线程原子性
synchronized(同步监视器){
//需要被同步的代码
}
注：1.同步监视器，俗称：锁。使用当前类的对象当成锁，锁住需要同步的代码。
    2.可以使用this关键字，也可以使用Object对象充当锁。
	3.非静态的同步方法，同步监视器是this；静态的同步方法，同步监视器是当前类本身

lock方法解决线程安全问题：
ReentrantLock lock = new ReentrantLock();
lock.lock();
lock.unlock();

lock方法与synchronized关键字解决线程安全问题的区别：
synchronized在执行完同步的代码块后，自动释放同步监视器
lock需要手动的启动同步，也要手动的实现解锁

Java多线程实现线程通讯：sleep()   wait()
sleep和wait的区别
1、sleep是线程中的方法，但是wait是Object中的方法。
2、sleep方法不会释放资源锁，但是wait会释放资源锁，而且会加入到等待队列中。
3、sleep方法不依赖于同步器synchronized，但是wait需要依赖synchronized关键字。
4、sleep不需要被唤醒（休眠之后推出阻塞），但是wait需要（不指定时间需要被别人中断）。


Java线程异步：
Java 的线程异步是指在 Java 应用程序中，多个线程同时执行不同的任务，并且他们是独立的，互不影响，任意一个线程的完成不会影响其他线程的运行。
在Java 异步编程中，不同的线程可以在不需要阻塞等待的情况下并行执行，这样可以提高程序的执行效率。

线程异步需要考虑原子性：
在Java中异步编程中，线程原子性是需要考虑的因素。线程原子性指的是线程执行过程中不会被其他线程打断的特性。
如果不考虑线程原子性，那么会有可能出现线程在执行过程中对数据的不一致性问题。
因此，在异步编程中，为了保证数据的一致性，需要考虑线程的原子性。

这可以通过以下几种方式来实现：

使用synchronized关键字：synchronized关键字可以保证同一时刻只有一个线程可以执行被synchronized修饰的方法或者代码块，因此可以保证原子性。
使用Lock：Lock是Java提供的一种更加灵活的线程同步机制，它可以在方法或者代码块前后分别加锁和解锁，从而保证原子性。
使用Atomic类：Java提供了许多Atomic类，如AtomicInteger、AtomicLong等，这些类可以保证对基本数据类型的操作是原子的。
使用CountDownLatch 和 CyclicBarrier：这两个工具类可以用来控制线程的执行顺序，从而保证多线程下的原子性。
使用Semaphore：Semaphore是一种用来控制访问资源的数量的工具类，可以在保证原子性的同时，控制并发线程的数量。


Future 异步：
@Test
public void futureTest() throws Exception {
 
    System.out.println("main函数开始执行");
 
    ExecutorService executor = Executors.newFixedThreadPool(1);
    Future<Integer> future = executor.submit(new Callable<Integer>() {
        @Override
        public Integer call() throws Exception {
 
            System.out.println("===task start===");
            Thread.sleep(5000);
            System.out.println("===task finish===");
            return 3;
        }
    });
    //这里需要返回值时会阻塞主线程，如果不需要返回值使用是OK的。倒也还能接收
    //Integer result=future.get();
    System.out.println("main函数执行结束");
    System.in.read();
 
}


CompletableFuture异步：
CompletableFuture<Long> completableFuture = CompletableFuture.supplyAsync(() -> factorial(number));
while (!completableFuture.isDone()) {
    System.out.println("CompletableFuture is not finished yet...");
}
long result = completableFuture.get();

SpringBoot @Async异步：
@SpringBootApplication
@EnableAsync
public class StartApplication {

    public static void main(String[] args) {
        SpringApplication.run(StartApplication.class, args);
    }
}
自定义线程池：

@Configuration
@Slf4j
public class ThreadPoolConfiguration {

    @Bean(name = "defaultThreadPoolExecutor", destroyMethod = "shutdown")
    public ThreadPoolExecutor systemCheckPoolExecutorService() {

        return new ThreadPoolExecutor(3, 10, 60, TimeUnit.SECONDS,
                new LinkedBlockingQueue<Runnable>(10000),
                new ThreadFactoryBuilder().setNameFormat("default-executor-%d").build(),
                (r, executor) -> log.error("system pool is full! "));
    }
}
Guava异步：
ExecutorService threadpool = Executors.newCachedThreadPool();
ListeningExecutorService service = MoreExecutors.listeningDecorator(threadpool);
ListenableFuture<Long> guavaFuture = (ListenableFuture<Long>) service.submit(()-> factorial(number));
long result = guavaFuture.get();

JUC：
JUC是Java.util.concurrent工具包的简称，这是一个处理线程的工具包。它提供了许多在并发编程工程中常用的工具类，
用于定义类似于线程的自定义子系统，包括线程池、异步IO、轻量级框架，还提供了多线程上下文的Collectiion的实现。

 Executor  接口:
-  void execute(Runnable command) : 提交一个任务以异步执行。

 ExecutorService  接口 (继承自 Executor)：
-  Future<?> submit(Runnable task) : 提交一个 Runnable 任务，并返回一个 Future 对象。
-  Future<T> submit(Callable<T> task) : 提交一个 Callable 任务，并返回一个 Future 对象。
-  void shutdown() : 优雅地关闭 ExecutorService。
-  List<Runnable> shutdownNow() : 立即关闭 ExecutorService 并返回尚未执行的任务列表。

 ThreadPoolExecutor  类 (ExecutorService 的一个实现)：
- 除了继承的方法外，还有一些用于配置线程池的方法，如  setCorePoolSize 、 setMaximumPoolSize 、 setKeepAliveTime  等。

Future 接口:
-  boolean cancel(boolean mayInterruptIfRunning) : 取消任务的执行。
-  boolean isDone() : 判断任务是否已完成。
-  boolean isCancelled() : 判断任务是否已被取消。
-  T get() : 等待任务执行完成并返回结果。
-  T get(long timeout, TimeUnit unit) : 等待指定时间后获取任务执行结果。

Callable接口:
-  T call() : 执行任务并返回结果。

CountDownLatch 类:
-  void countDown() : 减小计数器的值。
-  void await() : 阻塞当前线程，直到计数器减为0。

CyclicBarrier 类:
-  int await() : 阻塞当前线程，直到所有参与者都到达栅栏点。

Semaphore 类:
-  void acquire() : 获取一个许可。
-  void release() : 释放一个许可。

Lock 接口:
-  void lock() : 获取锁。
-  void unlock() : 释放锁。


操作系统并发区别于Java并发吗？Java并发是否用了操作系统并发
操作系统并发和Java并发是两个不同但相关的概念，它们在多线程编程中发挥不同的作用，但也有一些联系。

1. 操作系统并发：
   - 操作系统并发是指操作系统的内核和调度器如何管理和调度计算机上的进程和线程。
   - 操作系统负责分配CPU时间片、管理进程和线程的状态、实现上下文切换等，以便多个进程和线程可以在同一台计算机上并发执行。
   - 操作系统提供了基本的多线程支持，但它通常是底层的，与具体编程语言无关。

2. Java并发：
   - Java并发是一种编程范式，用于在Java编程语言中实现多线程和多任务处理。
   - Java提供了丰富的多线程编程工具和库，包括 java.lang.Thread 类、同步机制（如 synchronized 关键字）、线程池、原子操作类、并发集合等。
   - Java并发是建立在操作系统并发之上的，它通过Java虚拟机（JVM）实现多线程调度和管理。

虽然Java并发建立在操作系统并发之上，但它具有一些独立的特点和抽象，使得多线程编程更容易和可移植。例如，Java的线程模型抽象了底层的操作系统线程，使开发人员可以更轻松地创建和管理线程，而无需关心操作系统的细节。
Java并发通常使用了操作系统提供的底层线程支持，但它也在其之上构建了更高级别的抽象，以便于开发人员处理并发编程。 Java的并发库和工具旨在提供更高级别的抽象，帮助开发人员解决常见的并发问题，如同步、锁、线程安全性等。
这些工具和库在跨平台开发中尤其有用，因为它们隐藏了操作系统差异，使得Java程序在不同操作系统上的行为更加一致。

总的来说，操作系统并发和Java并发是相关的，但它们在概念上和实现上存在差异。 Java并发建立在操作系统并发之上，提供了更高级别的抽象和工具，以便于开发人员编写多线程应用程序。
操作系统并发管理底层的线程和进程，而Java并发是编写多线程Java应用程序的一种编程范式。

Java集合：
集合 → 数组 ：toArray()
数组 → 集合 ：调用Array类的静态方法asList()

遍历集合的方法：
1.迭代器
Collection coll = new ArrayList();
Iterator iterator = coll.iterator();
while(iterator.hasNext()){
	System.out.println(iterator.next());
};
2.foreach()
for (集合元素的类型 局部变量 ：集合对象)


Java集合可分为Collection和Set两个体系：
Collection接口：单列数据，定义了存取一组对象的方法的集合
	
	List：元素有序、可重复的集合 
	>ArrayList:作为list接口的主要实现类；线程不安全的，效率高；底层使用Object[]elementData存储
	>LinkedList：对于频繁的插入、删除操作，使用效率比ArrayList高；底层使用双向链表存储
	>Vector：作为list接口的古老实现类；线程安全的，效率低；底层使用Object[]elementData存储
	
	Set：元素无序、不可重复的集合
	>HashSet:作为Set接口的主要实现类；线程不安全的；可以存储null值（底层：数组+链表）
	>LinkedHashSet：作为HashSet的一个子类；遍历其内部数据时，可以按照添加的顺序遍历
	>TreeSet：只能添加同一类型的对象，可以按照添加对象的指定属性，进行排序（底层：红黑树）

Map接口：双列数据，存储的是键值对

ArrayList的源码分析:
jdk 7情况下
ArrayList arrayList=new ArrayList();//底层建了长度是10的Object[]数组elementData
list.add (123);//elementData[0] = new Integer(123);
...
list.add(11);//如果此次的添加导致底层元素数据数组容量不够，则扩容
默认情况下，扩容为原来的容量的1.5倍，同时需要将原有数组中的数据复制到新的数组中
结论:建议开发中使用带参的构造器:ArrayList arrayList=new ArrayList(int capacity)

jdk 8中ArrayList的变化:
ArrayList list = new ArrayList();//底层Object[] elementData始化为{}并没有创建长度为10的数组
list.add(123);//第一次调用add()时，底层才创建了长度10的数组，并将数据123添加到elementData[0]
...
后续的添加和扩容操作与jdk 7 无异

小结：jdk7中的ArrayList对象创建类似于单列模式的饿汉式；
而jdk8中的ArrayList对象创建类似于单列模式的懒汉式，延迟了数组的创建，节省内存

LinkedList的源码分析：
LinkedLtst List = new LinkedList(); 内部明JNode类型的first和last属性，默认值为null 
List.add(123);//将123封装到Node 中，创建了Node对象。
其中，Node定义为:体现了LinkedList的双向链表的说法
private static class Node<E> {
	E item;
	Node<E> next;
	Node<E> prev;
	Node(Node<E> prev， E element， Node<E> next) {
	this.item = element;
	this.next = next;
	this.prev = prev;
	}
}

总结:List常用方法
增: add(object obj)
删：remove(int index) / remove(Object obj)
改：set(int index, Object ele)
查：get(int index)
插: add(int index, Object ele)
长度: size()
遍历: ①@Iterator送代器方式
	②增强for循环
	③普通的循环

Set：
1.无序性：存储的数据在底层数组中并非按照数组索引添加，而是根据数据的哈希值来决定
2.不可重复性：保证添加的元素按照equals()判断时，不能返回true.即: 相同的元素只能添加一个
	
添加元素的过程(以Hashset 为例):
我们向Hashset中添加元素a,首先调用元素a所在类的hashcode()方法，计算元素a的哈希值，此哈希值接着通过某种算法计算出在HashSet底层数组中的存放位置(即为: 索引位置)，
判断数组此位置上是否已经有元素:
如果此位置上没有其他元素，则元素a添加成功。--->情况1
如果此位置上有其他元素b(或以链表形式存在的多个元素)，则比较元素a与元素b的hash值:如果hash值不相同，则元素a添加成功。--->情况2
如果hash值相同，进而需要调用元素a所在类的equlas()方法:equaLs()返回true，元素a添加失败equaLs()返回false，则元素a添加成功。--->情况2
	对于添加成功的情况2和情况3而言: 元素 与已经存在指定索引位置上数据以链表的方式存储
	jdk 7 : 元素a放到数组中，指向原来的元素。jdk 8 : 原来的元素在数组中，指向元素a	

Set中相同元素的比较：先比较两个元素的哈希值，然后再比较两个元素是否相同

关于hashCode()和equals()方法重写的规则	
	1。Set接口中没有额外定义新的方法，使用的都是CoLLection 中声明过的方法
	要求:向Set中添加的数据，其所在的类一定要重写hashCode()和equals()
	2.要求:重写的hashCode()和eguals()尽可能保一致性: 相等的对象必须具有相等的散列码
	重写两个方法的小技巧: 对象中用作 equals() 方法比较的 Feld，都应该用来计算 hashcode

Map接口：双列数据，存储的是键值对	
>Map:双列数据，存储key-value对的数据---类似于高中的函数: y = f(x)
>HashMap:作为Map的主要实现类，线程不安全的，效率高: 存储null的key和value
>LinkedHashMap: 保证在遍历map元素时，可以按照添加的顺序实现遍历。
原因:在原有的HashMap 底层结构基础上，添加了一对指针，指向前一个和后一个元素。
对于频繁的遍历操作，此类执行效率高于HashMap。
>TreeMap:保证按照添加的key-value对进行排序，实现排序遍历。此时考key的自然排序或定制排序。底层使用红黑树
>Hashtable: 作为古老的实现类: 线程安全的，效率低:不能存nulL的key和value
>Properties: 常用来处理配置文件。key和value都是string类型

HashMap的底层实现原理? 以jdk7为例说明:
HashMap map = new HashMap():在实例化以后，底层创建了长度是16的一维数组Entry[] table
...可能已经执行过多次put...
map.put(key1, value1):
首先，调用key1所在类的hashCode()计算key1哈希值，此哈希值经过某种算法计算以后，得到在Entry数组中的存放位置。
	如果此位置上的数据为空，此时的key1-value1添加成功。 ---- 情况1
	如果此位置上的数据不为空，(意味着此位置上存在一个或多个数据(以链表形式存在)，
	比较key1和已经存在的一个或多个数的哈希值:
		如果key1的哈希值与已经存在的数据的哈希值都不相同，此时key1-value1添加成功。----情况2
		如key1的哈希值和已经存在的某一个数(key2-value2)的哈希值相同，继续比较: 调用key1所在类的equals(key2)
			如果equals()返回false: 此时key1-value1添加成功。---- 情况3
			如果equals()返回true: 使用vaLue1 vaLue2.

补充:关于情况2和情况3: 此时key1-value1和原来的数据以链表的方式存储
在不断的添加过程中，会涉及到扩容问题，默认的扩容方式:扩容为原来容量的2倍，并将原有的数据复制过来。

jdk8相较于jdk7在底层安现方面的不同:
1.new HashMap(): 底层没有创建一个长度为16的数组
2.jdk8底层的数组是: Node[]，而Entry[]首次调用put()方法时，底层创建长度为16的数组
3.jdk7底层结构只有:数组+ 链表。jdk8中底层结构: 数组+链表+红黑树。
当数组的某一个索引位置上的元素以链表形式存在的数个数 >8 且当前数组的长度>64时此时此索引位置上的所有数据改为使用红黑树存储。

Java泛型：
所操作的数据类型被指定为一个参数（type parameter）这种参数类型可以用在类、接口和方法的创建中，分别称为泛型类、泛型接口、泛型方法。

在集合中使用泛型:
>集合接口或集合类在jdk5.0时都修改为带泛型的结构
>在实例化集合类时，可以指明具体的泛型类型
>指明完以后，在集合类或接口中凡是定义类或接口时，内部结构使用到类的泛型的位置，都指定为实例化的泛型类型
(比如: add(E e) --->实例化以后: add(Integer e))
注意点: 泛型的类型必须是类，不能是基本数据类型。需要用到基本数据类型的位置，拿包装类替换 
>如果实例化时，没有指明泛型的类型。默认类型为java.lang.object类型。

自定义泛型接口：
语法：Interface 接口名<T, R…>{ }
使用注意事项：
① 接口中，静态成员也不能使用泛型；
② 泛型接口的类型，在继承接口或者实现接口时确定；
③ 没有指定类型，默认为Object。
	
泛型的通配符：?
① <?>：支持任意泛型
② <? extends A>：支持A类以及A类的子类，规定了泛型的上限
③ <? Super A>：支持A类以及A类的父类，不限于直接父类，规定了泛型的下限。	
④ 不能向List<?> 内添加除null之外的数据
⑤ 允许读取数据，读取数据的类型为Object

Java IO（Flie类、IO流、网络编程、序列化与反序列化）:
Java的IO是实现输入和输出的基础，可以方便的实现数据的输入和输出操作。在Java中把对于输入/输出操作是以流的方式进行操作的。java.io 包下提供了大量的供我们使用的操作【流】的方法和接口，用于进行各类数据的处理和传输。
注意： Windows各个文件之间分隔符为：” \ “；Linux各个文件之间分割符为：” / “

Java Flie类：Flie类是文件和目录路径名的抽象表示，主要用于文件和目录的创建、查找和删除等操作。
Flie类构造方法：
public File(String pathname) ：通过将给定的路径名字符串转换为抽象路径名来创建新的 File实例。
public File(String parent, String child) ：从父路径名字符串和子路径名字符串创建新的 File实例。
public File(File parent, String child) ：从父抽象路径名和子路径名字符串创建新的 File实例。

Java IO流：通过IO可以完成硬盘文件的读和写   I:Input 往内存中去 O:Output 从内存中出来
在java中只要"类名"以 Stream 结尾的都是字节流。以"Reader/Writer"结尾的都是字符流。
字符流不能处理图片文件，字节流不能处理文本文件

流的体系结构
抽象基类
InputStream
OutputStream
Reader
Writer
节点流(或文件流)
FileInputStream
FileOutputstream
FileReader
Filewriter
缓冲流(处理流的一种)
BufferedInputStream
BufferedOutputstream
BufferedReader
Bufferedwriter

文件专属字符流FlieReader：
//1.实例化File类的对象，指明要操作的文件
File file = new File( pathname:"hello.txt");//相较于当前Module
//2.提供具体的流
FileReader fr = new FileReader(file);
//3.数据的读入
int data;
while((data = fr.read()) != -1){
System.out.print((char)data);
}
//4.流的关闭操作
try {
fr.close();
} catch (IOException e) {
e.printStackTrace()
};

文件专属字节流FileInputStream：
public class FileInputStreamTest04 {
    public static void main(String[] args) {
        FileInputStream fis = null;
        try {
            fis = new FileInputStream("chapter23/src/tempfile3");
            // 开始读，采用byte数组，一次读取多个字节。最多读取“数组.length”个字节。
            byte[] bytes = new byte[4];// 准备一个4个长度的byte数组，一次最多读取4个字节。
            int readCount = 0;
            // 这个方法的返回值是：读取到的字节数量。（不是字节本身）;1个字节都没有读取到返回-1(文件读到末尾)
            while((readCount = fis.read(bytes)) != -1) {
            	// 不应该全部都转换，应该是读取了多少个字节，转换多少个。
                System.out.print(new String(bytes, 0, readCount));
            }
        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
        	// 在finally语句块当中确保流一定关闭。
            if (fis != null) {// 避免空指针异常！
            	// 关闭流的前提是：流不是空。流是null的时候没必要关闭。
                try {
                    fis.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
    }
}

缓冲字符流BufferReader：
包装流的方法
public class BufferedReaderTest01 {
    public static void main(String[] args) throws Exception{

        FileReader reader = new FileReader("Copy02.java");
        // 当一个流的构造方法中需要一个流的时候，这个被传进来的流叫做：节点流。
        // 外部负责包装的这个流，叫做：包装流，还有一个名字叫做：处理流。
        // 像当前这个程序来说：FileReader就是一个节点流。BufferedReader就是包装流/处理流。
        BufferedReader br = new BufferedReader(reader);

        // br.readLine()方法读取一个文本行，但不带换行符。
        String s = null;
        while((s = br.readLine()) != null){
            System.out.print(s);
        }

        // 关闭流
        // 对于包装流来说，只需要关闭最外层流就行，里面的节点流会自动关闭。（可以看源代码。）
        br.close();
    }
}

缓冲流InputStreamReader转换流FileInputStream：
public class BufferedReaderTest02 {
    public static void main(String[] args) throws Exception{

        /*// 字节流
        FileInputStream in = new FileInputStream("Copy02.java");

        // 通过转换流转换（InputStreamReader将字节流转换成字符流。）
        // in是节点流。reader是包装流。
        InputStreamReader reader = new InputStreamReader(in);

        // 这个构造方法只能传一个字符流。不能传字节流。
        // reader是节点流。br是包装流。
        BufferedReader br = new BufferedReader(reader);*/

        // 合并
        BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream("Copy02.java")));

        String line = null;
        while((line = br.readLine()) != null){
            System.out.println(line);
        }

        // 关闭最外层
        br.close();
    }
}

DataInputStream:数据字节输入流。
DataOutputStream写的文件，只能使用DataInputStream去读。并且读的时候你需要提前知道写入的顺序。
读的顺序需要和写的顺序一致。才可以正常取出数据。


序列化：将对象写入到IO流中，说的简单一点就是将内存模型的对象变成字节数字，可以进行存储和传输。
使用ObjectOutputStream实现序列化：
public class ObjectOutputStreamTest01 {
    public static void main(String[] args) throws Exception{
        // 创建java对象
        Student s = new Student(1111, "zhangsan");
        // 序列化
        ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream("students"));
        // 序列化对象
        oos.writeObject(s);
        // 刷新
        oos.flush();
        // 关闭
        oos.close();
    }
}
注意：序列化的对象需要实现Serializable接口，用static和transient修饰的变量不可序列化

反序列化：从IO流中恢复对象，将存储在磁盘或者从网络接收的数据恢复成对象模型。
使用ObjectInputStream实现反序列化：
public class ObjectInputStreamTest01 {
    public static void main(String[] args) throws Exception{
        ObjectInputStream ois = new ObjectInputStream(new FileInputStream("students"));
        // 开始反序列化，读
        Object obj = ois.readObject();
        // 反序列化回来是一个学生对象，所以会调用学生对象的toString方法。
        System.out.println(obj);
        ois.close();
    }
}

使用场景：所有可在网络上传输的对象都必须是可序列化的，否则会出错；所有需要保存到磁盘的Java对象都必须是可序列化的。


磁盘IO：
磁盘I/O速度较慢，因为它需要等待物理磁盘的旋转和磁头的定位，同时还受到硬盘的物理限制。
通常发生在文件系统层面，用于读写文件或数据块。

磁盘I/O的工作机制主要有以下三种方式：

1.直接I/O方式。不经系统内核空间直接访问磁盘数据的方式（减少一次内核空间缓存到用户程序缓存的复制操作），
通常是在一些数据库管理系统中实现，该管理系统明确知道需要缓存哪些数据，不需要哪些数据，这样就可以对数据进行预加载，
提高数据的访问效率。但是当数据需要从磁盘中加载的时候，直接加载会非常缓慢。
2.同步访问文件的方式。访问方式同标准访问文件的方式大体上是一样的，只是需要等到数据同步到磁盘上才能成功返回应用程序，
性能较差，但安全性高。
3.异步访问文件的方式。当发起访问数据的请求之后，线程就会继续执行其他的操作，直到请求数据返回。


RandomAccessFile是Java输入/输出流体系中功能最丰富的文件内容访问类，既可以读取文件内容，也可以向文件输出数据。

RandomAccessFlie的使用：
1.RandomAccessFlie直接继承于java.lang.Object，实现了DataInput和DataOutput
2.RandomAccessFlie既可以作为输入流，又可以作为输出流
3.如果RandomAccessFlie作为一个输出流时，写出的文件如果不存在，则在执行过程中自动创建；
如果文件存在，则会对原有文件内容进行覆盖。（默认情况下，从头覆盖）
4.用seak方法可以实现在第N位后覆盖原文件

Java NIO：
NIO 中的 N 可以理解为 Non-blocking，不单纯是 New，是解决高并发、I/O高性能的有效方式。
Java NIO是Java1.4之后推出来的一套IO接口，NIO提供了一种完全不同的操作方式， NIO支持面向缓冲区的、基于通道的IO操作。
新增了许多用于处理输入输出的类，这些类都被放在java.nio包及子包下，并且对原java.io包中的很多类进行改写，新增了满足NIO的功能。

Java NIO： 同步非阻塞，服务器实现模式为一个线程处理多个请求(连接)，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求就进行处理。
一个线程中就可以调用多路复用接口（java中是select）阻塞同时监听来自多个客户端的IO请求，
一旦有收到IO请求就调用对应函数处理，NIO擅长1个线程管理多条连接，节约系统资源。

运用Java NIO通信框架有Mina、Netty、Grizzly等。

Java NIO详解：https://www.cnblogs.com/mikechenshare/p/16587635.html

NIO 包含3个核心的组件：

Channel(通道)
Buffer(缓冲区)
Selector(选择器)

关系图：
https://static.mikechen.cc/wp-content/uploads/2022/03/java-nio-08.png

关系图的说明：
1.每个 Channel 对应一个 Buffer。
2.Selector 对应一个线程，一个线程对应多个 Channel。
3.该图反应了有三个 Channel 注册到该 Selector。
4.程序切换到那个 Channel 是由事件决定的（Event）。
5.Selector 会根据不同的事件，在各个通道上切换。
6.Buffer 就是一个内存块，底层是有一个数组。
7.数据的读取和写入是通过 Buffer，但是需要flip()切换读写模式，而 BIO 是单向的，要么输入流要么输出流。

import java.io.IOException;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.file.Paths;
import java.nio.file.StandardOpenOption;

public class NIOExample {
    public static void main(String[] args) {
        try (FileChannel channel = FileChannel.open(Paths.get("example.txt"), StandardOpenOption.READ)) {
            ByteBuffer buffer = ByteBuffer.allocate(1024);
            while (channel.read(buffer) > 0) {
                buffer.flip();
                while (buffer.hasRemaining()) {
                    System.out.print((char) buffer.get());
                }
                buffer.clear();
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}

这个例子中，我们使用FileChannel类打开了一个名为example.txt的文件，并创建了一个ByteBuffer对象作为缓冲区。
然后我们循环读取文件内容到缓冲区中，并使用flip()方法切换缓冲区的读写模式，然后逐个字节读取缓冲区中的内容并打印出来。
最后使用clear()方法清除缓冲区。

创建NIOServer：
public static void main(String[] args) throws  Exception{
        //创建ServerSocketChannel，-->> ServerSocket
        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();
        InetSocketAddress inetSocketAddress = new InetSocketAddress(5555);
        serverSocketChannel.socket().bind(inetSocketAddress);
        serverSocketChannel.configureBlocking(false); //设置成非阻塞
 
        //开启selector,并注册accept事件
        Selector selector = Selector.open();
        serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);
 
        while(true) {
            selector.select(2000);  //监听所有通道
            //遍历selectionKeys
            Set<SelectionKey> selectionKeys = selector.selectedKeys();
            Iterator<SelectionKey> iterator = selectionKeys.iterator();
            while (iterator.hasNext()) {
                SelectionKey key = iterator.next();
                if(key.isAcceptable()) {  //处理连接事件
                    SocketChannel socketChannel = serverSocketChannel.accept();
                    socketChannel.configureBlocking(false);  //设置为非阻塞
                    System.out.println("client:" + socketChannel.getLocalAddress() + " is connect");
                    socketChannel.register(selector, SelectionKey.OP_READ); //注册客户端读取事件到selector
                } else if (key.isReadable()) {  //处理读取事件
                    ByteBuffer byteBuffer = ByteBuffer.allocate(1024);
                    SocketChannel channel = (SocketChannel) key.channel();
                    channel.read(byteBuffer);
                    System.out.println("client:" + channel.getLocalAddress() + " send " + new String(byteBuffer.array()));
                }
                iterator.remove();  //事件处理完毕，要记得清除
            }
        }
 
    }
	
	
网络编程：网络编程是指编写运行在多个设备（计算机）的程序，这些设备都通过网络连接起来。程序之间可以通信，互相发送消息。

网络七层架构的作用与协议：
层		功能								协议
应用层	提供应用程序之间的通信。		TFTP，HTTP，SNMP，FTP，SMTP，DNS，Telnet
表示层	处理数据格式，数据加密和压缩等。	没有协议
会话层	建立、管理、终止两主机的会话。		没有协议
传输层	建立主机的端到端连接。			TCP，UDP
网络层	路径选择。						ICMP，RIP，OSPF，BGP，IGMP，IP
数据链路层	负责两个相邻结点之间的数据传输。		SLIP，CSLIP，PPP，ARP，RARP，MTU
物理层	使原始的数据比特流能在物理媒介上传输。	ISO2110，IEEE802，IEEE802.2


网络数据传输的过程可以被划分为应用层、传输层、网络层、链路层和物理层这五个层次，每个层次都有其特定的功能和协议。
网络数据传输的过程，按照这五个层次来描述：

1. 物理层（Physical Layer）：
   - 物理层是网络协议的最底层，负责传输比特流，即0和1的电信号，通过物理媒体（如电缆、光纤或无线信号）进行传输。
   - 在这一层，数据以二进制形式从发送方的物理介质传输到接收方。

2. 链路层（Data Link Layer）：
   - 链路层负责将物理层传输的比特流划分为帧（Frame），并添加地址信息，以便确定帧的源和目标。
   - 这一层还包括错误检测和纠正，以确保数据的完整性和可靠性。
   - 在局域网中，以太网协议是链路层的典型代表。

3. 网络层（Network Layer）：
   - 网络层负责将帧从源主机传输到目标主机，跨越不同的网络。
   - 它使用路由协议来确定数据包的路径，使数据能够通过多个路由器（Router）进行中转。
   - IP（Internet Protocol）是网络层的核心协议，它定义了数据包的格式和寻址机制。

4. 传输层（Transport Layer）：
   - 传输层负责端到端的通信，确保数据在源和目标之间可靠地传输。
   - 常见的传输层协议包括TCP（Transmission Control Protocol）和UDP（User Datagram Protocol）。
   - TCP提供可靠的、面向连接的通信，包括错误检测、重传机制等，而UDP提供无连接的、不可靠的通信，更适合实时应用。

5. 应用层（Application Layer）：
   - 应用层是最高层，它包含了各种应用程序，如Web浏览器、电子邮件客户端、文件传输工具等。
   - 在这一层，数据被组织成消息、请求或响应，并与特定的应用程序协议相关联，如HTTP、SMTP、FTP等。
   - 应用程序通过传输层与目标应用程序通信，完成数据的交换和处理。

总的来说，网络数据传输的过程从物理层开始，逐层传递，最终到达应用层。每一层都具有不同的功能和责任，协同工作以确保数据在源和目标之间安全、可靠地传输。这个分层模型有助于实现网络的模块化、可扩展性和互操作性。



IP：唯一的标识 Internet上的计算机（通信实体）
IP分类：IPV4和IPV6；万维网和局域网
域名：由于IP地址具有不方便记忆并且不能显示地址组织的名称和性质等缺点，人们设计出了域名，并通过网域名称系统（DNS，Domain Name System）来将域名和IP地址相互映射，
使人更方便地访问互联网，而不用去记住能够被机器直接读取的IP地址数串
本地回路地址：127.0.0.1 对应：localhost
在Java中使用InetAddress类代表IP，实例化InetAddress的两个方法：
getByName(String host) getLocalHost()
两个常用方法：getHostName() / getHostAddress()
端口号：正在计算机上运行的进程
  要求：不同的进程有不同的端口号
  范围：被规定为一个16位的整数0-65535
端口号与IP地址的组合得出一个网络套接字:Socket

TCP和UDP协议是TCP/IP协议的核心。 TCP 传输协议：TCP 协议是一TCP (Transmission Control Protocol)和UDP(User Datagram Protocol)协议属于传输层协议。
其中TCP提供IP环境下的数据可靠传输，它提供的服务包括数据流传送、可靠性、有效流控、全双工操作和多路复用。通过面向连接、端到端和可靠的数据包发送。
通俗说，它是事先为所发送的数据开辟出连接好的通道，然后再进行数据发送；而UDP则不为IP提供可靠性、流控或差错恢复功能。
一般来说，TCP对应的是可靠性要求高的应用，而UDP对应的则是可靠性要求低、传输经济的应用。

网络编程之实现InetAddress实例化：
public class InetAddressTest {
    public static void main(String[] args) {
 
        InetAddress inet1 = null;
        try {
            inet1 = InetAddress.getByName("192.168.10.14");
            System.out.println(inet1);
 
            InetAddress inet2 = InetAddress.getByName("www.baidu.com");
            System.out.println(inet2);
 
            InetAddress inet3 = InetAddress.getByName("127.0.0.1");
            System.out.println(inet3);
 
            //获取本地ip
            InetAddress inet4 = InetAddress.getLocalHost();
            System.out.println(inet4);
 
            //getHostName()
            System.out.println(inet2.getHostName());
            //getHostAddress()
            System.out.println(inet2.getHostAddress());
        } catch (UnknownHostException e) {
            e.printStackTrace();
        }
 
    }
}

网络编程之Socket编程：
我们可以发现Socket就在应用程序的传输层和应用层之间，设计了一个Socket抽象层，传输层的底一层的服务提供给Socket抽象层，Socket抽象层再提供给应用层。
套接字使用TCP提供了两台计算机之间的通信机制。 客户端程序创建一个套接字，并尝试连接服务器的套接字。
当连接建立时，服务器会创建一个 Socket 对象。客户端和服务器现在可以通过对 Socket 对象的写入和读取来进行通信。
java.net.Socket 类代表一个套接字，并且 java.net.ServerSocket 类为服务器程序提供了一种来监听客户端，并与他们建立连接的机制。
IP和端口号通过Socket传输。

以下步骤在两台计算机之间使用套接字建立TCP连接时会出现：

服务器实例化一个 ServerSocket 对象，表示通过服务器上的端口通信。
服务器调用 ServerSocket 类的 accept() 方法，该方法将一直等待，直到客户端连接到服务器上给定的端口。
服务器正在等待时，一个客户端实例化一个 Socket 对象，指定服务器名称和端口号来请求连接。
Socket 类的构造函数试图将客户端连接到指定的服务器和端口号。如果通信被建立，则在客户端创建一个 Socket 对象能够与服务器进行通信。
在服务器端，accept() 方法返回服务器上一个新的 Socket 引用，该 Socket 连接到客户端的 Socket。

Java实现TCP网络程序设计：
服务器端类：
package dreamfly.net.server;

//读取客户端发来的数据，给客户端写出数据

import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.net.ServerSocket;
import java.net.Socket;

public class Server {

    public static void main(String[] args) throws IOException {

        //1.开启服务器，参数是指开着的端口号
        ServerSocket server = new ServerSocket(8899);
        System.out.println("服务器已成功启动");
        //2.接收客户端发来的连接
        Socket socket = server.accept();
        System.out.println("接收到客户端发来的请求");
        //3.获取读取流
        InputStream in = socket.getInputStream();
        //4.读取数据
//        int data = in.read();      //默认返回的是整数
        for (int i = 0;i < 5;i++){
            char data = (char)in.read();
            System.out.print(data);
        }
        //5.给客户端写出数据
        System.out.println();
        OutputStream out = socket.getOutputStream();
        out.write("world".getBytes());
        System.out.println("服务器端成功发送数据");
        out.close();
    }
}

客户端类：
package dreamfly.net.client;

//读取服务器端发来的数据，给服务器端写出数据

import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.net.Socket;

public class Client {

    public static void main(String[] args) throws IOException {
        //1.连接到指定的服务器(ip+port)
        Socket socket = new Socket("127.0.0.1",8899);
        System.out.println("已连接成功");
        //2.获取写出流
        OutputStream out = socket.getOutputStream();
        //3.写出数据,字节流只能写出整数或字节数组
        //将hello对应整数编程对应的字节数组，getBytes()将String转换为byte[]
        out.write("hello".getBytes());
        System.out.println("客户端成功发送数据");
        InputStream in = socket.getInputStream();
        for (int i = 0;i < 5;i++){
            char data = (char)in.read();
            System.out.print(data);
        }
        System.out.println();
        System.out.println("成功接收服务器端数据");
        out.close();
    }
}



Java实现UDP编程：
服务器端
DatagramSocket serverSocket = new DatagramSocket(1234)；//设置监听端口，可以和TCP端口重复，及一个应用程序用TCP占用端口1234，另一个程序可以用UDP占用端口1234

byte[] buff = new byte[1024];

客户端
DatagramPacket packet = new DatagramPacket(buff, buff.length);//设置接受长度为buff.leng的buff数据

serverSocket.receive(packet)；//收取UDP数据包

String word = new String( packet.getData(), packet.getOffset(), packet.getLength(),StandardCharsets.UTF_8 );//将收到的数据按UTF-8转换为String

System.out.println("已经收到"+word);//在服务器做出提示
                byte[] resultbuff = word.getBytes();
                packet.setData(resultbuff);
                serverSocket.send(packet);//发送数据给客户端做出回应


URL：在WWW上，每一信息资源都有统一的且在网上的地址，该地址就叫URL（Uniform Resource Locator,统一资源定位器），它是WWW的统一资源定位标志，就是指网络地址。
URL格式：协议 主机名 端口号 资源地址

Java实现URL网络编程：
public class UrlTest02 {

    public static void main(String[] args) throws Exception {

        HttpURLConnection urlConnection = null;
        InputStream is = null;
        FileOutputStream fos = null;
        try {
            URL url = new URL("http://localhost:8080/examples/beauty.jpg");

            urlConnection = (HttpURLConnection) url.openConnection();

            urlConnection.connect();

            is = urlConnection.getInputStream();
            fos = new FileOutputStream("day10\\beauty3.jpg");

            byte[] buffer = new byte[1024];
            int len;
            while((len = is.read(buffer)) != -1){
                fos.write(buffer,0,len);
            }

            System.out.println("下载完成");
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            //关闭资源
            if(is != null){
                try {
                    is.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
            if(fos != null){
                try {
                    fos.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
            if(urlConnection != null){
                urlConnection.disconnect();
            }
        }
    }
}

以上是TCP/IP协议，多用于C/S架构中客户端与服务器端之间的连接。



关于C/S架构和B/S架构：
1.C/S架构即客户端/服务器架构，指的是需要安装客户端应用程序才能进行操作的架构模式；
2.而B/S架构即浏览器/服务器架构，指的是无需安装客户端应用程序，通过浏览器进行操作的模式。

>在B/S架构中，用户通过浏览器访问Web服务器上的网页，数据传输使用HTTP或HTTPS协议进行。
HTTPS协议是一种安全的HTTP协议，通过使用SSL/TLS证书来对数据进行加密，以保证数据传输的安全性和完整性。

>在C/S架构中，客户端和服务器之间通过TCP/IP协议进行通信。TCP/IP协议是一种传输层协议，用于在局域网中进行通信，
它规定了如何在网络中传输数据，并且能够保证数据的可靠性、顺序性和完整性。

总结：B/S架构多使用HTTP或HTTPS协议，而C/S架构则更倾向于使用TCP/IP协议。
但是，这并不是绝对的，也取决于具体的应用和需求。
例如，在某些需要保证数据安全性和完整性的应用场景中，C/S架构也可能会使用HTTPS协议。

PS：在JavaEE开发中，几乎全都是B/S架构的开发。系统标准的三层架构在B/S中广泛运用，这种架构包括表现层、业务层、持久层。
PS: 微信小程序的开发用的是C/S架构。


什么是HTTP协议？
HTTP协议（HyperText Transfer Protocol）是一种网络通信协议，它允许将超文本标记语言（HTML）文档从Web服务器传送到客户端的浏览器。
HTTP协议的默认端口是80，它定义了Web客户端和Web服务器之间的通信规则，确保了数据的安全和正确传输。
HTTP协议是无状态协议，即服务器不会保留之前客户端请求的任何信息。
每个HTTP请求都是独立的，服务器不会记住之前的请求和响应，因此每个请求都需要包含所有必要的信息，包括身份验证、Cookie等。


什么是HTTPS协议？
HTTPS协议是超文本传输安全协议的英文翻译缩写，是以安全为目标的HTTP通道，下加入了SSL层。

HTTPS协议是一个抽象标识符体系，句法类同http：体系，用于安全的HTTP数据传输，
https：URL表明它使用了HTTP，但HTTPS存在不同于HTTP的默认端口及一个加密身份验证层。


HTTP协议的特点和基本工作原理：

1.HTTP协议支持客户/服务器模式。
2.HTTP协议简单快速：客户向服务器请求服务时，只需传送请求方法和路径，请求方法常用的有GET、HEAD、POST，
由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。
3.HTTP协议灵活：HTTP允许传输任意类型的数据对象，传输的类型由Content-Type加以标记。
4.HTTP协议无连接：无连接的含义是限制每次连接只处理一个请求，服务器处理完客户的请求，
并收到客户的应答后，即断开连接，采用这种方式可以节省传输时间。

HTTP请求报文格式：
HTTP请求报文格式是HTTP协议中用于从客户端向服务器发送请求的一种标准化格式。一个完整的HTTP请求报文通常由请求行、请求头部和请求体（可选）三部分组成。

请求行：
请求行包含HTTP请求方法、请求的URL和HTTP协议版本。HTTP请求方法常见的有GET、POST、PUT、DELETE等，用于指定对资源的不同操作。请求的URL指明了请求的具体目标资源。
HTTP协议版本则标识了使用的HTTP协议标准，如HTTP/1.1。

请求头部：
请求头部包含了一系列的字段，每个字段由字段名和字段值组成，字段名和字段值之间用冒号分隔。请求头部提供了关于请求的各种元信息，
如客户端的类型（User-Agent）、客户端能够处理的内容类型（Accept）、请求的源地址（Referer）、请求的目标主机（Host）等。这些元信息有助于服务器理解和处理请求。

请求体：
请求体是可选的，它包含了发送给服务器的数据。对于GET请求，通常不会有请求体，因为GET请求主要用于请求数据。而对于POST或PUT请求，请求体则包含了需要发送给服务器的数据，如表单数据、JSON数据等。
在格式上，请求行和请求头部以回车符（CR）和换行符（LF）结尾，形成CRLF序列。请求头部与请求体之间通常会有一个空行，即只包含CRLF的行，用于分隔请求头部和请求体。

下面是一个简单的HTTP GET请求报文的例子：

GET /example HTTP/1.1  
Host: www.example.com  
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36  
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9  
Accept-Encoding: gzip, deflate  
Accept-Language: en-US,en;q=0.9  
Connection: keep-alive  
  
// 此处为请求体开始的位置，对于GET请求，通常没有请求体
在这个例子中，GET /example HTTP/1.1是请求行，Host、User-Agent、Accept等是请求头部的字段，而请求体部分在这个GET请求中是缺失的。


发起HTTPS请求的过程：

1.客户端向服务器发起HTTPS请求，连接到服务器的443端口。
2.服务器端有一个密钥对，即公钥和私钥，是用来进行非对称加密使用的，服务器端保存着私钥，不能将其泄露，公钥可以发送给任何人。
3.服务器将自己的公钥发送给客户端。
4.客户端收到服务器端的证书之后，会对证书进行检查，验证其合法性，如果发现发现证书有问题，那么HTTPS传输就无法继续。
5.如果公钥合格，那么客户端会生成一个随机值，这个随机值就是用于进行对称加密的密钥，我们将该密钥称之为clientkey，即客户端密钥，这样在概念上和服务器端的密钥容易进行区分。
6.然后用服务器的公钥对客户端密钥进行非对称加密，这样客户端密钥就变成密文了。
7.HTTPS中的第一次HTTP请求结束。

HTTP请求响应格式：
HTTP请求响应格式是HTTP协议中服务器对客户端请求进行回应的一种标准化格式。一个完整的HTTP响应报文通常由状态行、响应头部和响应体三部分组成。

状态行：
状态行包含了HTTP协议版本号、状态码和状态描述。HTTP协议版本号用于标识所使用的HTTP协议标准，如HTTP/1.1。状态码是一个三位数字，用于表示请求的处理结果，
如200表示请求成功，404表示资源未找到等。状态描述是对状态码的简短文字描述，用于提供关于响应状态的额外信息。

响应头部：
响应头部包含了一系列的字段，每个字段由字段名和字段值组成，字段名和字段值之间用冒号分隔。
响应头部提供了关于响应的各种元信息，如内容类型（Content-Type）、内容长度（Content-Length）、服务器类型（Server）等。这些元信息有助于客户端理解和处理响应内容。

响应体：
响应体是服务器返回给客户端的实际数据内容。对于成功的请求，响应体通常包含了请求的资源；对于错误请求，响应体可能包含错误信息或描述。响应体的格式和内容取决于请求的资源类型和服务器的配置。

在格式上，状态行、响应头部和响应体之间都以回车符（CR）和换行符（LF）结尾，形成CRLF序列。响应头部与响应体之间通常会有一个空行，即只包含CRLF的行，用于分隔响应头部和响应体。

下面是一个简单的HTTP响应报文的例子：

http
HTTP/1.1 200 OK  
Content-Type: text/html; charset=UTF-8  
Content-Length: 1234  
Server: Apache/2.4.41  
  
<!DOCTYPE html>  
<html>  
<head>  
    <title>Example Page</title>  
</head>  
<body>  
    <h1>Welcome to the Example Page!</h1>  
    <!-- 页面内容 -->  
</body>  
</html>
在这个例子中，HTTP/1.1 200 OK是状态行，Content-Type、Content-Length和Server是响应头部的字段，而响应体则包含了HTML页面的实际内容。


设置在后端程序中统一返回响应对象：

1.创建Http枚举类
public enum HttpResponseStatus {  
    OK(200, "OK"),  
    CREATED(201, "Created"),  
    ACCEPTED(202, "Accepted"),  
    NO_CONTENT(204, "No Content"),  
    BAD_REQUEST(400, "Bad Request"),  
    UNAUTHORIZED(401, "Unauthorized"),  
    FORBIDDEN(403, "Forbidden"),  
    NOT_FOUND(404, "Not Found"),  
    INTERNAL_SERVER_ERROR(500, "Internal Server Error");  
  
    private final int statusCode;  
    private final String statusMessage;  
  
    HttpResponseStatus(int statusCode, String statusMessage) {  
        this.statusCode = statusCode;  
        this.statusMessage = statusMessage;  
    }  
  
    public int getStatusCode() {  
        return statusCode;  
    }  
  
    public String getStatusMessage() {  
        return statusMessage;  
    }  
  
    // 根据状态码获取枚举项  
    public static HttpResponseStatus getStatusByCode(int statusCode) {  
        for (HttpResponseStatus status : HttpResponseStatus.values()) {  
            if (status.getStatusCode() == statusCode) {  
                return status;  
            }  
        }  
        return null;  
    }  
}

2.创建返回对象
public class ResultData<T> {  
    private int code; // HTTP状态码  
    private String message; // 状态消息或错误信息  
    private T data; // 返回的数据  
    // 可以根据需要添加其他字段，如额外信息、时间戳等  
  
    private ResultData(int code, String message, T data) {  
        this.code = code;  
        this.message = message;  
        this.data = data;  
    }  
  
    // 静态方法，用于创建成功的响应对象  
    public static <T> ResultData<T> success(T data) {  
        return new ResultData<>(HttpResponseStatus.OK.getStatusCode(), HttpResponseStatus.OK.getStatusMessage(), data);  
    }  
  
    // 静态方法，用于创建失败的响应对象  
    public static <T> ResultData<T> fail(HttpResponseStatus status, String errorMessage) {  
        return new ResultData<>(status.getStatusCode(), errorMessage, null);  
    }  
  
    // 静态方法，根据状态码创建失败的响应对象  
    public static <T> ResultData<T> failByCode(int statusCode, String errorMessage) {  
        HttpResponseStatus status = HttpResponseStatus.getStatusByCode(statusCode);  
        if (status != null) {  
            return new ResultData<>(statusCode, status.getStatusMessage() + ": " + errorMessage, null);  
        } else {  
            return new ResultData<>(statusCode, "Unknown Error: " + errorMessage, null);  
        }  
    }  
  
    // Getter方法，用于获取响应的各个字段  
    public int getCode() {  
        return code;  
    }  
  
    public String getMessage() {  
        return message;  
    }  
  
    public T getData() {  
        return data;  
    }  
  
    // toString方法，用于调试或日志记录  
    @Override  
    public String toString() {  
        return "ResultData{" +  
                "code=" + code +  
                ", message='" + message + '\'' +  
                ", data=" + data +  
                '}';  
    }  
}


使用Java发起https请求：
import org.apache.http.HttpEntity;
import org.apache.http.HttpResponse;
import org.apache.http.client.methods.CloseableHttpResponse;
import org.apache.http.client.methods.HttpGet;
import org.apache.http.impl.client.CloseableHttpClient;
import org.apache.http.impl.client.HttpClients;
import org.apache.http.util.EntityUtils;

public class HttpClientExample {
    public static void main(String[] args) {
        // 创建HttpClient实例
        CloseableHttpClient httpClient = HttpClients.createDefault();

        // 创建HttpGet请求
        HttpGet httpGet = new HttpGet("http://example.com");

        try {
            // 发送HTTP请求并获取响应
            CloseableHttpResponse response = httpClient.execute(httpGet);

            // 从响应中获取HTTP实体
            HttpEntity entity = response.getEntity();

            if (entity != null) {
                // 将HTTP实体内容转换为字符串并输出
                String result = EntityUtils.toString(entity);
                System.out.println(result);
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            // 关闭HttpClient实例
            try {
                httpClient.close();
            } catch (Exception e) {
                e.printStackTrace();
            }
        }
    }
}

HTTPS中反斜杠（/）通常用于表示路径（path）的一部分。路径是指URL中主机名和查询字符串之间的部分，用于指定请求的资源位置。
其中，https中反斜杠指向的路径部分指定的是服务器的资源位置。当客户端向服务器发送请求时，服务器会根据路径部分来查找和提供相应的资源。

关于CDN：
什么是CDN？
CDN工作机制是通过在现有的Internet中增加一层新的网站架构，将网站的内容发布到最接近用户的网络“边缘”，使用户可以就近取得所需内容，提高用户访问网站的响应速度。
CDN以缓存网站中的静态数据为主，如CSS、JS、图片和静态页面等数据。用户从主站服务器请求到动态内容后，再从CDN上下载静态数据，
从而加速网页数据内容的下载数据，如淘宝有90%以上的数据都是由CDN来提供。
DNS服务器根据用户IP地址，将域名解析成相应节点的缓存服务器IP地址，实现用户就近访问。
使用CDN服务的网站，只需将其域名解析权交给CDN的GSLB设备，将需要分发的内容注入CDN，就可以实现内容加速了。

关于网络负载均衡：
什么是负载均衡？
负载均衡建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、
加强网络数据处理能力、提高网络的灵活性和可用性。
负载均衡（Load Balance）其意思就是分摊到多个操作单元上进行执行，
例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。

关于不同的负载均衡：
阐述一下分布式系统负载均衡、集群负载均衡、操作系统负载均衡、链路负载均衡的不同点。
分布式系统负载均衡、集群负载均衡、操作系统负载均衡和链路负载均衡是不同领域和层次的负载均衡技术，它们在应用场景、范围和实现方式上有不同点：

1. **分布式系统负载均衡**：
   - **应用领域：** 分布式系统负载均衡主要应用于分布式计算和分布式存储系统中，以确保各个节点上的任务或数据负载均衡。
   - **范围：** 它是在分布式系统内部实现的负载均衡，通常不涉及跨越不同物理服务器的负载均衡。
   - **实现方式：** 分布式系统负载均衡可以通过各种算法和策略来实现，如任务分配、数据分片等。

2. **集群负载均衡**：
   - **应用领域：** 集群负载均衡主要用于应用程序的高可用性和性能优化，通过将多个服务器组成集群，将负载均衡在这些服务器之间。
   - **范围：** 集群负载均衡通常涉及跨越多台物理服务器的负载均衡，以实现应用程序的水平扩展。
   - **实现方式：** 集群负载均衡可以通过硬件负载均衡器、软件负载均衡器（如Nginx、HAProxy）等来实现。

3. **操作系统负载均衡**：
   - **应用领域：** 操作系统负载均衡主要用于操作系统内核的进程和资源管理，以确保操作系统上运行的任务在CPU、内存、磁盘等资源上均衡分配。
   - **范围：** 它是在单个操作系统内部实现的负载均衡，用于优化操作系统的性能和资源利用率。
   - **实现方式：** 操作系统负载均衡通过调度算法、进程优先级、内存管理等机制来实现资源分配和任务调度。

4. **链路负载均衡**：
   - **应用领域：** 链路负载均衡主要应用于网络层，用于分发网络流量和请求到多个网络链接或路径上，以提高网络性能和可靠性。
   - **范围：** 它涉及到物理网络层，以确保数据包在不同链路之间均衡分布，以避免某一链路过载或失效。
   - **实现方式：** 链路负载均衡可以通过路由协议、硬件负载均衡器、软件路由器等来实现。

综上所述，这些负载均衡技术在不同领域和层次中发挥作用。分布式系统负载均衡和集群负载均衡主要关注应用程序的分布和性能，
操作系统负载均衡关注操作系统资源的管理，而链路负载均衡关注网络流量的分发和可靠性。
它们在实现方式、应用场景和目标方面存在差异，但都旨在提高系统的性能、可用性和资源利用率。

explain the difference between distributed system load balancing（分布式系统负载均衡）,cluster load balancing(集群负载均衡),operating system load balancing（操作系统负载均衡）,link load balancing （链路负载均衡）

Load balancing is a technique used in computer systems to distribute workloads or network traffic across multiple resources (such as servers or network links) to ensure optimal performance, 
minimize resource overload, and enhance system reliability. There are different types of load balancing, and here's an explanation of the differences between distributed system load balancing, 
cluster load balancing, operating system load balancing, and link load balancing:

Distributed System Load Balancing:

Purpose: Distributed system load balancing involves distributing workloads across multiple servers or nodes within a distributed computing environment.
 The goal is to improve the overall system's performance, scalability, and fault tolerance.
Use Case: It is commonly used in web applications, cloud computing, and large-scale distributed systems to evenly distribute user requests and processing tasks across multiple servers.
Techniques: Distributed load balancers often use algorithms like Round Robin, Least Connections, or Weighted Round Robin to determine how to route incoming requests to available resources.

Cluster Load Balancing:

Purpose: Cluster load balancing is a subset of distributed system load balancing. It specifically applies to clusters or groups of servers or nodes that work together as a single entity to provide services.
Use Case: Cluster load balancing is used in scenarios where high availability and fault tolerance are critical, such as in database clusters or application server clusters.
Techniques: Techniques like virtual IP addresses and load balancing algorithms are used to evenly distribute traffic among the nodes within the cluster.

Operating System Load Balancing:

Purpose: Operating system load balancing focuses on distributing the processing load among the CPU cores or processors within a single machine or server.
Use Case: It is relevant in multi-core or multi-processor systems where applications can benefit from parallelism and efficient resource utilization.
Techniques: Modern operating systems often have built-in load balancing mechanisms that distribute tasks or threads across available CPU cores based on factors like CPU utilization and affinity policies.

Link Load Balancing:

Purpose: Link load balancing (or network load balancing) involves distributing network traffic across multiple network links or paths to optimize network performance, increase bandwidth, 
and improve network reliability.
Use Case: It is commonly used in environments with redundant network connections, such as data centers, to ensure uninterrupted network connectivity and efficient use of available bandwidth.
Techniques: Network load balancers may use techniques like Equal-Cost Multipath (ECMP) routing or dynamic link aggregation (LACP) to balance traffic across multiple network links.

In summary, load balancing techniques are used at various levels of computing infrastructure to achieve different objectives. 
Distributed system load balancing is about distributing workloads across multiple servers or nodes in a distributed environment, 
while cluster load balancing specifically applies to clusters of servers. 
Operating system load balancing manages CPU resources within a single machine, and link load balancing optimizes network traffic distribution across multiple network links. 
Each type of load balancing serves a unique purpose and addresses specific performance and scalability challenges.

Tomcat:
Tomcat（Apache Tomcat）是一个流行的开源Java应用服务器，用于托管和运行Java Web应用程序。

在Tomcat中，webapps目录是专门用来存放Web应用程序的。这个目录结构允许Tomcat服务器识别并加载其中的Web应用程序，使得它们能够通过HTTP请求被访问。
在webapps目录下，可以存放各种类型的文件来构成完整的Web应用程序。以下是可以在webapps目录中存放的一些文件类型：

静态内容：
HTML文件：构成Web页面结构的基本文件。
CSS文件：用于定义Web页面的样式。
JavaScript文件：用于添加页面交互和动态功能的客户端脚本。
图片、音频、视频等媒体文件：作为Web页面的一部分被引用，提供多媒体内容。

动态内容：
JSP文件（Java Server Pages）：允许Java代码嵌入到HTML中，用于动态生成Web页面内容。
Servlet类文件：编译后的Java类文件，用于处理请求并生成响应。Servlet通常放在WEB-INF/classes目录下，或者打包成JAR文件放在WEB-INF/lib目录下。

配置文件：
web.xml：Web应用程序的部署描述符，用于配置Servlet、过滤器、监听器以及初始化参数等。
其他应用程序特定的配置文件：如数据库连接配置文件、日志配置文件等。

库文件：
JAR文件：Web应用程序所依赖的库和框架通常放在WEB-INF/lib目录下。这些JAR文件包含了应用程序运行所需的类库和依赖项。

目录结构：
META-INF：存放与JAR文件相关的元数据，如MANIFEST.MF文件。
WEB-INF：一个特殊的目录，用于存放仅供服务器访问的资源，如classes目录（存放编译后的Java类文件）、lib目录（存放JAR库文件）以及任何应用程序内部使用的配置文件。

在将文件添加到webapps目录时，Tomcat会按照其内部机制来加载和处理这些文件。当Tomcat服务器启动时，它会扫描webapps目录并自动部署其中的Web应用程序。
每个Web应用程序通常对应webapps下的一个子目录，这个子目录的名称就是Web应用程序的上下文路径（Context Path）。


Tomcat的系统架构主要包括以下关键组件和层次：
1. Servlet容器：
   - Tomcat的核心部分是Servlet容器，它是一个Web服务器扩展，用于执行Java Servlet和JavaServer Pages（JSP）等Web组件。
   - Servlet容器负责接收HTTP请求、处理Servlet和JSP、生成HTTP响应，并将响应发送回客户端浏览器。
   - Tomcat的Servlet容器遵循Java Servlet和JSP规范，并提供了Servlet的生命周期管理、多线程支持、会话管理等功能。

2. 连接器（Connectors）：
   - 连接器是Tomcat与客户端之间的通信接口。它们负责接受HTTP请求并将其传递给Servlet容器，然后将Servlet容器的响应发送回客户端。
   - Tomcat支持多种连接器，包括HTTP连接器（用于处理HTTP请求）、AJP连接器（用于与Apache HTTP服务器集成）等。

3. Catalina容器：
   - Catalina是Tomcat的核心组件之一，负责Web应用程序的生命周期管理和请求分派。
   - Catalina包括多个子容器，如Engine、Host和Context，它们用于组织和管理Web应用程序。
   - Engine表示整个Tomcat引擎，Host表示一个虚拟主机，Context表示一个Web应用程序上下文。

4. JSP引擎：
   - Tomcat包括一个JSP引擎，用于编译和执行JavaServer Pages。当JSP页面首次被访问时，JSP引擎将其编译成Servlet，并在后续请求中执行该Servlet。
   - JSP引擎支持JSP标签、自定义标签库（Tag Libraries）等JSP特性。

5. 类加载器：
   - Tomcat使用类加载器来加载Web应用程序的Java类。每个Web应用程序都有自己的类加载器，以隔离不同应用程序之间的类。
   - Tomcat的类加载器体系结构支持共享库（shared library）和全局库（global library），使得可以在多个应用程序之间共享某些类。

6. 管理工具：
   - Tomcat提供了一组Web管理工具，用于监视和管理Tomcat服务器。这些工具包括Tomcat管理应用程序、Tomcat管理控制台、Manager应用程序等。
   - 这些工具使管理员能够查看服务器状态、部署和管理Web应用程序、查看日志、配置数据源等。

总的来说，Tomcat的系统架构是一个多层次的体系结构，其中包括Servlet容器、连接器、Catalina容器、JSP引擎、类加载器和管理工具等组件。
这些组件协同工作，使Tomcat成为一个强大的Java应用服务器，用于托管和运行Web应用程序。 
Tomcat的开源性质和广泛的社区支持使其成为Java Web应用程序开发和部署的流行选择。


Nginx：
NGINX是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。
NGINX是由伊戈尔·赛索耶夫为俄罗斯访问量第二的Rambler.ru站点开发的，公开版本1.19.6发布于2020年12月15日。
其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、简单的配置文件和低系统资源的消耗而闻名。

Nginx（发音为"engine-x"）是一个高性能、可伸缩、开源的反向代理服务器和Web服务器，其系统架构具有以下关键组件和特点：

1. Master Process（主进程）：
   - Nginx的系统架构以主从进程模型为基础。主进程是第一个启动的Nginx进程，它负责管理其他子进程，处理配置文件加载、平滑升级、日志记录等任务。
   - 主进程不处理实际的客户端请求，而是将请求分配给工作进程（worker process）。

2. Worker Processes（工作进程）：
   - Nginx可以配置多个工作进程，每个工作进程独立处理客户端请求。
   - 工作进程是并发处理的核心，它们可以同时处理多个客户端请求，通过事件驱动方式来提供高性能的请求处理。
   - 每个工作进程都是一个独立的进程，它们不共享内存，提高了稳定性和安全性。

3. 事件驱动模型：
   - Nginx采用了事件驱动的架构，使用高效的I/O多路复用机制，如epoll（在Linux上）或kqueue（在BSD上），以实现非阻塞的事件处理。
   - 这意味着Nginx可以在单个工作进程中同时处理多个并发连接，而无需为每个连接创建一个新的线程或进程，从而降低了资源开销。

4. 反向代理（Reverse Proxy）：
   - Nginx经常用作反向代理服务器，接收来自客户端的请求，然后将请求代理到后端的应用服务器上，如Tomcat、Node.js或Ruby on Rails。
   - 这使得Nginx能够负责负载均衡、SSL终止、请求缓存、静态文件服务等功能。

//配置Nginx
   server {
    listen 80;
    server_name example.com;  # 修改为您的域名或IP地址
    location / {
        proxy_pass http://localhost:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}

5. HTTP和HTTPS支持：
   - Nginx是一个全功能的HTTP服务器，支持HTTP/1.0、HTTP/1.1和HTTP/2协议。它能够处理HTTP请求和响应、URL重写、反向代理、gzip压缩等。
   - Nginx还支持HTTPS，可以进行SSL/TLS终止、证书管理和安全连接。

6. 模块化架构：
   - Nginx采用模块化的设计，它允许通过第三方模块来扩展功能。管理员可以根据需要加载不同的模块，以适应特定的用例和需求。
   - 核心模块处理基本功能，如HTTP请求和响应，而第三方模块可以添加缓存、安全性、负载均衡等功能。

7. 负载均衡：
   - Nginx支持多种负载均衡算法，如轮询、IP哈希、最小连接数等，以将客户端请求分发到多个后端服务器上，实现高可用性和性能优化。

   http {
    upstream backend {
        server backend1.example.com;
        server backend2.example.com;
        server backend3.example.com;
    }

    # ...其他Nginx配置...

    server {
        listen 80;

        location / {
            proxy_pass http://backend;
        }
    }
}

负载均衡后的请求将会均匀的分发到backend中列出的三个服务器中。

总的来说，Nginx的系统架构是一个高性能、事件驱动的主从进程模型，具有反向代理、负载均衡、HTTP和HTTPS支持、模块化设计等特点。
这些特性使得Nginx成为一个非常受欢迎的Web服务器和反向代理服务器，适用于各种用例，从静态文件服务到高流量的Web应用程序。 
Nginx的性能和可伸缩性使其在构建现代Web架构中广泛使用。

Netty：
Netty是一个由JBOSS提供的开源框架，用于快速开发高性能、高可靠性的网络应用程序。
它简化和流线化了网络应用的编程开发过程，基于NIO（非阻塞IO）开发，使用异步事件驱动的方式处理网络请求。

Netty的主要特点包括：
异步事件驱动：Netty基于事件驱动编程模型，通过异步方式处理网络请求，避免了阻塞IO带来的性能问题。
基于NIO：Netty基于Java的NIO（非阻塞IO）库开发，能够高效地处理大量并发连接。
简化开发：Netty提供了一套丰富的API和工具类，使得开发者可以更加专注于业务逻辑的实现，而无需深入了解底层网络协议和IO处理的细节。
可扩展性强：Netty的设计采用了模块化结构，各个模块之间耦合度低，可以根据需要灵活地扩展和定制。
社区活跃：Netty拥有庞大的开发者社区，不断有新的功能和优化被加入到框架中，为开发者提供了强有力的支持。

使用netty创建一个服务器：
import io.netty.bootstrap.ServerBootstrap;  
import io.netty.channel.ChannelFuture;  
import io.netty.channel.ChannelInitializer;  
import io.netty.channel.ChannelOption;  
import io.netty.channel.EventLoopGroup;  
import io.netty.channel.nio.NioEventLoopGroup;  
import io.netty.channel.socket.SocketChannel;  
import io.netty.channel.socket.nio.NioServerSocketChannel;  
import io.netty.handler.logging.LogLevel;  
import io.netty.handler.logging.LoggingHandler;  
  
public class ServerBootstrap {  
    public static void main(String[] args) throws Exception {  
        EventLoopGroup bossGroup = new NioEventLoopGroup(1);  
        EventLoopGroup workerGroup = new NioEventLoopGroup();  
        try {  
            ServerBootstrap bootstrap = new ServerBootstrap();  
            bootstrap.group(bossGroup, workerGroup)  
                     .channel(NioServerSocketChannel.class)  
                     .option(ChannelOption.SO_BACKLOG, 128)  
                     .childOption(ChannelOption.SO_KEEPALIVE, true)  
                     .handler(new LoggingHandler(LogLevel.INFO))  
                     .childHandler(new ChannelInitializer<SocketChannel>() {  
                         @Override  
                         public void initChannel(SocketChannel ch) throws Exception {  
                             ch.pipeline().addLast(new ServerHandler());  
                         }  
                     });  
            ChannelFuture future = bootstrap.bind(8080).sync();  
            future.channel().closeFuture().sync();  
        } finally {  
            bossGroup.shutdownGracefully();  
            workerGroup.shutdownGracefully();  
        }  
    }  
}

使用netty创建客户端：
使用netty创建客户端引导程序
import io.netty.bootstrap.Bootstrap;  
import io.netty.channel.ChannelFuture;  
import io.netty.channel.ChannelInitializer;  
import io.netty.channel.ChannelOption;  
import io.netty.channel.EventLoopGroup;  
import io.netty.channel.nio.NioEventLoopGroup;  
import io.netty.channel.socket.SocketChannel;  
import io.netty.channel.socket.nio.NioSocketChannel;  
import io.netty.handler.logging.LogLevel;  
import io.netty.handler.logging.LoggingHandler;  
  
public class ClientBootstrap {  
    public static void main(String[] args) throws Exception {  
        EventLoopGroup group = new NioEventLoopGroup();  
        try {  
            Bootstrap bootstrap = new Bootstrap();  
            bootstrap.group(group)  
                     .channel(NioSocketChannel.class)  
                     .option(ChannelOption.SO_KEEPALIVE, true)  
                     .handler(new LoggingHandler(LogLevel.INFO))  
                     .childHandler(new ChannelInitializer<SocketChannel>() {  
                         @Override  
                         public void initChannel(SocketChannel ch) throws Exception {  
                             ch.pipeline().addLast(new ClientHandler());  
                         }  
                     });  
            ChannelFuture future = bootstrap.connect("localhost", 8080).sync();  
            future.channel().closeFuture().sync();  
        } finally {  
            group.shutdownGracefully();  
        }  
    }  
}

创建客户端处理器
import io.netty.buffer.ByteBuf;  
import io.netty.channel.ChannelHandlerContext;  
import io.netty.channel.ChannelInboundHandlerAdapter;  
import io.netty.handler.codec.http.*;  
import java.nio.charset.Charset;  
  
public class ClientHandler extends ChannelInboundHandlerAdapter {  
    @Override  
    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {  
        if (msg instanceof FullHttpResponse) {  
            FullHttpResponse response = (FullHttpResponse) msg;  
            System.out.println(response.content().toString(Charset.forName("UTF-8")));  
        } else {  
            super.channelRead(ctx, msg);  
        }  
    }  
    @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {   
        cause.printStackTrace();   
        ctx.close();   
    }   
}

关于网络传输的几个问题：
在实际生活中有哪些因素影响网络传输？

网络传输的性能和可靠性受到许多因素的影响，这些因素可以分为以下几类：

1.带宽（Bandwidth）：带宽是网络连接的最大传输速率，通常以每秒比特数（bps）或兆比特数（Mbps）来衡量。
更高的带宽意味着更快的数据传输速度。网络链路的带宽限制了数据传输的最大速度。

2.延迟（Latency）：延迟是数据从发送端到接收端所需的时间，通常以毫秒（ms）为单位。
延迟包括传播延迟（数据在物理媒体上传播的时间）和处理延迟（路由、交换和处理数据的时间）。较低的延迟通常意味着更快的响应时间。

3.丢包率（Packet Loss）：丢包率表示在数据传输过程中丢失的数据包的百分比。丢包率可能由网络拥塞、网络错误或不稳定的连接引起。
较高的丢包率会导致数据重传和性能下降。

4.拥塞（Congestion）：网络拥塞发生在网络上的数据流量超过了网络链路的容量，导致数据包延迟、丢失和排队。
拥塞可能由网络流量突增、恶意攻击或网络配置问题引起。

5.路由路径（Routing Path）：数据包在网络中的路由路径也会影响传输性能。不同的路由路径可能具有不同的延迟和丢包率。优化的路由路径可以提高性能。

6.网络设备和中间节点（Network Devices and Intermediate Nodes）：网络中的路由器、交换机和防火墙等设备以及它们的配置也会影响传输性能。
设备的性能、带宽和负载均衡策略都会对网络传输产生影响。

7.带宽共享（Bandwidth Sharing）：在共享网络环境中，多个用户或应用程序共享带宽。
网络传输的性能可能受到其他用户或应用程序的使用情况影响，特别是在拥挤的时候。

8.网络拓扑（Network Topology）：网络拓扑指网络中的设备和连接的物理和逻辑布局。
不同的拓扑结构可能导致不同的性能特点，如星型、总线型、环型、网状型等。

9.网络协议和编码（Network Protocols and Encoding）：使用的网络协议和数据编码方式也会影响传输性能。
一些协议和编码方式可能会增加数据包头部大小或引入额外的开销。

10.网络安全（Network Security）：安全策略、防火墙、加密和身份验证等安全机制可能会引入额外的延迟和处理时间，影响网络传输性能。

11.地理位置和距离（Geographical Location and Distance）：物理距离和地理位置对网络延迟和带宽有影响。
数据传输跨越较长的地理距离可能导致较高的延迟。

12.网络流量管理（Traffic Management）：流量管理策略、QoS（Quality of Service）配置和流量限制也可以影响网络传输的性能。

综上所述，网络传输性能受到多种因素的综合影响，包括带宽、延迟、丢包率、拥塞、路由路径、网络设备、带宽共享、网络拓扑、协议、安全性等。了解这些因素并采取相应的优化措施是确保网络传输在实际生活中高效和可靠的关键。


为什么Java比其他语言更适合开发Web应用程序？
Java比其他语言更适合开发Web应用程序的原因如下：

1.跨平台性。Java由于其跨平台的特点，可以在多种操作系统上运行，这使得Java在服务器端程序中占据了主导地位。
2.面向对象。Java是一种面向对象编程语言，具有封装、继承和多态等特性，这使得Java在编程中更易于理解和维护。
开源。Java拥有一个庞大的开源社区，提供了大量的开源框架和库，这使得Java在Web开发中具有更强的灵活性和可扩展性。
3.J2EE技术。J2EE是Java在Web开发中的一种重要技术，它提供了一组标准的技术和API，如Servlet、JSP和EJB等，
使得开发者可以轻松地构建出高性能、可扩展、可维护且安全的企业级应用程序。
4.高度安全。Java具有某些内置的安全功能，例如密码学、高级身份验证和访问控制，这些功能在很大程度上促成了Java开发服务的蓬勃发展。
5.可扩展性和多线程。Java是高度可扩展的，可以适应Web应用程序的需求，并为开发人员提供水平和垂直扩展的能力。
此外，Java的NIO（非阻塞I/O）API促进了在软件的单个副本中创建尽可能多的线程，这极大地提高了应用程序的性能。

为什么Java不是纯面向对象？
Java 是一种广泛使用的编程语言，它确实具有许多面向对象的特性，如类、对象、继承、封装和多态等。然而，Java 并不是纯面向对象的语言，原因主要有以下几点：

基本数据类型：Java 中有八种基本数据类型（如 int、float、char 等），这些基本数据类型不是对象。虽然 Java 为这些基本数据类型提供了对应的包装类（如 Integer、Float、Character 等），但在某些情况下，为了性能考虑，程序员仍然会直接使用基本数据类型。
静态成员和方法：Java 中的静态成员（包括静态变量和静态方法）并不属于任何对象实例，而是属于类本身。静态成员和方法可以通过类名直接访问，而不需要创建类的实例。这种特性与面向对象的封装和实例化的概念不完全一致。
单例模式：单例模式是一种设计模式，它保证一个类仅有一个实例，并提供一个全局访问点。在某些情况下，为了实现单例模式，需要使用静态成员和方法。这同样与面向对象的多实例、多态等特性不完全吻合。
原始类型数组：Java 中的数组实际上是原始类型，而不是对象。虽然数组可以包含对象，但数组本身并不是对象。这意味着数组没有继承自任何类，也没有实现任何接口。
主类和主方法：Java 程序从主类（包含 main 方法的类）开始执行。这个主方法是静态的，它不属于任何对象实例。这也是 Java 与纯面向对象语言的一个不同之处。

虽然 Java 不是纯面向对象的语言，但它的面向对象特性仍然非常强大和灵活。Java 通过类和对象的概念，以及封装、继承和多态等机制，为程序员提供了一种高效、可维护的方式来构建复杂的应用程序。
同时，Java 也提供了一些非面向对象的特性，以满足特定场景下的需求。这种折衷使得 Java 在实际应用中既具有面向对象的优势，又具有一定的灵活性。

J2EE应用程序开发技术：
前端技术：
在线帮助文档 https://www.w3school.com.cn/
HTML：(主要用于网页主体结构的搭建)
HTML 指的是超文本标记语言: HyperText Markup Language
HTML（HyperText Markup Language），全称超文本标记语言，是一种用于创建网页的标准标记语言。
它通过一系列标签将网络上的文档格式统一，使得分散的Internet资源能够连接成一个逻辑整体。
这些标签不仅可以描述文字，还可以描述图形、动画、声音、表格、链接等网页元素。

HTML文本由HTML命令组成，这些命令用于说明网页中的各种元素。一个HTML文档通常包括头部（Head）和主体（Body）两大部分。
头部描述浏览器所需的信息，如文档的标题、字符集、样式表链接等；主体则包含所要说明的具体内容，如段落、列表、图片、链接等。

HTML标签结构：
双标签：例<p></p>
单标签: 例</p>
属性: 例<a href = "http://www.xxx.com"/> 中，href = "http://www.xxx.com"是属性，href是属性名，"http://www.xxx.com"是属性值
文本：例<p>段落</p> 中，双标签中的文字
元素：开始标签+属性+文本 +结束标签，称之为一个元素

在Java Web中，.html文件通常放在服务器上。当用户通过浏览器访问Web应用时，服务器会响应请求并发送相应的.html文件给客户端（即用户的浏览器）。浏览器接收并解析这些.html文件，然后展示给用户。

HTML常用标签：
<!DOCTYPE html> 声明为 HTML5 文档
<html> 元素是 HTML 页面的根元素
<head> 元素包含了文档的元（meta）数据，如 <meta charset="utf-8"> 定义网页编码格式为 utf-8（由于在大部分浏览器中直接输出中文会出现乱码，所以要在头部将字符声明为UTF-8）
<title> 元素描述了文档的标题
<body> 元素包含了可见的页面内容
<h1> 元素定义一个大标题
<p> 元素定义一个段落

问：HTML语言比Java、python等语言语法都不严格，是因为浏览器的编译强大吗？
答：HTML语言（HyperText Markup Language，超文本标记语言）与Java、Python等编程语言在设计和用途上存在本质的区别，这导致了它们在语法严格性上的差异。
因此，不能简单地将HTML的语法不严格归因于浏览器的编译强大。

首先，HTML是一种标记语言，主要用于创建网页和网站结构。它的语法相对简单和直观，旨在允许开发人员通过标记（tags）来定义网页内容的结构和样式。
HTML的主要目的是让内容在浏览器中正确地显示，而不是执行复杂的逻辑或计算任务。

相比之下，Java和Python是编程语言，它们具有更复杂的语法和更强大的功能。这些语言允许开发人员编写复杂的程序，
包括算法、数据处理、系统操作等。因此，它们的语法需要更加严格和精确，以确保程序的正确性和可靠性。

浏览器的编译能力确实强大，能够解析和渲染HTML、CSS和JavaScript等前端技术。
然而，浏览器的编译过程主要是将HTML和CSS等标记语言转换为可视化的网页内容，而不是执行像Java或Python那样的复杂程序逻辑。

此外，HTML的语法不严格也与其设计初衷和用途有关。HTML的目标是使内容易于阅读和编写，
同时允许开发者通过简单的标记来控制内容的呈现方式。这种简单性和直观性使得HTML成为非专业开发人员也能轻松上手的工具。

HTML语言比Java、Python等语言语法不严格的原因在于它们的设计目的和用途不同，而不是因为浏览器的编译强大。
每种语言都有其适用的场景和优势，选择使用哪种语言取决于具体的开发需求和目标。

CSS：（主要用于页面元素美化）Cascading Style Sheet 层叠样式表
是一组样式设置的规则，用于控制页面的外观样式

CSS语法：
<head>
	<style>
		选择器{
			属性名：属性值;
			属性名：属性值;
		}
	</style>
</head>

CSS的引入方式：
方式1 行内式
>通过元素的style属性引入样式
>语法:style="样式名:样式值;样式名:样式值;... ..
>缺点:1 代码复用度低 不利于维护
     2 css样式代码和htm1结构代码交织在一起,影响阅读,影响文件大小,影响性能
方式2内嵌式
>通过在head标签中的style标签定义本页面的公共样式
>通过选择器确定样式的作用元素
方式3外部样式表
>将css代码单独放入一个.css文件中,哪个html需要这些代码就在head中通过link标签引入
<link href="路径名" rel="stylesheet">

CSS选择器：
    1 元素选择器 根据标签的名字确定样式的作用元素
        语法:标签名1
        缺点:某些同名的元素不希望使用某些样式,某些不同名的元素也使用该样式,都无法协调
    2 id选择器   根据标签的id值确定样式的作用元素。
                一般每个元素都有id属性,但是在一个页面中,id的值不应该相同,id具有唯一性
        语法: #id值{}
        缺点: id值有唯一性,样式只能作用到一个元素上
    3 class选择器 根据元素的class属性值确定样式的作用元素
        元素的class属性值可以重复 而且一个元素的class属性可以有多个值
        语法: .class属性值{}


    <!--元素选择器-->
    <style>
            input{
            width: 60px;
            height: 40px;
            background-color:rgb(166,232,66);
            color:white;
            font-size:22px;
            font-family:'隶书';
            border:2px solid green;
            border-radius:5px;
        }
    </style>
    
    <!--id选择器-->
    <style>    
    #btn4{
        width: 60px;
        height: 40px;
        background-color:rgb(166,232,66);
        color:white;
        font-size:22px;
        font-family:'隶书';
        border:2px solid green;
        border-radius:5px;
        }
    </style>

    <!--class选择器-->
    <style>
        .shapeClass{
            width: 80px;
            height: 40px;
            border-radius:5px;
        }


        .colorClass{
            background-color:rgb(179，241，85);
            color:white;
            border: 3px solid green;
        }


        .fontclass{
            font-size: 20px;
            font-family:'隶书';
            line-height: 30px;
        }
    </style>

CSS的定位方式：
position:
    static 默认
    absolute 绝对
    relative 相对 相对元素原本的位置
    fixed 相对 相对浏览器窗口

CSS的盒子模型：
CSS的盒子模型是CSS布局的基础，它规定了元素框处理元素内容、内边距、边框和外边距的方式。每个HTML元素都可以看作是由内容、内边距（padding）、边框（border）和外边距（margin）组成的矩形盒子。

内容（Content）：这是盒子模型的中心，它包含了元素的文本、图片或其他媒体内容。内容的大小可以通过 width 和 height 属性来设置。

内边距（Padding）：内边距是内容与边框之间的空间。它位于内容区域的周围，是透明的，不会占用实际的空间，但会影响元素的总大小。
内边距的大小可以通过 padding 属性来设置，例如 padding-top、padding-right、padding-bottom 和 padding-left。

边框（Border）：边框是围绕在内边距和内容周围的线。它的大小和样式可以通过 border 属性来设置。
例如，border-width 设置边框的宽度，border-style 设置边框的样式（如实线、虚线等），border-color 设置边框的颜色。

外边距（Margin）：外边距是边框与其他元素之间的空间。它位于边框的外部，是透明的，不会占用实际的空间，但会影响元素在布局中的位置。
外边距的大小可以通过 margin 属性来设置，例如 margin-top、margin-right、margin-bottom 和 margin-left。

盒子模型的总宽度和总高度可以通过以下公式计算：
总宽度 = 左外边距 + 左边框 + 左内边距 + 内容宽度 + 右内边距 + 右边框 + 右外边距
总高度 = 上外边距 + 上边框 + 上内边距 + 内容高度 + 下内边距 + 下边框 + 下外边距

其中，padding和margin不限定padding/margin - xx 时有默认值，例如margin 10px 20 px 30 px 40 px这四个值按照顺时针方向（上、右、下、左）指定了元素的外边距。
这种简写方式使得你可以在一个属性中一次性设置四个方向的外边距，提高了编写CSS的效率。

JavaScript：（主要用于页面元素的动态处理）JavaScript诞生于1995年，它的出现主要是用于处理网页中的前端验证。
所谓的前端验证，就是指检查用户输入的内容是否符合一定的规则。比如：用户名的长度，密码的长度，邮箱的格式等。

    <!--方式一-->
    <script>
        function suprise(){
        //弹窗提示
        alert("hello·我是惊喜")
        }
    </script>

    <!--方式二，外部引入-->
    <script src="JS/buttom.js" type="text/javascript"></script>

注意:
·一个htm1中可以有多个script标签
·一对script标签不能在引入外部is文件的同时定义内部脚本
·script标签如果用于引入外部is文件,中间最好不要有任何字符。包括空格和换行。
·script标签写成双标签，不要写成单标签。
·引用JS函数的时候要加上括号

JS的引用类型是弱引用类型，变量在声明时不指定类型，赋值时才确定类型。声明变量使用var。
例：var i = 10

JS中使用var声明变量的特点:
1.弱类型变量,可以统一声明成var
2.var声明的变量可以再次声明
3.变量可以使用不同的数据类型多次赋值
4.Js的语句可以以;结尾,也可以不用;结尾
5.变量标识符严格区分大小写
6.标识符的命名规则参照JAVA
7.如果使用了 一个没有声明的变量,那么运行时会报uncaught ReferenceError:***is not defined
8.如果一个变量只声明,没赋值,那么值是undefined

JS中foreach的语法：
for(var index in var){
    console.log(index)
}

函数声明的语法
1 function 函数名(){}
2 var 函数名=function(){}

和java相比有如下特点
1 没有访问修饰符
2 没有返回值类型也没有void 如果有值要返回,则直接return即可
3 没有异常列表
4 调用方法时,实参和形参可以在数量上不一致,在方法内部可以通过 arguments获得调用时的实参
5 函数也可以作为参数传递给另一个方法

JS创建对象：
person =var"name":“李四”,
age":10,
eat":function(food){console.log(this.age+"岁"+this.name+"正在吃"+food)
// 访问属性
console.log(person.name
console.log(person.age)
// 调用方法
person.eat("火锅”)

JS事件：
在JavaScript中，事件是用户或浏览器本身的某种行为，通常是由用户对页面的某些动作引起的，如单击某个链接或按钮、在文本框中输入文本、按下键盘上的某个按键、移动鼠标等。
当这些事件发生时，可以使用JavaScript中的事件处理程序（也称为事件监听器）来检测并执行特定的代码。

以下是一些常见的JavaScript事件：

点击事件：
onclick: 当用户点击某个元素时触发。
ondblclick: 当用户双击某个元素时触发。

焦点事件：
onblur: 当元素失去焦点时触发（例如，用户点击了页面上的另一个元素）。
onfocus: 当元素获得焦点时触发（例如，用户点击了输入框）。

加载事件：
onload: 当页面或某个资源（如图像）完成加载时触发。

鼠标事件：
onmousedown: 当鼠标按钮被按下时触发。
onmouseup: 当鼠标按钮被释放时触发。
onmousemove: 当鼠标在元素内部移动时触发。
onmouseover: 当鼠标指针移入某个元素上方时触发。
onmouseout: 当鼠标指针移出某个元素时触发。

键盘事件：
onkeydown: 当某个键盘按键被按下时触发。
onkeyup: 当某个键盘按键被释放时触发。
onkeypress: 当某个键盘按键被按下并释放时触发。

选择和改变事件：
onchange: 当表单元素（如<input>、<textarea>或<select>）的内容发生变化时触发。
onselect: 当文本被用户选中时触发。

表单事件：
onsubmit: 当表单的提交按钮被点击，或用户尝试提交表单时触发。
onreset: 当表单的重置按钮被点击时触发，或者表单通过代码重置时触发。

拖拽事件：
ondragstart: 当用户开始拖拽某个元素时触发。
ondragover: 当被拖拽的元素在目标元素上移动时触发。
ondrop: 当拖拽的元素在目标位置放下时触发。

触摸事件（针对移动设备）：
ontouchstart: 当用户开始触摸某个元素时触发。
ontouchmove: 当用户在某个元素上移动手指时触发。
ontouchend: 当用户停止触摸某个元素时触发。

滚动事件：
onscroll: 当用户滚动页面或某个元素时触发。

窗口大小变化事件：
onresize: 当浏览器窗口的大小变化时触发。

这只是JavaScript中事件的一小部分，实际上还有更多的事件类型，它们可以用于实现各种交互效果和响应用户动作。在编写JavaScript代码时，可以根据需要监听和处理这些事件。

BOM：
BOM编程涉及到浏览器对象模型（Browser Object Model）的概念，它使JavaScript有能力与浏览器进行交互。
BOM提供了一系列独立于内容的对象，允许开发者通过JavaScript操作浏览器窗口和框架等浏览器相关的对象。
BOM的核心对象是window，它是浏览器的顶级对象，具有双重角色：一方面，它是JS访问浏览器窗口的一个接口；
另一方面，它是一个全局对象，定义在全局作用域中的变量、函数都会变成window对象的属性和方法。

BOM（Browser Object Model，浏览器对象模型）的Windows API 提供了一系列函数和方法，用于操作和控制浏览器窗口及其组件。以下是一些常用的BOM Windows API：

window.alert()：显示一个带有指定消息和OK按钮的警告框。
window.confirm()：显示一个带有指定消息以及确定和取消按钮的对话框，并返回用户的选择（true或false）。
window.prompt()：显示一个对话框，提示用户输入一些文本（可带一个默认值），并返回用户输入的文本。
window.open()：打开一个新的浏览器窗口或查找一个已命名的窗口，并返回代表该窗口的Window对象。
window.close()：关闭当前窗口。
window.moveTo() 和 window.resizeTo()：移动和改变当前窗口的位置和大小。
window.scrollTo() 和 window.scrollBy()：滚动当前窗口到指定位置或滚动特定距离。
window.focus() 和 window.blur()：将焦点设置到当前窗口或使当前窗口失去焦点。
window.innerWidth 和 window.innerHeight：获取浏览器窗口的视口（viewport）宽度和高度（不包括工具栏和滚动条）。
window.location：包含有关当前URL的信息，并提供了一些方法和属性，用于获取或设置URL，以及重新加载页面。

DOM概述：
D0M(Document obiect Model)编程就是使用document对象的API完成对网页HTML文档进行动态修改,以实现,网页数据和样式动态变化效果的编程。

通过DOM对象模型，JavaScript 获得创建动态 HTML ：

JavaScript 能改变页面中的所有 HTML 元素
JavaScript 能改变页面中的所有 HTML 属性
JavaScript 能改变页面中的所有 CSS 样式
JavaScript 能删除已有的 HTML 元素和属性
JavaScript 能添加新的 HTML 元素和属性
JavaScript 能对页面中所有已有的 HTML 事件作出反应
JavaScript 能在页面中创建新的 HTML 事件
换言之：HTML DOM 是关于如何获取、更改、添加或删除 HTML 元素的标准。

DOM编程获取元素：
<div id="div01">
<input type="text" class="a" id="username name= aaa"/>
<input type="text" class="b" id="password" name="aaa"/>
<input type="text" class="a" id="email"/>
<input type="text" class="b" id="address"/>
</div>

<input type="text" class="a"/><br>
<input type="button" value="根据id获取指定元素" onclick="fun1()" id="btn01"/>
<input type="button" value="根据标签名获取多个元素"onclick="fun2()" id="btn02"/>
<input type="button" value="根据name属性值获取多个元素"onclick="fun3()"id="btn03"/>
<input type="button" value="根据class属性值获得多个元素" onclick="fun4()" id="btn04"/>
<input type="button" value="根据父元素获取子元素" onclick="fun5()" id="btn05"/>
<input type="button" value="根据子元素获取父元素" onclick="fun6()" id="btn06"/>
<input type="button" value="根据子元素获取兄弟元素" onclick="fun7()" id="btn07"/>

function fun1(){
//1 获得document
//2 通过document获得元素
var el1 =document.getElementById("username")//根据元素的id值获取页面上唯一的一个元素
console.log(el1)
}
function fun2(){
    var els =document.getElementsByTagName("input")//根据元素的标签名获取多个同名元素
    for(var i=0 ;i<els.length;i++){
        console.log(els[i])
    }
}

function fun3(){
    var els =document.getElementsByName("aaa")// 根据元素的name属性值获得多个元素
    console.log(els)
    for(var i =0;i< els.length;i++){
        console.log(els[i])
    }
}

function fun4(){
    var els =document.getElementsByClassName("a")//根据元素的class属性值获得多个元素
    for(var i =0;i< els.length;i++){
        console.log(els[i])
    }
}

function fun5(){
    // 先获取父元素
    var div01= document.getElementById("div01")// 获取所有子元素
    var cs=div01.children // 通过父元素获取全部的子元素
    for(var i =0;i< cs.length;i++){
    console.log(cs[i])
    }
    console.log(div01.firstElementChild)// 通过父元素获取第一个子元素
    console.log(div01.lastElementchild)// 通过父元素获取最后一个子元素
}

function fun6(){
    // 获取子元素
    var pinput =document.getElementById("password")
    console.log(pinput.parentElement)//通过子元素获取父元素
}

function fun7(){
    // 获取子元素
    var pinput =document.getElementById("password")
    console.log(pinput.previousElementsibling)// 获取前面的第一个元素
    console.log(pinput.nextElementsibling)//获取后面的第一个元素
}

Json：
JavaScript Object Notation（JavaScript 对象标记法），它是一种存储和交换数据的语法。
当数据在浏览器与服务器之间进行交换时，这些数据只能是文本，JSON 属于文本并且我们能够把任何 JavaScript 对象转换为 Json，然后将 Json 发送到服务器。
我们也能把从服务器接收到的任何 Json 转换为 JavaScript 对象。以这样的方式，我们能够把数据作为 JavaScript 对象来处理，无需复杂的解析和转译。

Json语法：
在json中，每一个数据项，都是由一个键值对（或者说是名值对）组成的，但是键必须是字符串，
且由双引号包围，而值必须是以下数据类型之一：

字符串（在 Json 中，字符串值必须由双引号编写）
数字
对象（Json 对象）
数组
布尔
null

数组（Array）用方括号(“[]”)表示。对象也可以是一个数组。
例：[1,2,"three","four",true,false,null,[1,2],{"name":"兮动人"}]

对象（0bject）用大括号(“{}”)表示。
例：{"name": "兮动人","age":22}

名称/值对(name/value）组合成数组和对象。
>名称(name）置于双引号中，值（value）有字符串、数值、布尔值、null、对象和数组。
>并列的数据之间用逗号(“,”）分隔

Josn 的值不可以是以下数据类型之一：
函数
日期
undefined

Json字符串转换为JS对象：
JSON.parse()

JS对象转换为JSON字符串：
JSON.stringify()

Json与Java对象转换-Json转换库：
GSON:
GSON是Google提供的用于在Java对象和Json数据之间进行相互转换的库，其包含的Json解析方法主要有：
toJson()：将Java对象转化为Json字符串。
fromJson()：将JSON字符串转化为Java对象。

将Java对象转化为Json字符串：
Gson g = new Gson();
book b = new book("100","金苹果","种植苹果的故事");
String s = g.toJson(b);

将Json字符串转化为Java对象：

Gson g = new Gson();
//2. 转换 {"id":"100","name":"金苹果","info":"种植苹果的故事","page":["远赴人间惊鸿晏","一度人间盛世颜","致hdd"]}
//2.1  返回book类型
book b = g.fromJson("{\"id\":\"100\",\"name\":\"金苹果\",\"info\":\"种植苹果的故事\"}", book.class);
System.out.println(b.getId());

//2.2 返回MAP类型，键值对形式
HashMap hm = g.fromJson("{\"id\":\"100\",\"name\":\"金苹果\",\"info\":\"种植苹果的故事\"}", HashMap.class);
System.out.println(hm.get("id"));

//2.3 MAP类型中值是一个数组形式
HashMap data = g.fromJson("{\"id\":\"100\",\"name\":\"金苹果\",\"info\":\"种植苹果的故事\",\"page\":[\"远赴人间惊鸿晏\",\"一度人间盛世颜\",\"致hdd\"]}", HashMap.class);
List list = (List) data.get("page");
System.out.println(list.get(1));


JWT:
JSON Web Tokens（JWT）是一种用于在网络应用中传递信息的开放标准（RFC 7519），它以紧凑且自包含的方式表示数据，
通常用于在身份验证和授权系统中进行安全传输信息。JWT 的具体作用如下：

1. **身份验证**：JWT可用于验证用户的身份。当用户登录成功后，服务器可以生成一个JWT令牌并将其返回给客户端。
客户端在后续请求中可以携带这个令牌，服务器可以使用令牌来验证用户的身份，而无需在每个请求中再次提供用户名和密码。

2. **授权**：JWT可以包含有关用户的授权信息，例如用户的角色或权限。
这使得服务器可以在接收到JWT后，轻松地确定用户是否有权限执行特定操作。

3. **信息交换**：JWT是一种方便的方式来在不同组件或微服务之间安全地传递信息。
例如，一个用户在一个身份验证服务登录后，可以生成一个JWT令牌，然后将其传递给其他服务，
这些服务可以使用令牌来验证用户身份和访问权限。

4. **状态无关性**：JWT是无状态的，令牌中包含了所有必要的信息，因此不需要在服务器上保留会话状态。
这使得 JWT 适用于分布式应用程序和负载均衡环境。

5. **跨域通信**：由于 JWT 可以在 HTTP 头或 URL 中传递，它们可以用于在不同域之间进行通信。
这对于单点登录（Single Sign-On，SSO）等应用程序非常有用。

6. **安全性**：JWT使用数字签名或加密来验证令牌的完整性和真实性。
这意味着只有拥有正确密钥的人才能生成有效的令牌，从而防止伪造令牌。

JWT通常由三部分组成：

- **Header（头部）**：包含了令牌类型和所用的签名算法等信息。
- **Payload（负载）**：包含了要传输的数据，如用户ID、过期时间、授权信息等。
- **Signature（签名）**：用于验证令牌的真实性。通常由头部和负载中的信息以及密钥生成。

创建一个JWT：
package boot.utils;
import io.jsonwebtoken.Jwts;
import io.jsonwebtoken.SignatureAlgorithm;
import io.jsonwebtoken.security.Keys;
import java.security.Key;
import java.util.Date;
public class JWTUtils {

    private static final String SECRET_KEY = "secret_key";

    public String JwtTokenGenerator (long userId){

            // 当前时间
            Date now = new Date();

            // 过期时间，设置为5小时后
            Date expiration = new Date(now.getTime() + 5 * 60 * 60 * 1000);

            // 创建JWT
            String jwt = Jwts.builder()
                    .setSubject(Long.toString(userId))  // 设置用户ID作为JWT的主题
                    .setIssuedAt(now)  // 设置JWT的发行时间
                    .setExpiration(expiration)  // 设置JWT的过期时间
                    .signWith(SignatureAlgorithm.HS256,SECRET_KEY)  // 使用密钥签名JWT
                    .compact();

            return jwt;

    }

    public String getUsernameFromToken(String token) {
        return Jwts.parser()
                .setSigningKey(SECRET_KEY)
                .parseClaimsJws(token)
                .getBody()
                .getSubject();
    }

    public boolean validateToken(String token, String userName) {
        String username = getUsernameFromToken(token);
        return username.equals(userName);
    }

}

FastJson：
FastJson是阿里巴巴公司基于Java语言开发的高性能且功能完善的Json操作类库。
Fastjson可以解析Json格式的字符串，支持将Java Bean序列化为Json字符串，也可以从Json字符串反序列化到JavaBean。


将Java对象转化为Json字符串：
book b = new book("1002","水浒传","讲述了一群讲义气的莽夫");
String s = JSON.toJSONString(b);


将Json字符串转化为Java对象：

book b = new book("1002","水浒传","讲述了一群讲义气的莽夫");

//1. 转换 {"id":"1002","info":"讲述了一群讲义气的莽夫","name":"水浒传"}   转换成对象
book books = JSON.parseObject("{\"id\":\"1002\",\"info\":\"讲述了一群讲义气的莽夫\",\"name\":\"水浒传\"}", book.class);
System.out.println(books.getName());

//2. 转换成数组 ["人生本该自由","乘兴而去","尽兴而归"]
List<String> strings = JSON.parseArray("[\"人生本该自由\",\"乘兴而去\",\"尽兴而归\"]", String.class);
for(String s:strings){
    System.out.println(s);
}

Json与JS对象之间的互相转换：
Json字符串转换为JS对象：
<script>
	var str = '{"name": "兮动人","age":22}';
	var obj = JSON.parse(str);
	console.log(obj);
</script>


JS对象转换为Json字符串：
<script>
	var str = '{"name": "兮动人","age":22}';
	var obj = JSON.parse(str);
	console.log(obj);
        
	var jsonstr = JSON.stringify(obj);
	console.log(jsonstr);
</script>


AJAX：
传统的web交互是用户触发一个http请求服务器，然后服务器收到之后，在做出响应到用户，并且返回一个新的页面，
每当服务器处理客户端提交的请求时，客户都只能空闲等待，并且哪怕只是一次很小的交互、
只需从服务器端得到很简单的一个数据，都要返回一个完整的HTML页，而用户每次都要浪费时间和带宽去重新读取整个页面。
这个做法浪费了许多带宽，由于每次应用的交互都需要向服务器发送请求，应用的响应时间就依赖于服务器的响应时间，
这导致了用户界面的响应比本地应用慢得多。

AJAX 的出现,刚好解决了传统方法的缺陷，AJAX 是一种用于创建快速动态网页的技术，通过在后台与服务器进行少量数据交换，
AJAX 可以使网页实现异步更新，这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。

AJAX的XMLHttpRequest对象：
AJAX 的核心是 XMLHttpRequest 对象。 所有现代浏览器都支持 XMLHttpRequest 对象。
XMLHttpRequest 对象用于幕后同服务器交换数据，这意味着可以更新网页的部分，而不需要重新加载整个页面。
所有现代浏览器（Chrom、IE7+、Firefox、Safari 以及 Opera）都有内建的 XMLHttpRequest 对象。

创建 XMLHttpRequest 的语法是：
variable = new XMLHttpRequest();

为了应对所有浏览器，包括 IE5 和 IE6，请检查浏览器是否支持 XMLHttpRequest 对象。
如果支持，创建 XMLHttpRequest 对象，如果不支持，则创建 ActiveX 对象：
var xhttp;
if (window.XMLHttpRequest) {
    xhttp = new XMLHttpRequest();
} else {
    // code for IE6, IE5
    xhttp = new ActiveXObject("Microsoft.XMLHTTP");
}

AJAX的请求整合：
JSON：
[
  {"name":"孙悟空","age":18,"gender":"男"},
  {"name":"猪八戒","age":19,"gender":"男"},
  {"name":"唐僧","age":20,"gender":"男"},
  {"name":"沙和尚","age":21,"gender":"男"}
]

index.html:
var Ajax = {
    get: function (url, fn) {
        var xhr = new XMLHttpRequest();
        xhr.open('GET', url, true);
        xhr.onreadystatechange = function () {
            if (xhr.readyState == 4 && xhr.status == 200 || xhr.status == 304) {
                fn.call(this, xhr.responseText);
            }
        };
        xhr.send();
    },
    post: function (url, data, fn) {
        var xhr = new XMLHttpRequest();
        xhr.open("POST", url, true);
        xhr.setRequestHeader("Content-Type", "application/x-www-form-urlencoded");
        xhr.onreadystatechange = function () {
            if (xhr.readyState == 4 && (xhr.status == 200 || xhr.status == 304)) {
                fn.call(this, xhr.responseText);
            }
        };
        xhr.send(data);
    }
};

// 演示GET请求
Ajax.get("users.json", function (response) {
    console.log(response);
});

// 演示POST请求
Ajax.post("users.json", "", function (response) {
    console.log(response);
});

Cookie:
Cookie 是一些数据，存储于你电脑上的文本文件中，当 web 服务器向浏览器发送 web 页面时，在连接关闭后，服务端不会记录用户的信息，Cookie 的作用就是用于解决 “如何记录客户端的用户信息”：

当用户访问 web 页面时，它的名字可以记录在 cookie 中。在用户下一次访问该页面时，可以在 cookie 中读取用户访问记录。

一个的Cookie创建，添加了过期时间和路径：
document.cookie = "username=zhangsan; expires=Thu, 18 Dec 2043 12:00:00 GMT; path=/";

当我们请求某个URL路径时，浏览器会根据这个URL路径将符合条件的Cookie放在Request请求头中传回给服务端，服务端通过request.getCookies()来获取所有Cookie。
Cookie是HTTP头中的一个字段，虽然HTTP本身对这个字段并没有多少限制，但是Cookie最终函数存储在浏览器里，所以不同的浏览器对Cookie的存储都有一些限制。


Session：
Session是在服务器端存储的用于跟踪用户状态的机制。

Session和Cookie的区别如下：

存储位置不同：Cookie保存在客户端浏览器中，而Session保存在服务器上。
安全性不同：由于Cookie存储在客户端，所以安全性相对较低，例如用户可以编辑或伪造Cookie信息。而Session存储在服务器上，相对较安全。
有效期不同：Cookie的有效期一般为会话期间，当关闭浏览器窗口后，Cookie就会消失。而Session一般会在一定时间内保存在服务器上，当访问增多，会占用服务器性能。


使用Session可以解决表单重复提交问题，其基本思想是在服务器端使用Session来记录用户提交表单的状态。
当用户提交表单时，将表单的提交状态存储在Session中，同时将表单的提交按钮禁用，防止用户多次点击提交按钮。
当表单处理完成后，将Session中的表单提交状态清除，并启用提交按钮，以便用户下一次提交表单。

下面是一个使用Session解决表单重复提交问题的示例代码：

<%@ page language="java" contentType="text/html; charset=UTF-8"
    pageEncoding="UTF-8"%>
<%@ page import="java.util.*" %>
<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Form Submit</title>
</head>
<body>
<%
  // 初始化Session中的表单提交状态为false
  if(session.getAttribute("submitStatus") == null) {
    session.setAttribute("submitStatus", false);
  }

  // 如果表单已经提交过，则显示相应的提示信息并禁用提交按钮
  if(session.getAttribute("submitStatus") == true) {
    out.println("表单已经提交过了，请等待处理完成！");
    // 将提交按钮禁用
    request.setAttribute("submitButton", "disabled");
  } else {
    // 如果表单未提交过，则处理表单数据并启用提交按钮
    String name = request.getParameter("name");
    String email = request.getParameter("email");
    // 处理表单数据，例如插入到数据库中
    // ...

    // 将表单提交状态存储在Session中并启用提交按钮
    session.setAttribute("submitStatus", true);
    // 将提交按钮启用
    request.setAttribute("submitButton", "");
  }
%>
<form action="" method="post">
  <label for="name">姓名：</label><br>
  <input type="text" name="name"><br>
  <label for="email">邮箱：</label><br>
  <input type="text" name="email"><br>
  <!-- 根据需要添加其他表单项 -->
  <input type="submit" value="提交" name="submitButton"
      style="disabled:;<?php echo $submitButton; ?>;">
</form>
</body>
</html>
在该示例代码中，当用户第一次提交表单时，将表单的提交状态存储在Session中，同时将表单的提交按钮禁用。当表单处理完成后，将Session中的表单提交状态清除，并启用提交按钮。这样就可以防止用户多次点击提交按钮，解决表单重复提交问题。

在会话管理中，域对象是指可以在不同的组件（如Servlet、JSP等）之间进行数据传递与共享的对象。这些对象在Web应用程序中起到了至关重要的作用，使得数据能够在不同的请求、响应以及页面之间流通。根据不同的作用范围，域对象可以分为以下几种：

请求域对象（Request Scope）：
生命周期：始于客户端的请求到达服务器，终于服务器对这次请求做出响应并返回给客户端。
作用范围：只在一个请求的生命周期内有效。
用途：主要用于存储与单个请求相关的数据，如从表单中获取的用户输入。

会话域对象（Session Scope）：
生命周期：始于用户第一次访问应用程序并创建会话，终于用户关闭浏览器或会话超时。
作用范围：跨多个请求有效，只要用户会话还在，数据就保持可用。
用途：常用于存储用户的个人信息、购物车内容等需要在多个页面间共享的数据。

应用程序域对象（Application Scope）：
生命周期：始于Web应用程序启动，终于Web应用程序关闭。
作用范围：在整个Web应用程序中都有效，所有用户共享这些数据。
用途：用于存储整个应用程序级别的信息，如配置参数、全局计数器等。

页面域对象（Page Scope）：
生命周期：始于JSP页面被请求，终于JSP页面执行完毕并将响应发送回客户端。
作用范围：仅在当前JSP页面中有效。
用途：主要用于存储与单个JSP页面相关的数据。


如何从请求域（Request Scope）、会话域（Session Scope）、应用程序域（Application Scope）和页面域（Page Scope）中获取数据的示例：

请求域对象（Request Scope）
在Servlet中设置属性到请求域：

protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {  
    String data = "This is request scope data";  
    request.setAttribute("requestData", data);  
    // 转发请求到JSP页面  
    RequestDispatcher dispatcher = request.getRequestDispatcher("result.jsp");  
    dispatcher.forward(request, response);  
}

在JSP页面中获取请求域中的数据：


<%@ page contentType="text/html;charset=UTF-8" language="java" %>  
<html>  
<body>  
    <p>Request Scope Data: ${requestScope.requestData}</p>  
</body>  
</html>

或者使用脚本表达式：

<p>Request Scope Data: <%= request.getAttribute("requestData") %></p>

会话域对象（Session Scope）
在Servlet中设置属性到会话域：


protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {  
    String data = "This is session scope data";  
    HttpSession session = request.getSession();  
    session.setAttribute("sessionData", data);  
    // 转发请求到JSP页面  
    RequestDispatcher dispatcher = request.getRequestDispatcher("result.jsp");  
    dispatcher.forward(request, response);  
}
在JSP页面中获取会话域中的数据：


<p>Session Scope Data: ${sessionScope.sessionData}</p>

或者使用脚本表达式：

<p>Session Scope Data: <%= session.getAttribute("sessionData") %></p>

应用程序域对象（Application Scope）

在Servlet中设置属性到应用程序域：

protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {  
    String data = "This is application scope data";  
    ServletContext context = request.getServletContext();  
    context.setAttribute("applicationData", data);  
    // 转发请求到JSP页面  
    RequestDispatcher dispatcher = request.getRequestDispatcher("result.jsp");  
    dispatcher.forward(request, response);  
}

在JSP页面中获取应用程序域中的数据：

<p>Application Scope Data: ${applicationScope.applicationData}</p>

或者使用脚本表达式：
<p>Application Scope Data: <%= getServletContext().getAttribute("applicationData") %></p>
页面域对象（Page Scope）

页面域实际上是在JSP页面中定义的局部变量，这些变量在JSP页面的生命周期内有效。它们不是通过Servlet设置的，而是在JSP页面中直接定义的。例如：

<%  
    String pageData = "This is page scope data";  
%>  
<p>Page Scope Data: <%= pageData %></p>
注意，页面域中的变量实际上是在JSP页面被转换成Servlet时定义的局部变量，所以它们并不是真正的“域对象”。在Servlet中，没有直接的API可以设置或获取页面域数据，因为页面域仅在JSP页面执行期间存在。


VUE：
Vue.js（通常简称为Vue）是一个用于构建用户界面的渐进式JavaScript框架。它旨在通过简洁的API实现响应的数据绑定和组合的视图组件。
Vue被设计为可以自底向上逐层应用，其核心库只关注视图层，不仅易于上手，也便于与第三方库或已有项目整合。

Vue的一些主要特点和概念：

响应式数据绑定：Vue通过其内置的响应式系统，可以自动追踪JavaScript对象的变化，并在数据发生变化时更新DOM。这使得开发者无需手动操作DOM来更新视图，提高了开发效率和代码的可维护性。
组件化开发：Vue允许开发者将界面拆分成独立的、可复用的组件。每个组件都包含了自己的HTML、CSS和JavaScript代码，并且可以与其他组件进行通信和交互。这种组件化的开发方式使得代码更加模块化和可维护。
模板系统：Vue使用基于HTML的模板语法来描述组件的视图结构。模板可以绑定到Vue实例的数据上，当数据发生变化时，视图会自动更新。模板系统还支持条件渲染、列表渲染和自定义指令等高级功能。
指令：Vue提供了一套内置指令（如v-if、v-for、v-bind等），用于在模板中操作DOM元素和绑定数据。这些指令可以简化常见的DOM操作，并使得模板代码更加清晰和易于理解。
插件和生态系统：Vue拥有一个活跃的插件和工具生态系统，包括路由管理、状态管理、构建工具等。这些工具和插件可以帮助开发者构建更复杂、更强大的应用程序。
轻量级和灵活性：Vue.js是一个轻量级的框架，核心库的大小相对较小，可以轻松地与其他库或现有项目集成。同时，Vue也提供了足够的灵活性，允许开发者根据项目的需求选择使用哪些功能或插件。

Vue的特点：
遵循MVVM模式
编码简洁，体积小，运行效率高，适合移动/PC端开发
它本身只关注UI，可以引入其它第三方库开发项目

与其他JS框架的关联：
借鉴 Angular 的模板和数据绑定技术
借鉴 React 的组件化和虚拟DOM技术

Vue周边库：
vue-cli：vue脚手架
vue-resource
axios
vue-router：路由
vuex：状态管理
element-ui：基于vue的UI组件库（PC端）

VUE简单实现：

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>初识vue</title>
    <!-- 引入Vue -->
    <script src="../js/vue.js"></script>
</head>
<body>
    <!-- 准备好一个容器 -->
    <div id="root">
        <h1>Hello！{{name}}!</h1>
    </div>

    <script>
        Vue.config.productionTip = false // 阻止vue在启动时生成生产提示
        new Vue({
            el:'#root', //el用于指定当前Vue实例为哪个容器服务，值通常为css选择器字符串
            data:{ //data用于存储数据，数据共el所指定的容器去使用
                name:'JOJO'
            }
        })
    </script>
</body>
</html>

注意：

想让Vue工作，就必须创建一个Vue实例，且要传入一个配置对象
root容器里的代码依然符合html规范，只不过混入了一些特殊的Vue语法
root容器里的代码被称为Vue模板
Vue实例与容器是一一对应的
真实开发中只有一个Vue实例，并且会配合着组件一起使用
{{xxx}}中的xxx要写js表达式，且xxx可以自动读取到data中的所有属性
一旦data中的数据发生变化，那么模板中用到该数据的地方也会自动更新

关于GET请求的安全性：
Get是不安全的，因为在传输过程，数据被放在请求的URL中，而如今现有的很多服务器、代理服务器或者用户代理都会将请求URL记录到日志文件中，然后放在某个地方，这样就可能会有一些隐私的信息被第三方看到。
另外，用户也可以在浏览器上直接看到提交的数据，一些系统内部消息将会一同显示在用户面前。Post的所有操作对用户来说都是不可见的。

Servlet：
Servlet（Server Applet）是Java Servlet的简称，称为小服务程序或服务连接器，用Java编写的服务器端程序，具有独立于平台和协议的特性，主要功能在于交互式地浏览和生成数据，生成动态Web内容。
狭义的Servlet是指Java语言实现的一个接口，广义的Servlet是指任何实现了这个Servlet接口的类，一般情况下，人们将Servlet理解为后者。Servlet运行于支持Java的应用服务器中。
从原理上讲，Servlet可以响应任何类型的请求，但绝大多数情况下Servlet只用来扩展基于HTTP协议的Web服务器。
最早支持Servlet标准的是JavaSoft的Java Web Server，此后，一些其它的基于Java的Web服务器开始支持标准的Servlet。

Servlet的工作原理：
Servlet接口定义了Servlet与servlet容器之间的契约。这个契约是：Servlet容器将Servlet类载入内存，并产生Servlet实例和调用它具体的方法。但是要注意的是，在一个应用程序中，每种Servlet类型只能有一个实例。

>用户请求致使Servlet容器调用Servlet的Service（）方法，并传入一个ServletRequest对象和一个ServletResponse对象。
ServletRequest对象和ServletResponse对象都是由Servlet容器（例如TomCat）封装好的，并不需要开发者去实现，开发者可以直接使用这两个对象。
>ServletRequest中封装了当前的Http请求，因此，开发人员不必解析和操作原始的Http数据。
>ServletResponse表示当前用户的Http响应，程序员只需直接操作ServletResponse对象就能把响应轻松的发回给用户。
>对于每一个应用程序，Servlet容器还会创建一个ServletContext对象。这个对象中封装了上下文（应用程序）的环境详情。
>每个应用程序只有一个ServletContext。每个Servlet对象也都有一个封装Servlet配置的ServletConfig对象。

Servlet接口中定义的方法：
public interface Servlet {
    void init(ServletConfig var1) throws ServletException;
 
    ServletConfig getServletConfig();
 
    void service(ServletRequest var1, ServletResponse var2) throws ServletException, IOException;
 
    String getServletInfo();
 
    void destroy();
}


在静态资源中的Content-type是如何体现的？
静态资源：
静态资源通常包括 HTML、CSS、JavaScript、图片、视频等文件。这些文件在服务器上通常是以文件的形式存储，并且服务器（如 Apache、Nginx）在接收到对这些资源的请求时，会直接读取并返回这些文件的内容。

对于静态资源，Content-Type 通常由服务器自动根据文件的扩展名来确定。例如，对于 .html 文件，Content-Type 通常是 text/html；
对于 .css 文件，Content-Type 是 text/css；对于 .js 文件，Content-Type 是 application/javascript；对于图片文件，如 .jpg 或 .png，Content-Type 则分别是 image/jpeg 或 image/png。

Servlet设置Content-type：
Servlet资源：
Servlet 是 Java Web 应用程序中的一部分，用于处理客户端的请求并生成动态内容。Servlet 资源不是以文件的形式存储在服务器上，而是作为 Java 类被加载和执行。
当浏览器请求一个 Servlet 时，服务器（如 Tomcat）会加载并执行相应的 Java 类，然后返回生成的内容。
由于 Servlet 生成的内容是动态的，因此 Content-Type 通常不是由文件的扩展名来确定，而是由 Servlet 代码本身来设置。

在 Servlet 中，可以通过 response.setContentType(String type) 方法来设置 Content-Type。
例如，如果 Servlet 生成的是 HTML 内容，那么可以调用 response.setContentType("text/html")；
如果生成的是 JSON 数据，那么可以调用 response.setContentType("application/json")。

使用注解@webServlet可以设置Servlet路径

ServletRequset接口:
    Servlet容器对于接受到的每一个Http请求，都会创建一个ServletRequest对象，并把这个对象传递给Servlet的Sevice( )方法。其中，ServletRequest对象内封装了关于这个请求的许多详细信息。

public interface ServletRequest {
  
 
    int getContentLength();//返回请求主体的字节数
 
    String getContentType();//返回主体的MIME类型
 
    String getParameter(String var1);//返回请求参数的值
 
}

ServletResponse接口:
    javax.servlet.ServletResponse接口表示一个Servlet响应，在调用Servlet的Service( )方法前，Servlet容器会先创建一个ServletResponse对象，并把它作为第二个参数传给Service( )方法。ServletResponse隐藏了向浏览器发送响应的复杂过程。

public interface ServletResponse {
    String getCharacterEncoding();
 
    String getContentType();
 
    ServletOutputStream getOutputStream() throws IOException;
 
    PrintWriter getWriter() throws IOException;
 
    void setCharacterEncoding(String var1);
 
    void setContentLength(int var1);
 
    void setContentType(String var1);
 
    void setBufferSize(int var1);
 
    int getBufferSize();
 
    void flushBuffer() throws IOException;
 
    void resetBuffer();
 
    boolean isCommitted();
 
    void reset();
 
    void setLocale(Locale var1);
 
    Locale getLocale();
}

在发送任何HTML之前，应该先调用setContentType（）方法，设置响应的内容类型，并将“text/html”作为一个参数传入，这是在告诉浏览器响应的内容类型为HTML，
需要以HTML的方法解释响应内容而不是普通的文本，或者也可以加上“charset=UTF-8”改变响应的编码方式以防止发生中文乱码现象。


ServletContext对象:
ServletContext对象表示Servlet应用程序。每个Web应用程序都只有一个ServletContext对象。在将一个应用程序同时部署到多个容器的分布式环境中，每台Java虚拟机上的Web应用都会有一个ServletContext对象。
有了ServletContext对象，就可以共享从应用程序中的所有资料处访问到的信息，并且可以动态注册Web对象。前者将对象保存在ServletContext中的一个内部Map中。保存在ServletContext中的对象被称作属性。

在Servlet中，ServletContext对象表示整个Web应用程序的上下文，它提供了在Web应用程序的范围内共享信息的方法。ServletContext对象在Web应用程序启动时创建，并在Web应用程序关闭时销毁。

你可以通过以下方式在Servlet中获取ServletContext对象的内容：

通过getServletContext()方法：在Servlet类中，你可以直接调用getServletContext()方法来获取ServletContext对象。
ServletContext context = getServletContext();

获取初始化参数：你可以使用ServletContext对象的getInitParameter(String name)方法来获取在web.xml文件中定义的初始化参数。
String paramValue = context.getInitParameter("paramName");

获取资源：你可以使用ServletContext对象的getResourceAsStream(String path)或getResource(String path)方法来获取Web应用程序中的资源。
InputStream inputStream = context.getResourceAsStream("/WEB-INF/config.properties");  
URL resourceURL = context.getResource("/images/logo.png");

获取属性：你可以使用ServletContext对象的getAttribute(String name)方法来获取之前通过setAttribute(String name, Object object)方法设置的属性。
Object attribute = context.getAttribute("attributeName");

获取上下文路径：你可以使用ServletContext对象的getContextPath()方法来获取Web应用程序的上下文路径。
String contextPath = context.getContextPath();

获取请求分发器：你可以使用ServletContext对象的getRequestDispatcher(String path)方法来获取一个请求分发器对象，用于将请求转发到另一个资源。
RequestDispatcher dispatcher = context.getRequestDispatcher("/someServlet");

请注意，ServletContext对象在整个Web应用程序中都是共享的，因此它通常用于存储需要在整个应用程序中访问的信息，如数据库连接、配置参数等。
但是，由于它是全局的，所以应该避免在其中存储与特定用户或请求相关的信息。

ServletConfig接口:
当Servlet容器初始化Servlet时，Servlet容器会给Servlet的init( )方式传入一个ServletConfig对象。

ServletConfig接口中定义的方法：
public String getInitParameter(String name): 此方法用于获取在 web.xml 文件中为 servlet 配置的初始化参数。这个参数名是字符串类型，返回值也是字符串类型。如果找不到给定名称的参数，此方法将返回 null。
public ServletContext getServletContext(): 此方法返回与该 servlet 关联的 ServletContext 对象。
ServletContext 对象提供了对 Servlet 环境的访问，包括请求和响应对象、会话跟踪、初始化参数、上下文路径等等。
public String getServletName(): 此方法返回 servlet 的名称，该名称在 web.xml 文件中为 servlet 定义。如果找不到 servlet 名称，此方法将返回 null。


GenericServlet抽象类：
在编写一个Servlet对象时，必须实现Servlet接口，在Servlet接口中包含5个方法，创建Servlet时必须都要实现这5个方法，这样操作非常不便。
GenericServlet类简化了此操作，实现了Servlet接口。

public void init() throws ServletException: 这个方法是在 Servlet 实例化后且在任何请求处理前被调用的。它允许 Servlet 进行任何必要的初始化。
public void service(ServletRequest request, ServletResponse response) throws ServletException, IOException: 这个方法处理来自客户端的请求，并向客户端发送响应。所有的 Servlet 请求都是由这个方法处理的。
public String getServletInfo(): 这个方法返回一个字符串，这个字符串包含了关于 servlet 的信息。
public void destroy(): 当 servlet 不再需要时，这个方法被调用。它允许 Servlet 进行任何必要的清理活动，例如释放资源。
此外，GenericServlet 还覆盖了 Servlet 接口中的一些方法，包括 getInitParameter(String name) 和 getServletContext()，它们在 GenericServlet 中的实现与在 Servlet 接口中的定义是相同的。

注意，虽然 GenericServlet 实现了大部分 Servlet 接口的方法，但是它并没有实现所有的方法。例如，Servlet 接口中的 getLoginPage() 和 isUserInRole(String role) 方法在 GenericServlet 中没有实现。
如果需要这两个方法的功能，你可能需要自定义你的 Servlet 类并实现这两个方法。

HttpServlet抽象类:
>HttpServlet抽象类是继承于GenericServlet抽象类而来的。使用HttpServlet抽象类时，还需要借助分别代表Servlet请求和Servlet响应的HttpServletRequest和HttpServletResponse对象。
>HttpServletRequest接口扩展于javax.servlet.ServletRequest接口，HttpServletResponse接口扩展于javax.servlet.servletResponse接口。

public interface HttpServletRequest extends ServletRequest
public interface HttpServletResponse extends ServletResponse

HttpServlet抽象类覆盖了GenericServlet抽象类中的Service( )方法，并且添加了一个自己独有的Service(HttpServletRequest request，HttpServletResponse方法。

HttpServlet抽象类如何实现自己的service方法?
public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException {
    HttpServletRequest request;
    HttpServletResponse response;
    try {
        request = (HttpServletRequest)req;
        response = (HttpServletResponse)res;
    } catch (ClassCastException var6) {
        throw new ServletException("non-HTTP request or response");
    }
 
    this.service(request, response);
}

我们发现，HttpServlet中的service方法把接收到的ServletRequsest类型的对象转换成了HttpServletRequest类型的对象，把ServletResponse类型的对象转换成了HttpServletResponse类型的对象。
之所以能够这样强制的转换，是因为在调用Servlet的Service方法时，Servlet容器总会传入一个HttpServletRequest对象和HttpServletResponse对象，预备使用HTTP。因此，转换类型不会出错。


随后的Service方法：
protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
    String method = req.getMethod();
    long lastModified;
    if (method.equals("GET")) {
        lastModified = this.getLastModified(req);
        if (lastModified == -1L) {
            this.doGet(req, resp);
        } else {
            long ifModifiedSince = req.getDateHeader("If-Modified-Since");
            if (ifModifiedSince < lastModified) {
                this.maybeSetLastModified(resp, lastModified);
                this.doGet(req, resp);
            } else {
                resp.setStatus(304);
            }
        }
    } else if (method.equals("HEAD")) {
        lastModified = this.getLastModified(req);
        this.maybeSetLastModified(resp, lastModified);
        this.doHead(req, resp);
    } else if (method.equals("POST")) {
        this.doPost(req, resp);
    } else if (method.equals("PUT")) {
        this.doPut(req, resp);
    } else if (method.equals("DELETE")) {
        this.doDelete(req, resp);
    } else if (method.equals("OPTIONS")) {
        this.doOptions(req, resp);
    } else if (method.equals("TRACE")) {
        this.doTrace(req, resp);
    } else {
        String errMsg = lStrings.getString("http.method_not_implemented");
        Object[] errArgs = new Object[]{method};
        errMsg = MessageFormat.format(errMsg, errArgs);
        resp.sendError(501, errMsg);
    }
 
}
接下来我们再看看service方法是如何工作的，我们会发现在service方法中还是没有任何的服务逻辑，但是却在解析HttpServletRequest中的方法参数，并调用以下方法之一：doGet,doPost,doHead,doPut,doTrace,doOptions和doDelete。
这7种方法中，每一种方法都表示一个Http方法。doGet和doPost是最常用的。所以，如果我们需要实现具体的服务逻辑，不再需要覆盖service方法了，只需要覆盖doGet或者doPost就好了。

HttpServlet有两个特性是GenericServlet所不具备的：
1.不用覆盖service方法，而是覆盖doGet或者doPost方法。在少数情况，还会覆盖其他的5个方法。
2.使用的是HttpServletRequest和HttpServletResponse对象。


Servlet的生命周期：
init( ),service( ),destroy( )是Servlet生命周期的方法，代表了Servlet的生命周期，即Servlet从“出生”到“工作”再到“死亡 ”的过程。
Servlet容器（例如TomCat）会根据下面的规则来调用这三个方法：
1.init( ),当Servlet第一次被请求时，Servlet容器就会开始调用这个方法来初始化一个Servlet对象出来，
但是这个方法在后续请求中不会在被Servlet容器调用，就像人只能“出生”一次一样。我们可以利用init（ ）方法来执行相应的初始化工作。
调用这个方法时，Servlet容器会传入一个ServletConfig对象进来从而对Servlet对象进行初始化。

2.service( )方法，每当请求Servlet时，Servlet容器就会调用这个方法。就像人一样，需要不停的接受老板的指令并且“工作”。
第一次请求时，Servlet容器会先调用init( )方法初始化一个Servlet对象出来，然后会调用它的service( )方法进行工作，
但在后续的请求中，Servlet容器只会调用service方法了。

3.destory,当要销毁Servlet时，Servlet容器就会调用这个方法，就如人一样，到时期了就得死亡。
在卸载应用程序或者关闭Servlet容器时，就会发生这种情况，一般在这个方法中会写一些清除代码。


在SpringBoot中创建Servlet，继承HttpServlet类：
方式一： 通过注解扫描方式实现
创建一个servlet类

package com.liuhaiyang.springboot.servlet;
 
import javax.servlet.ServletException;
import javax.servlet.annotation.WebServlet;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import java.io.IOException;
 
//servlet第一种方式
@WebServlet(urlPatterns = "/myservlet")  //定义请求路径，通过该路径能访问到这个servlet
public class MyServlet extends HttpServlet {
 
    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        resp.getWriter().println("My Springboot-servlet-1");
        resp.getWriter().flush();
        resp.getWriter().close();
    }
 
    @Override
    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        super.doPost(req, resp);
    }
}
 
在SpringBoot项目的入口类上方使用注解 @ServletComponentScan 注解来扫描Servlet中的注解即可。

package com.liuhaiyang.springboot;
 
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.boot.web.servlet.ServletComponentScan;
 
@SpringBootApplication
@ServletComponentScan(basePackages = "com.liuhaiyang.springboot.servlet")   //第一种的注解
public class SpringbootTest13Application {
 
    public static void main(String[] args) {
        SpringApplication.run(SpringbootTest13Application.class, args);
    }
 
}

方式二：通过 SpringBoot 的配置类实现（组件注册）

再次创建一个Servlet类。

package com.liuhaiyang.springboot.servlet2;
 
import javax.servlet.ServletException;
import javax.servlet.annotation.WebServlet;
import javax.servlet.http.HttpServlet;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import java.io.IOException;
 
 
//servlet第二种方式
public class MyServlet extends HttpServlet {
 
    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        resp.getWriter().println("My Springboot-servlet-2");
        resp.getWriter().flush();
        resp.getWriter().close();
    }
 
    @Override
    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        super.doPost(req, resp);
    }
}

编写一个 Spring Boot 的配置类，在该类中注册 Servlet
创建 ServletConfig 配置类

package com.liuhaiyang.springboot.config;
 
import com.liuhaiyang.springboot.servlet2.MyServlet;
import org.springframework.boot.web.servlet.ServletRegistrationBean;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
 
@Configuration //该注解将此类定义为配置类（相当于一个xml文件）
public class ServletConfig {
    //@Bean是一个方法级别上的注解，主要用于配置类里 相当于<beans> <bean id="" class="" > </beans>
    @Bean
    public ServletRegistrationBean myServletRegistrationBean(){
        ServletRegistrationBean servletRegistrationBean=new ServletRegistrationBean(new MyServlet(),"/myservlet");
        return servletRegistrationBean;
    }
}

在Servlet中，HttpServletRequest和ServletRequest HttpServletResponse和ServletResponse是什么关系？
ServletRequest 与 HttpServletRequest:
>ServletRequest 是一个通用的请求接口，定义了在Web应用中处理HTTP请求时的通用方法。
>HttpServletRequest 是 ServletRequest 的一个子接口，专门用于处理HTTP协议的请求。它提供了更多与HTTP协议相关的方法和属性，如获取请求头、查询参数、请求方法（GET、POST等）等。
>当你编写一个Servlet时，你通常会直接处理 HttpServletRequest，因为它提供了更丰富的功能来处理HTTP请求。

ServletResponse 与 HttpServletResponse:
>ServletResponse 是一个通用的响应接口，定义了在Web应用中构建HTTP响应时的通用方法。
>HttpServletResponse 是 ServletResponse 的一个子接口，专门用于构建HTTP协议的响应。它提供了更多与HTTP协议相关的方法和属性，如设置响应头、发送重定向、设置响应状态码等。
>同样地，在编写Servlet时，你通常会直接处理 HttpServletResponse，因为它允许你更精细地控制HTTP响应的各个方面。


关于转发和重定向的区别：

1.重定向访问服务器两次，转发只访问服务器一次。
2.转发页面的URL不会改变，而重定向地址会改变
3.转发只能转发到自己的web应用内，重定向可以重定义到任意资源路径。
4.转发相当于服务器跳转，相当于方法调用，在执行当前文件的过程中转向执行目标文件，两个文件(当前文件和目标文件)属于同一次请求，前后页共用一个request，
可以通过此来传递一些数据或者session信息，request.setAttribute()和 request.getAttribute()。而重定向会产生一个新的request，不能共享request域信息与请求参数
5.由于转发相当于服务器内部方法调用，所以转发后面的代码仍然会执行(转发之后记得return)；重定向代码执行之后是方法执行完成之后进行重定向操作，也就是访问第二个请求，如果是方法的最后一行进行重定向那就会马上进行重定向(重定向也需要return)。
6.无论是RequestDispatcher.forward方法，还是HttpServletResponse.sendRedirect方法，在调用它们之前，都不能有内容已经被实际输出到了客户端。如果缓冲区中已经有了一些内容，这些内容将被从缓冲区中移除。


关于JSP和Servlet的区别：
1.  不同之处在哪？
Servlet在Java代码中通过HttpServletResponse对象动态输出HTML内容
JSP在静态HTML内容中嵌入Java代码，Java代码被动态执行后生成HTML内容

2.  各自的特点
Servlet能够很好地组织业务逻辑代码，但是在Java源文件中通过字符串拼接的方式生成动态HTML内容会导致代码维护困难、可读性差
JSP虽然规避了Servlet在生成HTML内容方面的劣势，但是在HTML中混入大量、复杂的业务逻辑同样也是不可取的

关于浏览器渲染数据：
前端渲染:
前端渲染就是指后端返回JSON数据或者JSONP数据，在前端利用预先写的html模板，循环读取JSON数据或者JSONP数据，进行选取，拼接，并且将这些数据插入页面来达到渲染效果。
后端渲染：
前端进行数据请求，后端用后台模板引擎直接生成html，前端接受到数据之后，直接插入页面。

前端渲染和后端渲染两者的好处和坏处:
1.前端渲染:
好处：网络传输数据量小。不占用服务端运算资源（解析模板），模板在前端（很有可能仅部分在前端），改结构变交互都前端自己来了，改完自己调就行。
坏处：前端耗时较多，对前端工作人员水平要求相对较高。前端代码较多，因为部分以前在后台处理的交互逻辑交给了前端处理。占用少部分客户端运算资源用于解析模板。
2.后端渲染
好处：前端耗时少，即减少了首屏时间，模板统一在后端。前端（相对）省事，不占用客户端运算资源（解析模板）
坏处：占用服务器资源。

前端渲染与后端渲染对比：
    
前端渲染：
页面呈现速度：主要受限于带宽和客户端机器的好坏，优化效果好，可以逐步动态展开内容，感觉上会更快一点。
可维护性强，前后端分离，各施其职，代码一目明了。
SEO友好度(seo=Search(搜索) Engine(引擎) Optimization(优化),即搜索引擎优化)：差，大量使用ajax，多数浏览器不能抓取ajax数据。
编码效率：高，前后端各自只做自己擅长的东西，后端最后只输出接口，不用管页面呈现，只要前后端人员能力不错，效率不会低。
    
后端渲染：
页面呈现速度：快，受限于用户的带宽
可维护性：差（前后端不分离）
SEO友好度：好,后端的数据一步搞定,直接生成相对应的模板网页
编码效率：低（有时候可能手忙脚乱,找不到数据对应的位置或者数据）


什么是过滤器（Filter）
过滤器，是在java web中将你传入的request、response提前过滤掉一些信息，或者提前设置一些参数。
然后再传入Servlet或Struts2的 action进行业务逻辑处理。比如过滤掉非法url（不是login.do的地址请求，如果用户没有登陆都过滤掉），
或者在传入Servlet或Struts2的action前统一设置字符集，或者去除掉一些非法字符。
过滤器处于客户端与Web资源（Servlet、JSP、HTML）之间，客户端与Web资源之间的请求和响应都要通过过滤器进行过滤。

使用Servlet创建过滤器：
在Java Web开发中，过滤器（Filter）是一个常用的组件，它能够对Web应用程序的请求和响应进行预处理和后处理。Servlet规范定义了过滤器API，使得开发人员可以创建自定义的过滤器来处理HTTP请求和响应。以下是一个简单的示例，说明如何使用Servlet创建一个过滤器：

实现Filter接口
首先，你需要创建一个类，该类实现了javax.servlet.Filter接口。这个接口定义了三个方法：init(), doFilter(), 和 destroy()。

java
import javax.servlet.*;  
import javax.servlet.http.HttpServletRequest;  
import javax.servlet.http.HttpServletResponse;  
import java.io.IOException;  
  
public class MyFilter implements Filter {  
  
    @Override  
    public void init(FilterConfig filterConfig) throws ServletException {  
        // 初始化方法，在过滤器创建时调用一次  
        System.out.println("MyFilter initialized.");  
    }  
  
    @Override  
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)  
            throws IOException, ServletException {  
          
        // 在请求处理前执行代码  
        HttpServletRequest req = (HttpServletRequest) request;  
        HttpServletResponse res = (HttpServletResponse) response;  
          
        System.out.println("MyFilter is filtering request for " + req.getRequestURI());  
          
        // 继续过滤器链，即调用下一个过滤器或目标资源  
        chain.doFilter(request, response);  
          
        // 在请求处理后执行代码（如果需要的话）  
        System.out.println("MyFilter has finished filtering request for " + req.getRequestURI());  
    }  
  
    @Override  
    public void destroy() {  
        // 销毁方法，在过滤器销毁时调用一次  
        System.out.println("MyFilter destroyed.");  
    }  
}
在web.xml中配置过滤器
然后，你需要在你的web.xml文件中配置过滤器，以告诉Web容器何时应用这个过滤器。

<web-app ...>  
    <!-- 其他配置 -->  
      
    <filter>  
        <filter-name>MyFilter</filter-name>  
        <filter-class>com.example.MyFilter</filter-class>  
    </filter>  
      
    <filter-mapping>  
        <filter-name>MyFilter</filter-name>  
        <url-pattern>/*</url-pattern> <!-- 应用到所有请求 -->  
    </filter-mapping>  
      
    <!-- 其他配置 -->  
</web-app>

<filter>元素定义了过滤器的名称和类，而<filter-mapping>元素定义了该过滤器应用到哪些URL模式上。/*意味着过滤器会应用到Web应用程序中的所有请求。

使用注解：
如果你的Servlet容器（如Tomcat 7及更高版本、Jetty等）支持Servlet 3.0或更高版本的注解，你可以使用@WebFilter注解来替代web.xml中的配置。


import javax.servlet.annotation.WebFilter;  
import javax.servlet.annotation.WebInitParam;  
  
@WebFilter(urlPatterns = "/*", initParams = {  
    @WebInitParam(name = "param1", value = "value1")  
})  
public class MyFilter implements Filter {  
    // ... 实现方法与之前相同 ...  
}

使用Spring Boot创建过滤器：
在Spring Boot中创建过滤器（Filter）相对简单，因为Spring Boot提供了自动配置和简化配置的功能。
可以通过实现javax.servlet.Filter接口或者通过Spring Boot的@WebFilter注解（如果Servlet API版本和Servlet容器支持的话）来创建过滤器。
不过，更常见的做法是在Spring Boot中通过Java配置来定义过滤器。

创建过滤器类
首先，创建一个实现javax.servlet.Filter接口的类：

import javax.servlet.*;  
import javax.servlet.http.HttpServletRequest;  
import java.io.IOException;  
  
public class MyCustomFilter implements Filter {  
  
    @Override  
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain)  
            throws IOException, ServletException {  
          
        HttpServletRequest request = (HttpServletRequest) servletRequest;  
        System.out.println("MyCustomFilter is filtering request for " + request.getRequestURI());  
          
        // 继续过滤器链  
        filterChain.doFilter(servletRequest, servletResponse);  
          
        System.out.println("MyCustomFilter has finished filtering request for " + request.getRequestURI());  
    }  
  
    @Override  
    public void init(FilterConfig filterConfig) throws ServletException {  
        // 初始化方法  
    }  
  
    @Override  
    public void destroy() {  
        // 销毁方法  
    }  
}

注册过滤器：
接下来，你需要在Spring Boot配置中注册这个过滤器。你可以使用@Configuration和@Bean注解来定义一个配置类，并在这个类中注册过滤器：

import org.springframework.boot.web.servlet.FilterRegistrationBean;  
import org.springframework.context.annotation.Bean;  
import org.springframework.context.annotation.Configuration;  
  
@Configuration  
public class FilterConfig {  
  
    @Bean  
    public FilterRegistrationBean<MyCustomFilter> myCustomFilterRegistration() {  
        FilterRegistrationBean<MyCustomFilter> registrationBean = new FilterRegistrationBean<>();  
        registrationBean.setFilter(new MyCustomFilter());  
        registrationBean.addUrlPatterns("/*"); // 应用到所有请求  
        return registrationBean;  
    }  
}
在上面的代码中，我们创建了一个FilterRegistrationBean，并将我们的MyCustomFilter实例设置到它里面。然后，我们添加了一个URL模式/*，这表示该过滤器将应用于所有的请求。

使用@Component注解（可选）
如果你的过滤器类不需要任何特定的配置，你可以简单地将其标记为@Component，Spring Boot会自动发现并注册它：

import javax.servlet.*;  
import javax.servlet.annotation.WebFilter;  
import javax.servlet.http.HttpServletRequest;  
import java.io.IOException;  

@Component  
public class MyComponentFilter implements Filter {  
    // ... 实现方法与之前相同 ...  
}

在这种情况下，不需要创建FilterRegistrationBean，因为Spring Boot会自动处理它。但是，如果需要更细粒度的控制（比如指定URL模式），那么使用FilterRegistrationBean是更好的选择。
注：在Servlet中，过滤器执行的顺序按照配置的顺序运行

什么是监听器（Listener)
监听器（Listener）是一种运行在后台的程序，它主要用于监控某些事件在系统中的发生，并且根据这些事件执行特定的处理操作。
在Web应用程序中，监听器可以观察ServletContext、HttpSession以及ServletRequest等对象的变化，以便在这些对象变化时进行相应的处理。

使用Servlet创建一个监听器：

首先，我们需要实现一个监听器接口。假设我们想要创建一个ServletContextListener，用于监听ServletContext的创建和销毁事件：

import javax.servlet.ServletContextEvent;  
import javax.servlet.ServletContextListener;  
  
public class MyServletContextListener implements ServletContextListener {  
  
    @Override  
    public void contextInitialized(ServletContextEvent sce) {  
        // ServletContext被创建时调用  
        System.out.println("ServletContext 初始化");  
        // 在这里可以执行初始化操作，比如加载配置文件等  
    }  
  
    @Override  
    public void contextDestroyed(ServletContextEvent sce) {  
        // ServletContext被销毁时调用  
        System.out.println("ServletContext 销毁");  
        // 在这里可以执行清理操作，比如释放资源等  
    }  
}

然后，我们需要在web.xml文件中配置这个监听器：

xml
<web-app ...>  
    <!-- 其他配置 -->  
      
    <listener>  
        <listener-class>com.example.MyServletContextListener</listener-class>  
    </listener>  
</web-app>

如果你的项目使用的是Servlet 3.0或更高版本，你还可以使用注解来避免在web.xml中手动配置监听器。你只需要在监听器类上使用@WebListener注解即可：


import javax.servlet.annotation.WebListener;  
import javax.servlet.ServletContextEvent;  
import javax.servlet.ServletContextListener;  
  
@WebListener  
public class MyServletContextListener implements ServletContextListener {  
    // 实现与上面相同的contextInitialized和contextDestroyed方法  
}
使用@WebListener注解后，你就不需要在web.xml中手动添加<listener>配置了，Servlet容器会在启动时自动发现并注册这个监听器。

注意：监听器类应该放在WEB-INF/classes目录或其子目录下，或者打包在WEB-INF/lib目录下的JAR文件中，以确保Servlet容器能够找到和加载它们。
当Web应用程序启动或停止时，Servlet容器会自动调用监听器的相应方法。


什么是拦截器（Interceptor）
拦截器是一种面向方面/切面编程（AOP Aspect-Oriented Programming），而面向切面就是将多个模块的通用服务进行分离，
如权限管理、日志服务，他们在多个模块中都会用到，就可以将其各自封装为一个可重用模块。

而这些通用服务的具体实现是通过拦截器来完成，比如用户客户端访问一些保密模块都应先通过权限审查的拦截器来进行权限审查，
确定用户是否具有该项操作的权限后方能向下执行。在面向切面编程的就是在你的service或者一个方法前调用一个方法，
或者在方法后调用一个方法，比如动态代理就是拦截器的简单实现，在你调用方法前打印出字符串（或者做其它业务逻辑的操作），
也可以在你调用方法后打印出字符串，甚至在你抛出异常的时候做业务逻辑的操作。

拦截器与过滤器区别
1、拦截器是基于java的反射机制的，而过滤器是基于函数回调（职责链）
2、过滤器依赖与servlet容器，而拦截器不依赖与servlet容器
3、拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用
4、拦截器可以访问action上下文、值栈里的对象，而过滤器不能
5、在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次
6、拦截器可以获取IOC容器中的各个bean，而过滤器不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。

通俗理解：
（1）过滤器（Filter）：当你有一堆东西的时候，你只希望选择符合你要求的某一些东西。定义这些要求的工具，就是过滤器。（理解：就是一堆字母中取一个B）
（2）拦截器（Interceptor）：在一个流程正在进行的时候，你希望干预它的进展，甚至终止它进行，这是拦截器做的事情。（理解：就是一堆字母中，干预它，通过验证的少点，顺便干点别的东西

触发时机与执行顺序
触发时机：
拦截器与过滤器触发时机不一样
过滤器是在请求进入容器后，但请求进入servlet之前进行预处理的。请求结束返回也是，是在servlet处理完后，返回给前端之前。

过滤器包裹servlet，servlet包裹住拦截器。

执行顺序 ：
过滤前 - 拦截前 - Action处理 - 拦截后 - 过滤后。个人认为过滤是一个横向的过程，首先把客户端提交的内容进行过滤(例如未登录用户不能访问内部页面的处理)；
过滤通过后，拦截器将检查用户提交数据的验证，做一些前期的数据处理，接着把处理后的数据发给对应的Action；
Action处理完成返回后，拦截器还可以做其他过程(还没想到要做啥)，再向上返回到过滤器的后续操作。

例子：自定义拦截器
@Component
public class MyInterceptor implements HandlerInterceptor {
  @Override
  public boolean preHandle(HttpServletRequest request, HttpServletResponse response,
                           Object handler) throws Exception {
		return true;
		}
}

需要再写一个自己的配置类：
@Configuration
public class MyConfiguration implements WebMvcConfigurer {
	 @Override
	 public void addInterceptors(InterceptorRegistry registry) {
		  //将我们自定义的拦截器加入配置
	 	 InterceptorRegistration interceptor = registry.addInterceptor(new MyInterceptor());
		  //设置拦截的url
		  interceptor.addPathPatterns("/user/**");
	 }
}


使用Spring MVC拦截器实现控制权限：
首先，你需要创建一个实现了HandlerInterceptor接口的类。在这个类中，你可以重写preHandle方法来进行权限控制。

java
import javax.servlet.http.HttpServletRequest;  
import javax.servlet.http.HttpServletResponse;  
import org.springframework.web.servlet.HandlerInterceptor;  
import org.springframework.web.servlet.ModelAndView;  
  
public class AuthInterceptor implements HandlerInterceptor {  
  
    @Override  
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {  
        // 检查用户是否登录或者是否有权限访问  
        String username = (String) request.getSession().getAttribute("username");  
        if (username == null || !isUserAuthorized(username, request)) {  
            // 如果用户未登录或未授权，重定向到登录页面  
            response.sendRedirect(request.getContextPath() + "/login");  
            return false; // 返回false表示请求处理到此为止，不再继续执行后续的Controller方法  
        }  
        return true; // 返回true表示请求可以继续执行  
    }  
  
    private boolean isUserAuthorized(String username, HttpServletRequest request) {  
        // 这里应该实现具体的权限检查逻辑  
        // 例如，可以检查用户名是否匹配某个允许访问的列表  
        return true; // 示例中默认返回true，表示所有用户都有权限  
    }  
  
    @Override  
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {  
        // 请求处理完成后调用，通常用于视图渲染前的处理  
    }  
  
    @Override  
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {  
        // 整个请求完成后调用，通常用于资源清理  
    }  
}
然后，你需要在Spring MVC的配置中注册这个拦截器，并指定它应该拦截哪些URL。这可以通过Java配置或XML配置来完成。

Java配置示例：
import org.springframework.beans.factory.annotation.Autowired;  
import org.springframework.context.annotation.Configuration;  
import org.springframework.web.servlet.config.annotation.InterceptorRegistry;  
import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;  
  
@Configuration  
public class WebConfig implements WebMvcConfigurer {  
  
    @Autowired  
    private AuthInterceptor authInterceptor;  
  
    @Override  
    public void addInterceptors(InterceptorRegistry registry) {  
        registry.addInterceptor(authInterceptor)  
                .addPathPatterns("/secure/**") // 拦截所有以"/secure/"开头的URL  
                .excludePathPatterns("/secure/login"); // 排除"/secure/login"这个URL，不需要权限检查  
    }  
}

XML配置示例：

<mvc:interceptors>  
    <mvc:interceptor>  
        <mvc:mapping path="/secure/**" />  
        <mvc:exclude-mapping path="/secure/login" />  
        <bean class="com.example.AuthInterceptor" />  
    </mvc:interceptor>  
</mvc:interceptors>
在这个配置中，AuthInterceptor会被注册为一个拦截器，并配置为拦截所有以/secure/开头的URL，但排除/secure/login这个URL。


SpringBoot配置嵌入式Servlet容器：
1、找到接口ConfigurableEmbeddedServletContainer
2、找到接口EmbeddedServletContainerCustomizer
3、注册Servlet、Filter、Listener
	>ServletRegistrationBean
	>FilterRegistrationBean
	>ServletListenerRegistrationBean

配置Servlet:
@WebServlet(urlPatterns = "/portal/*")
public class HelloServlet extends HttpServlet {
    public HelloServlet() {
        super();
    }
 
    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        String name = req.getParameter("name");
        System.out.println("=====================Hello "+ name +", this is doGet Filter===================");
        PrintWriter writer = resp.getWriter();
        writer.write("Your request parameter is " + name);
        writer.flush();
        writer.close();
    }
 
    @Override
    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        System.out.println("=====================Hello doPost Filter===================");
        super.doPost(req, resp);
    }
 
    @Override
    protected void doPut(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        System.out.println("=====================Hello doPut Filter===================");
        super.doPut(req, resp);
    }
}

配置Filter：
@WebFilter(urlPatterns = "/*", filterName = "helloFilter")
public class HelloFilter implements Filter {
 
    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
        System.out.println("================init filter===================");
    }
 
    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
        System.out.println("=================this is filer method====================");
        filterChain.doFilter(servletRequest, servletResponse);
    }
 
    @Override
    public void destroy() {
        System.out.println("==========================destroy method===================");
    }
}

配置Listener：
package com.learn.listener;
 
import javax.servlet.ServletContextEvent;
import javax.servlet.ServletContextListener;
import javax.servlet.annotation.WebListener;
 
/**
 * springBoot整合Listener
 *
 *<listener>
 *	<listener-class>com.learn.listener.FirstListener</listener-class>
 *</listener>
 */
@WebListener
public class MyListener implements ServletContextListener {
 
	@Override
	public void contextDestroyed(ServletContextEvent arg0) {
		// TODO Auto-generated method stub
 
	}
 
	@Override
	public void contextInitialized(ServletContextEvent arg0) {
		System.out.println("Listener...init......");
 
	}
 
}

Java WEB 中什么是前后端不分离？
在Java WEB开发中，前后端不分离和前后端分离是两种常见的架构设计方式。
前后端不分离（Monolithic Architecture）：在这种架构中，前端和后端是紧密耦合的，它们运行在同一个应用程序中。
这种架构的设计初衷是为了简化开发和维护，尤其是在小型应用或初创公司中。下面是一些前后端不分离的例子：

1.Spring Boot：Spring Boot是一个全栈的Java框架，它可以创建独立的、生产级别的Spring应用程序。
Spring Boot可以构建Web应用，并且内置了Tomcat服务器，前端和后端代码都放在同一个应用中。
2.**JavaServer Pages (JSP)**：JSP是一种Java技术，让你可以在HTML中嵌入Java代码。
JSP在服务器上运行，并动态生成HTML页面返回给客户端。这种方式下，前端和后端的代码是混在一起的。


前后端分离（Microservices Architecture）：与前后端不分离相反，前后端分离将前端和后端的职责完全分开。
前端通常负责展示数据和用户交互，而后端则负责处理业务逻辑和数据持久化。这种架构有助于提高可扩展性、模块化和独立性。
下面是一些前后端分离的例子：

1.Spring Cloud + React/Vue：这是一种常见的微服务架构。Spring Cloud用于构建后端微服务，如API网关、服务发现、负载均衡等。
而React或Vue等前端框架则负责构建用户界面。
2.RESTful API + Front-end SPA：后端提供RESTful API来处理业务逻辑和数据，
而前端使用Single Page Application (SPA)框架（如Angular、React或Vue）来获取数据并展示给用户。

总之：这两种架构都有其优缺点。前后端不分离的架构简单易用，但在大型项目中可能限制了可扩展性和模块化。
前后端分离的架构提供了更高的灵活性，但同时也增加了开发和维护的复杂性。


路由控制:前后端分离的情况后端在任何都会返回一个json数据，不涉及路由处理，即页面跳转全是由前端自己完成。
不分离的情况，路由跳转一般由后端完成，而且携带数据，通过重定向或请求转发实现，依赖Servlet中的内置对象。
返回数据:前后端分离的情况后端返回的整体划分上只有执行逻辑响应的消息实体类和对应的需要展示的数据分页类对应的JSON。
不分离后端返回的是经过视图解析器处理前的字符串。

请求方式:前后端分离的情况以Rest风格的方式处理为主,当执行增删改查对应http请求方法POST,DELEE,PUT,GET,
一般以异步请求为主,不分离情况一般同步异步结合。请求上以GET和POST为主。

注解使用：前后端分离，接收的数据是Json时需要@RequestBody作用在方法参数上。
用于将POST请求数据转化为实体类。返回数据时使用@ResponseBody用于将POST请求数据转化为实体类。
返回数据时使用@ResponseBody,作用在方法上,当然对于全局的也可以使用@RespController注解。
前后端不分离一般使用@RequestMapping，请求方式不用管。前后端不分离一般使用@RequestMapping，请求方式不用管。


Spring Boot的功能及实现原理:
众所周知Spring框架需要进行大量的配置，Spring Boot引入自动配置的概念，让项目设置变得很容易。
Spring Boot本身并不提供Spring框架的核心特性以及扩展功能，只是用于快速、敏捷地开发新一代基于Spring框架的应用程序。
也就是说，它并不是用来替代Spring的解决方案，而是和Spring框架紧密结合用于提升Spring开发者体验的工具。
同时它集成了大量常用的第三方库配置(例如Jackson, JDBC, Mongo, Redis, Mail等等)，
Spring Boot应用中这些第三方库几乎可以零配置的开箱即用(out-of-the-box)，
大部分的Spring Boot应用都只需要非常少量的配置代码，开发者能够更加专注于业务逻辑。

Spring Boot只是承载者，辅助你简化项目搭建过程的。如果承载的是WEB项目，使用Spring MVC作为MVC框架，
那么工作流程和SpringMVC是完全一样的，因为这部分工作是Spring MVC做的而不是Spring Boot。
对使用者来说，换用Spring Boot以后，项目初始化方法变了，配置文件变了，另外就是不需要单独安装Tomcat这类容器服务器了，
maven打出jar包直接跑起来就是个网站，但你最核心的业务逻辑实现与业务流程实现没有任何变化。

Spring Boot 使用了特定的机制和策略来将配置文件打包成快速启动的应用程序。

>自动配置：Spring Boot 通过自动配置机制，根据项目中的依赖关系和条件，自动地创建和配置应用程序所需的组件。
这种机制大大简化了配置过程，减少了手动配置的工作量。

>默认配置：Spring Boot 提供了大量的默认配置，这些配置适用于大多数应用场景。通过使用默认配置，
您可以轻松地启动应用程序，而无需编写过多的配置文件。

>自定义配置：如果默认配置不能满足您的需求，您可以根据需要自定义配置。
Spring Boot 支持使用 application.properties 或 application.yml 文件来定义自定义配置。您可以在这些文件中设置自己的属性，以满足特定应用程序的需求。

>外部化配置：Spring Boot 支持将配置文件放置在项目外部，以便于在不同的环境中使用相同的配置。
您可以将配置文件放在项目的根目录或 classpath 根目录之外的位置，然后在应用程序中通过设置配置文件的路径来加载它们。

>热重载配置：Spring Boot 支持配置文件的热重载，这意味着当您更改配置文件时，应用程序将自动重新加载配置，而无需重启整个应用程序。
这使得开发过程更加高效，因为您无需等待应用程序重新启动就可以看到配置更改的效果。

>命令行参数：Spring Boot 还支持通过命令行参数来覆盖配置文件中的属性值。这使得您可以在启动应用程序时指定特定的属性值，
以便进行测试或生产环境的差异化配置。


所以，用最简练的语言概括就是：
Spring 是一个“引擎”；
Spring MVC 是基于Spring的一个 MVC 框架 ；
Spring Boot 是基于Spring的条件注册的一套快速开发整合包。


SpringBoot的启动方法：
import org.springframework.boot.SpringApplication;  
import org.springframework.boot.autoconfigure.SpringBootApplication;  
  
@SpringBootApplication  
public class Application {  
  
    public static void main(String[] args) {  
        SpringApplication.run(Application.class, args);  
    }  
  
}

在这个例子中：
Application类是一个普通的Java类，它包含了main方法，这是Java应用程序的入口点。
@SpringBootApplication注解告诉Spring Boot这是一个Spring Boot应用程序，并且它会自动配置应用程序。
SpringApplication.run(Application.class, args);启动了Spring Boot应用程序。它会加载应用程序上下文，启动嵌入式的Servlet容器（如果配置了的话），然后运行应用程序。
当你运行这个main方法时，Spring Boot会自动配置你的应用程序，并且启动嵌入式的Servlet容器（如Tomcat）来监听HTTP请求。



用Spring Boot解释一下约定大于配置大于编码?
"约定大于配置大于编码" 是一个设计原则，它强调了在设计软件时，应该优先考虑使用通用的、广泛接受的约定，其次是配置选项，最后才是直接编写代码。这个原则旨在提高软件的可维护性、可读性和可扩展性。在Spring Boot框架中，这个原则得到了很好的体现。

约定
在Spring Boot中，很多常见的配置和编码工作都通过约定来简化。例如：

项目结构约定：Spring Boot约定了项目的标准结构，例如src/main/java用于存放Java源代码，src/main/resources用于存放配置文件等。
端口号约定：默认情况下，Spring Boot应用会监听8080端口。除非有特别的需求，否则开发者无需手动配置端口。
日志约定：Spring Boot使用Logback作为默认的日志框架，并提供了默认的日志配置。
这些约定让开发者可以快速地开始一个新的Spring Boot项目，而无需花费太多时间在配置和编码上。

配置
当默认的约定不满足需求时，Spring Boot提供了丰富的配置选项。这些配置可以通过多种方式实现：

application.properties 或 application.yml：这是Spring Boot中最常用的配置方式。开发者可以在这些文件中定义各种属性，如数据库连接信息、服务器端口等。
环境变量：Spring Boot也支持通过环境变量来配置应用。
命令行参数：在启动应用时，可以通过命令行参数来覆盖配置文件中的设置。
通过这些配置选项，开发者可以灵活地调整应用的行为，而无需修改代码。

编码
当然，有些复杂的功能或定制化的需求可能无法通过约定或配置来实现，这时就需要编写代码了。Spring Boot提供了丰富的API和扩展点，使得开发者可以轻松地实现各种功能。
但即使需要编码，Spring Boot也尽可能地通过注解、自动配置等方式简化了编码的复杂性。

总结
在Spring Boot中，"约定大于配置大于编码"原则的应用使得开发者可以更加高效地构建应用。通过遵循通用的约定和利用强大的配置功能，开发者可以快速地搭建起一个功能完善的应用，
并在需要时通过编码来实现更高级的功能。这种设计方式不仅提高了开发效率，也增强了应用的可维护性和可读性。


SpringBoot的自动配置：
Spring Boot的自动配置是其核心功能之一，它极大地简化了Spring应用程序的初始搭建和配置过程。
自动配置的核心思想是根据项目中的依赖和类路径下的特定类，自动创建和配置Spring容器中的bean，从而省去了手动配置的大量工作。

以下是Spring Boot自动配置的主要原理和实现方式：
>条件化配置：Spring Boot通过条件注解（如@ConditionalOnClass、@ConditionalOnMissingBean等）来决定是否加载某个自动配置类或bean。
这些条件可以是类路径下是否存在某个类、是否存在某个bean等。只有当满足特定条件时，相关的自动配置才会生效。

>自动配置类：自动配置类通过@Configuration注解标识，它们包含了Spring容器需要自动创建的bean的定义。这些bean的创建和配置会根据条件化注解的条件来确定。
自动配置类通常存放在spring-boot-autoconfigure模块的jar包中。

>META-INF/spring.factories文件：Spring Boot通过在类路径下的META-INF/spring.factories文件中定义自动配置类，告诉Spring Boot哪些配置类需要被加载。
这个文件是一个属性文件，其中包含了自动配置类的全限定名。

>属性绑定：Spring Boot还允许开发者在application.properties或application.yml文件中定义外部化配置，这些配置会被自动绑定到相关的bean上。
这大大简化了配置的复杂性，使得开发者能够更专注于业务逻辑的实现。

>Starter依赖：Spring Boot提供了一系列的“Starter”依赖，这些依赖包含了构建某个特定类型应用程序所需的所有基本依赖和自动配置。
例如，spring-boot-starter-web包含了构建Web应用程序所需的Spring MVC和嵌入式Servlet容器等依赖和自动配置。


问：@SpringBootApplication注解是如何完成自动配置功能的？
@SpringBootApplication注解是SpringBoot中的一个复合注解，它包含了@Configuration、@EnableAutoConfiguration和@ComponentScan三个关键注解。
这个注解的作用是启用SpringBoot的自动配置功能，并告诉Spring Boot如何扫描和加载应用程序的组件。

下面我们来详细解析@SpringBootApplication注解是如何完成自动配置功能的：

@Configuration：
这个注解用于告诉Spring这是一个配置类，类似于XML配置文件中的<beans>标签。在这个类中，开发者可以使用@Bean注解来定义和初始化Spring容器管理的bean。

@EnableAutoConfiguration：
这个注解是自动配置的关键所在。当使用@EnableAutoConfiguration注解时，Spring Boot会根据项目中引入的依赖和类路径下的特定类，自动配置应用程序所需的bean。

条件注解：Spring Boot使用条件注解（如@ConditionalOnClass、@ConditionalOnMissingBean等）来决定是否创建和配置某个bean。这些条件可以是类路径上是否存在某个类、是否存在某个bean等。
自动配置类：Spring Boot提供了许多自动配置类，这些类包含了一些预定义的bean，并且会根据项目的条件进行创建和配置。
META-INF/spring.factories文件：自动配置类通过META-INF/spring.factories文件进行注册。Spring Boot在启动时，会扫描这个文件，并加载其中定义的自动配置类。

@ComponentScan：
这个注解用于告诉Spring Boot哪些包下的类需要被扫描并注册为Spring容器管理的bean。默认情况下，@SpringBootApplication注解会扫描启动类所在的包及其子包。

综合这三个注解，@SpringBootApplication完成了以下功能：

通过@Configuration定义了配置类。
通过@EnableAutoConfiguration启用了自动配置功能，根据项目的依赖和条件自动创建和配置bean。
通过@ComponentScan扫描并注册应用程序的组件。

当开发者在Spring Boot应用程序的主类上使用@SpringBootApplication注解时，Spring Boot会自动完成上述所有步骤，从而简化了应用程序的配置和初始化过程。
开发者只需要关注业务逻辑的实现，而不需要花费大量时间在繁琐的配置上。


SpringBoot中定制Web扩展配置：WebMvcConfigurerAdapter接口
这是一个接口，里边声明了很多的方法，例如拦截器，视图解析器，格式转化器。
如果想在webmvc中添加自己的功能，只需要去WebMvcConfigurer看看想增加什么功能，然后按照源码去写。

Spring与SpringBoot中一些常用注解：
@SpringBootApplication：实现自动化装配，启动SpringBoot，包含@Configuration、@EnableAutoConfiguration、@ComponentScan通常用在主类上
@Component：普通pojo注入spring容器
@Service：Service注入Spring容器
@Controller：Controller注入容器
@Repository：Dao注入容器
@ResponseBody：将java对象转为json格式的数据
@RestController：该注解是@Controller和@ResponseBody的结合体，一般用于类，作用等于在类上面添加了@ResponseBody和@Controller
@AutoWired：默认按类型装配，如果发现找到多个bean，则按照name方式比对，如果还有多个，则报出异常
@Qualifier：spring的注解，按名字注入 一般当出现两个及以上bean时,不知道要注入哪个，结合@AutoWired使用
@Resource：默认按名称注入例如@Resource(name = “zhaozhao”)则根据name属性注入找不到则报错，
若无name属性则根据属性名称注入，如果匹配不成功则按照类型匹配匹配不成功则报错。
@RequestMapping：@RequestMapping（url），通过该注解就可以通过配置的url进行访问，方式可以是get或post请求，两种方式均可
@GetMapping：只是这个限定了只能是Get请求
@PostMapping：只是这个限定了只能是Post请求
@Value：用于获取bean的属性，一般用于读取配置文件的数据，作用在变量上 
@ConfigurationProperties：用于注入Bean属性，然后再通过当前Bean获取注入值，作用在类上 
@PropertySource：用于指定要读取的配置文件，可以和@Value或@ConfigurationProperties配合使用
@Configuration：作用于类上表示这是一个配置类，可理解为用spring的时候xml里面的< beans>标签 
@Bean：产生bean对象加入容器，作用于方法，可理解为用spring的时候xml里面的标签
@RequestParam：获取查询参数。即url?name=这种形式
@RequestBody：获取Body的参数，一般用于post获取参数 
@PathVariable：获取路径参数。即url/{id}这种形式 
@RequestHeader：获取请求头的信息 
@CookieValue：获取Cookie的信息

Spring Boot的启动类实现方式：
1、程序从main方法开始运行
2、使用SpringApplication.run()加载主程序类
3、主程序类需要标注@SpringBootApplication
4、@EnableAutoConfiguration是核心注解；
5、@Import导入所有的自动配置场景
6、@AutoConfigurationPackage定义默认的包扫描规则
7、程序启动扫描加载主程序类所在的包以及下面所有子包的组件；

Spring Boot使用的全局配置文件：
>application.properties
>application.yml

配置文件放在src/main/resources目录或者类路径/config下
.yml是YAML(YAML Aint Markup Language)编写的文件格式，YAML是一种直观的能够被电脑识别的的数据数据序列化格式，比json、xml等更适合做配置文件

转载：https://www.zhihu.com/question/64671972/answer/223383505
作者：zhonghd
链接：https://www.jianshu.com/p/1d4d57a4db51
来源：简书
-------------------------------------------------------------------------------


后端技术：
Servlet → Java spring → springMVC
以前：J2EE应用框架 J2EE开发框架主要有Hibernate，Spring，Struts2，EXTJS，Json。

Hibernate：
Hibernate是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装，
它将POJO与数据库表建立映射关系，是一个全自动的orm框架，hibernate可以自动生成SQL语句，自动执行，
使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库。Hibernate可以应用在任何使用JDBC的场合，
既可以在Java的客户端程序使用，也可以在Servlet/JSP的Web应用中使用，
最具革命意义的是，Hibernate可以在应用EJB的JavaEE架构中取代CMP，完成数据持久化的重任。

创建映射配置文件：
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE hibernate-mapping PUBLIC 
    "-//Hibernate/Hibernate Mapping DTD 3.0//EN"
    "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd">
    
<hibernate-mapping>
	<!-- 建立类与表的映射 -->
	<class name="com.meimeixia.hibernate.demo01.Customer" table="cst_customer">
		<!-- 建立类中的属性与表中的主键相对应 -->
		<id name="cust_id" column="cust_id">
			<!-- 主键的生成策略，后面会讲，现在使用的是本地生成策略 -->
			<generator class="native" />
		</id>
		
		<!-- 建立类中的普通属性和表中的字段相对应 -->
		<property name="cust_name" column="cust_name" />
		<property name="cust_source" column="cust_source" />
		<property name="cust_industry" column="cust_industry" />
		<property name="cust_level" column="cust_level" />
		<property name="cust_phone" column="cust_phone" />
		<property name="cust_mobile" column="cust_mobile" />
	</class>
</hibernate-mapping>

创建核心配置文件：
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE hibernate-configuration PUBLIC
	"-//Hibernate/Hibernate Configuration DTD 3.0//EN"
	"http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd">
	
<hibernate-configuration>
	<session-factory>
		<!-- 下面是三个必须要有的配置 -->
		<!-- 配置连接MySQL数据库的基本参数 -->
		<property name="hibernate.connection.driver_class">com.mysql.jdbc.Driver</property>
		<property name="hibernate.connection.url">jdbc:mysql:///hibernate_demo01</property>
		<property name="hibernate.connection.username">root</property>
		<property name="hibernate.connection.password">liayun</property>
		
		<!-- 配置Hibernate的方言 -->
		<property name="hibernate.dialect">org.hibernate.dialect.MySQLDialect</property>
		
		<!-- 下面两个是可选的配置！ -->
		<!-- 打印sql语句 -->
		<property name="hibernate.show_sql">true</property>
		<!-- 格式化sql语句 -->
		<property name="hibernate.format_sql">true</property>
		
		<!-- 告诉Hibernate的核心配置文件加载哪个映射文件 -->
		<mapping resource="com/meimeixia/hibernate/demo01/Customer.hbm.xml"/>
	</session-factory>
</hibernate-configuration>

创建单元测试类：
package com.meimeixia.hibernate.demo01;

import org.hibernate.Session;
import org.hibernate.SessionFactory;
import org.hibernate.Transaction;
import org.hibernate.cfg.Configuration;
import org.junit.Test;

/**
 * Hibernate的入门案例
 * @author 
 *
 */
public class HibernateDemo1 {
	
	//保存用户的案例
	@Test
	public void demo1() {
		//1. 加载Hibernate的核心配置文件
		Configuration configuration = new Configuration().configure();
		//如果在Hibernate的核心配置文件没有设置加载哪个映射文件，则可手动加载映射文件
		//configuration.addResource("com/meimeixia/hibernate/demo01/Customer.hbm.xml");
		
		//2. 创建SessionFactory对象，类似于JDBC中的连接池
		SessionFactory sessionFactory = configuration.buildSessionFactory();
		
		//3. 通过SessionFactory获取到Session对象，类似于JDBC中的Connection
		Session session = sessionFactory.openSession();
		
		//4. 手动开启事务，（最好是手动开启事务）
		Transaction transaction = session.beginTransaction();
		
		//5. 编写代码
		Customer customer = new Customer();
		customer.setCust_name("张小敬aaa");
		
		session.save(customer);//保存一个用户
		
		//6. 事务提交
		transaction.commit();
		
		//7. 释放资源
		session.close();
		sessionFactory.close();
	}
	
}

Struts2：
Struts2框架是一个用于开发Java EE网络应用程序的开放源代码网页应用程序架构。它利用并延伸了Java Servlet API，鼓励开发者采用MVC架构。
Struts2以WebWork优秀的设计思想为核心，吸收了Struts框架的部分优点，提供了一个更加整洁的MVC设计模式实现的Web应用程序框架。

Strut2核心过滤器：web.xml
<?xml version="1.0" encoding="UTF-8"?>
<web-app version="2.5" 
	xmlns="http://java.sun.com/xml/ns/javaee" 
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
	xsi:schemaLocation="http://java.sun.com/xml/ns/javaee 
	http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd">
  <display-name></display-name>	
  <welcome-file-list>
    <welcome-file>index.jsp</welcome-file>
  </welcome-file-list>
  
  <!-- 配置struts2的核心过滤器 -->
  <!-- 所有请求都要通过核心过滤器 -->
  <filter>
  	<filter-name>struts2</filter-name>
  	<filter-class>org.apache.struts2.dispatcher.ng.filter.StrutsPrepareAndExecuteFilter</filter-class>
  </filter>
  
  <filter-mapping>
  	<filter-name>struts2</filter-name>
  	<url-pattern>/*</url-pattern>
  </filter-mapping>
  
</web-app>

编写启动类：
package com.banana.struts.demo1;
/*
 * Struts2的Action类
 */
public class HelloAction {
	public String execute(){
		System.out.print("HelloAction执行了......");
		return "success";
	}
}

编写struts.xml来控制转向：
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE struts PUBLIC
	"-//Apache Software Foundation//DTD Struts Configuration 2.3//EN"
	"http://struts.apache.org/dtds/struts-2.3.dtd">

<struts>
	<!-- Struts2为了管理Action的配置，通过包进行管理 -->
	<!-- 配置Struts2的包 -->
	<package name="hello" extends="struts-default" namespace="/">
		<!-- 配置Action -->
		<action name="hello" class="com.banana.struts.demo1.HelloAction">
		<!-- 页面的跳转 -->
			<result name="success">/demo1/success.jsp</result>
		</action>
	</package>
</struts>

添加页面：
<%@ page language="java" import="java.util.*" pageEncoding="UTF-8"%>
<%
String path = request.getContextPath();
String basePath = request.getScheme()+"://"+request.getServerName()+":"+request.getServerPort()+path+"/";
%>

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <base href="<%=basePath%>">
    <title>My JSP 'demo1' starting page</title>
  </head>
  
  <body>
    <h1>Struts2的入门</h1>
    <h3><a href="${ pageContext.request.contextPath }/hello.action">Struts2的入门</a></h3>
  </body>
  
</html>


MVC设计模式：MVC指MVC模式的某种框架，它强制性地使应用程序的输入、处理和输出分开。
使用MVC应用程序被分成三个核心部件：模型、视图、控制器。

>M即model模型是指模型表示业务规则。在MVC的三个部件中，模型拥有最多的处理任务。即Bean层、mapper层和service层。
被模型返回的数据是中立的，模型与数据格式无关，这样一个模型能为多个视图提供数据，由于应用于模型的代码只需写一次就可以被多个视图重用，所以减少了代码的重复性。

>V即View视图是指用户看到并与之交互的界面。比如由html元素组成的网页界面，或者软件的客户端界面。
MVC的好处之一在于它能为应用程序处理很多不同的视图。在视图中其实没有真正的处理发生，它只是作为一种输出数据并允许用户操作的方式。

>C即controller控制器是指控制器接受用户的输入并调用模型和视图去完成用户的需求，控制器本身不输出任何东西和做任何处理。
它只是接收请求并决定调用哪个模型构件去处理请求，然后再确定用哪个视图来显式返回的数据。

MVC(Model模型、View视图、Control控制层)，将软件进行分层达到松耦合的效果。
通用的软件编程思想, 在MVC设计模式中认为, 任何软件都可以分三层：
控制层（Controller）、数据处理模型（Model）、负责展示数据的视图（View）。
在MVC设计思想中要求一个符合MVC设计思想的软件应该保证上面这三部分相互独立，互不干扰，每一个部分只负责自己擅长的部分。
如果某一个模块发生变化，应该尽量做到不影响其他两个模块。提高代码的可读性，实现程序间的松耦合、提高代码复用性。


SSH：
SSH框架是Struts、Spring、Hibernate的一个合成框架，目前市场上比较流行的框架中也有它的身影。
Struts是一个基于MVC模式的应用框架，如果学过Servlet,那么其本质和Servlet差不多。
MVC模式主要包括模型(Model)，视图(View)，控制器(Controller)，而Struts主要作为控制器来建立模型和视图的数据交互。
Struts通过拦截器处理客户的各种请求。Spring使用基本的JavaBean来完成以前只可能由EJB完成的事情，
Spring的核-fl，主要控制翻转(IOC)和面向切面(AOP)，简单的说Spring是一种分层的轻量级开源框架。
Spring更像是一个容器，将所有配置的Struts和Hibernate中的东西都放置进来，只要能够做好配置，它就会找到相应的位置，进行处理。
Hibernate是一个开源代码的对象映射框架，是根据JDBC技术基础衍生而来的，它将直接操作原来的数据库变为直接操作数据表后生成的Java类，
实现了对象编程思维来操纵数据库。SSH框架中的各种技术相互协调、配合。实现了这一强大的框架。


SSM：SSM（Spring+SpringMVC+MyBatis）框架集由Spring、MyBatis两个开源框架整合而成（SpringMVC是Spring中的部分内容），常作为数据源较简单的web项目的框架。

1.spring MVC ＋ spring +mybatis，是标准的MVC设计模式，将整个系统划分为显示层，Controller层，Service层，DAO层四层
使用Spring MVC负责请求的转发和视图管理
spring实现业务对象管理，mybatis作为数据对象的持久化引擎。
2、Spring是一个开源框架，Spring是一个轻量级的控制反转（IoC）和面向切面（AOP）的容器框架，还能更好的让其他框架整合。
3、Spring MVC框架是有一个MVC框架，通过实现Model-View-Controller模式来很好地将数据、业务与展现进行分离。
4、MyBatis 是一个基于Java的持久层框架


  
Java Stream：
Stream流是一种顺序的元素集合，它支持类似于SQL语句的操作，如过滤、映射、排序等。通过使用Stream流，我们可以以声明式的方式对数据进行处理，而不需要关心具体的实现细节。

Stream流的主要特点包括：
Stream流不存储数据，而是通过管道传输数据。
Stream流可以操作任何数据源，如集合、数组、I/O通道等。
Stream流可以进行串行操作和并行操作。
Java中的Stream流主要包含两种类型：中间操作和终端操作。中间操作用于对流进行一系列的转换和操作，而终端操作用于从流中获取结果。

使用Stream流可以通过以下几个步骤进行：

创建流：可以从集合、数组、I/O通道等数据源中创建Stream流。
中间操作：对流进行一系列的转换和操作，如过滤、映射、排序等。
终端操作：从流中获取结果，如聚合、收集、遍历等。


常用的 Stream 函数包括：
中间操作符：通常对于Stream的中间操作，可以视为是源的查询，并且是懒惰式的设计，对于源数据进行的计算只有在需要时才会被执行，
与数据库中视图的原理相似；Stream流的强大之处便是在于提供了丰富的中间操作，相比集合或数组这类容器，极大的简化源数据的计算复杂度
一个流可以跟随零个或多个中间操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用

1. filter(Predicate<T> predicate)：根据指定的条件过滤出符合条件的元素。
userList.stream().filter(user -> user.getId() > 6).collect(Collectors.toList());
2. map(Function<T, R> mapper)：将每个元素映射为另一个元素。
userList.stream().map(user -> user.getName() + "用户").collect(Collectors.toList());
3. flatMap(Function<T, Stream<R>> mapper)：将每个元素映射为一个 Stream，并将所有 Stream 的元素合并为一个 Stream。
userList.stream().flatMap(user -> Arrays.stream(user.getCity().split(","))).forEach(System.out::println);

map：对流中每一个元素进行处理
flatMap：流扁平化，让你把一个流中的“每个值”都换成另一个流，然后把所有的流连接起来成为一个流 
本质区别：map是对一级元素进行操作，flatmap是对二级元素操作map返回一个值；flatmap返回一个流，多个值

4. distinct()：去除重复的元素。
userList.stream().map(User::getCity).distinct().collect(Collectors.toList());
5. sorted()：对元素进行排序。
userList.stream().sorted(Comparator.comparing(User::getName).reversed()).collect(Collectors.toList()).forEach(System.out::println);
6. limit(long maxSize)：限制 Stream 的大小。
userList.stream().limit(5).collect(Collectors.toList()).forEach(System.out::println);
7. skip(long n)：跳过前 n 个元素。
userList.stream().skip(7).collect(Collectors.toList()).forEach(System.out::println);
8. peek():对元素进行遍历处理
//每个用户ID加1输出
userList.stream().peek(user -> user.setId(user.getId()+1)).forEach(System.out::println);

---------------------终端操作符-----------------------------------------------------------------
终端操作符：Stream流执行完终端操作之后，无法再执行其他动作，否则会报状态异常，提示该流已经被执行操作或者被关闭，
想要再次执行操作必须重新创建Stream流。一个流有且只能有一个终端操作，当这个操作执行后，流就被关闭了，无法再被操作，
因此一个流只能被遍历一次，若想在遍历需要通过源数据在生成流。

9. forEach(Consumer<T> action)：对每个元素执行指定的操作。
userList.stream().forEach(user -> System.out.println(user));
userList.stream().filter(user -> "上海".equals(user.getCity())).forEach(System.out::println);
10. collect(Collector<T, A, R> collector)：收集器，将流转换为其他形式。
Set set = userList.stream().collect(Collectors.toSet());
List list = userList.stream().collect(Collectors.toList());
11. findFirst():返回第一个元素
User firstUser = userList.stream().findFirst().get();
User firstUser1 = userList.stream().filter(user -> "上海".equals(user.getCity())).findFirst().get();        
12. findAny():返回当前流中的任意元素
User findUser = userList.stream().findAny().get();
User findUser1 = userList.stream().filter(user -> "上海".equals(user.getCity())).findAny().get();
13. count():返回流中元素总数
long count = userList.stream().filter(user -> user.getAge() > 20).count();		
14. sum():求和
int sum = userList.stream().mapToInt(User::getId).sum();
15. max():最大值
int max = userList.stream().max(Comparator.comparingInt(User::getId)).get().getId();
16. min():最小值
int min = userList.stream().min(Comparator.comparingInt(User::getId)).get().getId();
17. anyMatch():检查是否至少匹配一个元素，返回boolean
boolean matchAny = userList.stream().anyMatch(user -> "北京".equals(user.getCity()));
18. allMatch():检查是否匹配所有元素，返回boolean
boolean matchAll = userList.stream().allMatch(user -> "北京".equals(user.getCity()));
19. noneMatch():检查是否没有匹配所有元素，返回boolean
boolean nonaMatch = userList.stream().allMatch(user -> "云南".equals(user.getCity()));
20.reduce():可以将流中元素反复结合起来，得到一个值
Optional reduce = userList.stream().reduce((user, user2) -> {
    return user;
});


		
通过使用这些函数，可以简化代码、提高效率，并且使代码更加易读和可维护。

Java反射：
反射是作为动态语言的关键，反射机制允许程序在执行期借助于Reflection API取得任何类的内部信息，并能直接操作任意对象的内部属性和方法。

动态语言和静态语言概念：
动态类型语言：动态类型语言是指在运行期间才去做数据类型检查的语言，也就是说，在用动态类型的语言编程时，永远也不用给任何变量指定数据类型（变量使用之前不需要类型声明），该语言会在你第一次赋值给变量时，在内部将数据类型记录下来。
Python 和 Ruby 就是一种典型的动态类型语言，其他的各种脚本语言如 JavaScript 、Shell也属于动态类型语言。
静态类型语言：静态类型语言与动态类型语言刚好相反，它的数据类型是在编译其间检查的，也就是说在写程序时要声明所有变量的数据类型，C/C++ 是静态类型语言的典型代表，其他的静态类型语言还有 C#、JAVA 、golang等。
总结：静态类型和动态类型的本质区别在于：变量的数据类型确定的时机不同，前者在运行时根据变量值确定；后者在编译时根据声明类型确定。

Java反射概述：
>Java反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；
对于任意一个对象，都能够调用它的任意一个方法和属性；
这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。
>要想解剖一个类,必须先要获取到该类的字节码文件对象。而解剖使用的就是Class类中的方法。
所以先要获取到每一个字节码文件对应的Class类型的对象。
>比如之前在没有使用反射的时候，我们这里有一个类，如果我们想要调用里面的属性、方法等，
我们要先创建一个对象，才可以调用里面的属性等。
>类似的，我们如果使用反射，想要使用一个类的成员变量，方法，构造器等，我们就要先获取一个Class对象，
这个Class对象里面有类的成员变量，方法等信息，这样我们才可以进行相关的操作。
>正因为反射是在运行时获取类的信息，所以用反射去获取类的注解时只能获取到运行时的注解。

Class 类：反射的核心类，可以获取类的属性，方法等信息。
Field 类：Java.lang.reflec 包中的类，表示类的成员变量，可以用来获取和设置类之中的属性值。
Method 类： Java.lang.reflec 包中的类，表示类的方法，它可以用来获取类中的方法信息或 者执行方法。
Constructor 类： Java.lang.reflec 包中的类，表示类的构造方法。

getFields():获取当前运行时类及父类中声明为public访问权限的属性
getDeclaredFields()：获取当前运行时类中声明的所有属性（不包括父类）
getMethods():获取当前运行时类及其父类中声明为public的方法
	

注解、反射、动态代理→ Java Spring  
JavaBean:JavaBean 是一种JAVA语言写成的可重用组件。为写成JavaBean，类必须是具体的和公共的，并且具有无参数的构造器。
JavaBean 通过提供符合一致性设计模式的公共方法将内部域暴露成员属性，set和get方法获取。

作用：JavaBean是一种可重用的Java组件，它可以被Applet、Servlet、JSP等Java应用程序调用。
也可以可视化地被Java开发工具使用。它包含属性(Properties)、方法(Methods)、事件(Events)等特性。

Java注解：
生成文档，通过代码里标识的元数据生成javadoc文档。
编译检查，通过代码里标识的元数据让编译器在编译期间进行检查验证。
编译时动态处理，编译时通过代码里标识的元数据动态处理，例如动态生成代码。
运行时动态处理，运行时通过代码里标识的元数据动态处理，例如使用反射注入实例。

四种元注解：
 ▷ Retention：指定注解的作用范围，三种 SOURCE,CLASS,RUNTIME
 ▷ Target：指定注解可以在哪些地方使用
 ▷ Documented ：指定该注解是否会在 javadoc 体现
 ▷ Inherited：子类会继承父类注解

注解的注意事项：
▷ 注解仅存在于源码中，在class字节码文件中不包含
▷ 默认的保留策略，注解会在class字节码文件中存在，但运行时无法获得，
▷ 注解会在class字节码文件中存在，在运行时可以通过反射获取到
▷ 首先要明确生命周期长度 SOURCE < CLASS < RUNTIME ，前者能作用的地方后者一定也能作用。
        ①：一般如果需要在 运行时去动态获取注解信息，那只能用 RUNTIME 注解；
        ②：如果要在 编译时进行一些预处理操作，比如生成一些辅助代码（如 ButterKnife），就用 CLASS注解；
        ③：如果只是做一些 检查性的操作如 @Override 和 @SuppressWarnings，则可选用 SOURCE 注解。

		
Retention注解：
只能用于修饰一个 Annotation 定义, 用于指定该 Annotation 可以保留多长时间,
@Rentention 包含一个 RetentionPolicy 类型的成员变量, 使用 @Rentention 时必须为该 value 成员变量指定值（值有三种）。
▲ 三种值：
▷ RetentionPolicy.SOURCE: 编译器使用后，直接丢弃这种策略的注释。
▷ RetentionPolicy.CLASS: 编译器将把注解记录在 class 文件中。当运行 Java 程序时 , JVM 不会保留注解。 这是默认值。
▷ RetentionPolicy.RUNTIME: 编译器将把注解记录在 class 文件中。当运行 Java 程序时 , JVM 会保留注解。程序可以通过反射获取该注解。

3、Target 注解
用于修饰 Annotation 定义，指定被修饰的 Annotation 能用于修饰哪些程序元素。@Target 也包含一个名为 value 的成员变量。

​​​​​​4、Documented 注解
@Documented: 用于指定被该元注解修饰的 Annotation 类将被javadoc 工具提取成文档，即在生成文档时，可以看到该注解。
注意：
定义为@Documented 的注解必须设置Retention值为RUNTIME。

5、Inherited 注解
被@Inherited 修饰的注解 将具有继承性，如果某个类使用了被 @Inherited修饰的注解，则其子类将自动具有该注解
	
Java动态代理：
代理类在程序运行时创建的代理方式被成为动态代理。在静态代理中，代理类（RenterProxy）是自己已经定义好了的，在程序运行之前就已经编译完成。
而动态代理是在运行时根据我们在Java代码中的“指示”动态生成的。Java运用了反射实现了动态代理。
动态代理相较于静态代理的优势在于可以很方便的对代理类的所有函数进行统一管理，如果我们想在每个代理方法前都加一个方法，如果代理方法很多，我们需要在每个代理方法都要写一遍，很麻烦。而动态代理则不需要。
代码实现：创建RenterInvocationHandler类，这个类实现了InvocationHandler接口，并持有一个被代理类的对象，InvocationHandler中有一个invoke方法，所有执行代理对象的方法都会被替换成执行invoke方法。
然后通过反射在invoke方法中执行代理类的方法。在代理过程中，在执行代理类的方法前或者后可以执行自己的操作，这就是spring aop的主要原理。

动态代理之Cglib代理：
动态代理需要被代理类实现接口，如果被代理类没有实现接口，那么这么实现动态代理？这时候就需要用到CGLib了。这种代理方式就叫做CGlib代理。
Cglib代理也叫作子类代理，他是通过在内存中构建一个子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，然后加入自己需要的操作。因为使用的是继承的方式，所以不能代理final 类
动态代理与CGLib动态代理都是实现Spring AOP的基础。如果加入容器的目标对象有实现接口,用动态代理，如果目标对象没有实现接口,用Cglib代理。

动态代理的运用：Spring

Java Spring：
Spring 框架就像一个家族，有众多衍生产品例如 boot、security、jpa等等。但他们的基础都是Spring 的 ioc和 aop ioc 提供了依赖注入的容器 aop ，解决了面向横切面的编程，然后在此两者的基础上实现了其他延伸产品的高级功能。
Spring MVC是基于 Servlet 的一个 MVC 框架 主要解决 WEB 开发的问题，因为 Spring 的配置非常复杂，各种XML、 JavaConfig、hin处理起来比较繁琐。于是为了简化开发者的使用，从而创造性地推出了Spring boot，约定优于配置，简化了spring的配置流程。
Spring的工作原理其实是，Spring在启动时读取bean配置信息，这里bean配置信息包括xml文件、Java类#Configuration、注解#AutoWired，存放到Bean注册表，并根据Bean注册表实例化Bean，实际上就是实例化Bean的实现类，然后将Bean实例放到Spring容器中。

Spring的IOC是通过反射来实现的：
在Spring中，通过IOC可以将实现类、参数信息等配置在其对应的配置文件中，当需要更改实现类或参数信息时，只需要修改配置文件即可。
Spring的IOC实现原理利用的就是Java的反射机制，Spring的工厂类会帮我们完成配置文件的读取、利用反射机制注入对象等工作，我们可以通过bean的名称获取对应的对象。

使用XML配置获取Bean的方式：
在Spring框架中，XML配置文件是一种传统的配置方式，用于定义和管理应用程序中的Bean。通过XML配置文件，我们可以定义Bean的属性、构造函数参数、依赖关系以及其他相关配置。
以下是使用XML配置文件在Spring中获取Bean的详细步骤：

创建XML配置文件
首先，需要创建一个XML配置文件，通常命名为applicationContext.xml或beans.xml，并将其放在类路径下（如src/main/resources目录）。

<?xml version="1.0" encoding="UTF-8"?>  
<beans xmlns="http://www.springframework.org/schema/beans"  
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"  
       xsi:schemaLocation="http://www.springframework.org/schema/beans  
       http://www.springframework.org/schema/beans/spring-beans.xsd">  
  
    <!-- Bean定义 -->  
    <bean id="myBean" class="com.example.MyBeanClass">  
        <property name="propertyName" value="propertyValue" />  
        <property name="anotherBean" ref="anotherBeanId" />  
    </bean>
</beans>

加载XML配置文件
在Java代码中，需要加载XML配置文件来创建Spring IoC容器。通常使用ClassPathXmlApplicationContext或FileSystemXmlApplicationContext类来加载配置文件。

import org.springframework.context.ApplicationContext;  
import org.springframework.context.support.ClassPathXmlApplicationContext;  
  
public class MyApp {  
    public static void main(String[] args) {  
        ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml");  
          
        // 获取Bean  
        MyBeanClass myBean = (MyBeanClass) context.getBean("myBean");  
          
        // 使用Bean  
        myBean.doSomething();  
    }  
}

在上面的示例中，ClassPathXmlApplicationContext用于加载名为applicationContext.xml的XML配置文件，并创建Spring IoC容器。
然后，通过调用context.getBean("myBean")方法，我们获取了id为myBean的Bean的实例，并将其转型为MyBeanClass类型。最后，我们可以调用Bean的方法来进行业务逻辑处理。

注意：XML配置方式虽然直观且易于理解，但在大型项目中可能会显得繁琐和难以维护。
因此，许多现代Spring项目倾向于使用基于Java的配置（如使用@Configuration和@Bean注解），这样可以更好地利用Java的类型安全性和IDE的支持。
不过，XML配置仍然是一个有效且被广泛使用的选择，特别是对于那些更喜欢XML格式或者需要在没有Java源代码访问权限的情况下进行配置的场景。


使用注解管理Bean的方式：
在Spring框架中，注解（Annotation）提供了一种声明式的方式来管理Bean，而不是传统的基于XML的配置方式。通过使用注解，你可以更简洁、更直接地在Java代码中定义和管理Bean。

以下是在Spring中使用注解管理Bean的一些关键步骤：

启用注解支持：
要在Spring中启用注解支持，你需要在Spring配置文件中添加<context:annotation-config/>标签，或者在Java配置中使用@Configuration和@EnableAnnotationConfiguration注解（如果你使用的是较新版本的Spring，通常只需添加@Configuration注解）。

<!-- 在XML配置中启用注解 -->  
<beans xmlns="http://www.springframework.org/schema/beans"  
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"  
       xmlns:context="http://www.springframework.org/schema/context"  
       xsi:schemaLocation="http://www.springframework.org/schema/beans  
       http://www.springframework.org/schema/beans/spring-beans.xsd  
       http://www.springframework.org/schema/context  
       http://www.springframework.org/schema/context/spring-context.xsd">  
  
    <context:annotation-config/>  
  
    <!-- 其他bean定义 -->  
</beans>

或者，在Java配置中：

@Configuration  
public class AppConfig {  
    // ... 其他配置 ...  
}


使用@Component及其衍生注解：
Spring提供了几个注解来标记组件类，使其作为Bean被Spring容器管理。这些注解包括@Component、@Service、@Repository和@Controller。它们都是@Component的特化版本，用于表示不同类型的组件。

@Component：通用组件，可以标记任何Spring管理的组件。
@Service：用于标记业务逻辑组件。
@Repository：用于标记数据访问组件，如DAO。
@Controller：用于标记Web层的组件（在Spring MVC中）。

示例：
@Service  
public class MyService {  
    // ... 服务实现 ...  
}

自动装配：
Spring的@Autowired注解用于自动装配bean之间的依赖关系。Spring容器会自动查找匹配的bean并注入到相应的字段或方法中。

示例：
@Service  
public class MyService {  
    private final MyRepository myRepository;  
  
    @Autowired  
    public MyService(MyRepository myRepository) {  
        this.myRepository = myRepository;  
    }  
}

使用@Qualifier解决歧义：
当存在多个相同类型的bean时，可以使用@Qualifier注解来指定要注入的bean的名称。

示例：
@Autowired  
@Qualifier("specificBeanName")  
private MyBean myBean;

使用@Scope定义作用域：
@Scope注解用于定义bean的作用域。默认的作用域是singleton，但也可以设置为prototype、request、session等。

示例：
@Service  
@Scope("prototype")  
public class MyPrototypeService {  
    // ... 服务实现 ...  
}
使用@Resource和@Inject：
除了@Autowired，你还可以使用JSR-250的@Resource注解或JSR-330的@Inject注解来进行依赖注入。这些注解提供了与@Autowired类似的功能，但具有一些不同的特性和用法。

7. 自定义注解和Bean定义：
你还可以创建自定义的注解，并使用@Bean方法在Java配置类中定义bean。这提供了一种更灵活的方式来定义和注册bean。

8. 使用@ComponentScan扫描组件：
@ComponentScan注解用于指定Spring应该扫描哪个包以查找带有@Component、@Service、@Repository和@Controller注解的类，并将它们注册为bean。你可以将其添加到配置类上。

9. 使用Java配置类替代XML：
除了使用注解标记组件类，你还可以使用Java配置类完全替代XML配置文件。这通过@Configuration类和使用@Bean方法来实现。这种方法提供了更类型安全和更强大的配置能力。


问：Spring里的注解@AutoWired和@Resource注解有什么区别
Spring框架中的@Autowired和@Resource注解都是用于依赖注入的，但它们之间存在一些重要的区别：

>来源不同：@Autowired是Spring框架提供的注解，主要用于实现Spring框架中的依赖注入功能。而@Resource是Java EE规范中的注解，它是JSR-250规范的一部分，因此在Java EE和Spring中都可以使用。
查找顺序不同：当Spring容器进行依赖注入时，@Autowired首先会尝试按类型（byType）查找匹配的bean，如果找到多个同类型的bean，则会根据bean的名称（name）或@Qualifier注解来进一步确定。
而@Resource的查找顺序则相反，它首先会按名称（byName）查找，如果找不到匹配的bean，则会根据类型查找。

>支持的参数不同：@Autowired只有一个可选参数required，表示是否自动装配。如果设置为false，那么在找不到匹配的bean时，不会抛出异常。
而@Resource可以设置更多的参数，包括name、type、authenticationType、mappedName、shareable和lookup等，提供了更丰富的配置选项。

>依赖注入的用法支持不同：@Autowired支持构造方法注入、属性注入和Setter方法注入。而@Resource只支持属性注入和Setter方法注入，不支持构造方法注入。
>IDEA编译器的提示不同：在IntelliJ IDEA等集成开发环境中，当使用@Autowired注解注入Mapper对象时，可能会收到关于找不到bean的警告或错误提示。而使用@Resource注解时，通常不会出现此类问题。

总结来说，@Autowired和@Resource都是Spring中用于实现依赖注入的注解，但它们在来源、查找顺序、支持的参数、用法支持和IDE提示等方面存在区别。
在选择使用哪个注解时，可以根据项目的具体需求和上下文环境进行考虑。


Spring AOP（Aspect-Oriented Programming）是面向切面编程的一种实现技术，主要用于实现程序功能的统一维护。
Spring AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。
Spring AOP的三种使用方式：

注解方式：通过注解的方式配置切入点，然后定义增强处理。
XML方式：通过XML配置文件的方式配置切入点，然后定义增强处理。
Java方式：通过Java配置类的方式配置切入点，然后定义增强处理。


Spring AOP是运用反射来实现的：
Spring AOP即面向切面编程，是Spring核心之一，其可以快速横向扩展。在Spring中，每一个代理实例都有一个关联的调用处理程序对象，它实现了接口InvocationHandler，该接口的invoke方法用于处理代理实例上的方法调用。
在Spring中，当需要使用该Service时，Spring会自动将对应的Bean注入到需要它的地方，这个过程是自动的，对于开发人员来说是透明的，无需手动进行配置。

SpringAOP创建步骤：
1.需要先自定义一个注解
package com.itheima.anno;
import java.lang.annotation.ElementType ;
import java.lang.annotation.Retention;
import java.lang.annotation.RetentionPolicy
import java.lang.annotation.Target;
@Retention(RetentionPolicy.RUNTIME)
@sarget(ElementType.METHOD)
public @interface Log{

}

2.创建切面类
@Slf4j
@Component
@Aspect //切新类
public class LogAspect {

@Autowired
private HttpServletRequest request;

@Autowired
private perateLogMapper operateLogMapper;

@Around("@annotation(com.itheima.anno.Log)")
public Obiect recordLog(ProceedingdoinPoint joinPoint) throws Throwable {
//操作人ID-当前登录员工ID
//获取请求头中的iwt令牌，解析令牌
String jwt=request.getHeader(name: "token");
Claims claims=JwtUtils.parseuWT(jwt);
Integer operateUser =(Integer)claims.get("id");
//操作时间
LocalDateTime operateTime = LocalDateTime.now();
//操作类名
String className = joinPoint.getTarget().getclass().getName ();
//操作方法名
String methodName = joinPoint.getSignature().getName ();
//操作方法参数
Object result =joinPoint.proceed();
String methodParams =Arrays.tostring(args);
long begin =System.currentTimeMillis();//调用原始目标方法运行
long end=System.currentTimeMillis();
//方法返回值
String returnValue = JsONObject.touSONstring(result);
//操作耗时
Long costTime =end-begin;
//记录操作日志
OperateLog operateLog = new OperateLog( id: null,operateUser,operaoperate,operateTime,className,methodName,methodName,returnValue,costTime)
LogMapper.insert(operateLog);
log.info("AOP记录操作日志:{}"operateLog);
return result;
    }
}
3.在需要的方法上添加注解


SpringMVC：
SpringMVC是一个基于Java的Web应用开发框架，用于构建灵活、可扩展的Web应用程序。它是Spring框架的一部分，提供了一种模型-视图-控制器（MVC）的架构模式，用于将应用程序的不同方面分离开来。
SpringMVC使用了前端控制器（Front Controller）设计模式，其中DispatcherServlet充当中央调度器，负责接收所有的客户端请求并将其分派给相应的处理程序（Controller）。
它还提供了丰富的功能，如请求映射、数据绑定、数据验证、视图解析和国际化支持等，以简化Web应用程序的开发过程。
通过使用SpringMVC，开发人员可以轻松地构建可维护和可扩展的Web应用程序，实现松耦合和高度可测试性。它还与其他Spring框架模块（如Spring IoC和Spring AOP）紧密集成，提供了全面的企业级开发解决方案。

SpringMVC中所有的请求都会封装成ModelAndView

Spring MVC的功能
Spring MVC提供了一种轻度耦合的方式来开发web应用。
Spring MVC是Spring的一个模块，是一个web框架。通过Dispatcher Servlet, ModelAndView 和 View Resolver，开发web应用变得很容易。
解决的问题领域是网站应用程序或者服务开发——URL路由、Session、模板引擎、静态Web资源等等。

在SpringMVC中设置配置文件：
在Spring MVC中，配置文件通常是用来设置各种bean、定义URL映射、配置视图解析器、设置拦截器等。这些配置可以放在XML文件中，或者在现代的Spring Boot应用中，也可以使用Java配置类来替代XML配置。

以下是使用XML配置文件配置Spring MVC的示例：

创建Spring MVC配置文件：
首先，你需要在你的项目资源目录下（通常是src/main/resources）创建一个XML配置文件，例如spring-mvc-servlet.xml。

配置DispatcherServlet：
DispatcherServlet是Spring MVC的核心组件，它负责接收HTTP请求，并将其分发给相应的控制器处理。

<beans xmlns="http://www.springframework.org/schema/beans"  
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"  
       xsi:schemaLocation="http://www.springframework.org/schema/beans  
       http://www.springframework.org/schema/beans/spring-beans.xsd  
       http://www.springframework.org/schema/context  
       http://www.springframework.org/schema/context/spring-context.xsd">  
  
    <!-- 配置DispatcherServlet -->  
    <bean class="org.springframework.web.servlet.DispatcherServlet"  
          id="dispatcherServlet">  
        <property name="contextConfigLocation" value="/WEB-INF/spring-mvc-servlet.xml"/>  
    </bean>  
  
    <!-- 配置Servlet映射 -->  
    <bean class="org.springframework.web.servlet.handler.SimpleUrlHandlerMapping">  
        <property name="mappings">  
            <props>  
                <prop key="/hello.do">helloController</prop>  
            </props>  
        </property>  
    </bean>  
  
    <!-- 配置控制器 -->  
    <bean id="helloController" class="com.example.HelloController"/>  
  
    <!-- 配置视图解析器 -->  
    <bean class="org.springframework.web.servlet.view.InternalResourceViewResolver">  
        <property name="prefix" value="/WEB-INF/views/"/>  
        <property name="suffix" value=".jsp"/>  
    </bean>  
  
    <!-- 其他配置，例如拦截器、消息转换器等 -->  
  
</beans>
在web.xml中配置DispatcherServlet
你还需要在web.xml中配置Servlet容器来加载并映射DispatcherServlet。


<web-app ...>  
    <servlet>  
        <servlet-name>dispatcherServlet</servlet-name>  
        <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>  
        <init-param>  
            <param-name>contextConfigLocation</param-name>  
            <param-value>/WEB-INF/spring-mvc-servlet.xml</param-value>  
        </init-param>  
        <load-on-startup>1</load-on-startup>  
    </servlet>  
  
    <servlet-mapping>  
        <servlet-name>dispatcherServlet</servlet-name>  
        <url-pattern>*.do</url-pattern>  
    </servlet-mapping>  
</web-app>

在现代的Spring Boot应用中，推荐使用Java配置类来代替XML配置，因为Java配置提供了类型安全、重构支持以及更简洁的配置方式。以下是Java配置类的简单示例：

java
import org.springframework.context.annotation.ComponentScan;  
import org.springframework.context.annotation.Configuration;  
import org.springframework.web.servlet.config.annotation.EnableWebMvc;  
import org.springframework.web.servlet.config.annotation.ViewResolverRegistry;  
import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;  
import org.springframework.web.servlet.view.InternalResourceViewResolver;  
  
@Configuration  
@EnableWebMvc  
@ComponentScan(basePackages = "com.example")  
public class WebConfig implements WebMvcConfigurer {  
  
    @Override  
    public void configureViewResolvers(ViewResolverRegistry registry) {  
        registry.jsp().prefix("/WEB-INF/views/").suffix(".jsp");  
    }  
  
    // 其他配置方法，例如配置拦截器、消息转换器等  
  
}

注：在Spring Boot应用中，通常不需要在web.xml中配置Servlet，因为Spring Boot会自动配置并注册DispatcherServlet。你只需要将Java配置类放在Spring Boot的主配置类所在的包或子包中，或者在主配置类上使用@Import注解来导入Java配置类。

Spring MVC获取请求参数的过程：
1、通过ServletAPI获取
将HttpServletRequest作为控制器方法的形参，此时HttpServletRequest类型的参数表示封装了当前请求的请求报文的对象
@RequestMapping("/testParam")
public String testParam(HttpServletRequest request){
String username = request.getParameter("username");
String password = request.getParameter("password");
System.out.println("username:"+username+",password:"+password);
return "success";
}

2、通过控制器方法的形参获取请求参数
在控制器方法的形参位置，设置和请求参数同名的形参，当浏览器发送请求，匹配到请求映射时，在DispatcherServlet中就会将请求参数赋值给相应的形参

<a th:href="@{/testRest/1/admin}">测试路径中的占位符-->/testRest</a><br>
@RequestMapping("/testRest/{id}/{username}")

@RequestMapping("/testParam")
public String testParam(String username, String password){
System.out.println("username:"+username+",password:"+password);
return "success";
}


注：
若请求所传输的请求参数中有多个同名的请求参数，此时可以在控制器方法的形参中设置字符串
数组或者字符串类型的形参接收此请求参数
若使用字符串数组类型的形参，此参数的数组中包含了每一个数据
若使用字符串类型的形参，此参数的值为每个数据中间使用逗号拼接的结果

3、@RequestParam
@RequestParam是将请求参数和控制器方法的形参创建映射关系
@RequestParam注解一共有三个属性：
value：指定为形参赋值的请求参数的参数名
required：设置是否必须传输此请求参数，默认值为true
若设置为true时，则当前请求必须传输value所指定的请求参数，若没有传输该请求参数，且没有设置
defaultValue属性，则页面报错400：Required String parameter 'xxx' is not present；若设置为
false，则当前请求不是必须传输value所指定的请求参数，若没有传输，则注解所标识的形参的值为
null
defaultValue：不管required属性值为true或false，当value所指定的请求参数没有传输或传输的值
为""时，则使用默认值为形参赋值

4、@RequestHeader
@RequestHeader是将请求头信息和控制器方法的形参创建映射关系
@RequestHeader注解一共有三个属性：value、required、defaultValue，用法同@RequestParam

5、@CookieValue
@CookieValue是将cookie数据和控制器方法的形参创建映射关系
@CookieValue注解一共有三个属性：value、required、defaultValue，用法同@RequestParam

6、通过POJO获取请求参数
可以在控制器方法的形参位置设置一个实体类类型的形参，此时若浏览器传输的请求参数的参数名和实体类中的属性名一致，那么请求参数就会为此属性赋值

7、解决获取请求参数的乱码问题
解决SpringMVC中的乱码问题通常涉及到对请求和响应的字符编码进行统一设置。通过配置过滤器、SpringMVC消息转换器或者在Controller中指定编码，可以有效地避免乱码问题的出现。同时，也需要确保客户端和数据库连接使用的字符集与服务器端设置一致。

Spring MVC的工作流程：
1.客户端发送请求：当客户端（如浏览器）发起一个HTTP请求时，它会通过URL地址和请求方法（如GET、POST等）来向服务器发送请求。
2.DispatcherServlet接收请求：在Spring MVC中，所有的请求都会先经过一个称为DispatcherServlet的中央控制器。当请求到达服务器后，Servlet容器会将请求交给DispatcherServlet进行处理。
3.HandlerMapping寻找处理器：DispatcherServlet会调用HandlerMapping来确定请求对应的处理器（Handler）。HandlerMapping会根据请求的URI等信息，找到匹配的Controller。
4.Controller处理请求：一旦确定了请求对应的处理器，DispatcherServlet就会将请求转发给目标Controller。Controller会执行相应的业务逻辑，并返回一个ModelAndView对象。这个对象包含了视图需要的数据以及要使用的视图名称。
5.ModelAndView处理：DispatcherServlet接收到Controller返回的ModelAndView对象后，会进一步处理。它会提取Model中的数据，准备用于视图的渲染。
6.视图解析：DispatcherServlet通过ViewResolver视图解析器找到对应的视图对象View。ViewResolver会根据ModelAndView对象中的视图名称，解析出具体的视图实现。
7.视图渲染：视图对象View负责渲染模型数据，生成最终的响应内容。这通常涉及到将模型数据填充到视图的模板中，生成HTML、JSON或其他格式的响应。
8.返回响应给客户端：视图渲染完成后，DispatcherServlet会将响应返回给客户端，客户端（如浏览器）会接收到这个响应并展示给用户。

以下组件通常使用框架提供实现：

DispatcherServlet：作为前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。
HandlerMapping：通过扩展处理器映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。
HandlAdapter：通过扩展处理器适配器，支持更多类型的处理器。
ViewResolver：通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。


域对象共享数据
1、使用ServletAPI向request域对象共享数据
<form th:action="@{/testpojo}" method="post">
用户名：<input type="text" name="username"><br>
密码：<input type="password" name="password"><br>
性别：<input type="radio" name="sex" value="男">男<input type="radio"
name="sex" value="女">女<br>
年龄：<input type="text" name="age"><br>
邮箱：<input type="text" name="email"><br>
<input type="submit">
</form>
@RequestMapping("/testpojo")
public String testPOJO(User user){
System.out.println(user);
return "success";
}
//最终结果-->User{id=null, username='张三', password='123', age=23, sex='男',
email='123@qq.com'}
<!--配置springMVC的编码过滤器-->
<filter>
<filter-name>CharacterEncodingFilter</filter-name>
<filterclass>org.springframework.web.filter.CharacterEncodingFilter</filter-class>
<init-param>
<param-name>encoding</param-name>
<param-value>UTF-8</param-value>
</init-param>
<init-param>
<param-name>forceResponseEncoding</param-name>
<param-value>true</param-value>
</init-param>
</filter>
<filter-mapping>
<filter-name>CharacterEncodingFilter</filter-name>
<url-pattern>/*</url-pattern>
</filter-mapping>
注：
SpringMVC中处理编码的过滤器一定要配置到其他过滤器之前，否则无效

总结：
SpringMVC本质上是对Java Web Servlet的封装，使得开发Java Web项目没有那么臃肿。
SpringMVC是后端渲染式的后台开发框架，没有做到前后端分离，对前端开发人员也要求有Java Web的开发环境。
前端人员作出的静态Html页面，也需要进行整合，改为Spring MVC里的View。
	
使用SpringMVC进行文件上传：
在Spring MVC中，文件上传通常使用MultipartFile接口来实现。以下是一个简单的步骤，指导你如何在Spring MVC中实现文件上传功能：

添加依赖
确保你的pom.xml中包含了Spring MVC和Apache Commons FileUpload的依赖。

<dependencies>  
    <!-- Spring MVC -->  
    <dependency>  
        <groupId>org.springframework.boot</groupId>  
        <artifactId>spring-boot-starter-web</artifactId>  
    </dependency>  
      
    <!-- Apache Commons FileUpload -->  
    <dependency>  
        <groupId>commons-fileupload</groupId>  
        <artifactId>commons-fileupload</artifactId>  
        <version>1.4</version>  
    </dependency>  
</dependencies>

配置Spring MVC
在你的Spring MVC配置中，确保已经配置了MultipartResolver。如果你使用Spring Boot，它通常会为你自动配置。

创建文件上传表单
在HTML中，创建一个包含enctype="multipart/form-data"属性的表单，以便能够上传文件。

<form method="POST" action="/upload" enctype="multipart/form-data">  
    <input type="file" name="file" />  
    <input type="submit" value="Upload" />  
</form>

处理文件上传的Controller
在Spring MVC的Controller中，使用@RequestParam注解来获取上传的文件。

java
import org.springframework.http.HttpStatus;  
import org.springframework.http.ResponseEntity;  
import org.springframework.web.bind.annotation.PostMapping;  
import org.springframework.web.bind.annotation.RequestParam;  
import org.springframework.web.bind.annotation.RestController;  
import org.springframework.web.multipart.MultipartFile;  
  
import java.io.File;  
import java.io.IOException;  
  
@RestController  
public class FileUploadController {  
  
    private static final String UPLOADED_FOLDER = "/tmp/";  
  
    @PostMapping("/upload")  
    public ResponseEntity<?> handleFileUpload(@RequestParam("file") MultipartFile file) {  
        if (file.isEmpty()) {  
            return new ResponseEntity<>("Please select a file to upload.", HttpStatus.BAD_REQUEST);  
        }  
  
        try {  
            byte[] bytes = file.getBytes();  
            File dest = new File(UPLOADED_FOLDER + file.getOriginalFilename());  
            dest.createNewFile();  
            java.nio.file.Files.write(dest.toPath(), bytes);  
            return new ResponseEntity<>("File uploaded successfully!", HttpStatus.OK);  
        } catch (IOException e) {  
            e.printStackTrace();  
        }  
        return new ResponseEntity<>("Failed to upload file!", HttpStatus.INTERNAL_SERVER_ERROR);  
    }  
}
在这个例子中，文件将被上传到服务器的/tmp/目录下。你可以根据需要更改这个路径。注意，这个路径应该是你的应用有写权限的目录。

使用SpringMVC实现文件下载：
import org.springframework.core.io.FileSystemResource;  
import org.springframework.core.io.Resource;  
import org.springframework.http.HttpHeaders;  
import org.springframework.http.MediaType;  
import org.springframework.http.ResponseEntity;  
import org.springframework.web.bind.annotation.GetMapping;  
import org.springframework.web.bind.annotation.PathVariable;  
import org.springframework.web.bind.annotation.RestController;  
import org.springframework.web.servlet.support.ServletUriComponentsBuilder;  
  
import java.io.IOException;  
import java.nio.file.Files;  
import java.nio.file.Path;  
import java.nio.file.Paths;  
  
@RestController  
public class FileDownloadController {  
  
    private static final String FILE_DIR = "/files/";  
  
    @GetMapping("/download/{filename:.+}")  
    public ResponseEntity<Resource> downloadFile(@PathVariable String filename) {  
        Path filePath = Paths.get(FILE_DIR + filename);  
  
        Resource resource = null;  
        try {  
            if (Files.exists(filePath)) {  
                resource = new FileSystemResource(filePath);  
            } else {  
                // 如果文件不存在，可以返回一个错误信息  
                return ResponseEntity.notFound().build();  
            }  
        } catch (Exception e) {  
            e.printStackTrace();  
            return ResponseEntity.internalServerError().build();  
        }  
  
        // 设置响应头  
        HttpHeaders headers = new HttpHeaders();  
        headers.add(HttpHeaders.CONTENT_DISPOSITION, "attachment; filename=" + resource.getFilename());  
        headers.add(HttpHeaders.CACHE_CONTROL, "no-cache, no-store, must-revalidate");  
        headers.add(HttpHeaders.PRAGMA, "no-cache");  
        headers.add(HttpHeaders.EXPIRES, "0");  
  
        return ResponseEntity.ok()  
                .headers(headers)  
                .contentType(MediaType.parseMediaType("application/octet-stream"))  
                .body(resource);  
    }  
}


Java JVM：
Java虚拟机(Jvm)是可运行Java代码的假想计算机。Java虚拟机包括一套字节码指令集、一组寄存器、一个栈、一个垃圾回收堆和一个存储方法域。
JVM让Java成为跨平台语言，Java有JVM从软件层面屏蔽了底层硬件、指令层面的细节让他兼容各种系统。

Java虚拟机主要由以下几个部分组成：
1.虚拟机栈。每个线程都在这个空间有一个私有的空间，每个线程会执行一个或多个方法，一个方法对应一个栈帧，栈帧包括局部变量表、操作数栈、动态链接、方法返回地址、附加信息等。
2.堆。所有线程共享的内存区域，用于存放对象实例和数组。
3.方法区。用于存放已被虚拟机加载的类信息、常量、静态变量等数据。
4.程序计数器。用于保存当前线程所执行的字节码指令的行号。


Javac的编译过程：
Javac编译过程主要包括四个步骤：词法分析、语法分析、语义分析和代码生成。词法分析器逐行读取源代码，
将源代码匹配到Token流，识别每一个单词是什么东西；语法分析器将Token流转换成更加结构化的语法树；
语义分析器对语法树进行精简和处理；代码生成器将语法树生成java字节码。


JVM的原理：				
Java源文件，通过编译器，能够生产相应的.Class文件，也就是字节码文件，而字节码文件又通过Java虚拟机中的解释器，
也就是前面所有的Java虚拟机中的字节码指令集编译成特定机器上的机器码
实现步骤：
1.Java源文件—->编译器—->字节码文件
2.字节码文件—->Jvm—->机器码

每一种平台的解释器是不同的，但是实现的虚拟机是相同的。这也就是Java为什么能够跨平台的原因
当一个程序从开始运行一个程序，这时虚拟机就开始实例化了。多个程序启动就会存在多个虚拟机实例。
程序退出或者关闭。则虚拟机实例消亡。多个虚拟机实例之间数据不能共享。				



区别于其他后端语言，C++在计算机上的运行原理与Java完全不同。C++程序是通过编译和链接过程转换为可执行程序后运行的。

1.首先，C++源代码被编译器转换成机器码，并链接成一个可执行文件。这个过程包括将源代码翻译成汇编语言，
然后将汇编语言转换为机器语言。链接器则将这个可执行文件与系统库和其他必要的库文件链接在一起，形成一个完整的程序。
2.当程序被执行时，操作系统会将程序加载到内存中，创建一个进程，并分配给该进程一些系统资源，如内存、文件、设备等。
程序中的代码会在CPU上运行，并按照程序员的指令执行各种操作。
3.在程序的运行过程中，操作系统会管理程序的执行，包括任务调度、内存管理、文件系统等方面。
程序运行结束后，操作系统会将程序的状态保存下来，并释放分配给该进程的资源。

总之，从计算机底层的角度来看，C++程序的运行过程包括编译、链接、加载、执行和退出等阶段，需要操作系统和硬件的支持。



Java在运行原理上与C++的对比：
相比于Java，C++没有虚拟机和垃圾回收机制，这使得C++在运行时的确更加复杂。

首先，C++需要手动管理内存，这意味着开发人员需要手动分配和释放内存。如果没有正确地管理内存，可能会导致内存泄漏、野指针等问题，
这会增加程序的复杂性和运行风险。

其次，C++没有类似于Java的垃圾回收机制，因此需要开发人员手动管理对象的生命周期，以避免内存泄漏和悬挂指针等问题。
这需要更加精细的内存管理技巧和经验，增加了程序的复杂性和开发难度。

此外，C++支持多种编程范式和语言特性，如面向对象编程、泛型编程、函数式编程等，这使得C++程序可能更加灵活和复杂。

总的来说，虽然C++没有虚拟机和垃圾回收机制，但它提供了更低级别的控制和更高的性能，同时也需要更严格的内存管理和更多的编程技巧。
因此，在运行原理上，C++的确比Java更加复杂。


python的运行原理与Java也不相同：
从计算机底层的角度来说，Python运行的过程可以大致分为以下几个步骤：

编译：当Python代码被执行时，首先会经过一个编译的过程。Python的编译过程与传统的编译过程有些不同，它并不是将代码直接编译成机器码，而是将代码编译成一种叫做字节码（bytecode）的形式。
这些字节码是平台无关的，可以在任何支持Python的平台上运行。这个编译过程是由Python解释器自动完成的，无需程序员手动干预。

解释执行：接下来，编译后的字节码会被加载到Python解释器中。Python解释器会按照字节码的指令顺序逐条解释执行。
在这个过程中，解释器会根据字节码指令调用相应的Python函数或对象方法，完成代码的逻辑执行。

对象引用：Python是一种动态类型语言，变量可以引用任何类型的对象。
在解释执行过程中，当一个变量被引用时，解释器会根据变量的类型和值，动态地创建相应的对象。
这些对象可以是Python内置类型（如整数、字符串、列表等），也可以是用户自定义的类型。

垃圾回收：为了防止内存泄漏，Python使用了垃圾回收机制。当一个对象不再被引用时，垃圾回收器会自动将其标记为可回收对象，
并在适当的时候释放其内存空间。

交互式模式：Python还支持交互式模式，可以在命令行中直接执行Python代码。当在交互式模式下输入代码时，解释器会立即执行并输出结果。

总之，Python的运行过程可以看作是将源代码编译成字节码，然后由解释器逐条解释执行字节码的过程。
在这个过程中，解释器还会处理变量引用、垃圾回收等操作，以保证程序的正常运行。



Java与python对比，在运行上的区别：
Python是一种解释性语言，它的解释器会在运行时解释执行代码。虽然Python解释器可以通过字节码进行编译，
但是在运行时仍然需要进行解释，这可能会影响Python的运行速度。

相反，Java是一种编译性语言，它的代码在编译时会生成与平台相关的机器码，因此Java的执行速度通常比Python更快。

然而，在实际应用中，Python和Java的运行速度差异可能并不明显。对于一些需要快速开发迭代的项目，Python的灵活性和易用性可能会更受欢迎。而对于一些需要更高运行效率的项目，Java可能会更适合。

类加载器：
Java类加载器是Java虚拟机的一部分，它的主要任务是将编译好的Java类到Java虚拟机中。类加载器有三个主要的任务：

找到类的二进制文件（.class文件或其他形式的类描述符）。
将这个文件转化为一个代表该类的数据结构。
通过这个数据结构创建一个代表该类的java.lang.Class对象。

类加载器子系统负责从文件系统或者网络中加载Class文件,class文在文件开头有特定的文件标识。
ClassLoader只负责clalss文件的加载,至于它是否可以运行,则由ExecutionEngine决定。
加载的类信息存放于一块称为方法区的内存空间。除了类的信息外,方法区中还会存放运行时常量池信息,
可能还包括字符串字面量和数字常量(这部分常量信息是Class文件中常量池部分的内存映射)。

注意：Java的反射正是运用了JVM类加载机制生成的反射类

类的加载过程：
验证(Verify):
目的在于确保Class文件的字节流中包含信息符合当前虚拟机要求,保证被加载类的正确性,不会危害虚拟机自身安全。
主要包括四种验证,文件格式验证,元数据验证,字节码验证,符号引用验证。

准备(Prepare):
为类变量分配内存并且设置该类变量的默认初始值,即零值。
这里不包含用final修饰的static,因为final在编译的时候就会分配了,准备阶段会显式初始化。
这里不会为实例变量分配初始化,类变量会久配在方法区中,而实例变量是会随着对象一起分配到Java堆中。

解析(Resolve):
将常量池内的符号引用转换为直接引用的过程。
事实上,解析操作往往会伴随着JVM在执行完初始化之后再执行。
符号引用就是一组符号来描述所引用的目标。符号引用的字面量形式明确定义在《java虚拟机规范》的Class文件格式中。
直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。
解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等。对应常量池中的
CONSTANT Class info, CONSTANT Fieldref infoCONSTANT Methodref info等

初始化:
初始化阶段就是执行类构造器方法<clinit>()的过程。
此方法不需定义,是javac编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并而来。
构造器方法中指令按语句在源文件中出现的顺序执行。
<clinit>()不同于类的构造器。(关联:构造器是虚拟机视角下的<init>())
若该类具有父类,JVM会保证子类的<clinit>()执行前,父类的<clinit>()已经执行完毕。
虚拟机必须保证一个类的<clinit>()方法在多线程下被同步加锁 

获取ClassLoader的方法：
1.直接获取当前类的ClassLoader
ClassLoader classLoader = Class.forName("java.lang.String").getClassLoader()
2.获取当前线程上下文的ClassLoader
ClassLoader classLoader1 = Thread.currentThread().getContextClassLoader();
3.获取系统的ClassLoader
ClassLoader classLoader2 = ClassLoader.getSystemClassLoader().getParent();
4.获取调用者的ClassLoader
ClassLoader classLoader3 = DriverManager.getCallerClassLoader ();

双亲委派机制：
Java JVM的双亲委派机制（Parent Delegation Mechanism）是一种类加载机制，它规定了当一个类加载器收到了类加载请求时，
它首先不会自己尝试去加载这个类，而是把这个请求委派给父类加载器去完成，直到最终由系统类加载器（Bootstrap ClassLoader）加载。
如果父类加载器也无法完成这个加载请求（比如父类加载器也找不到这个类），那么子加载器才会尝试自己去加载。

这种双亲委派机制的主要目的是为了保护Java的核心API，防止恶意代码通过自定义类加载器的方式去加载和修改这些核心API。
它确保了Java的核心类库只被系统类加载器加载一次，从而避免了类定义的混乱和冲突。

沙箱安全机制：
Java JVM里的沙箱安全机制是一种将Java代码限定在虚拟机特定运行范围中，并严格限制代码对本地系统资源访问的机制，以保证对代码的有效隔离，防止对本地系统造成破坏。
沙箱主要限制了CPU、内存、文件系统、网络等系统资源的访问，不同级别的沙箱对这些资源访问的限制也可以不一样。所有的Java程序运行都可以指定沙箱，可以定制安全策略。


.class文件经过类加载器到达运行时数据区，在运行时数据区进行下一步处理。
JVM运行时数据区：运行时数据区是JVM在执行Java程序时使用的内存区域。

PS：CPU如何调用内存去运行系统的？
在计算机系统中，内存扮演着非常重要的角色。它是CPU和外部存储设备（如硬盘）之间的桥梁，用于临时存储正在被处理的数据和指令。
CPU通过内存来访问和操作这些数据，以执行程序和操作系统的各种任务。
CPU调用内存的方式是通过地址总线（Address Bus）和数据总线（Data Bus）。地址总线用于指定要访问的内存地址，数据总线则用于传输数据。

以下是CPU调用内存的基本步骤：
1.CPU通过地址总线发送要访问的内存地址。这个地址是由程序计数器（Program Counter）生成的，它指向下一条要执行的指令在内存中的位置。
2.内存根据接收到的地址，将对应位置上的数据加载到数据总线上。
3.CPU从数据总线上读取加载到数据总线上的数据，然后对其进行处理。
4.如果CPU需要向内存写入数据，它首先通过地址总线发送要写入数据的内存地址，然后将要写入的数据发送到数据总线上。
5.内存接收到写入数据的请求和数据后，将数据存储到指定地址的位置。

通过这种方式，CPU可以不断地在内存中读取和写入数据，以执行程序和操作系统的各种任务。
内存的访问速度比外部存储设备快得多，因此CPU通过访问内存可以更快地执行程序和操作系统的操作。 

PS：在计算机系统里，什么是进程，什么是线程？
在计算机系统里，进程是指在系统中正在运行的一个应用程序，程序一旦运行就是进程，而线程是进程的一个实体，是进程的一条执行路径。
进程是系统资源分配的独立实体，且每个进程都有独立的地址空间。一个进程可以拥有多个线程，每个线程使用其所属进程的栈空间。
线程是CPU独立运行和独立调度的基本单位，它负责当前进程中程序的执行。
线程之间的通信是线程直接读写进程数据段（如全局变量）来进行通信，需要进程同步和互斥的手段的辅助，以保证数据的一致性。

在JVM中，每个线程是独立：程序计数器、栈、本地栈。线程间共享：堆、堆外内存（永久代或元空间、代码缓存）。

PC寄存器为什么被设定为私有？
为了能够准确地记录各个线程正在执行的当前字节码指令地址，为每一个线程都分配一个PC寄存器


方法区（Method Area）
方法区是所有线程共享的内存区域，它用于存储已被Java虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。
它有个别命叫Non-Heap（非堆）。当方法区无法满足内存分配需求时，抛出OutOfMemoryError异常。

Java堆（Java Heap）
java堆是java虚拟机所管理的内存中最大的一块，是被所有线程共享的一块内存区域，在虚拟机启动时创建。
此内存区域的唯一目的就是存放对象实例。
在Java虚拟机规范中的描述是：所有的对象实例以及数组都要在堆上分配。
java堆是垃圾收集器管理的主要区域，因此也被成为“GC堆”。
从内存回收角度来看java堆可分为：新生代和老生代。


从内存分配的角度看，线程共享的Java堆中可能划分出多个线程私有的分配缓冲区。
无论怎么划分，都与存放内容无关，无论哪个区域，存储的都是对象实例，进一步的划分都是为了更好的回收内存，或者更快的分配内存。
根据Java虚拟机规范的规定，java堆可以处于物理上不连续的内存空间中。当前主流的虚拟机都是可扩展的（通过 -Xmx 和 -Xms 控制）。
如果堆中没有内存可以完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。


程序计数器、PC寄存器（Program Counter Register）
程序计数器是一块较小的内存空间，它可以看作是：保存当前线程所正在执行的字节码指令的地址(行号)
由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，一个处理器都只会执行一条线程中的指令。

因此，为了线程切换后能恢复到正确的执行位置，每条线程都有一个独立的程序计数器，各个线程之间计数器互不影响，独立存储。
称之为“线程私有”的内存。
程序计数器内存区域是虚拟机中唯一没有规定OutOfMemoryError情况的区域。

Java JVM里的PC寄存器是链表结构吗？
在Java虚拟机中，PC寄存器是一个较小的寄存器，用于存储当前正在执行的指令的地址。
这个寄存器是线程私有的，每个线程都有自己的程序计数器。
PC寄存器的主要作用是帮助JVM实现指令集中的跳转指令。当JVM执行跳转指令时，程序计数器（PC）的值会被更新为跳转指令的目标地址。
这样，JVM就可以从跳转指令的目标地址开始执行字节码指令。

因此，PC寄存器的结构更类似于一个指向当前执行字节码指令的指针，而不是链表结构。

Java虚拟机栈（Java Virtual Machine Stacks）
java虚拟机是线程私有的，它的生命周期和线程相同。

虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）
用于存储局部变量表、操作数栈、动态链接、方法出口等信息，栈帧和方法是一一对应的关系。

解释：每虚拟机栈中是有单位的，单位就是栈帧，一个方法一个栈帧。一个栈帧中他又要存储、局部变量表，操作数栈，动态链接，出口等。
虚拟机栈的异常：StackOverFlowError（栈溢出）、OutOfMemoryError（内存不足）
设置栈内存大小：设置选项-Xss来设置线程的最大栈空间

局部变量表：
局部变量表是用于存储方法中定义的局部变量的数据结构。这些变量包括方法参数、方法内部声明的变量等。
局部变量表中的每个条目都包含变量的名称、类型和值等信息。
在Java中，每个方法调用都会在调用栈中创建一个新的栈帧（Stack Frame），用于存储该方法的局部变量、操作数栈和其他信息。
当方法被调用时，它的局部变量表会被创建并存储在栈帧中。当方法执行完毕并返回时，该栈帧会被弹出，同时其中的局部变量表也会被销毁。
在JVM中，局部变量表是在编译时确定的，每个方法的每个局部变量都会在局部变量表中创建一个条目。
在运行时，可以通过访问局部变量表来获取和修改局部变量的值。

操作数栈：
操作数栈是虚拟机栈中的一个重要部分，它用于存储方法执行过程中的中间结果和操作数。
在方法的执行过程中，许多操作都需要在操作数栈中进行，例如算术运算、方法调用、对象创建等。
操作数栈中的每个元素都有一个值和一个类型，这些元素可以是原始类型（例如int、char等）或引用类型（例如对象、数组等）。
在方法执行过程中，一些操作（例如算术运算、方法调用等）会向操作数栈中压入新的元素，而其他操作（例如取值、赋值等）则会从操作数栈中弹出元素。
当一个方法调用另一个方法时，被调用的方法会在自己的栈帧中创建一个新的操作数栈。
被调用方法的执行结果会被压入到调用方法的操作数栈中，以供后续使用。

总之，Java虚拟机中的操作数栈是用于存储中间结果和操作数的数据结构，它在方法的执行过程中起着非常重要的作用。

栈顶缓存：
Java虚拟机（JVM）的栈顶缓存（TSA，Top Stack Abstraction）是一种优化技术，用于减少在JVM的堆栈中创建和销毁对象的开销。
这种技术主要在HotSpot JVM中使用。

在JVM中，每次方法调用都会创建一个新的栈帧（stack frame），其中包含该方法的局部变量、操作数栈和方法出口信息。
每当方法调用发生时，JVM需要在堆栈中分配新的栈帧空间，并在方法执行结束后释放这些空间。这是一个相对昂贵的过程，
特别是在频繁的方法调用情况下，可能会导致性能下降。

栈顶缓存技术的核心思想是在堆栈上保留一些额外的栈帧空间，以便在下次方法调用时重用这些空间，而无需再次分配和释放内存。
这样可以减少堆栈分配和垃圾回收的开销，提高方法的执行速度。

在HotSpot JVM中，栈顶缓存的实现是通过JVM的内部数据结构完成的。JVM维护了一个栈顶缓存区（stack top cache），
用于存储当前线程的堆栈顶部的位置信息。当线程执行方法调用时，JVM会检查栈顶缓存区是否有足够的空间来容纳新的栈帧。

如果有足够的空间，JVM会将新的栈帧分配到缓存区中的空闲空间中，而不是在堆栈中创建新的栈帧。
这样可以避免频繁的堆栈分配操作，提高了方法的执行性能。

需要注意的是，栈顶缓存技术并不是没有限制的。如果线程的堆栈空间不足以容纳新的栈帧，或者缓存区中没有足够的空间来容纳新的栈帧，
那么JVM仍然需要在堆栈中分配新的栈帧空间。此外，如果线程调用的方法数量过多，缓存区可能会被填满，导致无法继续使用栈顶缓存技术。
总之，Java虚拟机中的栈顶缓存技术是一种优化技术，用于减少在堆栈中创建和销毁对象的开销，从而提高方法的执行性能。
它是通过在堆栈上保留一些额外的栈帧空间，以便在下次方法调用时重用这些空间来实现的。

动态链接：
Java虚拟机（JVM）的动态链接（Dynamic Linking）是指在运行时解析和加载类、接口、字段和方法的信息。
在Java中，类、接口、字段和方法并不是在程序编译时链接在一起的，而是在程序运行时动态链接到一起的。
动态链接的实现是通过Java虚拟机的类加载器（ClassLoader）来完成的。类加载器负责从文件系统、网络或其他来源加载类的字节码文件，
并将其转换为Java虚拟机中的类对象。在类加载过程中，类加载器会解析类的结构，
确定类之间的关系，例如确定一个类继承自另一个类，实现一个接口等。

在动态链接过程中，Java虚拟机会对类进行验证和解析。验证是确保类的字节码文件符合Java虚拟机的规范，并且没有安全方面的问题。
解析是将类中的符号引用转换为直接引用。符号引用是指在类或接口的声明中使用的一种引用方式，例如一个方法调用另一个方法或访问一个字段。
直接引用是指具体的内存地址或方法指针，例如在调用方法时使用的指令地址。

动态链接的好处是可以在程序运行时动态地加载新的类或更新已有的类，而不需要重新编译程序。
这使得Java程序具有很高的灵活性和可扩展性，可以方便地添加或修改功能。
然而，动态链接也带来了一些性能开销，因为需要在运行时解析和加载类、接口、字段和方法的信息。

Java虚拟机栈的执行原理：
Java虚拟机栈执行原理是遵循先进后出（后进先出）原则，JVM直接对Java栈的操作只有两个，就是对栈帧的压栈和出栈。
在一条活动线程中，一个时间点上，只会有一个活动的栈帧。即只有当前正在执行的方法的栈帧（栈顶栈帧）是有效的。
这个栈帧被称为当前栈帧。与当前栈帧相对应的方法就是当前方法。定义这个方法的类就是当前类。
执行引擎运行的所有字节码指令只针对当前栈帧进行操作。如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，
放在栈的顶端，成为新的当前帧。不同线程中所包含的栈帧不允许存在相互引用的，即不可能在一个栈帧之中引用另外一个线程的栈帧。


JVM内存结构：
直接内存（Direct Memory）：
直接内存不是虚拟机运行时数据区的一部分，也不是java虚拟机规范中定义的内存区域。
但是既然是内存，肯定还是受本机总内存（包括RAM以及SWAP区或者分页文件）大小以及处理器寻址空间的限制。

在JDK1.4 中新加入了NIO(New Input/Output)类，引入了一种基于通道(Channel)与缓冲区（Buffer）的I/O 方式，
它可以使用native 函数库直接分配堆外内存，然后通脱一个存储在Java堆中的DirectByteBuffer 对象作为这块内存的引用进行操作。
这样能在一些场景中显著提高性能，因为避免了在Java堆和Native（本地）堆中来回复制数据。

直接内存与堆内存的区别：
直接内存申请空间耗费很高的性能，堆内存申请空间耗费比较低
直接内存的IO读写的性能要优于堆内存，在多次读写操作的情况相差非常明显

JVM的垃圾回收机制：
垃圾回收机制简称GC

GC主要用于Java堆的管理。Java 中的堆是 JVM 所管理的最大的一块内存空间，主要用于存放各种类的实例对象。

关于什么是垃圾回收机制：
程序在运行过程中，会产生大量的内存垃圾（一些没有引用指向的内存对象都属于内存垃圾，因为这些对象已经无法访问，程序用不了它们了，
对程序而言它们已经死亡），为了确保程序运行时的性能，java虚拟机在程序运行的过程中不断地进行自动的垃圾回收（GC）。

GC是不定时去堆内存中清理不可达对象。不可达的对象并不会马上就会直接回收， 垃圾收集器在一个Java程序中的执行是自动的，
不能强制执行清楚那个对象，即使程序员能明确地判断出有一块内存已经无用了，是应该回收的，程序员也不能强制垃圾收集器回收该内存块。
程序员唯一能做的就是通过调用System.gc 方法来"建议"执行垃圾收集器，但是他是否执行，什么时候执行却都是不可知的。
这也是垃圾收集器的最主要的缺点。当然相对于它给程序员带来的巨大方便性而言，这个缺点是瑕不掩瑜的。

手动执行GC：System.gc(); 

finalize方法作用：
-finalize()方法是在每次执行GC操作之前时会调用的方法，可以用它做必要的清理工作。
-它是在Object类中定义的，因此所有的类都继承了它。子类覆盖finalize()方法以整理系统资源或者执行其他清理工作。
finalize()方法是在垃圾收集器删除对象之前对这个对象调用的。

新生代、老年代、永久代(方法区)的区别：
-Java 中的堆是 JVM 所管理的最大的一块内存空间，主要用于存放各种类的实例对象。
-在 Java 中，堆被划分成两个不同的区域：新生代 ( Young )、老年代 ( Old )。
-老年代就一个区域。新生代 ( Young ) 又被划分为三个区域：Eden、From Survivor、To Survivor。
-这样划分的目的是为了使 JVM 能够更好的管理堆内存中的对象，包括内存的分配以及回收。

-默认的，新生代 ( Young ) 与老年代 ( Old ) 的比例的值为 1:2 ( 该值可以通过参数 –XX:NewRatio 来指定 )，
即：新生代 ( Young ) = 1/3 的堆空间大小。老年代 ( Old ) = 2/3 的堆空间大小。
-其中，新生代 ( Young ) 被细分为 Eden 和 两个 Survivor 区域，这两个 Survivor 区域分别被命名为 From Survivor 和 ToSurvivor ，以示区分。
-默认的，Edem ：From Survivor ： To Survivor = 8 : 1 : 1 ( 可以通过参数 –XX:SurvivorRatio 来设定 )，
即： Eden = 8/10 的新生代空间大小，From Survivor = To Survivor = 1/10 的新生代空间大小。

-JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块 Survivor 区域是空闲着的。
-因此，新生代实际可用的内存空间为 9/10 ( 即90% )的新生代空间。
-永久代就是JVM的方法区。在这里都是放着一些被虚拟机加载的类信息，静态变量，常量等数据。
这个区中的东西比老年代和新生代更不容易回收。

GC算法：
Minor GC、Major GC、Full GC区别及触发条件：
-Minor GC是新生代GC，指的是发生在新生代的垃圾收集动作。由于java对象大都是朝生夕死的，所以Minor GC非常频繁，一般回收速度也比较快。
-Major GC是老年代GC，指的是发生在老年代的GC，通常执行Major GC会连着Minor GC一起执行。Major GC的速度要比Minor GC慢的多。
-Full GC是清理整个堆空间，包括年轻代和老年代

Minor GC 触发条件一般为：

eden区满时，触发MinorGC。即申请一个对象时，发现eden区不够用，则触发一次MinorGC。
​ 新创建的对象大小 > Eden所剩空间
Major GC和Full GC 触发条件一般为：
Major GC通常是跟full GC是等价的

每次晋升到老年代的对象平均大小>老年代剩余空间
MinorGC后存活的对象超过了老年代剩余空间
永久代空间不足
执行System.gc()
CMS GC异常
堆内存分配很大的对象

JVM垃圾收集器：

垃圾收集器是垃圾回收算法（引用计数法、标记清楚法、标记整理法、复制算法）的具体实现，
不同垃圾收集器、不同版本的JVM所提供的垃圾收集器可能会有很在差别。

1.Serial 收集器：新生代。发展历史最悠久的收集器。它是一个单线程收集器，它只会使用一个 CPU 或者线程去完成垃圾收集工作，而且在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。
特点：

新生代收集器，使用复制算法收集新生代垃圾。
单线程的收集器，GC工作时，其它所有线程都将停止工作。
简单高效，适合单 CPU 环境。单线程没有线程交互的开销，因此拥有最高的单线程收集效率。


2.ParNew 收集器：新生代。Serial 的多线程版本，即同时启动多个线程去进行垃圾收集。
特点：

新生代收集器。ParNew垃圾收集器是Serial收集器的多线程版本，采用复制算法。
除了多线程外，其余的行为、特点和Serial收集器一样。
只有它能与 CMS 收集器配合使用。
但在单个CPU环境中，不比Serail收集器好，多线程使用它比较好。


3.Parallel Scavenge 收集器：新生代。和 ParNew 的关注点不一样，该收集器更关注吞吐量，尽快地完成计算任务。
特点：

新生代收集器。
采用复制算法。
多线程收集。
与ParNew 不同的是：高吞吐量为目标，（减少垃圾收集时间，让用户代码获得更长的运行时间）


4.Serial Old 收集器：Serial 的老年代版本，使用标记 - 整理算法。
特点：

老年代收集器， 采用"标记-整理"算法。
单线程收集。

5.Parallnel old 收集器，多线程：Parallel 的老年代版本，使用标记 - 整理算法。
特点：

针对老年代。
采用"标记-整理"算法。
多线程收集。
但在单个CPU环境中，不比Serial Old收集器好，多线程使用它比较好。

6.CMS 收集器：老年代。是一种以获取最短回收停顿时间为目标的收集器，适用于互联网站或者 B/S 系统的服务端上。
特点：

针对老年代，采用标记-清楚法清除垃圾；
基于"标记-清除"算法(不进行压缩操作，产生内存碎片)；
以获取最短回收停顿时间为目标；
并发收集、低停顿；
CMS收集器有3个明显的缺点：1.对CPU资源非常敏感、2.无法处理浮动垃圾，可能出现"Concurrent Mode Failure"失败、3.产生大量内存碎片
垃圾收集线程与用户线程（基本上）可以同时工作

7.G1 收集器：分代收集器。当今收集器技术发展最前沿成果之一，是一款面向服务端应用的垃圾收集器。G1可以说是CMS的终极改进版，解决了CMS内存碎片、更多的内存空间登问题。虽然流程与CMS比较相似，但底层的原理已是完全不同。
特点：

能充分利用多CPU、多核环境下的硬件优势；
可以并行来缩短(Stop The World)停顿时间；
也可以并发让垃圾收集与用户程序同时进行；
分代收集，收集范围包括新生代和老年代
能独立管理整个GC堆（新生代和老年代），而不需要与其他收集器搭配；
能够采用不同方式处理不同时期的对象；
应用场景可以面向服务端应用，针对具有大内存、多处理器的机器；
采用标记-整理 + 复制算法来回收垃圾



Java程序通过设计模式、数据结构与算法等技术组成框架

设计模式：
设计模式（Design Patterns）是在软件设计中针对特定问题的最佳解决方案。它们是在软件开发过程中，对常见问题的反复出现的解决方案的总结与抽象。
这些模式描述了在特定上下文中，针对某类问题的一组相互协作的类、接口和通信机制，用于解决某一类通用设计问题。
设计模式是经验的总结，是软件开发人员在长期开发过程中，针对某一类问题的解决方案的抽象和提炼。
使用设计模式可以帮助我们提高代码的可重用性、可维护性和可扩展性，同时降低系统的复杂度，提高软件开发的效率和质量。

设计模式的目的是提供一套可复用的设计问题的解决方案，提高代码的可维护性、可重用性和可读性。具体来说，设计模式有以下几个主要目的：
1.代码重用：设计模式提供了一种抽象化和标准化的方式，使开发者能够针对常见的设计问题重用已有的解决方案，而无需每次都从头开始设计。
2.使代码易于理解：设计模式为软件设计提供了通用的术语和视觉表示，使得其他开发者能够更容易地理解代码的结构和意图。
3.提高软件的可维护性：通过使用设计模式，代码的结构更加清晰，各部分之间的耦合度降低，使得软件更易于维护和扩展。
4.促进团队协作：团队成员之间共享对设计模式的理解和经验，可以促进团队之间的沟通和协作，提高开发效率。
5.系统灵活性：设计模式有助于构建一个灵活且可扩展的系统，能够应对不断变化的需求。


设计模式的七大原则：
开闭原则：对扩展开放、对修改关闭。

单一指责原则：一个类只做一件事。
该原则强调一个类或者一个模块应该只有一个引起变化的原因，也就是说，它应该只负责一项职责。
当一个类或模块承担过多的职责时，它的可维护性和可读性都会受到影响，因为任何一个职责的变化都可能导致整个类或模块需要重新设计或修改。

依赖倒转原则：类似于ioc，采用接口编程。
迪米特原则：高内聚，低耦合。
接口隔离原则：应该使用多个接口，而不是用单一的总接口。
合成复用原则：尽量使用对象组合，而不是继承来达到复用目的。
里氏替换原则：子类可以扩展父类的功能，但不能改变原有的功能。

Java的23种设计模式：

1、创建型-工厂方法模式：
工厂方法模式分为三种：

（1）简单工厂模式：

建立一个工厂类，并定义一个接口对实现了同一接口的产品类进行创建。

（2）工厂方法模式：

工厂方法模式是对简单工厂模式的改进，简单工厂的缺陷在于不符合“开闭原则”，每次添加新产品类就需要修改工厂类，不利于系统的扩展维护。而工厂方法将工厂抽象化，并定义一个创建对象的接口。每增加新产品，只需增加该产品以及对应的具体实现工厂类，由具体工厂类决定要实例化的产品是哪个，将对象的创建与实例化延迟到子类，这样工厂的设计就符合“开闭原则”了，扩展时不必去修改原来的代码。UML关系图如下：

（3）静态工厂方法模式：

静态工厂模式是将工厂方法模式里的方法置为静态的，不需要创建实例，直接调用即可。

// 抽象产品类
public interface class Car {
    public void run();
    public void stop();
}
 
//两个具体实现类
public class Benz implements Car {
    public void run() {
        System.out.println("Benz开始启动了。。。。。");
    }
 
    public void stop() {
        System.out.println("Benz停车了。。。。。");
    }
}
public class Ford implements Car {
    public void run() {
        System.out.println("Ford开始启动了。。。");
    }
 
    public void stop() {
        System.out.println("Ford停车了。。。。");
    }
}
 
// 工厂类
public class Factory {
    public static Car getCarInstance(String type) {
        Car c = null;
        if ("Benz".equals(type)) {
            c = new Benz();
        }
        if ("Ford".equals(type)) {
            c = new Ford();
        }
        return c;
    }
}
//测试类
public class Test {
    public static void main(String[] args) {
        Car c = Factory.getCarInstance("Benz");
        if (c != null) {
            c.run();
            c.stop();
        } else {
            System.out.println("造不了这种汽车。。。");
        }
    }
}


2、创建型-抽象工厂模式：
抽象工厂模式主要用于创建相关对象的家族。当一个产品族中需要被设计在一起工作时，
通过抽象工厂模式，能够保证客户端始终只使用同一个产品族中的对象；并且通过隔离具体类的生成，
使得客户端不需要明确指定具体生成类；所有的具体工厂都实现了抽象工厂中定义的公共接口，
因此只需要改变具体工厂的实例，就可以在某种程度上改变整个软件系统的行为。
但该模式的缺点在于添加新的行为时比较麻烦，如果需要添加一个新产品族对象时，
需要更改接口及其下所有子类，这必然会带来很大的麻烦。

	//抽象类
	public interface Sender {
		public void Send();
	}
	
	//两个具体实现类
    public class MailSender implements Sender {
    	@Override
    	public void Send() {
    		System.out.println("this is mailsender!");
    	}
    }
    public class MailSender implements Sender {
    	@Override
    	public void Send() {
    		System.out.println("this is mailsender!");
    	}
    }
    
    //提供的接口类
    public interface Provider {
		public Sender produce();
	}

	//两个工厂类
    public class SendMailFactory implements Provider {
    	@Override
    	public Sender produce(){
    		return new MailSender();
    	}
    }
    public class SendSmsFactory implements Provider{
    	@Override
    	public Sender produce() {
    		return new SmsSender();
    	}
    }

	//测试类
	public class Test {
		public static void main(String[] args) {
			Provider provider = new SendMailFactory();
			Sender sender = provider.produce();
			sender.Send();
		}
	}
        





3、创建型-建造者模式：
建造者模式将复杂产品的创建步骤分解在在不同的方法中，使得创建过程更加清晰，从而更精确控制复杂对象的产生过程；
通过隔离复杂对象的构建与使用，也就是将产品的创建与产品本身分离开来，使得同样的构建过程可以创建不同的对象；
并且每个具体建造者都相互独立，因此可以很方便地替换具体建造者或增加新的具体建造者，
用户使用不同的具体建造者即可得到不同的产品对象。

建造者模式结构组成
Product: 表示被构造的复杂对象,其中包含需要构建的部件属性。
Builder: 创建一个产品对象的各个部件指定抽象接口。
ConcreteBuilder： 实现Builder的接口以构造和装配该产品的各个部件，定义并明确它所创建的表示。
Director： 调用具体建造者角色以创建产品对象。

	//抽象类
	public interface Sender {
		public void Send();
	}
	
	//两个具体实现类
    public class MailSender implements Sender {
    	@Override
    	public void Send() {
    		System.out.println("this is mailsender!");
    	}
    }
    public class MailSender implements Sender {
    	@Override
    	public void Send() {
    		System.out.println("this is mailsender!");
    	}
    }
    
    public class Builder {
		private List<Sender> list = new ArrayList<Sender>();
	
		public void produceMailSender(int count){
			for(int i=0; i<count; i++){
				list.add(new MailSender());
			}
		}
	
		public void produceSmsSender(int count){
			for(int i=0; i<count; i++){
				list.add(new SmsSender());
			}
		}
	}

	//测试类
	public class Test {
		public static void main(String[] args) {
			Builder builder = new Builder();
			builder.produceMailSender(10);
		}
	}


4、创建型-单例模式：
        单例模式可以确保系统中某个类只有一个实例，该类自行实例化并向整个系统提供这个实例的公共访问点，除了该公共访问点，不能通过其他途径访问该实例。单例模式的优点在于：
	>系统中只存在一个共用的实例对象，无需频繁创建和销毁对象，节约了系统资源，提高系统的性能
	>可以严格控制客户怎么样以及何时访问单例对象。
	>单例模式的写法有好几种，主要有三种：懒汉式单例、饿汉式单例、登记式单例。

饿汉式单例：
class Bank {
    private Bank(){

    }
    private static Bank instance = new Bank();

    private static Bank getInstance(){
        return instance;
    }
}

懒汉式单例：
class Order{
    private Order(){

    }
    private static Order instance = null;

    public static Order getInstance(){
            if(instance == null){
            	instance = new Order();
        	  }
        return instance;
    }
}

区分饿汉式单例和懒汉式单例：
饿汉式：好处：线程安全 坏处：对象加载时间过长
懒汉式：好处：延迟对象的创建 坏处：线程不安全

登记式单例：
import java.util.HashMap;

import java.util.Map;

/**

* 登记式单例实际上维护的是一组单例类的实例，将这些实例存储到一个Map(登记簿)

* 中，对于已经登记过的单例，则从工厂直接返回，对于没有登记的，则先登记，而后

* 返回

* @author pp

*

*/

public class RegSingleton {

/**

* 登记簿，用来存放所有登记的实例

*/

private static Map map = new HashMap();

//在类加载时添加一个实例到登记簿

static{

RegSingleton singleton = new RegSingleton();

map.put(singleton.getClass().getName(), singleton);//运用了反射

}

/**

* 受保护的默认构造方法

*/

protected RegSingleton() {

}

/**

* 静态工厂方法，返回指定登记对象的唯一实例

* 对于已经登记的直接取出返回，对于还未登记的先登记，然后取出返回

*

*/

public static RegSingleton getInstance(String name){

if(name==null){

name="RegSingleton";

}

if(map.get(name)==null){

try {

map.put(name, (RegSingleton) Class.forName(name).newInstance());

} catch (Exception e) {

e.printStackTrace();

}

}

return map.get(name);

}

/**

* 一個示意性的商业方法

*/

public String about(){

return "Hello,I am RegSingleton";

}

}


5、创建型-原型模式：
原型模式也是用于对象的创建，通过将一个对象作为原型，对其进行复制克隆，产生一个与源对象类似的新对象。
原型模式包含如下角色：
抽象原型类：规定了具体原型对象必须实现的的 clone() 方法。
具体原型类：实现抽象原型类的 clone() 方法，它是可被复制的对象。
访问类：使用具体原型类中的 clone() 方法来复制新的对象。


 在 Java 中，原型模式的核心是就是原型类 Prototype，Prototype 类需要具备以下两个条件：

实现 Cloneable 接口：
重写 Object 类中的 clone() 方法，用于返回对象的拷贝；
Object 类中的 clone() 方法默认是浅拷贝，如果想要深拷贝对象，则需要在 clone() 方法中自定义自己的复制逻辑。

@Data
@AllArgsConstructor
@NoArgsConstructor
public class Student implements Cloneable {
    private String name;
    private String sex;
    private Integer age;
    @Override
    protected Object clone() throws CloneNotSupportedException {
        return super.clone();
    }
 
    public static void main(String[] args) throws Exception{
        Student stu1 = new Student("张三", "男", 18);
        Student stu2 = (Student)stu1.clone();
        stu2.setName("李四");
        System.out.println(stu1);// Student(name=张三, sex=男, age=18)
        System.out.println(stu2);// Student(name=李四, sex=男, age=18)
    }
}

可以看到，把一个学生复制过来，只是改了姓名而已，其他属性完全一样没有改变，
需要注意的是，一定要在被拷贝的对象上实现Cloneable接口，否则会抛出CloneNotSupportedException异常。


浅复制：将一个对象复制后，基本数据类型的变量会重新创建，而引用类型指向的还是原对象所指向的内存地址。

@Data
public class Clazz implements Cloneable {
    private String name;
    private Student student;
    @Override
    protected Object clone() throws CloneNotSupportedException {
        return super.clone();
    }
}
@Data
@AllArgsConstructor
@NoArgsConstructor
public class Student implements Serializable {
    private String name;
    private String sex;
    private Integer age;
}
 
    public static void main(String[] args) throws Exception{
        Clazz clazz1 = new Clazz();
        clazz1.setName("高三一班");
        Student stu1 = new Student("张三", "男", 18);
        clazz1.setStudent(stu1);
        System.out.println(clazz1); // Clazz(name=高三一班, student=Student(name=张三, sex=男, age=18))
        Clazz clazz2 = (Clazz)clazz1.clone();
        Student stu2 = clazz2.getStudent();
        stu2.setName("李四");
        System.out.println(clazz1); // Clazz(name=高三一班, student=Student(name=李四, sex=男, age=18))
        System.out.println(clazz2); // Clazz(name=高三一班, student=Student(name=李四, sex=男, age=18))
    }
	
可以看到，当修改了stu2的姓名时，stu1的姓名同样也被修改了，这说明stu1和stu2是同一个对象，这就是浅克隆的特点，
对具体原型类中的引用类型的属性进行引用的复制。同时，这也可能是浅克隆所带来的弊端，因为结合该例子的原意，
显然是想在班级中新增一名叫李四的学生，而非让所有的学生都改名叫李四，于是我们这里就要使用深克隆。
	
深复制：将一个对象复制后，不论是基本数据类型还有引用类型，都是重新创建的。
        使用原型模式进行创建对象不仅简化对象的创建步骤，还比 new 方式创建对象的性能要好的多，
		因为 Object 类的 clone() 方法是一个本地方法，直接操作内存中的二进制流，特别是复制大对象时，性能的差别非常明显；

		@Data
public class Clazz implements Cloneable, Serializable {
    private String name;
    private Student student;
    @Override
    protected Object clone() throws CloneNotSupportedException {
        return super.clone();
    }
 
    protected Object deepClone() throws IOException, ClassNotFoundException {
        ByteArrayOutputStream bos = new ByteArrayOutputStream();
        ObjectOutputStream oos = new ObjectOutputStream(bos);
        oos.writeObject(this);
        ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray());
        ObjectInputStream ois = new ObjectInputStream(bis);
        return ois.readObject();
    }
}
 
    public static void main(String[] args) throws Exception{
        Clazz clazz1 = new Clazz();
        clazz1.setName("高三一班");
        Student stu1 = new Student("张三", "男", 18);
        clazz1.setStudent(stu1);
        Clazz clazz3 = (Clazz)clazz1.deepClone();
        Student stu3 = clazz3.getStudent();
        stu3.setName("王五");
        System.out.println(clazz1); // Clazz(name=高三一班, student=Student(name=张三, sex=男, age=18))
        System.out.println(clazz3); // Clazz(name=高三一班, student=Student(name=王五, sex=男, age=18))
    }

可以看到，当修改了stu3的姓名时，stu1的姓名并没有被修改了，这说明stu3和stu1已经是不同的对象了，
说明Clazz中的Student也被克隆了，不再指向原有对象地址，这就是深克隆。
这里需要注意的是，Clazz类和Student类都需要实现Serializable接口，否则会抛出NotSerializableException异常。
	        

6、结构型-适配器模式：
适配器模式主要用于将一个类或者接口转化成客户端希望的格式，使得原本不兼容的类可以在一起工作，
将目标类和适配者类解耦；同时也符合“开闭原则”，可以在不修改原代码的基础上增加新的适配器类；
将具体的实现封装在适配者类中，对于客户端类来说是透明的，而且提高了适配者的复用性，
但是缺点在于更换适配器的实现过程比较复杂。

所以，适配器模式比较适合以下场景：
（1）系统需要使用现有的类，而这些类的接口不符合系统的接口。
（2）使用第三方组件，组件接口定义和自己定义的不同，不希望修改自己的接口，但是要使用第三方组件接口的功能。
下面有个非常形象的例子很好地说明了什么是适配器模式：

适配器模式（Adapter）包含以下主要角色：

目标（Target）接口：当前系统业务所期待的接口，它可以是抽象类或接口。
适配者（Adaptee）类：它是被访问和适配的现存组件库中的组件接口。
适配器（Adapter）类：它是一个转换器，通过继承或引用适配者的对象，把适配者接口转换成目标接口，让客户按目标接口的格式访问适配者。

// 适配者 220V电压
public class AC220 {
    public int output() {
        System.out.println("输出220V交流电");
        return 220;
    }
}
// 目标 5V
public interface DC5 {
    public int output5();
}
// 适配器类（电源适配器）
public class PowerAdapter extends AC220 implements DC5 {
    @Override
    public int output5() {
        int output220 = super.output();
        int output5 = output220 / 44;
        System.out.println(output220 + "V适配转换成" + output5 + "V");
        return output5;
    }
}
    // 测试
    public static void main(String[] args) {
        PowerAdapter powerAdapter = new PowerAdapter();
        // 输出220V交流电
        powerAdapter.output();
        // 输出220V交流电
        // 220V适配转换成5V
        powerAdapter.output5();
    }

通过上面代码例子可以看出，类适配器有一个很明显的缺点，就是违背了合成复用原则。
结合上面的例子，假如我不是220V的电压了，是380V电压呢？那就要多建一个380V电压的适配器了。
同理，由于Java是单继承的原因，如果不断的新增适配者，那么就要无限的新增适配器，于是就有了对象适配器。

对象适配器：
// 电源接口
public interface Power {
    int output();
}
// 适配者 220V电压
public class AC220 implements Power {
    @Override
    public int output() {
        System.out.println("输出220V交流电");
        return 220;
    }
}
// 目标 5V
public interface DC5 {
    public int output5();
}
@AllArgsConstructor
public class PowerAdapter implements DC5 {
 
    // 适配者
    private Power power;
    @Override
    public int output5() {
        int output220 = power.output();
        int output5 = output220 / 44;
        System.out.println(output220 + "V适配转换成" + output5 + "V");
        return output5;
    }
}
    // 测试
    public static void main(String[] args) {
        DC5 powerAdapter = new PowerAdapter(new AC220());
        // 输出220V交流电
        // 220V适配转换成5V
        powerAdapter.output5();
    }
	
可以看到，上面代码中，只实现了目标接口，并没有继承适配者，而是将适配者类实现适配者接口，
在适配器中引入适配者接口，当我们需要使用不同的适配者通过适配器进行转换时，就无需再新建适配器类了，
如上面例子，假如我需要380V的电源转换成5V的，那么客户端只需要调用适配器时传入380V电源的类即可，
就无需再新建一个380V电源的适配器了
（PS：上述逻辑代码中output220 / 44请忽略，可以根据实际情况编写实际的通用逻辑代码）。

接口适配器：
接口适配器主要是解决类臃肿的问题，我们可以把所有相近的适配模式的方法都放到同一个接口里面，去实现所有方法，
当客户端需要哪个方法直接调用哪个方法即可。如上面例子所示，我们只是转换成了5V电压，
那假如我要转换成12V，24V，30V...呢？那按照上面的写法就需要新建12V，24V，30V...的接口，这样就会导致类过于多了。
那么我们就可以把5V，12V，24V，30V...这些转换方法，通通都写到一个接口里去，
这样当我们需要转换哪种就直接调用哪种即可。

// 这里例子 输出不同直流电接口
public interface DC {
    int output5();
    int output12();
    int output24();
    int output30();
}
// 适配器类（电源适配器）
@AllArgsConstructor
public class PowerAdapter implements DC {
    private Power power;
    @Override
    public int output5() {
        // 具体实现逻辑
        return 5;
    }
    @Override
    public int output12() {
        // 具体实现逻辑
        return 12;
    }
    @Override
    public int output24() {
        // 具体实现逻辑
        return 24;
    }
    @Override
    public int output30() {
        // 具体实现逻辑
        return 30;
    }
}

7、结构型-装饰器模式：
装饰器模式可以动态给对象添加一些额外的职责从而实现功能的拓展，在运行时选择不同的装饰器，从而实现不同的行为；
比使用继承更加灵活，通过对不同的装饰类进行排列组合，创造出很多不同行为，得到功能更为强大的对象；
符合“开闭原则”，被装饰类与装饰类独立变化，用户可以根据需要增加新的装饰类和被装饰类，在使用时再对其进行组合，原有代码无须改变。
但是装饰器模式也存在缺点，首先会产生很多的小对象，增加了系统的复杂性，
第二是排错比较困难，对于多次装饰的对象，调试时寻找错误可能需要逐级排查，较为烦琐。

装饰（Decorator）模式中的角色：

抽象构件（Component）角色 ：定义一个抽象接口以规范准备接收附加责任的对象。
具体构件（Concrete Component）角色 ：实现抽象构件，通过装饰角色为其添加一些职责。
抽象装饰（Decorator）角色 ： 继承或实现抽象构件，并包含具体构件的实例，可以通过其子类扩展具体构件的功能。
具体装饰（ConcreteDecorator）角色 ：实现抽象装饰的相关方法，并给具体构件对象添加附加的责任。

// 炒饭类
public class FriedRice {
    String getDesc() {
        return "炒饭";
    }
    Integer getPrice() {
        return 5;
    }
}
// 配料表
public abstract class Ingredients extends FriedRice{
    private FriedRice friedRice;
    public Ingredients(FriedRice friedRice) {
        this.friedRice = friedRice;
    }
    String getDesc() {
        return this.friedRice.getDesc();
    }
    Integer getPrice() {
        return this.friedRice.getPrice();
    }
}
// 鸡蛋配料
public class Egg extends Ingredients {
    public Egg(FriedRice friedRice) {
        super(friedRice);
    }
    String getDesc() {
        return super.getDesc() + "+鸡蛋";
    }
    Integer getPrice() {
        return super.getPrice() + 2;
    }
}
// 火腿配料
public class Ham extends Ingredients {
    public Ham(FriedRice friedRice){
        super(friedRice);
    }
    String getDesc() {
        return super.getDesc() + "+火腿";
    }
    Integer getPrice() {
        return super.getPrice() + 3;
    }
}
    // 测试方法
    public static void main(String[] args) {
        FriedRice friedRice = new FriedRice();
        System.out.println(friedRice.getDesc() + friedRice.getPrice() + "元"); // 炒饭5元
        friedRice = new Egg(friedRice);
        System.out.println(friedRice.getDesc() + friedRice.getPrice() + "元"); // 炒饭+鸡蛋7元
        friedRice = new Egg(friedRice);
        System.out.println(friedRice.getDesc() + friedRice.getPrice() + "元");// 炒饭+鸡蛋+鸡蛋9元
        friedRice = new Ham(friedRice);
        System.out.println(friedRice.getDesc() + friedRice.getPrice() + "元");// 炒饭+鸡蛋+鸡蛋+火腿12元
    }

装饰器模式与代理模式对比：
装饰器模式就是一种特殊的代理模式。
装饰器模式强调自身的功能扩展，用自己说了算的透明扩展，可动态定制的扩展；代理模式强调代理过程的控制。
获取目标对象构建的地方不同，装饰者是从外界传递进来的，可以通过构造方法传递；静态代理是在代理类内部创建，以此来隐藏目标对象。

适用场景：
用于扩展一个类的功能或者给一个类添加附加职责。
动态的给一个对象添加功能，这些功能同样也可以再动态的撤销。

优点：
装饰器是继承的有力补充，比继承灵活，不改变原有对象的情况下动态地给一个对象扩展功能，即插即用。
通过使用不同装饰类以及这些装饰类的排列组合，可实现不同效果。
装饰器完全遵守开闭原则。

缺点：
会出现更多的代码，更多的类，增加程序的复杂性。
动态装饰时，多层装饰会更复杂。
	
8、结构型-代理模式：
代理模式的设计动机是通过代理对象来访问真实对象，通过建立一个对象代理类，
由代理对象控制原对象的引用，从而实现对真实对象的操作。在代理模式中，代理对象主要起到一个中介的作用，
用于协调与连接调用者(即客户端)和被调用者(即目标对象)，在一定程度上降低了系统的耦合度，同时也保护了目标对象。
但缺点是在调用者与被调用者之间增加了代理对象，可能会造成请求的处理速度变慢。

静态代理：静态代理就是指我们在给一个类扩展功能的时候，我们需要去书写一个静态的类，
相当于在之前的类上套了一层，这样我们就可以在不改变之前的类的前提下去对原有功能进行扩展，
静态代理需要代理对象和目标对象实现一样的接口。

// 火车站接口，有卖票功能
public interface TrainStation {
    void sellTickets();
}
// 广州火车站卖票
public class GuangzhouTrainStation implements TrainStation {
    @Override
    public void sellTickets() {
        System.out.println("广州火车站卖票啦");
    }
}
// 代售点卖票（代理类）
public class ProxyPoint implements TrainStation {
    // 目标对象（代理火车站售票）
    private GuangzhouTrainStation station = new GuangzhouTrainStation();
    @Override
    public void sellTickets() {
        System.out.println("代售加收5%手续费");
        station.sellTickets();
    }
    public static void main(String[] args) {
        ProxyPoint proxyPoint = new ProxyPoint();
        // 代售加收5%手续费
        // 广州火车站卖票啦
        proxyPoint.sellTickets();
    }
}
    // 测试
    public static void main(String[] args) {
        ProxyPoint proxyPoint = new ProxyPoint();
        // 代售加收5%手续费
        // 火车站卖票啦
        proxyPoint.sellTickets();
    }
	
动态代理：
代理类在代码运行时创建的代理称之为动态代理。
动态代理中代理类并不是预先在Java代码中定义好的，而是运行时由JVM动态生成，并且可以代理多个目标对象。	
// 火车站接口，有卖票功能
public interface TrainStation {
    void sellTickets();
}
// 广州火车站卖票
public class GuangzhouTrainStation implements TrainStation {
    @Override
    public void sellTickets() {
        System.out.println("广州火车站卖票啦");
    }
}
// 深圳火车站卖票
public class ShenzhenTrainStation implements TrainStation {
    @Override
    public void sellTickets() {
        System.out.println("深圳火车站卖票啦");
    }
}
// 代售点卖票（代理类）
public class ProxyPoint implements InvocationHandler {
    private TrainStation trainStation;
    public TrainStation getProxyObject(TrainStation trainStation) {
        this.trainStation = trainStation;
        Class<? extends TrainStation> clazz = trainStation.getClass();
        return (TrainStation) Proxy.newProxyInstance(clazz.getClassLoader(), clazz.getInterfaces(), this);
    }
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println("代售火车票收取5%手续费");
        return method.invoke(this.trainStation, args);
    }
}
    // 测试
    public static void main(String[] args) {
        ProxyPoint proxy = new ProxyPoint();
        TrainStation guangzhouTrainStation = proxy.getProxyObject(new GuangzhouTrainStation());
        // 代售火车票收取5%手续费
        // 广州火车站卖票啦
        guangzhouTrainStation.sellTickets();
        TrainStation shenzhenTrainStation = proxy.getProxyObject(new ShenzhenTrainStation());
        // 代售火车票收取5%手续费
        // 深圳火车站卖票啦
        shenzhenTrainStation.sellTickets();
    }

9、结构型-桥接模式：
桥接模式也称为桥梁模式、接口模式或者柄体（Handle and Body）模式，是将抽象部分与他的具体实现部分分离，
使它们都可以独立地变化，通过组合的方式建立两个类之间的联系，而不是继承。
桥接（Bridge）模式包含以下主要角色：
抽象化（Abstraction）角色 ：定义抽象类，并包含一个对实现化对象的引用。
扩展抽象化（Refined Abstraction）角色 ：是抽象化角色的子类，实现父类中的业务方法，并通过组合关系调用实现化角色中的业务方法。
实现化（Implementor）角色 ：定义实现化角色的接口，供扩展抽象化角色调用。
具体实现化（Concrete Implementor）角色 ：给出实现化角色接口的具体实现。

// 视频接口
public interface Video {
    void decode(String fileName);
}
 
// MP4格式类
public class Mp4 implements Video{
    @Override
    public void decode(String fileName) {
        System.out.println("MP4视频文件："+ fileName);
    }
}
// RMVB格式类
public class Rmvb implements Video{
    @Override
    public void decode(String fileName) {
        System.out.println("rmvb文件：" + fileName);
    }
}
// 操作系统抽象类
@AllArgsConstructor
public abstract class OperatingSystem {
    Video video;
    public abstract void play(String fileName);
 
}
// iOS系统
public class Ios extends OperatingSystem {
    public Ios(Video video){
        super(video);
    }
    @Override
    public void play(String fileName) {
        video.decode(fileName);
    }
}
// windows系统
public class Windows extends OperatingSystem {
    public Windows(Video video){
        super(video);
    }
    @Override
    public void play(String fileName) {
        video.decode(fileName);
    }
}
视频类和操作系统类之间通过OperatingSystem类桥接关联起来。

在JDBC中使用桥接模式：
在Java中我们使用 JDBC 连接数据库时，在各个数据库之间进行切换，基本不需要动太多的代码，
原因就是使用了桥接模式，JDBC 提供统一接口，每个数据库提供各自的实现，
然后由桥接类创建一个连接数据库的驱动，使用某一个数据库的时候只需要切换一下就行。

在 JDBC 中，桥接模式的实现化角色 (Implementor) 为的 Driver 接口，
具体实现化 (Concrete Implementor) 角色对应 MysqlDriver、OracleDriver 和 MariadbDriver，
扩展抽象化 (Refined Abstraction) 角色对应 DriverManager，不具有抽象化 (Abstraction) 角色作为扩展抽象化角色的父类。

适用场景：
在抽象和具体实现之间需要增加更多的灵活性的场景。
一个类存在两个（或多个）独立变化的维度，而这两个（或多个）维度都需要独立进行扩展。
不希望使用继承，或因为多层继承导致系统类的个数剧增。

优点：
分离抽象部分及其具体实现部分。
提高了系统的扩展性。
符合开闭原型。
符合合成复用原则。

缺点：
增加了系统的理解与设计难度。
需要正确地识别系统中两个独立变化的维度。


10、结构型-外观模式：
外观模式又称门面模式，提供了一个统一的接口，用来访问子系统中的一群接口。

特征：门面模式定义了一个高层接口，让子系统更容易使用。

外观（Facade）模式包含以下主要角色：
外观（Facade）角色：为多个子系统对外提供一个共同的接口。
子系统（Sub System）角色：实现系统的部分功能，客户可以通过外观角色访问它。

public class Light {
    public void on() {
        System.out.println("开灯");
    }
    public void off() {
        System.out.println("关灯");
    }
}
public class Tv {
    public void on() {
        System.out.println("开电视");
    }
    public void off() {
        System.out.println("关电视");
    }
}
public class Fan {
    public void on() {
        System.out.println("开风扇");
    }
    public void off() {
        System.out.println("关风扇");
    }
}

public class SmartSpeaker {
    private Light light;
    private Tv tv;
    private Fan fan;
    public SmartSpeaker() {
        light = new Light();
        tv = new Tv();
        fan = new Fan();
    }
    public void say(String order) {
        if (order.contains("起床")) {
            getUp();
        } else if (order.contains("睡觉")) {
            sleep();
        } else {
            System.out.println("我还听不懂你说的啥！");
        }
    }
    public void getUp() {
        System.out.println("起床");
        light.on();
        tv.on();
        fan.off();
    }
    public void sleep() {
        System.out.println("睡觉");
        light.off();
        tv.off();
        fan.on();
    }
}
    public static void main(String[] args) {
        SmartSpeaker smartSpeaker = new SmartSpeaker();
        //睡觉
        //关灯
        //关电视
        //开风扇
        smartSpeaker.say("我要睡觉了!");
        //起床
        //开灯
        //开电视
        //关风扇
        smartSpeaker.say("我起床了!");
        //我还听不懂你说的啥！
        smartSpeaker.say("Emmm");
    }


适用场景：
对分层结构系统构建时，使用外观模式定义子系统中每层的入口点可以简化子系统之间的依赖关系。
当一个复杂系统的子系统很多时，外观模式可以为系统设计一个简单的接口供外界访问。
当客户端与多个子系统之间存在很大的联系时，引入外观模式可将它们分离，从而提高子系统的独立性和可移植性。

优点：
简化了调用过程，无需深入了解子系统，以防给子系统带来风险。
减少系统依赖、松散耦合。
更好地划分访问层次，提高了安全性。
遵循迪米特法则，即最少知道原则。

缺点：
当增加子系统和扩展子系统行为时，可能容易带来未知风险。
不符合开闭原则。
某些情况下可能违背单一职责原则。


11、结构型-组合模式：
组合模式也称为整体-部分（Part-Whole）模式，它的宗旨是通过将单个对象（叶子结点）和组合对象（树枝节点）用相同的接口进行表示。
作用：使客户端对单个对象和组合对象保持一致的方式处理。

组合模式主要包含三种角色：
抽象根节点（Component）：定义系统各层次对象的共有方法和属性，可以预先定义一些默认行为和属性。
树枝节点（Composite）：定义树枝节点的行为，存储子节点，组合树枝节点和叶子节点形成一个树形结构。
叶子节点（Leaf）：叶子节点对象，其下再无分支，是系统层次遍历的最小单位。

// 菜单组件
public abstract class MenuComponent {
    String name;
    Integer level;
    public void add(MenuComponent menuComponent) {
        throw new UnsupportedOperationException("不支持添加操作!");
    }
    public void remove(MenuComponent menuComponent) {
        throw new UnsupportedOperationException("不支持删除操作!");
    }
    public MenuComponent getChild(Integer i) {
        throw new UnsupportedOperationException("不支持获取子菜单操作!");
    }
    public String getName() {
        throw new UnsupportedOperationException("不支持获取名字操作!");
    }
    public void print() {
        throw new UnsupportedOperationException("不支持打印操作!");
    }
}
// 菜单类
public class Menu extends MenuComponent {
    private List<MenuComponent> menuComponentList = new ArrayList<>();
    public Menu(String name,int level){
        this.level = level;
        this.name = name;
    }
    @Override
    public void add(MenuComponent menuComponent) {
        menuComponentList.add(menuComponent);
    }
    @Override
    public void remove(MenuComponent menuComponent) {
        menuComponentList.remove(menuComponent);
    }
    @Override
    public MenuComponent getChild(Integer i) {
        return menuComponentList.get(i);
    }
    @Override
    public void print() {
        for (int i = 1; i < level; i++) {
            System.out.print("--");
        }
        System.out.println(name);
        for (MenuComponent menuComponent : menuComponentList) {
            menuComponent.print();
        }
    }
}
// 子菜单类
public class MenuItem extends MenuComponent {
    public MenuItem(String name,int level) {
        this.name = name;
        this.level = level;
    }
    @Override
    public void print() {
        for (int i = 1; i < level; i++) {
            System.out.print("--");
        }
        System.out.println(name);
    }
}
    // 测试方法
    public static void main(String[] args) {
        //创建一级菜单
        MenuComponent component = new Menu("系统管理",1);
 
        MenuComponent menu1 = new Menu("用户管理",2);
        menu1.add(new MenuItem("新增用户",3));
        menu1.add(new MenuItem("修改用户",3));
        menu1.add(new MenuItem("删除用户",3));
 
        MenuComponent menu2 = new Menu("角色管理",2);
        menu2.add(new MenuItem("新增角色",3));
        menu2.add(new MenuItem("修改角色",3));
        menu2.add(new MenuItem("删除角色",3));
        menu2.add(new MenuItem("绑定用户",3));
 
        //将二级菜单添加到一级菜单中
        component.add(menu1);
        component.add(menu2);
 
        //打印菜单名称(如果有子菜单一块打印)
        component.print();
    }
// 测试结果
系统管理
--用户管理
----新增用户
----修改用户
----删除用户
--角色管理
----新增角色
----修改角色
----删除角色
----绑定用户
 

12、结构型-享元模式：
享元模式又称为轻量级模式，是对象池的一种实现，类似于线程池，线程池可以避免不停的创建和销毁多个对象，消耗性能。
提供了减少对象数量从而改善应用所需的对象结构的方式。宗旨：共享细粒度对象，将多个对同一对象的访问集中起来。

享元（Flyweight ）模式中存在以下两种状态：
内部状态，即不会随着环境的改变而改变的可共享部分。
外部状态，指随环境改变而改变的不可以共享的部分。享元模式的实现要领就是区分应用中的这两种状态，并将外部状态外部化。

享元模式的主要有以下角色：

抽象享元角色（Flyweight）：通常是一个接口或抽象类，在抽象享元类中声明了具体享元类公共的方法，
这些方法可以向外界提供享元对象的内部数据（内部状态），同时也可以通过这些方法来设置外部数据（外部状态）。

具体享元（Concrete Flyweight）角色 ：它实现了抽象享元类，称为享元对象；
在具体享元类中为内部状态提供了存储空间。通常我们可以结合单例模式来设计具体享元类，
为每一个具体享元类提供唯一的享元对象。

非享元（Unsharable Flyweight)角色 ：并不是所有的抽象享元类的子类都需要被共享，
不能被共享的子类可设计为非共享具体享元类；当需要一个非共享具体享元类的对象时可以直接通过实例化创建。

享元工厂（Flyweight Factory）角色 ：负责创建和管理享元角色。当客户对象请求一个享元对象时，
享元工厂检査系统中是否存在符合要求的享元对象，如果存在则提供给客户；如果不存在的话，则创建一个新的享元对象。

// 抽象接口
public interface ITicket {
    void show(String seat);
}
public class TrainTicket implements ITicket {
    private String from;
    private String to;
    private Integer price;
    public TrainTicket(String from, String to) {
        this.from = from;
        this.to = to;
    }
    @Override
    public void show(String seat) {
        this.price = new Random().nextInt(500);
        System.out.println(from + "->" + to + ":" + seat + "价格:" + this.price);
    }
}
// 工厂类
public class TicketFactory {
    private static Map<String, ITicket> pool = new ConcurrentHashMap<>();
    public static ITicket getTicket(String from, String to) {
        String key = from + "->" + to;
        if (pool.containsKey(key)) {
            System.out.println("使用缓存获取火车票:" + key);
            return pool.get(key);
        }
        System.out.println("使用数据库获取火车票:" + key);
        ITicket ticket = new TrainTicket(from, to);
        pool.put(key, ticket);
        return ticket;
    }
}
    // 测试
    public static void main(String[] args) {
        ITicket ticket = getTicket("北京", "上海");
        //使用数据库获取火车票:北京->上海
        //北京->上海:二等座价格:20
        ticket.show("二等座");
        ITicket ticket1 = getTicket("北京", "上海");
        //使用缓存获取火车票:北京->上海
        //北京->上海:商务座价格:69
        ticket1.show("商务座");
        ITicket ticket2 = getTicket("上海", "北京");
        //使用数据库获取火车票:上海->北京
        //上海->北京:一等座价格:406
        ticket2.show("一等座");
        System.out.println(ticket == ticket1);//true
        System.out.println(ticket == ticket2);//false
    }
	
注意：
可以看到ticket和ticket2是使用数据库查询的，而ticket1是使用缓存查询的，
同时ticket == ticket1返回的是true，ticket == ticket2返回的是false，证明ticket和ticket1是共享的对象。

适用场景：
一个系统有大量相同或者相似的对象，造成内存的大量耗费。
对象的大部分状态都可以外部化，可以将这些外部状态传入对象中。
在使用享元模式时需要维护一个存储享元对象的享元池，而这需要耗费一定的系统资源，因此，应当在需要多次重复使用享元对象时才值得使用享元模式。

优点：
减少对象的创建，降低内存中对象的数量，降低系统的内存，提高效率。
减少内存之外的其他资源占用。

缺点：
关注内、外部状态。
关注线程安全问题。
使系统、程序的逻辑复杂化。

Java 中，String 类型就是使用享元模式，String 对象是 final 类型，对象一旦创建就不可改变。
而 Java 的字符串常量都是存在字符串常量池中的，JVM 会确保一个字符串常量在常量池中只有一个拷贝。
而且提到共享池，我们也很容易联想到 Java 里面的JDBC连接池，通过连接池的管理，实现了数据库连接的共享，
不需要每一次都重新创建连接，节省了数据库重新创建的开销，提升了系统的性能！


 13、行为型-策略模式：
策略模式又叫政策模式（Policy Pattern），它是将定义的算法家族分别封装起来，让它们之间可以互相替换，从而让算法的变化不会影响到使用算法的用户。可以避免多重分支的if......else和switch语句。

策略模式的主要角色如下：

抽象策略（Strategy）类：这是一个抽象角色，通常由一个接口或抽象类实现。此角色给出所有的具体策略类所需的接口。
具体策略（Concrete Strategy）类：实现了抽象策略定义的接口，提供具体的算法实现或行为。
环境（Context）类：持有一个策略类的引用，最终给客户端调用。

策略模式适用用于以下几种场景：
（1）应用程序需要实现特定的功能服务，而该程序有多种实现方式使用，所以需要动态地在几种算法中选择一种
（2）一个类定义了多种行为算法，并且这些行为在类的操作中以多个条件语句的形式出现，
就可以将相关的条件分支移入它们各自的Strategy类中以代替这些条件语句。

// 会员卡接口
public interface VipCard {
    public void discount();
}
public class GoldCard implements VipCard {
    @Override
    public void discount() {
        System.out.println("金卡打7折");
    }
}
public class SilverCard implements VipCard {
    @Override
    public void discount() {
        System.out.println("银卡打8折");
    }
}
public class CopperCard implements VipCard {
    @Override
    public void discount() {
        System.out.println("铜卡打9折");
    }
}
public class Normal implements VipCard {
    @Override
    public void discount() {
        System.out.println("普通会员没有折扣");
    }
}
// 会员卡容器类
public class VipCardFactory {
    private static Map<String, VipCard> map = new ConcurrentHashMap<>();
    static {
        map.put("gold", new GoldCard());
        map.put("silver", new SilverCard());
        map.put("copper", new CopperCard());
    }
    public static VipCard getVIPCard(String level) {
        return map.get(level) != null ? map.get(level) : new Normal();
    }
 
}
    // 测试方法
    public static void main(String[] args) {
        //金卡打7折
        VipCardFactory.getVIPCard("gold").discount();
        //银卡打8折
        VipCardFactory.getVIPCard("silver").discount();
        //普通会员没有折扣
        VipCardFactory.getVIPCard("other").discount();
    }
	
总结：
适用场景：
系统中有很多类，而它们的区别仅仅在于它们的行为不同。
系统需要动态地在几种算法中选择一种。
需要屏蔽算法规则。

优点：
符合开闭原则。
避免使用多重条件语句。
可以提高算法的保密性和安全性。
易于扩展。

缺点：
客户端必须知道所有的策略，并且自行决定使用哪一个策略类。
代码中会产生非常多的策略类，增加维护难度。
	
14、行为型-模板方法：
模板方法模式通常又叫模板模式，是指定义一个算法的骨架，并允许之类为其中的一个或者多个步骤提供实现。模板方法模式使得子类可以在不改变算法结构的情况下，重新定义算法的某些步骤。

模板方法（Template Method）模式包含以下主要角色：

抽象类（Abstract Class）：负责给出一个算法的轮廓和骨架。它由一个模板方法和若干个基本方法构成。
模板方法：定义了算法的骨架，按某种顺序调用其包含的基本方法。
基本方法：是实现算法各个步骤的方法，是模板方法的组成部分。基本方法又可以分为三种：
抽象方法(Abstract Method) ：一个抽象方法由抽象类声明、由其具体子类实现。
具体方法(Concrete Method) ：一个具体方法由一个抽象类或具体类声明并实现，其子类可以进行覆盖也可以直接继承。
钩子方法(Hook Method) ：在抽象类中已经实现，包括用于判断的逻辑方法和需要子类重写的空方法两种。一般钩子方法是用于判断的逻辑方法，这类方法名一般为isXxx，返回值类型为boolean类型。
具体子类（Concrete Class）：实现抽象类中所定义的抽象方法和钩子方法，它们是一个顶级逻辑的组成步骤。

public abstract class DayOffProcess {
    // 请假模板
    public final void dayOffProcess() {
        // 领取申请表
        this.pickUpForm();
        // 填写申请信息
        this.writeInfo();
        // 签名
        this.signUp();
        // 提交到不同部门审批
        this.summit();
        // 行政部备案
        this.filing();
    }
    private void filing() {
        System.out.println("行政部备案");
    }
    protected abstract void summit();
    protected abstract void signUp();
    private void writeInfo() {
        System.out.println("填写申请信息");
    }
    private void pickUpForm() {
        System.out.println("领取申请表");
    }
}
public class ZhangSan extends DayOffProcess {
    @Override
    protected void summit() {
        System.out.println("张三签名");
    }
    @Override
    protected void signUp() {
        System.out.println("提交到技术部审批");
    }
}
public class Lisi extends DayOffProcess {
    @Override
    protected void summit() {
        System.out.println("李四签名");
    }
    @Override
    protected void signUp() {
        System.out.println("提交到市场部审批");
    }
}
    // 测试方法
    public static void main(String[] args) {
        DayOffProcess zhangsan = new ZhangSan();
        //领取申请表
        //填写申请信息
        //提交到技术部审批
        //张三签名
        //行政部备案
        zhangsan.dayOffProcess();
        DayOffProcess lisi = new Lisi();
        //领取申请表
        //填写申请信息
        //提交到市场部审批
        //李四签名
        //行政部备案
        lisi.dayOffProcess();
    }


适用场景：
一次性实现一个算法不变的部分，并将可变的行为留给子类来实现。
各子类中公共的行为被提取出来并集中到一个公共的父类中，从而避免代码重复。

优点：
利用模板方法将相同处理逻辑的代码放到抽象父类中，可以提高代码的复用性。
将不同的代码不同的子类中，通过对子类的扩展增加新的行为，提高代码的扩展性。
把不变的行为写在父类上，去除子类的重复代码，提供了一个很好的代码复用平台，符合开闭原则。

缺点：
类数目的增加，每一个抽象类都需要一个子类来实现，这样导致类的个数增加。
类数量的增加，间接地增加了系统实现的复杂度。
继承关系自身缺点，如果父类添加新的抽象方法，所有子类都要改一遍。


15、行为型-责任链模式：
职责链可以将请求的处理者组织成一条链，并将请求沿着链传递，如果某个处理者能够处理请求则处理，否则将该请求交由上级处理。客户端只需将请求发送到职责链上，无须关注请求的处理细节，通过职责链将请求的发送者和处理者解耦了，这也是职责链的设计动机。        

职责链模式可以简化对象间的相互连接，因为客户端和处理者都没有对方明确的信息，同时处理者也不知道职责链中的结构，处理者只需保存一个指向后续者的引用，而不需要保存所有候选者的引用。

另外职责链模式增加了系统的灵活性，我们可以任意增加或更改处理者，甚至更改处理者的顺序，不过有可能会导致一个请求无论如何也得不到处理，因为它可能被放置在链末端。

所以责任链模式有以下几个优点：

（1）降低耦合度，将请求的发送者和接收者解耦。反映在代码上就是不需要在类中写很多丑陋的 if….else 语句，如果用了职责链，相当于我们面对一个黑箱，只需将请求递交给其中一个处理者，然后让黑箱内部去负责传递就可以了。
（2）简化了对象，使得对象不需要链的结构。
（3）增加系统的灵活性，通过改变链内的成员或者调动他们的次序，允许动态地新增或者删除处理者
（4）增加新的请求处理类很方便。
但是责任链模式也存在一些缺点：

（1）不能保证请求一定被成功处理
（2）系统性能将受到一定影响，并且可能会造成循环调用。
（3）可能不容易观察运行时的特征，而且在进行代码调试时不太方便，有碍于除错。
 

// 用户实体类
@Data
public class User {
    private String username;
    private String password;
    private String role;
}
// handler抽象类
public abstract class Handler {
    protected Handler next;
    // 返回handler方便链式操作
    public void next(Handler next) {
        this.next = next;
    }
    // 流程开始的方法
    public abstract void doHandler(User user);
}
// 校验用户名或者密码是否为空
public class ValidateHandler extends Handler {
    @Override
    public void doHandler(User user) {
        if (StringUtils.isBlank(user.getUsername()) || StringUtils.isBlank(user.getPassword())) {
            System.out.println("用户名或者密码为空!");
            return;
        }
        System.out.println("校验通过");
        next.doHandler(user);
    }
}
// 登录校验，校验用户名是否匹配密码
public class LoginHandler extends Handler {
    @Override
    public void doHandler(User user) {
        if (!"pyy52hz".equals(user.getUsername()) || !"123456".equals(user.getPassword())) {
            System.out.println("用户名或者密码不正确!请检查!");
            return;
        }
        user.setRole("admin");
        System.out.println("登陆成功!角色为管理员!");
        next.doHandler(user);
    }
}
// 权限校验
public class AuthHandler extends Handler {
    @Override
    public void doHandler(User user) {
        if (!"admin".equals(user.getRole())) {
            System.out.println("无权限操作!");
            return;
        }
        System.out.println("角色为管理员,可以进行下一步操作!");
    }
}
// 登录流程
public class LoginService {
    public void login(User user) {
        Handler validateHandler = new ValidateHandler();
        Handler loginHandler = new LoginHandler();
        Handler authHandler = new AuthHandler();
        validateHandler.next(loginHandler);
        loginHandler.next(authHandler);
        validateHandler.doHandler(user);
    }
}
    // 测试方法
    public static void main(String[] args){
      User user = new User();
      //校验通过
      //用户名或者密码不正确!请检查!
      user.setUsername("pyy52hz");
      user.setPassword("1234567");
      LoginService loginService = new LoginService();
      loginService.login(user);
      //校验通过
      //登陆成功!角色为管理员!
      //角色为管理员,可以进行下一步操作!
      user.setUsername("pyy52hz");
      user.setPassword("123456");
      loginService.login(user);
    }


       
16、行为型-观察者模式：
观察者模式又称为 发布-订阅模式，定义了对象之间一对多依赖关系，当目标对象(被观察者)的状态发生改变时，它的所有依赖者(观察者)都会收到通知。
一个观察目标可以对应多个观察者，而这些观察者之间没有相互联系，所以能够根据需要增加和删除观察者，使得系统更易于扩展，符合开闭原则；
并且观察者模式让目标对象和观察者松耦合，虽然彼此不清楚对方的细节，但依然可以交互，目标对象只知道一个具体的观察者列表，
但并不认识任何一个具体的观察者，它只知道他们都有一个共同的接口。

但观察者模式的缺点在于如果存在很多个被观察者的话，那么将需要花费一定时间通知所有的观察者，如果观察者与被观察者之间存在循环依赖的话，那么可能导致系统崩溃，并且观察者模式没有相应的机制让观察者知道被观察对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。

// 抽象观察者接口
public interface Observer {
    void update(String message);
}
// 微信用户类 具体的观察者
@AllArgsConstructor
public class WeixinUser implements Observer {
    private String name;
    @Override
    public void update(String message) {
        System.out.println(name + "接收到了消息(观察到了):" + message);
    }
}
// 被观察者接口
public interface Observable {
    // 新增用户(新增观察者)
    void add(Observer observer);
    // 移除用户,或者说用户取消订阅(移除观察者)
    void del(Observer observer);
    // 发布 推送消息
    void notify(String message);
}
// 具体的被观察者(公众号)
public class Subject implements Observable {
    // 观察者列表(订阅用户)
    private List<Observer> list = new ArrayList<>();
    @Override
    public void add(Observer observer) {
        list.add(observer);
    }
    @Override
    public void del(Observer observer) {
        list.remove(observer);
    }
    // 给每一个观察者(订阅者)推送消息
    @Override
    public void notify(String message) {
        list.forEach(observer -> observer.update(message));
    }
 
}
    // 测试
    public static void main(String[] args){
      Observable o = new Subject();
      WeixinUser user1 = new WeixinUser("张三");
      WeixinUser user2 = new WeixinUser("李四");
      WeixinUser user3 = new WeixinUser("王五");
      o.add(user1);
      o.add(user2);
      o.add(user3);
      o.notify("薛之谦演唱会要来到广州啦!");
      // 运行结果
      // 张三接收到了消息(观察到了):薛之谦演唱会要来到广州啦!
      // 李四接收到了消息(观察到了):薛之谦演唱会要来到广州啦!
      // 王五接收到了消息(观察到了):薛之谦演唱会要来到广州啦!
    }
 
JDK实现
在 Java 中，通过java.util.Observable类和 java.util.Observer接口定义了观察者模式，只要实现它们的子类就可以编写观察者模式实例。

1 Observable类
Observable类是抽象目标类（被观察者），它有一个Vector集合成员变量，用于保存所有要通知的观察者对象，下面是它最重要的 3 个方法：
void addObserver(Observer o) 方法：用于将新的观察者对象添加到集合中。
void notifyObservers(Object arg) 方法：调用集合中的所有观察者对象的update方法，通知它们数据发生改变。通常越晚加入集合的观察者越先得到通知。
void setChange() 方法：用来设置一个boolean类型的内部标志，注明目标对象发生了变化。当它为true时，notifyObservers() 才会通知观察者。

2 Observer 接口
Observer 接口是抽象观察者，它监视目标对象的变化，当目标对象发生变化时，观察者得到通知，并调用 update 方法，进行相应的工作。

3 代码实现
// 具体的被观察者(公众号)
@Data
@AllArgsConstructor
public class Subject extends Observable {
    // 公众号的名字
    private String name;
    // 公众号发布消息
    public void notifyMessage(String message) {
        System.out.println(this.name + "公众号发布消息:" + message + "请关注用户留意接收!");
        super.setChanged();
        super.notifyObservers(message);
    }
}
@AllArgsConstructor
public class WeixinUser implements Observer {
    private String name;
    /**
     * @param o 被观察者
     * @param arg 被观察者带过来的参数，此例子中是公众号发布的消息
     */
    @Override
    public void update(Observable o, Object arg) {
        System.out.println(name + "关注了公众号(被观察者):" + ((Subject)o).getName() + ",接收到消息:" + arg);
    }
}
    // 测试
    public static void main(String[] args){
        WeixinUser user1 = new WeixinUser("张三");
        WeixinUser user2 = new WeixinUser("李四");
        WeixinUser user3 = new WeixinUser("王五");
        Subject subject = new Subject("演唱会消息发布");
        subject.addObserver(user1);
        subject.addObserver(user2);
        subject.addObserver(user3);
        subject.notifyMessage("薛之谦演唱会要来到广州啦!");
        // 返回结果
        // 演唱会消息发布公众号发布消息:薛之谦演唱会要来到广州啦!请关注用户留意接收!
        // 王五关注了公众号(被观察者):演唱会消息发布,接收到消息:薛之谦演唱会要来到广州啦!
        // 李四关注了公众号(被观察者):演唱会消息发布,接收到消息:薛之谦演唱会要来到广州啦!
        // 张三关注了公众号(被观察者):演唱会消息发布,接收到消息:薛之谦演唱会要来到广州啦!
    }

适用场景：
当一个抽象模型包含两个方面内容，其中一个方面依赖于另一个方面。
其他一个或多个对象的变化依赖于另一个对象的变化。
实现类似广播机制的功能，无需知道具体收听者，只需分发广播，系统中感兴趣的对象会自动接收该广播。
多层级嵌套使用，形成一种链式触发机制，使得事件具备跨域（跨越两种观察者类型）通知。

优点：
观察者和被观察者是松耦合（抽象耦合）的，符合依赖倒置原则。
分离了表示层（观察者）和数据逻辑层（被观察者），并且建立了一套触发机制，使得数据的变化可以相应到多个表示层上。
实现了一对多的通讯机制，支持事件注册机制，支持兴趣分发机制，当被观察者触发事件时，只有感兴趣的观察者可以接收到通知。

缺点：
如果观察者数量过多，则事件通知会耗时较长。
事件通知呈线性关系，如果其中一个观察者处理事件卡壳，会影响后续的观察者接收该事件。
如果观察者和被观察者之间存在循环依赖，则可能造成两者之间的循环调用，导致系统崩溃。

17、行为型-访问者模式：
访问者模式是一种将数据结构与数据操作分离的设计模式。是指封装一些作用于某种数据结构中的各元素的操作。

特征：可以在不改变数据结构的前提下定义作用于这些元素的新的操作。

访问者模式包含以下主要角色:

抽象访问者（Visitor）角色：定义了对每一个元素 （Element） 访问的行为，它的参数就是可以访问的元素，它的方法个数理论上来讲与元素类个数（Element的实现类个数）是一样的，从这点不难看出，访问者模式要求元素类的个数不能改变。
具体访问者（ConcreteVisitor）角色：给出对每一个元素类访问时所产生的具体行为。
抽象元素（Element）角色：定义了一个接受访问者的方法（ accept ），其意义是指，每一个元素都要可以被访问者访问。
具体元素（ConcreteElement）角色： 提供接受访问方法的具体实现，而这个具体的实现，通常情况下是使用访问者提供的访问该元素类的方法。
对象结构（Object Structure）角色：定义当中所提到的对象结构，对象结构是一个抽象表述，具体点可以理解为一个具有容器性质或者复合对象特性的类，它会含有一组元素（ Element ），并且可以迭代这些元素，供访问者访问。


// 访问者接口
public interface IVisitor {
    void visit(Engineer engineer);
    void visit(Pm pm);
}
// 具体的访问者类,访问者角色(CEO)
public class CeoVisitor implements IVisitor {
    @Override
    public void visit(Engineer engineer) {
        System.out.println(engineer.getName() + "KPI为:" + engineer.getKpi());
    }
    @Override
    public void visit(Pm pm) {
        System.out.println(pm.getName() + "KPI为:" + pm.getKpi());
    }
}
// 具体的访问者类,访问者角色(CTO)
public class CtoVisitor implements IVisitor {
    @Override
    public void visit(Engineer engineer) {
        System.out.println(engineer.getName() + "工作内容:" + engineer.getCodeLine() + "行代码");
    }
    @Override
    public void visit(Pm pm) {
        System.out.println(pm.getName() + "工作内容:" + pm.getProject() + "个项目");
    }
}
@Data
// 抽象元素(员工)
public abstract class Employee {
    private String name;
    private Integer kpi;
    public Employee(String name) {
        this.name = name;
        this.kpi = new Random().nextInt(10);
    }
    public abstract void accept(IVisitor visitor);
}
// 具体元素(程序员)
public class Engineer extends Employee {
    public Engineer(String name) {
        super(name);
    }
    @Override
    public void accept(IVisitor visitor) {
        visitor.visit(this);
    }
    public Integer getCodeLine() {
        return new Random().nextInt(10000);
    }
}
// 具体元素(项目经理)
public class Pm extends Employee {
    public Pm(String name) {
        super(name);
    }
    @Override
    public void accept(IVisitor visitor) {
        visitor.visit(this);
    }
    public Integer getProject() {
        return new Random().nextInt(10);
    }
}
@AllArgsConstructor
public class Report {
    private List<Employee> employeeList;
    public void showReport(IVisitor visitor) {
        for (Employee employee : employeeList) {
            employee.accept(visitor);
        }
    }
}
    // 测试
    public static void main(String[] args){
      List<Employee> employeeList = new ArrayList<>();
      employeeList.add(new Engineer("工程师A"));
      employeeList.add(new Engineer("工程师B"));
      employeeList.add(new Engineer("项目经理A"));
      employeeList.add(new Engineer("工程师C"));
      employeeList.add(new Engineer("工程师D"));
      employeeList.add(new Engineer("项目经理B"));
      Report report = new Report(employeeList);
      System.out.println("=============CEO==============");
      report.showReport(new CeoVisitor());
      System.out.println("=============CTO==============");
      report.showReport(new CtoVisitor());
      // =============CEO==============
      // 工程师AKPI为:2
      // 工程师BKPI为:4
      // 项目经理AKPI为:4
      // 工程师CKPI为:2
      // 工程师DKPI为:0
      // 项目经理BKPI为:0
      // =============CTO==============
      // 工程师A工作内容:5811行代码
      // 工程师B工作内容:9930行代码
      // 项目经理A工作内容:2163行代码
      // 工程师C工作内容:4591行代码
      // 工程师D工作内容:333行代码
      // 项目经理B工作内容:3940行代码
    }



在访问者模式使用了双分派技术，所谓双分派技术就是在选择方法的时候，不仅仅要根据消息接收者的运行时区别，还要根据参数的运行时区别。
在访问者模式中，客户端将具体状态当做参数传递给具体访问者，这里完成第一次分派，然后具体访问者作为参数的“具体状态”中的方法，同时也将自己this作为参数传递进去，
这里就完成了第二次分派。双分派意味着得到的执行操作决定于请求的种类和接受者的类型。

适用场景：

数据结构稳定，作用于数据结构的操作经常变化的场景。
需要数据结构与数据操作分离的场景。
需要对不同数据类型（元素）进行操作，而不使用分支判断具体类型的场景。
优点：

解耦了数据结构与数据操作，使得操作集合可以独立变化。
扩展性好：可以通过扩展访问者角色，实现对数据集的不同操作。
元素具体类型并非单一，访问者均可操作。
各角色职责分离，符合单一职责原则。
缺点：

无法增加元素类型：若系统数据结构对象易于变化，经常有新的数据对象增加进来，则访问者类必须增加对应元素类型的操作，违背了开闭原则。
具体元素变更困难：具体元素增加属性，删除属性等操作会导致对应的访问者类需要进行相应的修改，尤其当有大量访问者类时，修改访问太大。
违背依赖倒置原则：为了达到“区别对待”，访问者依赖的是具体元素类型，而不是抽象。


18、行为型-中介者模式：
中介者模式又称为调解者模式或调停者模式。用一个中介对象封装一系列的对象交互，中介者使各对象不需要显示地相互作用，从而使其耦合松散，而且可以独立地改变它们之间的交互。

核心：通过中介者解耦系统各层次对象的直接耦合，层次对象的对外依赖通信统统交由中介者转发。

中介者模式包含以下主要角色：

抽象中介者（Mediator）角色：它是中介者的接口，提供了同事对象注册与转发同事对象信息的抽象方法。
具体中介者（ConcreteMediator）角色：实现中介者接口，定义一个 List 来管理同事对象，协调各个同事角色之间的交互关系，因此它依赖于同事角色。
抽象同事类（Colleague）角色：定义同事类的接口，保存中介者对象，提供同事对象交互的抽象方法，实现所有相互影响的同事类的公共功能。
具体同事类（Concrete Colleague）角色：是抽象同事类的实现者，当需要与其他同事对象交互时，由中介者对象负责后续的交互。

// 抽象同事类
@AllArgsConstructor
public class Person {
    protected String name;
    protected MediatorCompany mediatorCompany;
}
// 房主
public class HouseOwner extends Person {
    public HouseOwner(String name, MediatorCompany mediatorCompany) {
        super(name, mediatorCompany);
    }
    // 联络方法
    public void connection(String message) {
        mediatorCompany.connection(this, message);
    }
    // 获取消息
    public void getMessage(String message) {
        System.out.println("房主" + name + "获取到的信息:" + message);
    }
}
// 租客
public class Tenant extends Person {
    public Tenant(String name, MediatorCompany mediatorCompany) {
        super(name, mediatorCompany);
    }
    public void connection(String message) {
        mediatorCompany.connection(this, message);
    }
    public void getMessage(String message) {
        System.out.println("租客" + name + "获取到的信息:" + message);
    }
}
// 中介公司(中介者)
@Data
public class MediatorCompany {
    private HouseOwner houseOwner;
    private Tenant tenant;
    public void connection(Person person, String message) {
        // 房主需要通过中介获取租客信息
        if (person.equals(houseOwner)) {
            this.tenant.getMessage(message);
        } else { // 反之租客通过中介获取房主信息
            this.houseOwner.getMessage(message);
        }
    }
}
    // 测试
    public static void main(String[] args){
        // 先创建三个角色，中介公司，房主，租客
        MediatorCompany mediatorCompany = new MediatorCompany();
        // 房主和租客都在同一家中介公司
        HouseOwner houseOwner = new HouseOwner("张三", mediatorCompany);
        Tenant tenant = new Tenant("李四", mediatorCompany);
        // 中介公司获取房主和租客的信息
        mediatorCompany.setHouseOwner(houseOwner);
        mediatorCompany.setTenant(tenant);
        // 房主和租客都在这家中介公司发布消息，获取到对应的消息
        tenant.connection(tenant.name + "想租一房一厅!");
        houseOwner.connection(houseOwner.name + "这里有!来看看呗!");
        // 测试结果
        // 房主张三获取到的信息:李四想租一房一厅!
        // 租客李四获取到的信息:张三这里有!来看看呗!
    }


但是，中介者对象封装了对象之间的关联关系，导致中介者对象变得比较庞大复杂，所承担的责任也比较多，维护起来也比较困难，
它需要知道每个对象和他们之间的交互细节，如果它出问题，将会导致整个系统都会出问题。

适用场景：
系统中对象之间存在复杂的引用关系，产生的我相互依赖关系结构混乱且难以理解。
交互的公共行为，如果需要改变行为则可以增加新的中介者类。

优点：
减少类间的依赖，将多对多依赖转化成了一对多，降低了类间耦合。
类间各司其职，符合迪米特法则。

缺点：
中介者模式中将原本多个对象直接的相互依赖变成了中介者和多个同事类的依赖关系。当同事类越多时，中介者就会越臃肿，变得复杂且难以维护。


19、行为型-命令模式：
        命令模式的本质是将请求封装成对象，将发出命令与执行命令的责任分开，命令的发送者和接收者完全解耦，发送者只需知道如何发送命令，不需要关心命令是如何实现的，甚至是否执行成功都不需要理会。命令模式的关键在于引入了抽象命令接口，发送者针对抽象命令接口编程，只有实现了抽象命令接口的具体命令才能与接收者相关联。

        使用命令模式的优势在于降低了系统的耦合度，而且新命令可以很方便添加到系统中，也容易设计一个组合命令。但缺点在于会导致某些系统有过多的具体命令类，因为针对每一个命令都需要设计一个具体命令类。

        命令模式的UML结构图如下：



命令模式详情： Java设计模式之行为型：命令模式

20、行为型-状态模式：
命令模式是对命令的封装，每一个命令都是一个操作：请求的一方发出请求要求执行一个操作；接收的一方收到请求，并执行操作。命令模式解耦了请求方和接收方，请求方只需请求执行命令，不用关心命令是怎样被接收，怎样被操作以及是否被执行等。本质：解耦命令的请求与处理。

命令模式包含以下主要角色：

抽象命令类（Command）角色： 定义命令的接口，声明执行的方法。
具体命令（Concrete Command）角色：具体的命令，实现命令接口；通常会持有接收者，并调用接收者的功能来完成命令要执行的操作。
实现者/接收者（Receiver）角色： 接收者，真正执行命令的对象。任何类都可能成为一个接收者，只要它能够实现命令要求实现的相应功能。
调用者/请求者（Invoker）角色： 要求命令对象执行请求，通常会持有命令对象，可以持有很多的命令对象。这个是客户端真正触发命令并要求命令执行相应操作的地方，也就是说相当于使用命令对象的入口。

// 播放器类
public class Player {
    public void play() {
        System.out.println("正常播放");
    }
    public void pause() {
        System.out.println("暂停播放");
    }
    public void stop() {
        System.out.println("停止播放");
    }
}
// 命令接口
public interface IAction {
    void excuse();
}
// 播放命令类
@AllArgsConstructor
public class PlayAction implements IAction {
    private Player player;
    @Override
    public void excuse() {
        this.player.play();
    }
}
// 暂停命令类
@AllArgsConstructor
public class PauseAction implements IAction {
    private Player player;
    @Override
    public void excuse() {
        this.player.pause();
    }
}
// 停止命令类
@AllArgsConstructor
public class StopAction implements IAction{
    private Player player;
    @Override
    public void excuse() {
        this.player.stop();
    }
}
// 控制器
public class Controller {
    public void excuse(IAction action) {
        action.excuse();
    }
}
   // 测试方法
   public static void main(String[] args) {
        // 正常播放
        new Controller().excuse(new PlayAction(new Player()));
        // 暂停播放
        new Controller().excuse(new PauseAction(new Player()));
        // 停止播放
        new Controller().excuse(new StopAction(new Player()));
    }


适用场景：
现实语义中具备“命令”的操作（如命令菜单，shell命令...）。
请求调用者和请求接收者需要解耦，使得调用者和接收者不直接交互。
需要抽象出等待执行的行为，比如撤销操作和恢复操作等。
需要支持命令宏（即命令组合操作）。

优点：
通过引入中间件（抽象接口），解耦了命令的请求与实现。
扩展性良好，可以很容易地增加新命令。
支持组合命令，支持命令队列。
可以在现有的命令的基础上，增加额外功能。

缺点：
具体命令类可能过多。
增加 了程序的复杂度，理解更加困难。


21、行为型-备忘录模式：
备忘录模式又称为快照模式（Snapshot Pattern）或令牌模式（Token Pattern），是指在不破坏封装的前提下，
捕获一个对象的内部状态，并在对象之外保存这个状态，这样以后就可将该对象恢复到原先保存的状态。
特征：“后悔药”

备忘录模式的主要角色如下：
发起人（Originator）角色：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，它可以访问备忘录里的所有信息。
备忘录（Memento）角色：负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人。
管理者（Caretaker）角色：对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改。
备忘录有两个等效的接口：

窄接口：管理者(Caretaker)对象（和其他发起人对象之外的任何对象）看到的是备忘录的窄接口(narror Interface)，这个窄接口只允许他把备忘录对象传给其他的对象。
宽接口：与管理者看到的窄接口相反，发起人对象可以看到一个宽接口(wide Interface)，这个宽接口允许它读取所有的数据，以便根据这些数据恢复这个发起人对象的内部状态。

“白箱”备忘录模式：
下面就以游戏打怪为简单的例子进行代码实现（下面“黑箱”同这个例子）：
备忘录角色对任何对象都提供一个宽接口，备忘录角色的内部所存储的状态就对所有对象公开。


// 游戏角色类
@Data
public class GameRole {
    private Integer vit; // 生命力
    private Integer atk; // 攻击力
    private Integer def; // 防御力
    // 初始化状态
    public void init() {
        this.vit = 100;
        this.atk = 100;
        this.def = 100;
    }
    // 战斗到0
    public void fight() {
        this.vit = 0;
        this.atk = 0;
        this.def = 0;
    }
    // 保存角色状态
    public RoleStateMemento saveState() {
        return new RoleStateMemento(this.vit, this.atk, this.def);
    }
    // 回复角色状态
    public void recoverState(RoleStateMemento roleStateMemento) {
        this.vit = roleStateMemento.getVit();
        this.atk = roleStateMemento.getAtk();
        this.def = roleStateMemento.getDef();
    }
    // 展示状态
    public void showState() {
        System.out.println("角色生命力:" + this.vit);
        System.out.println("角色攻击力:" + this.atk);
        System.out.println("角色防御力:" + this.def);
    }
}
// 游戏状态存储类(备忘录类)
@Data
@AllArgsConstructor
public class RoleStateMemento {
    private Integer vit; // 生命力
    private Integer atk; // 攻击力
    private Integer def; // 防御力
}
// 角色状态管理者类
@Data
public class RoleStateCaretaker {
    private RoleStateMemento roleStateMemento;
}
    // 测试结果
    public static void main(String[] args){
      System.out.println("===========打boss前状态===========");
      GameRole gameRole = new GameRole();
      gameRole.init();
      gameRole.showState();
      // 保存进度
      RoleStateCaretaker roleStateCaretaker = new RoleStateCaretaker();
      roleStateCaretaker.setRoleStateMemento(gameRole.saveState());
      System.out.println("===========打boss后状态===========");
      gameRole.fight();
      gameRole.showState();
      System.out.println("===========恢复状态===========");
      gameRole.recoverState(roleStateCaretaker.getRoleStateMemento());
      gameRole.showState();
      // ===========打boss前状态===========
      // 角色生命力:100
      // 角色攻击力:100
      // 角色防御力:100
      // ===========打boss后状态===========
      // 角色生命力:0
      // 角色攻击力:0
      // 角色防御力:0
      // ===========恢复状态===========
      // 角色生命力:100
      // 角色攻击力:100
      // 角色防御力:100
    }
 
"白箱"备忘录模式是破坏封装性的，但是通过程序员自律，同样可以在一定程度上实现大部分的用意。

“黑箱”备忘录模式:
备忘录角色对发起人对象提供了一个宽接口，而为其他对象提供一个窄接口，
在Java语言中，实现双重接口的办法就是将备忘录类设计成发起人类的内部成员类。
将RoleStateMemento设为GameRole的内部类，从而将RoleStateMemento对象封装在GameRole 里面；
在外面提供一个标识接口Memento给RoleStateCaretaker及其他对象使用。
这样GameRole类看到的是RoleStateMemento所有的接口，
而RoleStateCaretaker及其他对象看到的仅仅是标识接口Memento所暴露出来的接口，从而维护了封装型。


// 窄接口,标识接口
public interface Memento {
}
// 角色状态管理者类
@Data
public class RoleStateCaretaker {
    private Memento memento;
}
// 游戏角色类
@Data
public class GameRole {
    private Integer vit; // 生命力
    private Integer atk; // 攻击力
    private Integer def; // 防御力
    // 初始化状态
    public void init() {
        this.vit = 100;
        this.atk = 100;
        this.def = 100;
    }
    // 战斗到0
    public void fight() {
        this.vit = 0;
        this.atk = 0;
        this.def = 0;
    }
    // 保存角色状态
    public RoleStateMemento saveState() {
        return new RoleStateMemento(this.vit, this.atk, this.def);
    }
    // 回复角色状态
    public void recoverState(Memento memento) {
        RoleStateMemento roleStateMemento = (RoleStateMemento) memento;
        this.vit = roleStateMemento.getVit();
        this.atk = roleStateMemento.getAtk();
        this.def = roleStateMemento.getDef();
    }
    // 展示状态
    public void showState() {
        System.out.println("角色生命力:" + this.vit);
        System.out.println("角色攻击力:" + this.atk);
        System.out.println("角色防御力:" + this.def);
    }
    // 备忘录内部类
    @Data
    @AllArgsConstructor
    private class RoleStateMemento implements Memento {
        private Integer vit; // 生命力
        private Integer atk; // 攻击力
        private Integer def; // 防御力
    }
}
    // 测试结果
    public static void main(String[] args){
      System.out.println("===========打boss前状态===========");
      GameRole gameRole = new GameRole();
      gameRole.init();
      gameRole.showState();
      // 保存进度
      RoleStateCaretaker roleStateCaretaker = new RoleStateCaretaker();
      roleStateCaretaker.setMemento(gameRole.saveState());
      System.out.println("===========打boss后状态===========");
      gameRole.fight();
      gameRole.showState();
      System.out.println("===========恢复状态===========");
      gameRole.recoverState(roleStateCaretaker.getMemento());
      gameRole.showState();
      // ===========打boss前状态===========
      // 角色生命力:100
      // 角色攻击力:100
      // 角色防御力:100
      // ===========打boss后状态===========
      // 角色生命力:0
      // 角色攻击力:0
      // 角色防御力:0
      // ===========恢复状态===========
      // 角色生命力:100
      // 角色攻击力:100
      // 角色防御力:100
    }

适用场景：
需要保存历史快照的场景。
希望在对象之外保存状态，且除了自己其他类对象无法访问状态保存具体内容。

优点：
简化发起人实体类职责，隔离状态存储与获取，实现了信息的封装，客户端无需关心状态的保存细节。
提供状态回滚功能。

缺点：
消耗资源：如果需要保存的状态过多时，每一次保存都会消耗很多内存。

	
22、行为型-迭代器模式：
迭代器模式又称为游标模式（Cursor Pattern），它提供一种顺序访问集合/容器对象元素的方法，而又无须暴露结合内部表示。
本质：抽离集合对象迭代行为到迭代器中，提供一致访问接口。

迭代器模式主要包含以下角色：
抽象聚合（Aggregate）角色：定义存储、添加、删除聚合元素以及创建迭代器对象的接口。
具体聚合（ConcreteAggregate）角色：实现抽象聚合类，返回一个具体迭代器的实例。
抽象迭代器（Iterator）角色：定义访问和遍历聚合元素的接口，通常包含 hasNext()、next() 等方法。
具体迭代器（Concretelterator）角色：实现抽象迭代器接口中所定义的方法，完成对聚合对象的遍历，记录遍历的当前位置。

// 迭代器接口
public interface Iterator<T> {
    Boolean hasNext();
    T next();
}
// 迭代器接口实现类
public class IteratorImpl<T> implements Iterator<T> {
    private List<T> list;
    private Integer cursor;
    private T element;
 
    public IteratorImpl(List<T> list) {
        this.list = list;
    }
    @Override
    public Boolean hasNext() {
        return cursor < list.size();
    }
    @Override
    public T next() {
        element = list.get(cursor);
        cursor++;
        return element;
    }
}
// 容器接口
public interface Aggregate<T> {
    void add(T t);
    void remove(T t);
    Iterator<T> iterator();
}
// 容器接口实现类
public class AggregateImpl<T> implements Aggregate<T> {
    private List<T> list = new ArrayList<>();
    @Override
    public void add(T t) {
        list.add(t);
    }
    @Override
    public void remove(T t) {
        list.remove(t);
    }
    @Override
    public Iterator<T> iterator() {
        return new IteratorImpl<>(list);
    }
}

适用场景：
访问一个集合对象的内容而无需暴露它的内部表示。
为遍历不同的集合结构提供一个统一的访问接口。

优点：
多态迭代：为不同的聚合结构提供一致的遍历接口，即一个迭代接口可以访问不同的聚集对象。
简化集合对象接口：迭代器模式将集合对象本身应该提供的元素迭代接口抽取到了迭代器中，使集合对象无须关心具体迭代行为。
元素迭代功能多样化：每个集合对象都可以提供一个或多个不同的迭代器，使的同种元素聚合结构可以有不同的迭代行为。
解耦迭代与集合：迭代器模式封装了具体的迭代算法，迭代算法的变化，不会影响到集合对象的架构。

缺点：
对于比较简单的遍历（像数组或者有序列表），使用迭代器方式遍历较为繁琐。
增加了类的个数，在一定程度上增加了系统的复杂性。


23、行为型-解释器模式：
解释器模式给定一个语言，定义它的文法的一种表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。
特征：为了解释一种语言，而为语言创建的解释器。

解释器模式包含以下主要角色：
抽象表达式（Abstract Expression）角色：定义解释器的接口，约定解释器的解释操作，主要包含解释方法 interpret()。
终结符表达式（Terminal Expression）角色：是抽象表达式的子类，用来实现文法中与终结符相关的操作，文法中的每一个终结符都有一个具体终结表达式与之相对应。
非终结符表达式（Nonterminal Expression）角色：也是抽象表达式的子类，用来实现文法中与非终结符相关的操作，文法中的每条规则都对应于一个非终结符表达式。
环境（Context）角色：通常包含各个解释器需要的数据或是公共的功能，一般用来传递被所有解释器共享的数据，后面的解释器可以从这里获取这些值。
客户端（Client）：主要任务是将需要分析的句子或表达式转换成使用解释器对象描述的抽象语法树，然后调用解释器的解释方法，当然也可以通过环境角色间接访问解释器的解释方法。


// 抽象角色 定义解释器
public interface Expression {
    int interpret();
}
@AllArgsConstructor
public class NumberTerminal implements Expression {
    private int number;
    @Override
    public int interpret() {
        return this.number;
    }
}
// 非终结表达式（抽象类）
@AllArgsConstructor
public abstract class NonTerminal implements Expression {
    protected Expression left;
    protected Expression right;
}
// 非终结表达式（加法）
public class PlusNonTerminal extends NonTerminal implements Expression {
    public PlusNonTerminal(Expression left, Expression right) {
        super(left, right);
    }
    @Override
    public int interpret() {
        return left.interpret() + right.interpret();
    }
}
// 非终结表达式（减法）
public class MinusNonTerminal extends NonTerminal implements Expression {
    public MinusNonTerminal(Expression left, Expression right) {
        super(left, right);
    }
    @Override
    public int interpret() {
        return left.interpret() - right.interpret();
    }
}
// 非终结表达式（乘法）
public class MclNonTerminal extends NonTerminal implements Expression {
    public MclNonTerminal(Expression left, Expression right) {
        super(left, right);
    }
    @Override
    public int interpret() {
        return left.interpret() * right.interpret();
    }
}
// 非终结表达式（除法）
public class DivisionNonTerminal extends NonTerminal implements Expression {
    public DivisionNonTerminal(Expression left, Expression right) {
        super(left, right);
    }
    @Override
    public int interpret() {
        return left.interpret() / right.interpret();
    }
}
// 计算器类（实现运算逻辑）
public class Cal {
    private Expression left;
    private Expression right;
    private Integer result;
    public Cal(String expression) {
        this.parse(expression);
    }
    private Integer parse(String expression) {
        // 获取表达式元素
        String [] elements = expression.split(" ");
        for (int i = 0; i < elements.length; i++) {
            String element = elements[i];
            // 判断是否是运算符号
            if (OperatorUtils.isOperator(element)) {
                // 运算符号的右边就是右终结符
                right = new NumberTerminal(Integer.valueOf(elements[++i]));
                //计算结果
                result = OperatorUtils.getNonTerminal(left, right, element).interpret();
                // 计算结果重新成为左终结符
                left = new NumberTerminal(result);
            } else {
                left = new NumberTerminal(Integer.valueOf(element));
            }
        }
        return result;
    }
    public Integer cal() {
        return result;
    }
 
}
// 操作工具类
public class OperatorUtils {
    // 判断是不是非终结符
    public static boolean isOperator(String symbol) {
        return symbol.equals("+") || symbol.equals("-") || symbol.equals("*")|| symbol.equals("/");
    }
    // 简单工厂
    public static NonTerminal getNonTerminal(Expression left, Expression right, String symbol) {
        if (symbol.equals("+")) {
            return new PlusNonTerminal(left, right);
        } else if (symbol.equals("-")) {
            return new MinusNonTerminal(left, right);
        } else if (symbol.equals("*")) {
            return new MclNonTerminal(left, right);
        } else if (symbol.equals("/")) {
            return new DivisionNonTerminal(left, right);
        }
        return null;
    }
}
    // 测试
    // PS：此处进行的逻辑仅仅实现从左到右运算，并没有先乘除后加减的逻辑
    public static void main(String[] args) {
        System.out.println(new Cal("10 + 20 - 40 * 60").cal()); // -600
        System.out.println(new Cal("20 + 50 - 60 * 2").cal()); // 20
    }
	
Spring中的解释器模式：

public static void main(String[] args) {
        ExpressionParser expressionParser = new SpelExpressionParser();
        org.springframework.expression.Expression expression = expressionParser.parseExpression("10 + 20 + 30 * 4");
        Integer value = expression.getValue(Integer.class);
        System.out.println(value); // 150
        expression = expressionParser.parseExpression("(10+20+30)*4");
        value = expression.getValue(Integer.class);
        System.out.println(value); // 240
    }

可以看到Spring中解释器写的是比较完善的，不仅有先乘除后加减和先括号进行运算的日常计算规则，
而且对于空格也并没有要求，仅需要写出完整的表达式即可运算出来。

适用场景：
一些重复出现的问题可以用一种简单的语言来进行表述。
一个简单语法需要解释的场景。

优点：
扩展性强：在解释器模式中由于语法是由很多类表示的，当语法规则更改时，只需修改相应的非终结符表达式即可；若扩展语法时，只需添加相应非终结符类即可。
增加了新的解释表达式的方式。
易于实现文法：解释器模式对应的文法应当是比较简单且易于实现的，过于复杂的语法并不适合使用解释器模式。

缺点：
语法规则较复杂时，会引起类膨胀。
执行效率比较低


数据结构与算法：
数据结构与算法相辅相成，不会孤立存在；数据结构是为算法服务的，
算法是作用在特定的数据结构之上（如数组具有随机访问的特点，二分查找算法需要用数组来存储数据）。
数据结构是静态的，只是组织数据的一种形式，若不在它的基础上操作、构建算法、孤立存在的数据结构是没有意义的。

数据结构与算法之数组：
数组是一种线性表数据结构，它用一组连续的内存空间，来存储一组具有相同类型的数据。

无序数组：
public class MyArray {
	//声明一个数组
	private long[] arr;
	
	//有效数据的长度
	private int elements;
	
	//无参构造函数，默认长度为50
	public MyArray(){
		arr = new long[50];
	}
	
	public MyArray(int maxsize){
		arr = new long[maxsize];
	}
	
	
	//添加数据
	public void insert(long value){
		arr[elements] = value;
		elements++;
	}
	
	//显示数据
	public void display(){
		System.out.print("[");
		for(int i = 0;i < elements;i++){
			System.out.print(arr[i] + " ");
		}
		System.out.println("]");
	}
	
	//根据下标查找数据
	public long get(int index){
		if(index >= elements || index < 0){
			throw new ArrayIndexOutOfBoundsException();
		}else{
			return arr[index];
		}
	}
	
	/**
	 * 根据值查询
	 * @param value 需要被查询的值
	 * @return 被查询值的下标
	 */
	public int search(int value){
		//声明一个变量i用来记录该数据的下标值
		int i ;
		for(i = 0;i < elements;i++){
			if(value == arr[i]){
				break;
			}
		}
		//如果查询到最后一个元素依然没有找到
		if(i == elements){
			return -1;
		}else{
			return i;
		}
	}
	
	//根据下标删除数据
	public void delete(int index){
		if(index >= elements || index < 0){
			throw new ArrayIndexOutOfBoundsException();
		}else{
			//删除该元素后，后面所有元素前移一位
			for(int i = index; i < elements;i++){
				arr[i] = arr[i+1];
			}
			elements--;
		}
		
	}
	/**
	 * 替换数据
	 * @param index 被替换的下标
	 * @param newvalue 新的数据
	 */
	public void change(int index,int newvalue){
		if(index >= elements || index < 0){
			throw new ArrayIndexOutOfBoundsException();
		}else{
			arr[index] = newvalue;
		}
	} 
}

有序数组：
public class MyOrderArray { 
	private long[] arr;
	
	private int elements;
	
	public MyOrderArray(){
		arr = new long[50];
	}
	
	public MyOrderArray(int maxsize){
		arr = new long[maxsize];
	}
	
	//添加数据
	public void insert(int value){
		int i;
		for(i = 0;i < elements;i++){
			if(arr[i] > value){
				break;
			}
		}
		for(int j = elements;j > i;j--){
			arr[j] = arr[j -1];
		}
		arr[i] = value;
		elements++;
	}
	
	
	//删除数据
	public void delete(int index){
		if(index >=elements || index <0){
			throw new ArrayIndexOutOfBoundsException();
		}else{
			for(int i = index;i < elements; i++){
				arr[i] = arr[i+1];
			}
			elements--;
		}
	}
	
	//修改数据
	public void change(int index,int value){
		if(index >= elements || index < 0){
			throw new IndexOutOfBoundsException();
		}else{
			arr[index] = value;
		}
	}
	
	//根据下标查询数据
	public long get(int index){
		if(index >= elements || index < 0){
			throw new IndexOutOfBoundsException();
		}else{
			return arr[index];
		}
	}
	
	//展示数据
	public void display(){
		System.out.print("[");
		for(int i = 0; i < elements;i++){
			System.out.print(arr[i] + " ");
		}
		System.out.println("]");
	}
	
	
	//二分法查找数据
	public int binarySearch(long value){
			//声明三个指针分别指向数组的头，尾，中间
			int low = 0;
			int pow = elements;
			int middle = 0;
			
			while(true){
				middle = (low + pow) / 2;
				//如果中指针所指的值等于带查询数
				if(arr[middle] == value){
					return middle;
				}else if(low > pow){
					return -1;
				}else{
					if(arr[middle] > value){
						//待查询的数在左边,右指针重新改变指向
						pow = middle-1;
					}else{
						//带查询的数在右边，左指针重新改变指向
						low = middle +1;
					}
				}
			}
	}
}


数据结构与算法之栈：
栈（stack）是一种容器，可存入数据元素、访问元素、删除元素，它的特点在于只能允许在容器的一端（称为栈顶端指标，英语：top）
进行加入数据（英语：push）和输出数据（英语：pop）的运算。

1.由于栈数据结构只允许在一端进行操作，因而按照后进先出的原理运作。
2.栈可以用顺序表实现，也可以用链表实现。

package mystack;

public class MyStack {

    //栈的底层使用数组来存储数据
    //private int[] elements;
    int[] elements; //测试时使用

    public MyStack() {
        elements = new int[0];
    }

    //添加元素
    public void push(int element) {
        //创建一个新的数组
        int[] newArr = new int[elements.length + 1];
        //把原数组中的元素复制到新数组中
        for (int i = 0; i < elements.length; i++) {
            newArr[i] = elements[i];
        }
        //把添加的元素放入新数组中
        newArr[elements.length] = element;
        //使用新数组替换旧数组
        elements = newArr;
    }

    //取出栈顶元素
    public int pop() {
        //当栈中没有元素
        if (is_empty()) {
            throw new RuntimeException("栈空");
        }
        //取出数组的最后一个元素
        int element = elements[elements.length - 1];
        //创建一个新数组
        int[] newArr = new int[elements.length - 1];
        //原数组中除了最后一个元素其他元素放入新数组
        for (int i = 0; i < elements.length - 1; i++) {
            newArr[i] = elements[i];
        }
        elements = newArr;
        return element;
    }

    //查看栈顶元素
    public int peek() {
        return elements[elements.length - 1];
    }

    //判断栈是否为空
    public boolean is_empty() {
        return elements.length == 0;
    }

    //查看栈的元素个数
    public int size() {
        return elements.length;
    }
}
	

数据结构与算法之队列：
队列（Queue）是只允许在一端进行插入操作，而在另一端进行删除操作的线性表。
队列是一种先进先出的（First In First Out）的线性表，简称FIFO。允许插入的一端为队尾，允许删除的一端为队头。
1.队列不允许在中间部位进行操作！
2.同栈一样，队列也可以用顺序表或者链表实现。

public class MyQueue {

    int[] elements;

    public MyQueue() {
        elements = new int[0];
    }

    //入队
    public void enqueue(int element) {
        //创建一个新的数组
        int[] newArr = new int[elements.length + 1];
        //把原数组中的元素复制到新数组中
        for (int i = 0; i < elements.length; i++) {
            newArr[i] = elements[i];
        }
        //把添加的元素放入新数组中
        newArr[elements.length] = element;
        //使用新数组替换旧数组
        elements = newArr;
    }

    //出队
    public int dequeue() {
        if (isEmpty()) {
            throw new RuntimeException("队空，无数据");
        }
        //把数组中第1个元素取出来
        int element = elements[0];
        //创建一个新数组
        int[] newArr = new int[elements.length - 1];
        //把原数组除了第一个数据，其他存入新数组
        for (int i = 0; i < newArr.length; i++) {
            newArr[i] = elements[i + 1];
        }
        //新数组替换旧数组
        elements = newArr;

        return element;
    }

    //判断是否队空
    public boolean isEmpty() {
        return elements.length==0;
    }

    //获取队列长度
    public int size() {
        return elements.length;
    }
}

数据结构与算法之链表：
单链表：
单链表也叫单向链表，是链表中最简单的一种形式，它的每个节点包含两个域，一个信息域（元素域）和一个链接域。
这个链接指向链表中的下一个节点，而最后一个节点的链接域则指向一个空值。	
1.表元素域data用来存放具体的数据。
2.链接域next用来存放下一个节点的位置。

//一个节点
public class Node {

    //节点内容
    int data;
    //下一个节点
    Node next;

    public Node(int data) {
        this.data = data;
    }

    //为节点追加节点
    public Node append(Node node) {
        //当前节点
        Node currentNode = this;
        //循环向后找
        while (true) {
            //取出下一个节点
            Node nextNode = currentNode.next();
            //如果下一个节点为null，当前节点已经是最后一个节点
            if (nextNode == null) {
                break;
            }
            //赋给当前节点，无线向后找
            currentNode = nextNode;
        }
        //把需要追加的节点，追加为找到的当前节点（最后一个节点）的下一个节点
        currentNode.next = node;
        return this;
    }

    //显示所有节点信息
    public void show() {
        Node currentNode = this;
        while (true) {
            System.out.print(currentNode.data + " ");
            //取出下一个节点
            currentNode = currentNode.next;
            //如果是最后一个节点
            if (currentNode == null) {
                break;
            }
        }
        System.out.println();
    }

    //插入一个节点作为当前节点的下一个节点
    public void after(Node node) {
        //取出下一个节点，作为下下一个节点
        Node nextNext = next;
        //把新节点作为当前节点的下一个节点
        this.next = node;
        //把下下一个节点设置为新节点的下一个节点
        node.next = nextNext;

    }

    //删除下一个节点
    public void removeNode() {
        //取出下下一个节点
        Node newNext = next.next;
        //把下下一个节点设置为当前节点的下一个节点
        this.next = newNext;
    }

    //获取下一个节点
    public Node next() {
        return this.next;
    }

    //获取节点中的数据
    public int getData() {
        return this.data;
    }

    //判断节点是否为最后一个节点
    public boolean isLast() {
        return next == null;
    }

}

双向链表：
在双向链表中有两个指针域，一个是指向前驱结点的prev，一个是指向后继结点的next指针。

public class DoubleNode {
    //上一个节点
    DoubleNode pre = this;
    //下一个节点
    DoubleNode next = this;
    //节点数据
    int data;

    public DoubleNode(int data) {
        this.data = data;
    }

    //增加节点
    public void after(DoubleNode node) {
        //原来的下一个节点
        DoubleNode nextNext = next;
        //新节点作为当前节点的下一个节点
        this.next = node;
        //当前节点作为新节点的前一个节点
        node.pre = this;
        //原来的下一个节点作为新节点的下一个节点
        node.next = nextNext;
        //原来的下一个节点的上一个节点为新节点
        nextNext.pre = node;
    }

    //获取下一个节点
    public DoubleNode getNext() {
        return this.next;
    }

    //获取上一个节点
    public DoubleNode getPre() {
        return this.pre;
    }

    //获取数据
    public int getData() {
        return this.data;
    }
}

数据结构与算法之树：
树是一种非线性数据结构，它是由一个或多个结点组成的。

树的结构：
1、根节点：最顶上的唯一的一个；
2、双亲节点：子节点的父节点就叫做双亲节点；
3、子节点：双亲节点所产生的节点就是子节点
4、路径：从根节点到目标节点所走的路程叫做路径；
5、节点的度：有多少个子节点就有多少的度（最下面的度一定为0，所以是叶子节点）
6、节点的权：在节点中所存的数字
7、叶子节点：没有子节点的节点，就是没有下一代的节点；
8、子树：在整棵树中将一部分看成也是一棵树，即使只有一个节点也是一棵树，不过这个树是在整个大树职中的，包含的关系
9、层：就是族谱中有多少代的人；
10、树的高度：树的最大的层数：就是层数中的最大值
11、森林：多个树组成的集合

树结构的优点：
1.空间利用率比较高
2.可以非常快速地查找到最大值和最小值

树的种类：
无序树：树中任意节点的子节点之间没有顺序关系，这种树称为无序树，也称为自由树；

有序树：树中任意节点的子节点之间有顺序关系，这种树称为有序树；

二叉树：每个节点最多含有两个子树的树称为二叉树；
完全二叉树：对于一颗二叉树，假设其深度为d(d>1)。除了第d层外，其它各层的节点数目均已达最大值，且第d层所有节点从左向右连续地紧密排列，这样的二叉树被称为完全二叉树，其中满二叉树的定义是所有叶节点都在最底层的完全二叉树;
平衡二叉树（AVL树）：当且仅当任何节点的两棵子树的高度差不大于1的二叉树；
排序二叉树（二叉查找树（英语：Binary Search Tree），也称二叉搜索树、有序二叉树）；
霍夫曼树（用于信息编码）：带权路径最短的二叉树称为哈夫曼树或最优二叉树；
B树：一种对读写操作进行优化的自平衡的二叉查找树，能够保持数据有序，拥有多余两个子树。

数据结构与算法之排序算法：

直接插入排序：

算法思想：
直接插入排序的核心思想就是：将数组中的所有元素依次跟前面已经排好的元素相比较，
如果选择的元素比已排序的元素小，则交换，直到全部元素都比较过。
因此，从上面的描述中我们可以发现，直接插入排序可以用两个循环完成：

第一层循环：遍历待比较的所有数组元素
第二层循环：将本轮选择的元素(selected)与已经排好序的元素(ordered)相比较。
如果：selected > ordered，那么将二者交换

代码实现：
#直接插入排序
def insert_sort(L):
    #遍历数组中的所有元素，其中0号索引元素默认已排序，因此从1开始
    for x in range(1,len(L)):
    #将该元素与已排序好的前序数组依次比较，如果该元素小，则交换
    #range(x-1,-1,-1):从x-1倒序循环到0
        for i in range(x-1,-1,-1):
    #判断：如果符合条件则交换
            if L[i] > L[i+1]:
                temp = L[i+1]
                L[i+1] = L[i]
                L[i] = temp

希尔排序
算法思想：
希尔排序的算法思想：将待排序数组按照步长gap进行分组，然后将每组的元素利用直接插入排序的方法进行排序；
每次将gap折半减小，循环上述操作；当gap=1时，利用直接插入，完成排序。
同样的：从上面的描述中我们可以发现：希尔排序的总体实现应该由三个循环完成：

第一层循环：将gap依次折半，对序列进行分组，直到gap=1
第二、三层循环：也即直接插入排序所需要的两次循环。具体描述见上。

代码实现：
#希尔排序
def insert_shell(L):
    #初始化gap值，此处利用序列长度的一般为其赋值
    gap = (int)(len(L)/2)
    #第一层循环：依次改变gap值对列表进行分组
    while (gap >= 1):
    #下面：利用直接插入排序的思想对分组数据进行排序
    #range(gap,len(L)):从gap开始
        for x in range(gap,len(L)):
    #range(x-gap,-1,-gap):从x-gap开始与选定元素开始倒序比较，每个比较元素之间间隔gap
            for i in range(x-gap,-1,-gap):
    #如果该组当中两个元素满足交换条件，则进行交换
                if L[i] > L[i+gap]:
                    temp = L[i+gap]
                    L[i+gap] = L[i]
                    L[i] =temp
    #while循环条件折半
        gap = (int)(gap/2)


简单选择排序
算法思想：
简单选择排序的基本思想：比较+交换。

从待排序序列中，找到关键字最小的元素；
如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换；
从余下的 N - 1 个元素中，找出关键字最小的元素，重复(1)、(2)步，直到排序结束。
因此我们可以发现，简单选择排序也是通过两层循环实现。
第一层循环：依次遍历序列当中的每一个元素
第二层循环：将遍历得到的当前元素依次与余下的元素进行比较，符合最小元素的条件，则交换。

代码实现：
# 简单选择排序
def select_sort(L):
#依次遍历序列中的每一个元素
    for x in range(0,len(L)):
#将当前位置的元素定义此轮循环当中的最小值
        minimum = L[x]
#将该元素与剩下的元素依次比较寻找最小元素
        for i in range(x+1,len(L)):
            if L[i] < minimum:
                temp = L[i];
                L[i] = minimum;
                minimum = temp
#将比较后得到的真正的最小值赋值给当前位置
        L[x] = minimum	

堆排序
堆的概念
堆：本质是一种数组对象。特别重要的一点性质：<b>任意的叶子节点小于（或大于）它所有的父节点</b>。
对此，又分为大顶堆和小顶堆，大顶堆要求节点的元素都要大于其孩子，
小顶堆要求节点元素都小于其左右孩子，两者对左右孩子的大小关系不做任何要求。
利用堆排序，就是基于大顶堆或者小顶堆的一种排序方法。下面，我们通过大顶堆来实现。

基本思想：
堆排序可以按照以下步骤来完成：

1.首先将序列构建称为大顶堆；
（这样满足了大顶堆那条性质：位于根节点的元素一定是当前序列的最大值）

2.取出当前大顶堆的根节点，将其与序列末尾元素进行交换；
（此时：序列末尾的元素为已排序的最大值；由于交换了元素，当前位于根节点的堆并不一定满足大顶堆的性质）
对交换后的n-1个序列元素进行调整，使其满足大顶堆的性质；

3.重复2.3步骤，直至堆中只有1个元素为止
	
#-------------------------堆排序--------------------------------
#**********获取左右叶子节点**********
def LEFT(i):
    return 2*i + 1
def RIGHT(i):
    return 2*i + 2
#********** 调整大顶堆 **********
#L:待调整序列 length: 序列长度 i:需要调整的结点
def adjust_max_heap(L,length,i):
#定义一个int值保存当前序列最大值的下标
    largest = i
#执行循环操作：两个任务：1 寻找最大值的下标；2.最大值与父节点交换
    while (1):
#获得序列左右叶子节点的下标
        left,right = LEFT(i),RIGHT(i)
#当左叶子节点的下标小于序列长度 并且 左叶子节点的值大于父节点时，将左叶子节点的下标赋值给largest
        if (left < length) and (L[left] > L[i]):
            largest = left
            print('左叶子节点')
        else:
            largest = i
#当右叶子节点的下标小于序列长度 并且 右叶子节点的值大于父节点时，将右叶子节点的下标值赋值给largest
        if (right < length) and (L[right] > L[largest]):
            largest = right
            print('右叶子节点')
#如果largest不等于i 说明当前的父节点不是最大值，需要交换值
        if (largest != i):
            temp = L[i]
            L[i] = L[largest]
            L[largest] = temp
            i = largest
            print(largest)
            continue
        else:
            break
#********** 建立大顶堆 **********
def build_max_heap(L):
    length = len(L)
    for x in range((int)((length-1)/2),-1,-1):
        adjust_max_heap(L,length,x)
#********** 堆排序 **********
def heap_sort(L):
#先建立大顶堆，保证最大值位于根节点；并且父节点的值大于叶子结点
    build_max_heap(L)
#i：当前堆中序列的长度.初始化为序列的长度
    i = len(L)
#执行循环：1. 每次取出堆顶元素置于序列的最后(len-1,len-2,len-3...)
#         2. 调整堆，使其继续满足大顶堆的性质，注意实时修改堆中序列的长度
    while (i > 0):
        temp = L[i-1]
        L[i-1] = L[0]
        L[0] = temp
#堆中序列长度减1
        i = i-1
#调整大顶堆
        adjust_max_heap(L,i,0)

冒泡排序
基本思想:
冒泡排序思路比较简单：

将序列当中的左右元素，依次比较，保证右边的元素始终大于左边的元素；
（ 第一轮结束后，序列最后一个元素一定是当前序列的最大值；）
对序列当中剩下的n-1个元素再次执行步骤1。
对于长度为n的序列，一共需要执行n-1轮比较
（利用while循环可以减少执行次数）

#冒泡排序
def bubble_sort(L):
    length = len(L)
#序列长度为length，需要执行length-1轮交换
    for x in range(1,length):
#对于每一轮交换，都将序列当中的左右元素进行比较
#每轮交换当中，由于序列最后的元素一定是最大的，因此每轮循环到序列未排序的位置即可
        for i in range(0,length-x):
            if L[i] > L[i+1]:
                temp = L[i]
                L[i] = L[i+1]
                L[i+1] = temp

快速排序
算法思想：
快速排序的基本思想：挖坑填数+分治法
从序列当中选择一个基准数(pivot)
在这里我们选择序列当中第一个数最为基准数
将序列当中的所有数依次遍历，比基准数大的位于其右侧，比基准数小的位于其左侧
重复步骤1.2，直到所有子集当中只有一个元素为止。
用伪代码描述如下：
1．i =L; j = R; 将基准数挖出形成第一个坑a[i]。
2．j--由后向前找比它小的数，找到后挖出此数填前一个坑a[i]中。
3．i++由前向后找比它大的数，找到后也挖出此数填到前一个坑a[j]中。
4．再重复执行2，3二步，直到i==j，将基准数填入a[i]中

代码实现：
#快速排序
#L：待排序的序列；start排序的开始index,end序列末尾的index
#对于长度为length的序列：start = 0;end = length-1
def quick_sort(L,start,end):
    if start < end:
        i , j , pivot = start , end , L[start]
        while i < j:
#从右开始向左寻找第一个小于pivot的值
            while (i < j) and (L[j] >= pivot):
                j = j-1
#将小于pivot的值移到左边
            if (i < j):
                L[i] = L[j]
                i = i+1 
#从左开始向右寻找第一个大于pivot的值
            while (i < j) and (L[i] < pivot):
                i = i+1
#将大于pivot的值移到右边
            if (i < j):
                L[j] = L[i]
                j = j-1
#循环结束后，说明 i=j，此时左边的值全都小于pivot,右边的值全都大于pivot
#pivot的位置移动正确，那么此时只需对左右两侧的序列调用此函数进一步排序即可
#递归调用函数：依次对左侧序列：从0 ~ i-1//右侧序列：从i+1 ~ end
        L[i] = pivot
#左侧序列继续排序
        quick_sort(L,start,i-1)
#右侧序列继续排序
        quick_sort(L,i+1,end)

归并排序
算法思想：
1.归并排序是建立在归并操作上的一种有效的排序算法，该算法是采用分治法的一个典型的应用。
它的基本操作是：将已有的子序列合并，达到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。
2.归并排序其实要做两件事：
分解----将序列每次折半拆分
合并----将划分后的序列段两两排序合并
因此，归并排序实际上就是两个操作，拆分+合并
3.如何合并？
L[first...mid]为第一段，L[mid+1...last]为第二段，并且两端已经有序，现在我们要将两端合成达到L[first...last]并且也有序。
首先依次从第一段与第二段中取出元素比较，将较小的元素赋值给temp[]
重复执行上一步，当某一段赋值结束，则将另一段剩下的元素赋值给temp[]
此时将temp[]中的元素复制给L[]，则得到的L[first...last]有序
4.如何分解？
在这里，我们采用递归的方法，首先将待排序列分成A,B两组；然后重复对A、B序列分组；
直到分组后组内只有一个元素，此时我们认为组内所有元素有序，则分组结束。

代码实现:

# 归并排序
#这是合并的函数
# 将序列L[first...mid]与序列L[mid+1...last]进行合并
def mergearray(L,first,mid,last,temp):
#对i,j,k分别进行赋值
    i,j,k = first,mid+1,0
#当左右两边都有数时进行比较，取较小的数
    while (i <= mid) and (j <= last):
        if L[i] <= L[j]:
            temp[k] = L[i]
            i = i+1
            k = k+1
        else:
            temp[k] = L[j]
            j = j+1
            k = k+1
#如果左边序列还有数
    while (i <= mid):
        temp[k] = L[i]
        i = i+1
        k = k+1
#如果右边序列还有数
    while (j <= last):
        temp[k] = L[j]
        j = j+1
        k = k+1
#将temp当中该段有序元素赋值给L待排序列使之部分有序
    for x in range(0,k):
        L[first+x] = temp[x]
# 这是分组的函数
def merge_sort(L,first,last,temp):
    if first < last:
        mid = (int)((first + last) / 2)
#使左边序列有序
        merge_sort(L,first,mid,temp)
#使右边序列有序
        merge_sort(L,mid+1,last,temp)
#将两个有序序列合并
        mergearray(L,first,mid,last,temp)
# 归并排序的函数
def merge_sort_array(L):
#声明一个长度为len(L)的空列表
    temp = len(L)*[None]
#调用归并排序
    merge_sort(L,0,len(L)-1,temp)	


基数排序
算法思想:
基数排序：通过序列中各个元素的值，对排序的N个元素进行若干趟的“分配”与“收集”来实现排序。
分配：我们将L[i]中的元素取出，首先确定其个位上的数字，根据该数字分配到与之序号相同的桶中
收集：当序列中所有的元素都分配到对应的桶中，再按照顺序依次将桶中的元素收集形成新的一个待排序列L[ ]
对新形成的序列L[]重复执行分配和收集元素中的十位、百位...直到分配完该序列中的最高位，则排序结束
根据上述“基数排序”的展示，我们可以清楚的看到整个实现的过程

代码实现:
#************************基数排序****************************
#确定排序的次数
#排序的顺序跟序列中最大数的位数相关
def radix_sort_nums(L):
    maxNum = L[0]
#寻找序列中的最大数
    for x in L:
        if maxNum < x:
            maxNum = x
#确定序列中的最大元素的位数
    times = 0
    while (maxNum > 0):
        maxNum = (int)(maxNum/10)
        times = times+1
    return times
#找到num从低到高第pos位的数据
def get_num_pos(num,pos):
    return ((int)(num/(10**(pos-1))))%10
#基数排序
def radix_sort(L):
    count = 10*[None]       #存放各个桶的数据统计个数
    bucket = len(L)*[None]  #暂时存放排序结果
#从低位到高位依次执行循环
    for pos in range(1,radix_sort_nums(L)+1):
        #置空各个桶的数据统计
        for x in range(0,10):
            count[x] = 0
        #统计当前该位(个位，十位，百位....)的元素数目
        for x in range(0,len(L)):
            #统计各个桶将要装进去的元素个数
            j = get_num_pos(int(L[x]),pos)
            count[j] = count[j]+1
        #count[i]表示第i个桶的右边界索引
        for x in range(1,10):
            count[x] = count[x] + count[x-1]
        #将数据依次装入桶中
        for x in range(len(L)-1,-1,-1):
            #求出元素第K位的数字
            j = get_num_pos(L[x],pos)
            #放入对应的桶中，count[j]-1是第j个桶的右边界索引
            bucket[count[j]-1] = L[x]
            #对应桶的装入数据索引-1
            count[j] = count[j]-1
        # 将已分配好的桶中数据再倒出来，此时已是对应当前位数有序的表
        for x in range(0,len(L)):
            L[x] = bucket[x]


Java数据库及持久层技术以及多种数据库的应用：
关系型数据库及其底层工作原理：
MYSQL体系结构：
Client Connectors
接入方。支持很多协议(JDBC、ODBC、.NET、PHP、Python、PERL、C 等)
Management Serveices & Utilities
系统管理和控制工具，mysqldump、 mysql复制集群、分区管理等
Connection Pool
连接池：管理缓冲用户连接、用户名、密码、权限校验、线程处理等需要缓存的需求
SQL Interface
SQL接口：接受用户的SQL命令，并且返回用户需要查询的结果
Parser
解析器，SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的
Optimizer
查询优化器，SQL语句在查询之前会使用查询优化器对查询进行优化
Cache和Buffer（高速缓存区）
查询缓存，如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据
pluggable storage Engines
插件式存储引擎。存储引擎是MySql中具体的与文件打交道的子系统
File System
文件系统，数据、日志（redo，undo）、索引、错误日志、查询记录、慢查询等

MYSQL架构：
连接层：最上层是一些客户端和连接服务。主要完成一些类似于连接处理、授权认证、及相关的安全方案。
在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。
服务器也会为安全接入的每个客户端验证它所具有的操作权限。

服务层：第二层服务层，主要完成大部分的核心服务功能， 包括查询解析、分析、优化、缓存、以及所有的内置函数，所有跨存储引擎的功能也都在这一层实现，
包括触发器、存储过程、视图等

引擎层：第三层存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信。
不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取。

存储层：第四层为数据存储层，主要是将数据存储在运行于该设备的文件系统之上，并完成与存储引擎的交互

关于SQL语句
SQL语言包括以下几个部分：
1.数据定义语言（Data-Definition Language，DDL）：创建、删除、修改关系模式的命令
2.数据操纵语言（Data-Manipulation Language，DML）：对数据库其中的对象和数据运行访问工作的编程语句，包括查询、修改、插入、添加
3.完整性（integrity）：SQL DDL包括定义完整性约束的命令
4.视图定义（view definition）：SQL DDL包括定义视图的命令
5.事务控制（transaction control）：SQL 包括定义事务的开始点和结束点的命令
6.嵌入式SQL（embedded SQL）和动态SQL（dynamic SQL）：定义如何嵌入诸如C、C++和Java这样的编程语言中
7.授权（authorization）：SQL DCL用来定义访问权限和安全级别。

SQL的基本数据类型：
SQL的基本数据类型由13个基本数据类型组成，它们是由 Microsoft Jet 数据库引擎和几个验证过的有效同义字定义的。常见的有：

整形（Integer）。
单精度（Single）。
双精度（Double）。
可变长度字符（VarChar）。
固定长度字符（Char）。
长型（Long）。
日期（Date）。

此外，还有货币、文本、时间、位串、UI格式化类型等。
       

关于SQL语句在MySQL中执行过程详解
一、SQL语句执行原理：
第一步:客户端把语句发给服务器端执行
当我们在客户端执行 select 语句时,客户端会把这条 SQL 语句发送给服务器端,让服务器端的
进程来处理这语句。也就是说,Oracle 客户端是不会做任何的操作,他的主要任务就是把客户端产生
的一些 SQL 语句发送给服务器端。虽然在客户端也有一个数据库进程,但是,这个进程的作用跟服务器
上的进程作用是不相同的。服务器上的数据库进程才会对SQL语句进行相关的处理。不过,有个问题需
要说明,就是客户端的进程跟服务器的进程是一一对应的。也就是说,在客户端连接上服务器后,在客户
端与服务器端都会形成一个进程,客户端上的我们叫做客户端进程;而服务器上的我们叫做服务器进程。
第二步:语句解析
当客户端把 SQL 语句传送到服务器后,服务器进程会对该语句进行解析。同理,这个解析的工作,
也是在服务器端所进行的。虽然这只是一个解析的动作,但是,其会做很多“小动作”。
1. 查询高速缓存(library cache)。服务器进程在接到客户端传送过来的 SQL 语句时,不
会直接去数据库查询。而是会先在数据库的高速缓存中去查找,是否存在相同语句的执行计划。如果在
数据高速缓存中,则服务器进程就会直接执行这个 SQL 语句,省去后续的工作。所以,采用高速数据缓
存的话,可以提高 SQL 语句的查询效率。一方面是从内存中读取数据要比从硬盘中的数据文件中读取
数据效率要高,另一方面,也是因为这个语句解析的原因。
大多数情况下查询缓存不管用。因为①只有相同的查询操作才会命中查询缓存②如果该表使用了DML、DCL
语句，那么该表的所有高速缓存查询就会失效。③使用了每次查询都返回不一样结果的函数（例如NOW（）），
不会命中查询缓存
不过这里要注意一点,这个数据缓存跟有些客户端软件的数据缓存是两码事。有些客户端软件为了
提高查询效率,会在应用软件的客户端设置数据缓存。由于这些数据缓存的存在,可以提高客户端应用软
件的查询效率。但是,若其他人在服务器进行了相关的修改,由于应用软件数据缓存的存在,导致修改的
数据不能及时反映到客户端上。从这也可以看出,应用软件的数据缓存跟数据库服务器的高速数据缓存
不是一码事。
2. 语句合法性检查(data dict cache)。当在高速缓存中找不到对应的 SQL 语句时,则服
务器进程就会开始检查这条语句的合法性。这里主要是对 SQL 语句的语法进行检查,看看其是否合乎
语法规则。如果服务器进程认为这条 SQL 语句不符合语法规则的时候,就会把这个错误信息,反馈给客
户端。在这个语法检查的过程中,不会对 SQL 语句中所包含的表名、列名等等进行 SQL 他只是语法
上的检查。
3. 语言含义检查(data dict cache)。若 SQL 语句符合语法上的定义的话,则服务器进程
接下去会对语句中的字段、表等内容进行检查。看看这些字段、表是否在数据库中。如果表名与列名不
准确的话,则数据库会就会反馈错误信息给客户端。所以,有时候我们写 select 语句的时候,若语法
与表名或者列名同时写错的话,则系统是先提示说语法错误,等到语法完全正确后,再提示说列名或表名
错误。
4. 获得对象解析锁(control structer)。当语法、语义都正确后,系统就会对我们需要查询
的对象加锁。这主要是为了保障数据的一致性,防止我们在查询的过程中,其他用户对这个对象的结构发
生改变。
5. 数据访问权限的核对(data dict cache)。当语法、语义通过检查之后,客户端还不一定
能够取得数据。服务器进程还会检查,你所连接的用户是否有这个数据访问的权限。若你连接上服务器
的用户不具有数据访问权限的话,则客户端就不能够取得这些数据。有时候我们查询数据的时候,辛辛苦
苦地把 SQL 语句写好、编译通过,但是,最后系统返回个 “没有权限访问数据”的错误信息,让我们气
半死。这在前端应用软件开发调试的过程中,可能会碰到。所以,要注意这个问题,数据库服务器进程先
检查语法与语义,然后才会检查访问权限。
6. 确定最佳执行计划 。当语句与语法都没有问题,权限也匹配的话,服务器进程还是不会直接对
数据库文件进行查询。服务器进程会根据一定的规则,对这条语句进行优化。不过要注意,这个优化是有
限的。一般在应用软件开发的过程中,需要对数据库的 sql 语言进行优化,这个优化的作用要大大地大
于服务器进程的自我优化。所以,一般在应用软件开发的时候,数据库的优化是少不了的。当服务器进程
的优化器确定这条查询语句的最佳执行计划后,就会将这条 SQL 语句与执行计划保存到数据高速缓存
(library cache)。如此的话,等以后还有这个查询时,就会省略以上的语法、语义与权限检查的步骤,
而直接执行 SQL 语句,提高 SQL 语句处理效率。
第三步:语句执行
语句解析只是对 SQL 语句的语法进行解析,以确保服务器能够知道这条语句到底表达的是什么意
思。等到语句解析完成之后,数据库服务器进程才会真正的执行这条 SQL 语句。这个语句执行也分两
种情况。
一是若被选择行所在的数据块已经被读取到数据缓冲区的话,则服务器进程会直接把这个数据传递
给客户端,而不是从数据库文件中去查询数据。
若数据不在缓冲区中,则服务器进程将从数据库文件中查询相关数据,并把这些数据放入到数据缓冲
区中(buffer cache)。
第四步:提取数据
当语句执行完成之后,查询到的数据还是在服务器进程中,还没有被传送到客户端的用户进程。所以,
在服务器端的进程中,有一个专门负责数据提取的一段代码。他的作用就是把查询到的数据结果返回给
用户端进程,从而完成整个查询动作。从这整个查询处理过程中,我们在数据库开发或者应用软件开发过
程中,需要注意以下几点:
一是要了解数据库缓存跟应用软件缓存是两码事情。数据库缓存只有在数据库服务器端才存在,在
客户端是不存在的。只有如此,才能够保证数据库缓存中的内容跟数据库文件的内容一致。才能够根据
相关的规则,防止数据脏读、错读的发生。而应用软件所涉及的数据缓存,由于跟数据库缓存不是一码事
情,所以,应用软件的数据缓存虽然可以提高数据的查询效率,但是,却打破了数据一致性的要求,有时候
会发生脏读、错读等情况的发生。所以,有时候,在应用软件上有专门一个功能,用来在必要的时候清除
数据缓存。不过,这个数据缓存的清除,也只是清除本机上的数据缓存,或者说,只是清除这个应用程序
的数据缓存,而不会清除数据库的数据缓存。
二是绝大部分 SQL 语句都是按照这个处理过程处理的。我们 DBA 或者基于 Oracle 数据库的
开发人员了解这些语句的处理过程,对于我们进行涉及到 SQL 语句的开发与调试,是非常有帮助的。有
时候,掌握这些处理原则,可以减少我们排错的时间。特别要注意,数据库是把数据查询权限的审查放在
语法语义的后面进行检查的。所以,有时会若光用数据库的权限控制原则,可能还不能满足应用软件权限
控制的需要。此时,就需要应用软件的前台设置,实现权限管理的要求。而且,有时应用数据库的权限管
理,也有点显得繁琐,会增加服务器处理的工作量。因此,对于记录、字段等的查询权限控制,大部分程
序涉及人员喜欢在应用程序中实现,而不是在数据库上实现。

SQL语句中的函数、关键字、排序等执行顺序:
1. FROM 子句返回初始结果集。
2. WHERE 子句排除不满足搜索条件的行。
3. GROUP BY 子句将选定的行收集到 GROUP BY 子句中各个唯一值的组中。
4. 选择列表中指定的聚合函数可以计算各组的汇总值。
5. 此外,HAVING 子句排除不满足搜索条件的行。
6. 计算所有的表达式;
7. 使用 order by 对结果集进行排序。
8. 查找你要搜索的字段。

MYSQL事务机制：
1.原子性 。原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，
如果操作失败则不能对数据库有任何影响。
2.一致性 。一致性是指一个事务中，事务前后数据的完整性必须保持一致。
3.隔离性 。隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，
多个并发事务之间要相互隔离。
4.持久性 。持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响。

MYSQL视图：
MySQL视图是一种虚拟表，它是存储在数据库中的查询语句，并不实际存在于数据库中。
视图的结构和数据是建立在对表的查询基础上的，视图包括几个被定义的数据列和多个数据行，这些数据列和数据行来源于其所引用的表。
视图所对应的数据并不实际地以视图结构存储在数据库中，而是存储在视图所引用的表中，通过视图看到的数据只是存放在基本表中的数据。
对视图的操作与对表的操作一样，可以对其进行查询、修改（有一定的限制）、删除。 
当对视图中的数据进行修改时，相应的基本表的数据也要发生变化，同时，若基本表的数据发生变化，则这种变化也可以自动地反映到视图中。
视图能够对机密数据提供安全保证，可以在设计数据库的时候，对不同的用户定义不同的视图，
使机密数据不出现在不应该看到这些数据的用户所使用的视图中。

CREATE VIEW employee_view AS
SELECT employee_id, first_name, last_name, salary
FROM employees
WHERE department_id = 10;

MySQL索引：
1.索引列的数据长度能少则少；
2.索引一定不是越多越好，越全越好，一定是建合适的；
3.匹配列前缀可用到索引 like 9999%，like %9999%、like %9999用不到索引；
注意： like 9999% 并不会一定用到索引（离散型太差，就不会用到索引）
    like %9999%、like %9999 是绝对不会用到索引的

4.Where 条件中 not in 和 <>操作无法使用索引；
5.匹配范围值，order by 也可用到索引；
6.多用指定列查询，只返回自己想到的数据列，少用select *；
7.联合索引中如果不是按照索引最左列开始查找，无法使用索引；
8.联合索引中精确匹配最左前列并范围匹配另外一列可以用到索引；
比如说：有个[name,phone]联合索引
    where name=‘abc’ and phone>‘136xxxxxxxx’ 这种是可以用到索引的

9.联合索引中，如果查询中有某个列的范围查询，则其右边的所有列都无法使用索引；
比如说：有个[age,name]联合索引
    where age>18 and name='abc’这是用不到索引的
它只会age使用索引，name不会使用索引。还是基于最左匹配原则

Mysql索引数据结构:
首先，数据库索引使用树来存储，因为树的查询效率高，而且二叉查找树还可以保持数据的有序。
那么索引为什么没有使用二叉树来实现呢？
其实从算法逻辑上讲，二叉查找树的查找速度和比较次数都是最小的，但是从Mysql的角度讲，我们不得不考虑一个现实问题：磁盘IO。
查找都是索引操作，一般来说索引非常大，尤其是关系型数据库这种，当数据量比较大的时候，索引的大小有可能几个G甚至更多，数据量大的索引能达到亿级别，所以为了减少内存的占用，数据库索引是存储在外部磁盘上的。
当我们利用索引查询的时候，不可能把整个索引全部加载到内存，只能逐一加载每个磁盘页，磁盘页对应索引树的节点。
那么Mysql衡量查询效率的标准就是磁盘IO次数。
如果我们利用二叉树作为索引结构，那么磁盘的IO次数和索引树的高度是相关的。
那么为了提高查询效率，就需要减少磁盘IO数。为了减少磁盘IO的次数，就需要尽量降低树的高度，需要把原来“瘦高”的树结构变的“矮胖”，树的每层的分叉越多越好，因此B树正好符合我们的要求，这也是B-树的特征之一。
原来的二叉树一个节点只存储一个数据，要想把它变“矮胖”，就需要在一个节点存储多个数据，同时为了查找必须保持节点结构的有序，这样B树就应运而生了。

B-树（B类树）的特点就是每层节点数目非常多，层数很少，目的就是为了就少磁盘IO次数。
B-树是一种多路平衡查找树，它的每一个节点最多包含K个孩子，k称为B树的阶。k的大小取决于磁盘页的大小。
一个m阶的B树具有如下几个特征：

1.根结点至少有两个子女。
2.每个中间节点都包含k-1个元素和k个孩子，其中 m/2 <= k <= m。
3.每一个叶子节点都包含k-1个元素，其中 m/2 <= k <= m。
4.所有的叶子结点都位于同一层。
5.每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。
一个B树结构的具体例子。


在B-树中进行查询时，在查询的中的比较次数其实不比二叉查找树少，尤其当单一节点中的元素数量很多时。
可是相比磁盘IO的速度，内存中的耗时几乎可以忽略，所以只要树的高度足够低，IO次数足够少，就可以提高查询性能。
相比之下节点内部元素多一点也没有关系，仅仅是多了几次内存交互，只要不超过磁盘页的大小即可。这就是B-树的优势之一。
B树在插入和删除节点的时候如果导致树不平衡，就通过自动调整节点的位置来保持树的自平衡。
非关系型数据库MongoDB使用B树作为数据库索引。
大部分关系型数据库，比如Mysql，则使用B+树作为索引。
B+树是基于B-树的一种变体，有着比B-树更高的查询性能。
B+树和B-树有一些共同点，但是B+树也具备一些新的特征。

一个m阶的B+树具有如下几个特征：
1.有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。
2.所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
3.所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。


从B+树的结构可以看出，B+树中的节点之间不但含有重复元素，而且叶子节点还用指针连在一起。
在B+树中，每一个父节点的中的元素都出现在子节点中，是子节点的最大（或最小元素）。
由于父节点的所有元素都出现在子节点，因此所有叶子节点包含了全量元素信息。
并且每个叶子节点都有指向下一个叶子节点的指针，形成了有序链表。
在B+树中，只有叶子节点才真正存储数据，非叶子节点不存储数据。
使用B+树做索引的好处主要体现在查询性能上。
在单元素查询的时候，B+树会自顶向下逐层查找节点，最终找到匹配的叶子节点。
对于范围查询，比如查询范围为3~11的元素，B-树只能依靠繁琐的中序遍历，首先自顶向下查找范围的下限，然后中序遍历找到上限。
B+树的范围查询则要简单的多，首先自顶向下查找范围的下限，然后只需要在叶子节点所在的链表上做遍历即可。

B+树和B-树的区别： 
B+树中间节点没有存储数据，只有叶节点存放数据，其余节点用来索引，所以同样大小的磁盘页可以容纳更多的节点元素，而B-树是每个索引节点都会有Data域。这就意味着，数据量相同的情况下，B+树的结构比B-树更加“矮胖”，因此查询是IO次数也更少。这就决定了B+树更适合用来存储外部数据，也就是所谓的磁盘数据。
其次，B+树的查询必须最终查询到叶子节点，而B-树只要找到匹配元素即可，无论匹配元素处于中间节点还是叶子节点。
因此，B-树的查询性能并不稳定（最好情况是只查根节点，最坏情况是查到叶子节点）。而B+树每一次查找都是稳定的。

综合起来，B+树相比B-树的优势有三个：
1.单一节点存储更多的元素，使得查询的IO次数更少。
2.所有查询都要查找到叶子节点，查询性能稳定。
3.所有叶子节点形成有序链表，便于范围查询。

最后总结一下：

数据库索引为什么不用AVL（平衡二叉树）？
数据库索引是存储在磁盘上，磁盘IO操作比较耗时，为了提高查询效率就需要减少磁盘IO的次数。而磁盘IO次数和树的高度有关，所以为了减少磁盘IO就需要降低树的高度，这时查找的结构就可以把二叉树变成B类的树。
数据库索引为什么用B+树而不用B-树？
数据库索引采用B+树的主要原因是B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。正是为了解决这个问题，B+树应运而生。B+树只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作（或者说效率太低）。

那么MongoDB为什么使用B-树而不是B+树？
至于MongoDB为什么使用B-树而不是B+树，可以从它的设计角度来考虑，它并不是传统的关系性数据库，而是以Json格式作为存储的nosql，目的就是高性能，高可用，易扩展。首先它摆脱了关系模型，上面所述的范围查询的优点就没那么强烈了，其次Mysql由于使用B+树，数据都在叶节点上，每次查询都需要访问到叶节点，而MongoDB使用B-树，所有节点都有Data域，只要找到指定索引就可以进行访问，无疑单次查询平均快于Mysql（但侧面来看Mysql至少平均查询耗时差不多）。
总体来说，Mysql选用B+树和MongoDB选用B-树还是以自己的需求来选择的。

数据库索引为什么不用红黑树？
首先看一下红黑树的特点：
红黑树是一种自平衡的二叉查找树，除了符合二叉查找树的基本特征外，它还具有下列的附加特征。
1.节点是红色或黑色。
2.根节点是黑色。
3.每个叶子节点都是黑色的空节点（NIL节点）。
4 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)
5.从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。


这是因为这些规则限制，才保证了红黑树的自平衡。红黑树从根到叶子的最长路径不会超过最短路径的2倍。
当插入或删除节点的时候，红黑树的规则可能被打破。这时候就需要做出一些调整， 来继续维持我们的规则。
那么在大规模数据存储的时候，红黑树往往出现由于树的深度过大而造成磁盘IO读写过于频繁，进而导致效率低下的情况。磁盘查找存取的次数往往由树的高度所决定，所以，只要我们通过某种较好的树结构尽量减少树的高度，就可以提高查询性能。B树可以有多个子女，从几十到上千，可以降低树的高度。
归结起来，使用B+树而不是用其他结构的原因就是为了减少磁盘IO的次数，减少数的高度，而B+树就很好的做到了这一点。
那么什么情况下使用红黑树?红黑树和B树使用场合有什么不同？两者都是有序的数据结构，可用作数据容器。

红黑树多用在内部排序，即全放在内存中的，微软STL的map和set的内部实现就是红黑树。
B树多用在内存里放不下，大部分数据存储在外存上时。因为B树层数少，因此可以确保每次操作，读取磁盘的次数尽可能的少。
在数据较小，可以完全放到内存中时，红黑树的时间复杂度比B树低。
反之，数据量较大，外存中占主要部分时，B树因其读磁盘次数少，而具有更快的速度。

MySQL不等于（!= 或者<>）操作为什么会导致索引失效？
MySQL中不等于（!= 或者<>）操作会导致索引失效的原因主要有以下几点：

全表扫描的必要性：当MySQL使用不等于操作符时，它通常需要扫描整个表来查找不满足条件的记录。这是因为不等于操作不像等于操作那样具有明确的匹配值，MySQL无法直接定位到具体的索引位置。
因此，为了找到所有不满足条件的记录，MySQL需要逐行扫描整个表，这就导致了索引失效。

索引结构的限制：索引在MySQL中通常是以B+树等数据结构实现的，这些结构对于范围查询和精确匹配查询非常高效。
然而，对于不等于操作，索引结构无法有效地定位到不满足条件的记录，因为索引是按照某种顺序排列的，而不等于操作可能跨越索引中的多个位置。

优化器的选择：MySQL的查询优化器会根据查询条件和表的结构选择最合适的查询策略。当优化器认为全表扫描比使用索引更快时，它会选择不使用索引。
对于不等于操作，由于需要扫描大量的记录，优化器可能会认为全表扫描更为高效，从而选择不使用索引。

需要注意的是，虽然不等于操作通常会导致索引失效，但在某些特定情况下，如果索引列的选择性很高（即不同值的比例很高），或者查询中涉及到其他可以使用索引的条件，优化器可能会选择使用索引。
然而，这种情况相对较少见，因此在编写查询语句时，应该尽量避免使用不等于操作符，尤其是在涉及到大量数据的查询中。
此外，对于需要使用不等于操作的场景，可以考虑使用其他查询策略或优化方法，如使用NOT EXISTS、LEFT JOIN等替代不等于操作，或者使用覆盖索引来优化查询性能。

MySQL事务机制：
事务（Transaction），是指作为单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行。 
事务处理可以确保除非事务性单元内的所有操作都成功完成，否则不会永久更新面向数据的资源。
简单理解事务，即：当前操作要么全部成功，要么全部失败。这样可以简化错误恢复并使应用程序更加可靠。

事务 4 大特性：原子性、一致性、隔离性、持久性。通常称为 ACID 特性。

原子性(Atomicity)：指一个事务是一个不可分割的工作单元，事务中包括的所有操作要么都完成，要么都不完成。
一致性(Consistency)：指事务必须是使数据库从一个一致性状态变到另一个一致性状态，是否一致性与原子性是密切相关的。
隔离性(Isolation)：指一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对 并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。
持久性(Durability)：指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的，接下来的其他操作或故障不应该对这些数据有任何影响。

事务并发带来的问题：
1.脏读 ：一个事务对数据进行了增删改，但未提交，另一事务可以读取到未提交的数据。如果第一个事务这时候回滚了，那么第二个事务就读到了脏数据。
2.不可重复读：一个事务中发生了两次读操作，第一次读操作和第二次读操作之间，另外一个事务对数据进行了修改，这就会导致两次读取的数据是不一致的。
3.幻读：第一个事务对一定范围的数据进行批量查询，第二个事务在这个范围增加一条数据，这时候第一个事务就会丢失对新增数据的内容。

MySQL锁：
锁的出现，就是用于解决不同事务对共享资源并发访问所引起的脏读、不可重复读、幻读问题。
MySQL InnoDB 锁类型，分别是：共享锁(Shard Lock)、排它锁(Exclusive Lock)、
意向共享锁(Intention Shared Lock)、意向排它锁(Intention Exclusive Lock)、自增锁(AUTO-INC Lock)、
临键锁(Next-key Lock)、间隙锁(Gap Lock)、记录锁(Record Lock) 八种。
(记录锁、间隙锁、临键锁这三种锁，都是行锁的具体实现算法。我们可以将其理解为锁的类型，也可以理解为行锁的具体实现算法)

MySQL行级锁：行级锁，每次操作锁住对应的行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。
应用在InnoDB存储引擎中,MyISAM不支持行级锁。

MySQL表级锁：表级锁，每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。
应用在MyISAM、InnoDB、BDB等存储引擎中。
对于表级锁，主要分为以下三类：
表锁
元数据锁（meta data lock，MDL）
意向锁

共享锁（S锁）：
添加共享锁之后，如果查询未命中索引，则不会使用行锁，会退变为表锁。
所以在没有创建name索引时，修改徐勇数据时，会被阻塞；
>当创建name索引后，由于查询命中索引，所以行锁将曹茜这条数据锁住，并不会影响表中其他数据的操作。此时修改徐勇这条数据能够成功。
>由于行锁、表锁的原因，其他事务会处于等待状态。锁超时等待，默认为 50 s。
我们可通过命令：show variables like ‘innodb_lock_wait_timeout’;来查看(CSDN原因，将引号修改为英文状态单引号)。
锁超时时间也分会话/全局级别，我们可通过set session innodb_lock_wait_timeout = 20; 
或 set global innodb_lock_wait_timeout = 20; 来进行修改设置。

排他锁（X锁）：
添加排他锁之后，如果 name 字段查询未命中索引，则不会使用行锁，会退变为表锁。
所以在没有创建name索引时，修改徐勇数据时，会被阻塞；
>当创建name索引后，由于 name 字段查询命中索引，所以行锁会将曹茜这条数据锁住（其他会话无法获取该条数据的共享锁、排它锁），
并不会影响表中其他数据的操作。此时修改徐勇这条数据能够成功。
>此时查询数据是可以正常进行的。是因为 InnoDB 还有一个"一致性的非锁定读"的概念，
就是说行锁未释放之前，其他事务读取该行数据读取的是它的快照数据，并不会与行锁冲突
>由于行锁、表锁的原因，其他事务会处于等待状态。锁超时等待，默认为 50 s。

意向锁：
1 意向共享锁（IS锁）
表锁。表示事务准备给数据行加入共享锁时，即一个数据行加共享锁前必须先取得该表的 IS 锁， 意向共享锁之间是可以相互兼容的

2 意向排他锁（IX锁）
表锁。表示事务准备给数据行加入排他锁时，即一个数据行加排他锁前必须先取得该表的 IX 锁， 意向排它锁之间是可以相互兼容的

意向锁(IS锁、IX锁)是 InnoDB 数据操作之前自动加的，不需要用户干预。所以此处不做介绍，有个概念即可。当事务想去进行锁表时，可以先判断意向锁是否存在，存在时则可快速返回该表不能启用表锁。

自增锁：
当我们插入数据时，自增锁会 +1，但是此时如果事务执行了 rollback 等其他操作，导致数据并没有插入成功，
此时自增锁 id 并不会随之回退，会永久丢失，从而导致的自增 id 列不连续。

临键锁：
临键锁（Next-key Lock），作为 InnoDB 引擎默认行锁算法。就是解决 幻读 问题。
当 SQL 执行按照索引进行数据查询时，查询条件为范围查找(between and 、< 、> 等)并有数据命中时，
此时 SQL 语句加上的锁为 Next-key Lock，锁住的是索引的记录+下一个区间（左开右闭）。

临键锁，为什么要锁住下一个区间？
这和索引底层 B+Tree 有关系。MySQL 索引底层选择 B+Tree。B+Tree 数据都保存在叶子节点，并且具有顺序性，
从左到右依次增大。临键锁锁住相邻区间，此时 insert 插入数据时，我们并不能够将数据成功的插入到该区间，
就能够满足每次查询的数据一致，从而解决幻读问题。

示例解释：还是select * from orders where id > 5 and id < 9 for update;这个查询，
事务A 第一次查询出来一条 id = 7 的数据。如果不锁住相邻区间，此时事务B 插入了一条 id = 8 的数据。
那么事务A 在接下来就会查询出 2 条数据。如果锁住相邻区间，那么只要在事务 A 没结束期间，
查询到的都会只有 id = 7 这1条数据。这就解决了幻读问题。

间隙锁：
间隙锁（Gap Lock）。当 SQL 执行按照索引进行数据查询时，查询条件的数据不存在，
此时 SQL 语句加上的锁即为 Gap Lock，锁住的是数据不存在的区间（左开右开）。

因为只有在 RR 事务隔离级别下，InnoDB 引擎才能够解决数据幻读的问题。
临键锁(Next-key Lock) = 间隙锁(Gap Lock) + 记录锁(Record Lock)，所以 Gap 锁只有在 RR 级别下存在。

记录锁：
记录锁（Record Lock）。当 SQL 执行按照唯一性（Primary key、Unique key）索引进行数据查询时，查询条件等值匹配且查询的数据存在，
此时 SQL 语句加上的锁即为 Record Lock，锁住的是具体的索引项。

MySQL MVCC：
MVCC 多版本并发控制
MySQL的大多数事务型存储引擎实现都不是简单的行级锁。基于提升并发性考虑，一般都同时实现了多版本并发控制（MVCC），包括Oracle、PostgreSQL。只是实现机制各不相同。
可以认为 MVCC 是行级锁的一个变种，但它在很多情况下避免了加锁操作，因此开销更低。
虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只是锁定必要的行。
MVCC 的实现是通过保存数据在某个时间点的快照来实现的。也就是说不管需要执行多长时间，每个事物看到的数据都是一致的。
典型的MVCC实现方式，分为乐观（optimistic）并发控制和悲观（pressimistic）并发控制。
下边通过 InnoDB的简化版行为来说明 MVCC 是如何工作的。
InnoDB 的 MVCC，是通过在每行记录后面保存两个隐藏的列来实现。这两个列，一个保存了行的创建时间，一个保存行的过期时间（删除时间）。
当然存储的并不是真实的时间，而是系统版本号（system version number）。
每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。

REPEATABLE READ（可重读）隔离级别下MVCC如何工作：

SELECT：
InnoDB会根据以下两个条件检查每行记录：
①InnoDB只查找版本早于当前事务版本的数据行，这样可以确保事务读取的行，要么是在开始事务之前已经存在要么是事务自身插入或者修改过的
②行的删除版本号要么未定义，要么大于当前事务版本号，这样可以确保事务读取到的行在事务开始之前未被删除

只有符合上述两个条件的才会被查询出来

INSERT：InnoDB为新插入的每一行保存当前系统版本号作为行版本号
DELETE：InnoDB为删除的每一行保存当前系统版本号作为行删除标识
UPDATE：InnoDB为插入的一行新纪录保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为删除标识

保存这两个额外系统版本号，使大多数操作都不用加锁。使数据操作简单，性能很好，并且也能保证只会读取到符合要求的行。
不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作和一些额外的维护工作。
MVCC 只在 COMMITTED READ（读提交）和REPEATABLE READ（可重复读）两种隔离级别下工作。


MYSQL存储引擎：
MySQL 提供了多个不同的存储引擎，包括处理事务安全表的引擎和处理非事务安全表的引擎。
在 MySQL 中，不需要在整个服务器中使用同一种存储引擎，针对具体的要求，可以对每一个表使用不同的存储引擎。
MySQL 5.7 支持的存储引擎有 InnoDB、MyISAM、Memory、Merge、Archive、CSV、BLACKHOLE 等。
可以使用SHOW ENGINES;语句查看系统所支持的引擎类型

InnoDB：
在 MySQL 5.5 及以后版本后，MySQL 选择使用 InnoDB为默认存储引擎。
在创建数据库表时，不指定存储引擎时，使用的就是 InnoDB。如需使用其他存储引擎，可以手动来指定。
 
特点：
InnoDB 支持事务操作；（每一条SQL都默认封装成事务，自动提交，会影响速度）
InnoDB 支持外键；
InnoDB 是聚集索引（聚簇索引）；
InnoDB 不保存表的总条数；
InnoDB 5.7版本之前不支持全文检索；
InnoDB 支持表级锁、行级锁，默认为行级锁；
InnoDB 表必须有主键（如果我们没有明确去指定创建主键索引。它会帮我们隐藏的生成一个 6 byte 的 int 型的索引作为主键索引）；
InnoDB 文件存储方式为.frm文件存储表结构，ibd文件存储数据内容。

名词解释：
什么是聚集(簇)索引？
聚簇索引的特点是叶子节点包含了完整的记录行，而非聚簇索引的叶子节点只有所以字段和主键ID。
MySQL 索引采用 B+Tree（不熟悉？来跳转链接了解：MySQL 索引底层为什么选择B+Tree）。
InnoDB 和 MyISAM 作为 MySQL 中 B+Tree 索引的两种重要体现形式。 
InnoDB 推荐以主键作为索引来组织数据进行存储，它认为主键是一个非常重要的属性。
InnoDB 表数据文件本身就是按B+Tree组织的一个索引结构，聚簇索引就是按照每张表的主键来构造一个B+树，
叶子节点中存放的就是整张表的数据。
 
一般建表会用一个自增主键做聚簇索引，没有的话MySQL会默认创建，
但是这个主键如果更改代价较高，故建表时要考虑自增ID不能频繁 update 这一点。
MySQL一张表，比如有id(主键)，name，age等字段。我们可以建很多个索引，MySQL除了主键索引外，都是非聚簇索引。
即只有我们创建的主键id索引，我们可以叫他id索引，它别名又叫做聚簇索引，
（因为只有id索引，叶子节点包含了完整的记录行）理解成一个别名的即可。
如果我们再创建一个name索引，它就叫做非聚簇索引，或者辅助索引。）
 
我们日常工作中，根据实际情况自行添加的索引都是辅助索引，辅助索引就是一个为了需找主键索引的二级索引，
现在找到主键索引再通过主键索引找数据；

MyISAM存储引擎：
MyISAM 作为 MySQL 中 B+Tree 索引的另一种重要体现形式。
 
特点：

MyISAM 是非聚集索引；
MyISAM 有一个变量专门来保存整个表的行数，查询count很快(注意不能加任何 where 条件)
MyISAM 支持全文索引；
MyISAM 可以被压缩后进行查询操作，节省空间容量；
MyISAM 支持表级锁，不支持行级锁；
MyISAM 中主键不是必须的；
MyISAM 文件存储方式为.frm文件存储表结构，.MYD文件存储数据内容，.MYI文件存储索引文件。

MySQL主从复制（数据库的主数据库复制到从数据库）
读写分离：主（master）实现写请求，从（slave）实现读请求，从而减轻数据库的压力。
redis可以实现读写分离，elasticsearch没有主从同步，kafka用的是主读主写

MySQL分库分表：
分库分表的方式有四种，它们分别是：垂直分表、垂直分库、水平分库和水平分表。

垂直分表：可以把一个宽表的字段按照访问频率、是否是大字段的原则拆分为多个表，这样既能使业务清晰，还能提高部分性能。
拆分后，尽量从业务角度避免联查，否则性能方面将得不偿失。

垂直分库：可以把多个表按照业务的耦合性来进行分类，分别存放在不同的数据库中，
这些库可以分布在不同的服务器，从而使访问压力被分摊在多个服务器，大大提高性能，同时能提高整体架构的业务清晰度，
不同的业务库可根据自身情况定制优化方案。但是它需要解决跨库带来的所有复杂问题。

水平分库：可以把一个表的数据(按数据行)分到多个不同的库，每个库只有这个表的部分数据，
这些库可以分布在不同的服务器，从而使访问压力被多服务器负载，提升性能。
它不仅需要解决跨库带来的问题，还需要解决数据路由的问题。

水平分表：可以把一个表的数据(按数据行)分到多个同一个数据库的多张表中，每个表的数据只有这个表的部分数据，
这样做能小幅提升性能，它仅仅作为水平分库的一个补充优化。

最后，一般来说，在系统设计阶段就应该根据业务耦合程度来确定用哪种分库分表的方式(方案)，
在数据量及访问压力不是特别大的情况，首先考虑缓存、读写分离、索引技术等方案。
若数据量极大，且连续增长，再考虑水平分库水平分表的方案。


Oracle:
SQL语句在Oracle中执行过程详解
Oracle采用了共享池来判断SQL语句是否存在缓存和执行计划。
1.语法检查
2.语义检查
3.权限检查
4.共享池检查：最主要的作用是缓存SQL语句和该语句的执行计划→ 软解析
5.优化器→硬解析


数据库连接技术：
JDBC：传统连接数据库的方法，容易产生硬编码问题，难以保证SQL注入安全性
//步骤一:定义连接数据库的相关信息
static String driver = "com.mysql.jdbc.Driver";
连接数据库
    static String url = "jdbc:mysql://localhost:3306/school?useSSL=false";
    static String username = "root";
    static String password = "root";

public static void main(String[] args) {
//步骤二:加载jdbc驱动
 Class.forName(driver);

//步骤三:通过驱动管理器获得和数据的连接
Connection conn = DriverManager.getConnection(url,username,password);
System.out.println("数据库的连接:"+conn);

//步骤四:定义查询的sql语句

//步骤五:创建一个PreparedStatement对象(可以用来执行sql,来操作数据库)
PreparedStatement pstmt = conn.prepareStatement(sql);

//步骤六:执行sql,得到结果集
ResultSet rs = pstmt.executeQuery();

//步骤七:关闭资源
}

数据库连接池Druid：
1.数据库连接池是个容器，负责分配、管理数据库连接(Connection)；
2.它允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个；
3.释放空闲时间超过最大空闲时间的数据库连接来避免因为没有释放数据库连接而引起的数据库连接遗漏；
public class Druid_ {
    @Test
    public void testDruid() throws Exception {
        //1.加入Druid jar包
        //2.加入配置文件，将该文件拷贝到项目的src目录下
        //3.创建Properties对象，读取配置文件
        Properties properties = new Properties();
        properties.load(new FileInputStream("src\\druid.properties"));

        //4.创建一个指定参数的数据库连接池
        DataSource dataSource = DruidDataSourceFactory.createDataSource(properties);
        long start =System.currentTimeMillis();
        for (int i = 0; i < 5000; i++) {
            Connection connection = dataSource.getConnection();
            connection.close();
        }
        long end =System.currentTimeMillis();
        System.out.println("Druid 5000次连接mysql耗时：" + (end - start));//Druid 5000次连接mysql耗时：3608
    }
}

Mybatis：
MyBatis是一个优秀的持久层框架，它对jdbc的操作数据库的过程进行封装，
使开发者只需要关注 SQL 本身，而不需要花费精力去处理例如注册驱动、创建connection、创建statement、手动设置参数、
结果集检索等jdbc繁杂的过程代码。
Mybatis通过xml或注解的方式将要执行的各种statement（statement、preparedStatemnt、CallableStatement）配置起来，
并通过java对象和statement中的sql进行映射生成最终执行的sql语句，
最后由mybatis框架执行sql并将结果映射成java对象并返回。
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org/DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="com.mybitis.mapper.UserMapper">
    <resultMap id="result" type="com.mybitis.entity.User">
        <result column="userid" jdbcType="INTEGER" property="userid" />
        <result column="username" jdbcType="VARCHAR" property="username" />
        <result column="password" jdbcType="VARCHAR" property="password" />
    </resultMap>

    <select id="findAllUser" resultType="com.mybitis.entity.User">
        select  * from user;
    </select>

    <select id="findUserByUserId" resultType="com.mybitis.entity.User">
        select * from user where userid=#{userid};
    </select>
    <select id="findUserByUsername" resultType="com.mybitis.entity.User">
        select * from user where username=#{username};
    </select>

    <insert id="insertUser" parameterType="com.mybitis.entity.User" keyProperty="userid" useGeneratedKeys="true">
        insert into user(userid,username,password) values (#{userid},#{username},#{password});
    </insert>

    <update id="updateUser" parameterType="com.mybitis.entity.User">
        update user set username=#{username},password=#{password} where userid=#{userid};
    </update>

    <delete id="deleteUser" parameterType="com.mybitis.entity.User">
        delete from user where userid=#{userid};
    </delete>
</mapper>

MyBatis获取参数值的两种方式：${}和#{}
${}的本质就是字符串拼接，#{}的本质就是占位符赋值
${}使用字符串拼接的方式拼接sql，若为字符串类型或日期类型的字段进行赋值时，需要手动加单引
号；但是#{}使用占位符赋值的方式拼接sql，此时为字符串类型或日期类型的字段进行赋值时，可以自动添加单引号
使用#{}可以防止SQL注入

1、单个字面量类型的参数
若mapper接口中的方法参数为单个的字面量类型
此时可以使用${}和#{}以任意的名称获取参数的值，注意${}需要手动加单引号

2、多个字面量类型的参数
若mapper接口中的方法参数为多个时
此时MyBatis会自动将这些参数放在一个map集合中，以arg0,arg1...为键，以参数为值；
以param1,param2...为键，以参数为值；因此只需要通过${}和#{}访问map集合的键就可以获取相对应的值，注意${}需要手动加单引号

3、map集合类型的参数
若mapper接口中的方法需要的参数为多个时，此时可以手动创建map集合，将这些数据放在map中
只需要通过${}和#{}访问map集合的键就可以获取相对应的值，注意${}需要手动加单引号

4、实体类类型的参数
若mapper接口中的方法参数为实体类对象时
此时可以使用${}和#{}，通过访问实体类对象中的属性名获取属性值，注意${}需要手动加单引号

5、使用@Param标识参数
可以通过@Param注解标识mapper接口中的方法参数
此时，会将这些参数放在map集合中，以@Param注解的value属性值为键，以参数为值；
以param1,param2...为键，以参数为值；只需要通过${}和#{}访问map集合的键就可以获取相对应的值，注意${}需要手动加单引号

MyBatis的缓存：

1、MyBatis的一级缓存
一级缓存是SqlSession级别的，通过同一个SqlSession查询的数据会被缓存，下次查询相同的数据，
就会从缓存中直接获取，不会从数据库重新访问

使一级缓存失效的四种情况：
1) 不同的SqlSession对应不同的一级缓存
2) 同一个SqlSession但是查询条件不同
3) 同一个SqlSession两次查询期间执行了任何一次增删改操作
4) 同一个SqlSession两次查询期间手动清空了缓存

2、MyBatis的二级缓存
二级缓存是SqlSessionFactory级别，通过同一个SqlSessionFactory创建的SqlSession查询的结果会被缓存；
此后若再次执行相同的查询语句，结果就会从缓存中获取。

二级缓存开启的条件：
a>在核心配置文件中，设置全局配置属性cacheEnabled="true"，默认为true，不需要设置
<settings>
    <setting name="cacheEnabled" value="true"/>
</settings>
b>在映射文件中设置标签<cache />
<mapper namespace="com.example.MyMapper">
    <cache/>
    <!-- 其他映射配置 -->
</mapper>
c>二级缓存必须在SqlSession关闭或提交之后有效
d>查询的数据所转换的实体类类型必须实现序列化的接口
使二级缓存失效的情况：
两次查询之间执行了任意的增删改，会使一级和二级缓存同时失效

Mybatis的逆向工程：
MyBatis Generator是一个用于生成MyBatis的Java数据访问层代码和SQL映射文件的逆向工程工具。你可以通过配置MyBatis Generator来自动生成数据库表的实体类、Mapper接口以及SQL映射文件。

逆向工程的配置文件：
<!DOCTYPE generatorConfiguration PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN"
    "http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd">

<generatorConfiguration>
    <classPathEntry location="path/to/your/database/driver.jar" />

    <context id="MyBatisGenerator" targetRuntime="MyBatis3">
        <property name="javaFileEncoding" value="UTF-8" />
        <property name="beginningDelimiter" value=" " />
        <property name="endingDelimiter" value=" " />

        <!-- 数据库连接配置 -->
        <jdbcConnection driverClass="com.mysql.cj.jdbc.Driver"
            connectionURL="jdbc:mysql://localhost:3306/your_database"
            userId="your_username"
            password="your_password">
        </jdbcConnection>

        <!-- 生成实体类的目标包 -->
        <javaModelGenerator targetPackage="com.example.model" targetProject="src/main/java">
            <property name="enableSubPackages" value="true" />
            <property name="trimStrings" value="true" />
        </javaModelGenerator>

        <!-- 生成Mapper接口的目标包 -->
        <sqlMapGenerator targetPackage="com.example.mapper" targetProject="src/main/resources">
            <property name="enableSubPackages" value="true" />
        </sqlMapGenerator>

        <!-- 生成Mapper XML 文件的目标包 -->
        <javaClientGenerator type="XMLMAPPER" targetPackage="com.example.mapper" targetProject="src/main/resources">
            <property name="enableSubPackages" value="true" />
        </javaClientGenerator>

        <!-- 配置要生成的表和生成规则 -->
        <table tableName="your_table_name" domainObjectName="YourTable" enableCountByExample="false" enableUpdateByExample="false"
            enableDeleteByExample="false" enableSelectByExample="false" selectByExampleQueryId="false" />
    </context>
</generatorConfiguration>


列式存储数据库：
列存储不同于传统的关系型数据库，其数据在表中是按行存储的，列方式所带来的重要好处之一就是，由于查询中的选择规则是通过列来定义的，因此整个数据库是自动索引化的。
列式数据库是以列相关存储架构进行数据存储的数据库，主要适合于批量数据处理和即时查询。相对应的是行式数据库，数据以行相关的存储体系架构进行空间分配，主要适合于大批量的数据处理，常用于联机事务型数据处理。
列存储数据库使用一个称为 keyspace 的概念。keyspace 有点像关系模型中的模式。keyspace 包含所有列族(有点像关系模型中的表)，其中包含行，包含列。
列式存储多用于OLAP(Online analytical processing)联机分析处理系统

>列族由多行组成。
>每一行可以包含与其他行不同数量的列。而且这些列不必与其他行的列匹配(例如，它们可以有不同的列名、数据类型、数量等)。
>每行包含一列。它不像关系数据库那样跨所有行。每个列包含一个名称/值对，以及一个时间戳。

		  Column 		Column 		   Column
		  Name 			Name		   Name 
Row Key   Value 		Value 		   Value
		  Timestamp   	Timestamp	   Timestamp

每一行的结构：
Row Key：每一行都有一个惟一的键，这是该行的惟一标识符。
Column：每个列包含名称、值和时间戳。
Name：KV 对的 K
Value：KV 对的 V
Timestamp：这提供了插入数据的日期和时间。这可以用来确定数据的最新版本。

特点/优点
高效的压缩效率，节省磁盘空间和计算CPU和内存
基于 CPU L2 缓存高效的数据迭代
压缩算法：列式数据库由于其每一列都是分开储存的。所以很容易针对每一列的特征运用不同的压缩算法。常见的列式数据库压缩算法有Run Length Encoding ， Data Dictionary ， Delta Compression ， BitMap Index ， LZO ， Null Compression 等等。根据不同的特征进行的压缩效率从10W:1 到10:1 不等。而且数据越大其压缩效率的提升越为明显。
延迟物化：列式数据库由于其特殊的执行引擎，在数据中间过程运算的时候一般不需要解压数据而是以指针代替运算，直到最后需要输出完整的数据时。
聚合查询：由于它们的结构，柱状数据库在聚合查询(如SUM、COUNT、AVG等)方面表现得特别好。
可扩展性：列式存储数据库是可伸缩的。它们非常适合大规模并行处理(MPP)，这涉及到将数据分散到一个大的机器集群中——通常是数千台机器。
快速查询和写入：可以非常快地加载。可以在几秒钟内加载十亿行表。几乎可以立即开始查询和分析。

列式存储数据库有：1.HBase；2.ClickHouse；3.Druid；4.HP Vertica（也支持行式存储）。

非关系型数据库(nosql)：
redis：
Redis 是一个开源(BSD许可)的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。
它支持多种类型的数据结构，如 字符串 (strings) ，散列 (hashes) ， 列表(lists)集合 (sets)，有集合 (sorted sets) 与范围查询，bitmaps， hyperloglogs和地理空间 (geospatial) 索引半径查询。 
Redis 内置了 复制 (replication) ，LUA脚本(Luascripting)，LRU驱动事件(LRU eviction)，事务 transactions) 
和不同级别的 磁盘持久化(persistence) ，并通过 Redis哨兵 (Sentinel) 和自动 分区(Cluster) 提供高可用性 (highavailability)

redis五大数据类型：
1.String字符串
2.List
3.Set
4.Hash
5.ZSet

SpringBoot整合Redis：SpringBoot配置Redis工具类
@Configuration
public class RedisConfig {
    @Bean
    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {
        RedisTemplate<String, Object> template = new RedisTemplate<String, Object>();
        template.setConnectionFactory(factory);
        // key采用String的序列化方式
        template.setKeySerializer(new StringRedisSerializer());
        // hash的key也采用String的序列化方式
        template.setHashKeySerializer(new StringRedisSerializer());
        // value序列化方式采用jackson
        template.setValueSerializer(new GenericJackson2JsonRedisSerializer());
        // hash的value序列化方式采用jackson
        template.setHashValueSerializer(new GenericJackson2JsonRedisSerializer());
        template.afterPropertiesSet();
        return template;
    }

}

自动注入redisTemplate
@Autowired
private RedisTemplate redisTemplate;


Memcache:
memcache是一个高性能的分布式的内存对象缓存系统，用于动态Web应用以减轻数据库负担。
它通过在内存中缓存数据和对象，来减少读取数据库的次数。从而提高动态、数据库驱动网站速度。
memcache通过在内存里维护一个统一的巨大的hash表，它能够用来存储各种格式的数据，包括图像、视频、文件以及数据库检索的结果等。
memcache主要用于分担数据库负的压力，memcache将数据调用到内存中，然后从内存中读取，从而大大提高读取速度。

优点：
1.Memcached可以利用多核优势，单实例吞吐量极高，可以达到几十万QPS（取决于key、value的字节大小以及服务器硬件性能，日常环境中QPS高峰大约在4-6w左右）。适用于最大程度扛量。
2.支持直接配置为session handle。

缺点：
1只支持简单的key/value数据结构，不像Redis可以支持丰富的数据类型。
2.无法进行持久化，数据不能备份，只能用于缓存使用，且重启后数据全部丢失。
3.无法进行数据同步，不能将MC中的数据迁移到其他MC实例中。
4.Memcached内存分配采用Slab Allocation机制管理内存，value大小分布差异较大时会造成内存利用率降低，并引发低利用率时依然出现踢出等问题。需要用户注重value设计。


MongoDB:
MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。
在高负载的情况下，添加更多的节点，可以保证服务器性能。
MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。
MongoDB 将数据存储为一个文档，数据结构由键值(key=>value)对组成。
MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。

优点：
1.更高的写负载，MongoDB拥有更高的插入速度。
2.处理很大的规模的单表，当数据表太大的时候可以很容易的分割表。
3.高可用性，设置M-S不仅方便而且很快，MongoDB还可以快速、安全及自动化的实现节点（数据中心）故障转移。
4.快速的查询，MongoDB支持二维空间索引，比如管道，因此可以快速及精确的从指定位置获取数据。MongoDB在启动后会将数据库中的数据以文件映射的方式加载到内存中。如果内存资源相当丰富的话，这将极大地提高数据库的查询速度。
5.非结构化数据的爆发增长，增加列在有些情况下可能锁定整个数据库，或者增加负载从而导致性能下降，由于MongoDB的弱数据结构模式，添加1个新字段不会对旧表格有任何影响，整个过程会非常快速。

缺点：
1.不支持事务。
2.MongoDB占用空间过大 。
3.MongoDB没有成熟的维护工具。

ShardingSphere：
ShardingSphere是一个开源的分布式数据库中间件，用于实现关系型数据库的分片和分布式数据库操作。
它提供了跨多个数据库实例的数据分片、读写分离、分布式事务等功能，以帮助开发人员构建可伸缩和高可用性的数据库架构。

ShardingSphere 主要包括以下子项目：

1.Sharding-JDBC：用于实现关系型数据库的数据分片（Sharding）和读写分离（Master-Slave）功能。
它允许应用程序在使用关系型数据库时将数据分散到多个数据库实例，从而提高数据库性能和扩展性。
2.Sharding-Proxy：这是一个数据库代理，它支持分片和分布式事务，并允许应用程序通过一个中心化的访问点来访问分布式数据库，而不需要直接连接到底层数据库实例。
3.Sharding-Sidecar：这是 ShardingSphere 的云原生版本，它提供了 Kubernetes 和 Service Mesh（如 Istio）的支持，
以便更轻松地在云原生环境中部署和管理 ShardingSphere。

ShardingSphere 的主要特点包括：

- 数据分片：支持水平分片和垂直分片，允许将数据分散存储在不同的数据库实例中。
- 读写分离：可以将读操作分发到只读数据库实例，从而减轻主数据库的负载。
- 分布式事务：提供分布式事务支持，确保多个数据库实例之间的一致性。
- 高可用性：支持数据库故障切换和自动恢复，以确保系统的高可用性。
- 多种数据库支持：支持多种关系型数据库，如MySQL、PostgreSQL、Oracle等。

ShardingSphere 是一个强大的工具，可用于构建大规模、高性能和高可用性的分布式数据库架构，特别适用于云原生环境和大型企业应用程序。


Java容器技术：
容器技术是一种软件开发和部署技术，允许开发人员在虚拟环境中将应用程序与其依赖关系封装在一起，以实现在不同的环境中的一致性。
容器技术通过使用容器映像来管理应用程序，并在系统上运行容器实例。容器映像是包含所有应用程序代码和依赖关系的可执行文件。容器实例则是运行在特定环境中的应用程序副本。

容器技术的优势在于：
避免了环境问题：应用程序在容器中与其依赖关系一起运行，因此可以避免环境问题导致的故障。
提高了部署效率：容器可以快速部署，并且可以方便地进行版本管理和回滚。
支持微服务架构：容器可以作为微服务架构的基础设施，帮助开发人员快速构建、部署和管理复杂的分布式系统。
目前，Docker是最常用的容器技术，它提供了一个开放的生态系统，可以方便地管理容器。


CI/CD流水线：
CI/CD是持续集成和持续交付或持续部署的软件开发流程模型。CI/CD旨在通过自动化和持续性的构建、测试、部署和交付过程，来提高软件开发和发布的效率和质量。
CI/CD的目标是缩短软件开发和发布的周期，降低开发和发布的成本和风险，以满足快速变化和不断迭代的业务需求。
CI/CD中的"CI"指的是持续集成，是指开发人员将代码不断地提交到源代码管理系统中，在此过程中，
自动化的测试和构建工具会自动从源代码库中获取最新的代码，进行编译、测试、打包等操作，并生成相应的构建产物；
"CD"指的是持续交付和/或持续部署，将构建产物部署到测试环境进行测试和验证，最终生成可部署的产物，
实现自动化的部署和发布，从而实现快速的交付和迭代。

CI/CD 中的 "CI"指的是持续集成：
持续集成属于开发人员的自动化流程，它帮助开发人员更加频繁地将代码的更改合并到主分支或共享分支，
并自动构建和运行不同级别的自动化测试来验证这些更改，确保这些更改没有对应用造成破坏。

CI/CD中的"CD"指的是持续交付和/或持续部署：
持续交付（Continuous Delivery）的目的是最小化部署或释放过程中固有的摩擦，实现自动化构建和部署。
持续部署（Continuous Deployment）指的是自动将开发人员的更改从存储库发布到生产环境，以供客户使用，
主要为了解决因手动流程降低应用交付速度，从而使运维团队超负荷的问题。


CI/CD流水线将程序部署到Kubernetes（k8s）的方式如下（以Jenkins为例）：

1.建立流水线项目。首先建立一个Jenkins流水线项目，并配置相关参数，如选择源代码管理系统、设置构建环境等。
2.从源代码管理系统拉取代码。Jenkins通过参数化的构建方式，从源代码管理系统中拉取代码并下载到本地。
3.编译代码。通过Dockerfile的方式对代码进行编译和制作镜像，并将镜像上传到镜像仓库。
4.部署应用。流水线项目将应用部署到Kubernetes集群中。
5.配置邮件通知功能。配置邮件通知功能，将镜像构建结果通过邮件的方式通知给相关人员。


前端项目如何部署？
前端项目的部署流程：
1.链接服务器：通过ssh @root[ipaddress]命令链接你的服务器（将ipaddress替换成你服务器的公网IP地址）。
2.配置服务器：在服务器上配置Apache或Nginx的静态文件目录，以及反向代理，将客户端请求转发到前端项目的访问入口文件index.html。
3.自动化部署：使用自动化工具，如Jenkins、Travis CI等，在Github中托管代码，Travis CI将自动触发构建和部署流程，
生成可运行的前端代码并部署到服务器上。


Docker的镜像技术是一种特殊的文件系统，它除了提供容器运行时所需的程序、库、资源、配置等文件外，
还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。
镜像不包含任何动态数据，其内容在构建之后也不会被改变。
Docker镜像的只读形式，在启动Docker容器中，文件系统结构和内容都包含在其中，Docker镜像是启动Docker容器的基础。
Docker镜像的文件内容和配置文件组成了Docker容器的静态文件系统运行环境--rootfs。
简单的理解为：Docker镜像是Docker容器的静态视角，Docker容器是Docker镜像的运行状态。
rootfs是Docker容器的根目录，在启动时Docker容器可见到的文件系统，rootfs包含了操作系统运行所需的文件系统，
例如：dev、proc、bin、etc、lib等Unix目录系统以及配置文件、工具等。



镜像技术的优势在于：
简化部署：使用镜像可以快速地将应用程序部署到任何环境中。
提高一致性：镜像文件包含了所有所需的文件和配置，因此可以保证在不同的环境中的一致性。
方便回滚：如果一个镜像不能正常工作，可以方便地回滚到以前的版本。
镜像技术是虚拟化、容器化和云计算等计算机领域的重要技术，在微服务架构、云部署等场景中被广泛使用。
常见的镜像技术有Docker镜像、Kubernetes镜像、OpenShift镜像等。



Docker：
Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。
Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。
容器是完全使用沙箱机制，相互之间不会有任何接口,更重要的是容器性能开销极低。
Docker支持将软件编译成一个镜像；然后在镜像中各种软件做好配置，将镜像发布出去，其他使用者可以直接使用这个镜像。
运行中的这个镜像称为容器，容器启动是非常快速的。类似windows里面的ghost操作系统，安装好后什么都有了；

Docker的原理：
Docker的原理基于Linux的核心命名空间（Namespaces）和核心资源隔离机制（Cgroups）以及AUFS文件系统进行创建独立的容器。

Docker利用Linux中的核心分离机制，例如Cgroups，以及Linux的核心Namespace来创建独立的容器。
Docker容器的本质还是一个直接运行在宿主机上面的特殊进程，看到的文件系统是隔离后的，
但是操作系统内核是共享宿主机的，所以说Docker是轻量级的虚拟化技术。


Docker的分层存储：
Docker中的分层存储是指Docker镜像的一种存储方式。它使用联合挂载系统（Union Mount）的技术，
其文件系统是分层的，将多个只读层叠加在一起，形成一个可读写的联合文件系统，以提供Docker镜像的高效存储和管理。
分层存储是Docker镜像轻量级、易于管理，以及更容易与其他Docker操作进行组合的重要原因。
       

Docker核心概念：
docker镜像(Images)：Docker 镜像是用于创建 Docker 容器的模板。
docker容器(Container)：容器是独立运行的一个或一组应用。
docker客户端(Client)：客户端通过命令行或者其他工具使用
Docker API(https://docs.docker.com/reference/api/docker_remote_api) 与 Docker 的守护进程通信
docker主机(Host)：一个物理或者虚拟的机器用于执行Docker 守护进程和容器。
docker仓库(Registry)：Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。
Docker Hub(https://hub.docker.com) 提供了庞大的镜像集合供使用。


为什么Docker比Vm快？
1、docker有着比虚拟机更少的抽象层。由于docker不需要Hypervisor实现硬件资源虚拟化,
运行在docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker将会在效率上有明显优势。

2、docker利用的是宿主机的内核,而不需要Guest OS。
因此,当新建一个 容器时,docker不需要和虚拟机一样重新加载一个操作系统内核。
仍而避免引导、加载操作系统内核返个比较费时费资源的过程,当新建一个虚拟机时,虚拟机软件需要加载GuestOS,返个新建过程是分钟级别的。
而docker由于直接利用宿主机的操作系统,则省略了这个复杂的过程,因此新建一个docker容器只需要几秒钟。

kernel：Linux系统内核

boot file system （bootfs）：包含boot loader和kernel。用户不会修改这个文件系统。Linux系统刚启动时会加载bootfs文件系统；
而在启动完成后，整个内核都会被加载进内存，此时bootfs会被卸载掉从而释放出所占用的内存。
对于同样内核版本的不同的Linux发行版的bootfs都是一致的。

root file system （rootfs）：包含典型的目录结构，包括/dev, /proc, /bin, /etc, /lib, /usr, and /tmp等，
再加上要运行用户应用所需要的所有配置文件，二进制文件和库文件。这个文件系统在不同的Linux发行版中是不同的，
且用户可以对这个文件进行修改。



Kubernetes：
Kubernetes（简称K8s）是一个开源的、用于管理云平台中多个主机上的容器化的应用。

Kubernetes的目标是让部署容器化的应用简单并且高效，它提供了应用部署，规划，更新，维护的一种机制。
传统的应用部署方式是通过插件或脚本来安装应用，这样做有缺点，比如：应用的运行、配置、管理、所有生存周期将与当前操作系统绑定，
不利于应用的升级更新/回滚等操作。

新的方式是通过部署容器方式实现，每个容器之间互相隔离，每个容器有自己的文件系统 ，容器之间进程不会相互影响，能区分计算资源。
相对于虚拟机，容器能快速部署，由于容器与底层设施、机器文件系统解耦的，所以它能在不同云、不同版本操作系统间进行迁移。
容器占用资源少、部署快，每个应用可以被打包成一个容器镜像，每个应用与容器间成一对一关系也使容器有更大优势。
使用容器可以在build或release 的阶段，为应用创建容器镜像，因为每个应用不需要与其余的应用堆栈组合，
也不依赖于生产环境基础结构，这使得从研发到测试、生产能提供一致环境。
类似地，容器比虚拟机轻量、更“透明”，这更便于监控和管理。
       
K8S和Docker的区别：

K8S是一套自动化部署工具，可以管理Docker容器，是容器编排层面的，而Docker是一种开放源码的应用容器引擎，是容器层面的。
K8S是一个完整的分布式系统支撑平台，集群管理功能齐全，而Docker只是一种容器化技术。
K8S提供完善的管理工具，涵盖了开发、部署、测试、运行监控等各个环节，而Docker只实现了容器层面的虚拟化。



Java分布式系统：
分布式系统是计算机程序的集合，这些程序利用跨多个独立计算节点的计算资源来实现共同的目标。
它也被称为分布式计算或分布式数据库，并依靠不同的节点通过公共网络进行通信和同步。
这些节点通常代表独立的物理硬件设备，但也可代表单独的软件进程或其他递归封装的系统。
分布式系统旨在消除系统的瓶颈或中心故障点。

分布式框架通常使用以下技术：
1.分布式系统的基本架构，包括节点、通信、一致性、数据分布等。
2.分布式资源管理，如负载均衡、任务调度、数据复制等。
3.分布式通信技术，如RPC、消息队列等。
4.集群管理和监控技术，如ZooKeeper、Nagios等。
5.分布式数据存储技术，如分布式文件系统、NoSQL数据库等。
这些技术与其他技术，如容错、可扩展性、数据一致性等结合使用，以构建一个完整的分布式系统。

分布式系统模式发展阶段：
1.单一应用框架(ORM)
当网站流量很小时，只需一个应用，将所有功能如下单支付等都部署在一起，以减少部署节点和成本。
2.垂直应用框架(MVC)
垂直应用架构解决了单一应用架构所面临的扩容问题，流量能够分散到各个子系统当中，且系统的体积可控，
一定程度上降低了开发人员之间协同以及维护的成本，提升了开发效率。
MVC架构将网络交互层和数据交互层区分开，实现了业务读取和数据的分离。
3.分布式应用架构(RPC)
当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心。
不同业务场景的模块之间互相调用、通信。
4.流动计算架构(SOA)
随着服务化的进一步发展，服务越来越多，服务之间的调用和依赖关系也越来越复杂，诞生了面向服务的架构体系(SOA)，
也因此衍生出了一系列相应的技术，如对服务提供、服务调用、连接处理、通信协议、序列化方式、服务发现、服务路由、日志输出等行为进行封装的服务框架。
在分布式架构的基础上，延申出的架构。

对于分布式系统和垂直系统的理解：
一个微服务是垂直式MVC的集合，而分布式RPC是将多个微服务整合的系统，并保证系统的一致性、高性能、高可用和可拓展性等特性。

可以把分布式系统理解为集群吗？
分布式系统和集群是相关概念，但它们并不完全相同，尽管它们通常一起使用。以下是它们之间的区别：

分布式系统：
分布式系统是一种计算系统，其中多台计算机协同工作，共同完成一组相关任务或服务。
这些计算机可以分布在不同的地理位置，彼此之间通过网络连接。
分布式系统的设计目标是提高性能、可伸缩性、可靠性和可用性，同时允许更好的资源利用和负载分配。
分布式系统通常包括多个独立的计算节点，这些节点可以运行不同的服务或应用程序，并相互协调合作，以提供某种服务。

集群：
集群是一组紧密连接的计算机（节点）或服务器，它们共同工作以提供高可用性、容错性和负载均衡的服务。
这些计算机通常部署在同一物理位置，并连接在一起，以实现共享资源和协同工作。
集群的目标是提高性能和可靠性，以便在一个节点失败时可以无缝切换到其他节点，从而保持服务的连续性。
集群可以是部署在单一数据中心或多个数据中心的服务器集合。
虽然集群通常用于构建分布式系统的基础架构，但分布式系统更广泛，可以跨越多个地理位置，涉及多个应用程序和服务之间的协同工作。集群则更侧重于提供高可用性和性能，通常在相对较小的范围内操作。

因此，分布式系统可以包含多个集群，但它们不是同一概念。集群是分布式系统的一部分，用于支持特定服务或应用程序的高可用性和负载均衡需求。
简单的来说，分布式是指不同的业务分布在不同的地方。而集群指的是将几台服务器集中在一起，实现同一业务。
分布式中每一个节点，都可以做集群。而集群不一定都是分布式的。

微服务和分布式之间的关系：
微服务是实现分布式系统的一种方式。微服务架构是一种云原生架构方法，它将单个应用拆分为众多松散耦合且可单独部署的小型组件或服务。
这些服务拥有自己的技术栈，通过REST API、事件流和消息代理进行通信，并且按照业务能力进行组织。通过微服务架构，可以将大型应用拆分为多个小服务，
每个服务都可以独立地部署、扩展和管理，从而实现分布式系统的特性。

微服务之间的调用可以是RPC（远程过程调用）：
RPC（Remote Procedure Call，远程过程调用）是一种用于在不同的计算机或进程之间进行通信和调用远程方法的协议和框架。
下面是一个简化的RPC框架调用的过程：

1. 定义服务接口：首先，需要定义远程服务的接口，包括方法名、参数和返回值等。这个接口描述了调用方可以通过RPC调用的方法。
2. 生成客户端和服务器端代码：使用RPC框架的工具，将定义的服务接口生成客户端和服务器端的代码，这些代码用于实现远程调用的逻辑。
3. 发起远程调用：在客户端代码中，可以通过调用生成的客户端接口方法来发起远程调用。参数将被序列化，并通过网络发送到服务器端。
4. 传输和通信：客户端将序列化的参数通过网络传输到服务器端，服务器端接收到请求后进行解析和处理。
5. 服务器端处理：服务器端代码会根据方法名和参数执行实际的逻辑，并返回相应的结果。
6. 结果返回：服务器端将处理得到的结果序列化后，通过网络返回给客户端。
7. 客户端处理：客户端接收到服务器端返回的结果，进行反序列化，并将结果返回给调用方。

需要注意的是，上述过程是一个简化的描述，实际的RPC框架通常还包括更多的细节处理，如连接管理、负载均衡、错误处理等。
常见的RPC框架有gRPC、Apache Dubbo、Thrift等，它们提供了丰富的功能和配置选项，可以满足不同的使用需求。
在选择和使用RPC框架时，需要考虑框架的性能、可靠性、跨语言支持等因素。


分布式系统的CAP理论：
Consistency：一致性，在分布式系统中，更新操作执行成功后所有的用户的读操作必须返回最新值；
client写入，server同步至整个系统；
Availability：可用性，只要收到用户的请求，在一定的时间内服务器就必须给出回应，回应的结果可以是成功或是失败；
Partition tolerance：分区容错，即区间通信可能失败，在网络中断，消息丢失的情况下，仍对外提供服务；
一般无法避免，可以认为CAP中的P总是成立

在一个分布式计算机系统中，一致性C，可用性A，分区容错性P这三种保证无法同时得到满足，最多满足两个：
1.放弃P
为了避免分区容错性问题的发生，一种做法是将所有与事务相关的数据都放在一台服务器上，虽然不能保证100%系统不会出错，
但是不会碰到由分区带来的负面效果，这样的做法会严重影响系统的扩展性。
2.放弃A
放弃可用性，一旦遇到分区容错故障，受到影响的服务器需要等待一定的时间，因此会导致在等待期间系统无法对外提供服务。
3.放弃C
这儿说的放弃一致性，并不是完全放弃数据的一致性，而是放弃数据的强一致性，而保留数据的最终一致性。
以网络购物为例，对只剩下一件库存的商品，如果同时接受到了两份订单，那么较晚的订单将被告知商品告罄。

根据CAP理论，一个分布式系统无法同时满足一致性、可用性和分区容错性。因此，在设计分布式系统时，需要根据实际需求进行权衡。

如何避免CAP理论的问题：

尽量减少分区的影响：通过优化网络架构和通信协议，降低通信中断的可能性，从而减少分区容错性的需求。
选择合适的CAP组合：根据实际需求，选择合适的CAP组合。例如，在强一致性和可用性之间进行权衡，或者在分区容错性和一致性之间进行权衡。
使用分布式事务：通过分布式事务来保证数据的一致性和可靠性。分布式事务可以将多个节点的操作绑定在一起，从而保证操作的原子性和一致性。
设计冗余机制：通过数据复制、备份等方式来提高系统的可用性和可靠性。当某个节点出现故障时，可以通过其他节点的数据来恢复系统的正常运行。
使用消息队列：消息队列可以保证数据的有序传输和可靠性，同时可以减轻节点的负载。通过消息队列，可以将数据从生产者节点传输到消费者节点，从而避免直接通信和阻塞问题。
优化数据结构：通过优化数据结构来提高系统的性能和可靠性。例如，使用分布式哈希表来避免单点故障和性能瓶颈问题。
考虑使用云服务：云服务提供商可以提供高可用、高可扩展的分布式系统解决方案。通过使用云服务，可以降低运维成本和提高系统的可靠性。

总之，在设计和实现分布式系统时，需要根据实际需求进行权衡和选择合适的方案。同时，需要不断优化和改进系统的性能和可靠性，以满足日益增长的业务需求。


分布式系统的通信方式：
分布式通信是指在分布式系统中，不同节点之间进行消息传递和交互的方式。
以下是常见的分布式通信方式：

消息队列（Message Queue）
使用消息队列作为中间件，节点之间通过发送和接收消息来实现通信。消息队列提供了异步、解耦和可靠性的通信机制，常见的消息队列系统包括RabbitMQ、Apache Kafka和ActiveMQ等。

消息队列通信原理：
消息队列是用于应用程序之间进行通信的中间件，通过将消息在不同的应用程序之间进行传递来实现应用程序之间的通信。
消息队列的应用层协议连接互联网的方式如下：

应用程序通过消息队列的API连接到消息队列服务器，例如RabbitMQ、ActiveMQ等。
应用程序向消息队列发送消息，消息队列将消息存储在本地数据库或内存中。
目标应用程序从消息队列中接收消息，并进行相应的处理。
消息队列服务器将消息传递给目标应用程序的过程可以通过不同的协议实现，例如AMQP协议、MQTT协议等。

总之，消息队列的应用层协议连接互联网的方式是通过应用程序与消息队列服务器之间的API通信来实现的，
而具体的实现方式则取决于使用的协议和应用场景。


实现方式
消息队列底层的实现可以有多种方式，具体取决于所使用的消息队列系统。以下是一些常见的底层实现方式：

1.基于内存：某些消息队列系统使用内存作为底层实现，以实现高吞吐量和低延迟。消息在内存中进行存储和传递，因此速度非常快。
然而，这种实现方式通常会面临数据持久性和可靠性的挑战，因为内存是易失性存储。

2.基于文件系统：一些消息队列系统使用文件系统作为底层实现。消息被写入到文件中，并通过文件进行传递。
这种实现方式可以提供较好的数据持久性，因为文件可以在系统重启后仍然存在。
然而，相对于内存实现，文件系统实现的吞吐量和延迟可能较低。

3.基于数据库：部分消息队列系统使用数据库作为底层实现。消息被存储在数据库表中，并通过数据库进行传递。
这种实现方式可以提供较好的数据持久性和可靠性，因为数据库通常具有事务支持和持久化机制。
但是，数据库的读写开销可能较大，从而影响性能。

4.基于网络协议：一些消息队列系统使用网络协议作为底层实现，如TCP/IP协议栈。
消息通过网络进行传输，可以在不同的计算节点之间进行通信。这种实现方式提供了跨网络的分布式消息传递，但可能受限于网络延迟和可靠性。

需要注意的是，不同的消息队列系统可能使用不同的底层实现方式，并且可以结合多种技术来实现不同的特性和性能。
例如，一些消息队列系统可能会将内存和文件系统结合使用，以在内存中提供高性能的消息传递，并在需要持久性时将消息写入文件系统。
选择适当的底层实现方式取决于应用程序的需求，包括性能、可靠性和持久性等方面的考虑。

优缺点及适用场景
优点：异步通信、解耦性高、支持可靠性消息传递、支持消息持久化、可扩展性好。
缺点：引入中间件，增加了系统复杂性；消息顺序性可能受到影响；需要额外的管理和维护。
适用场景：分布式系统解耦、异步任务处理、实时数据流处理、事件驱动架构。


RocketMQ:
RocketMQ作为一款纯java、分布式、队列模型的开源消息中间件，支持事务消息、顺序消息、批量消息、定时消息、消息回溯等。

RocketMQ 特点：
>支持发布/订阅（Pub/Sub）和点对点（P2P）消息模型
>在一个队列中可靠的先进先出（FIFO）和严格的顺序传递 （RocketMQ可以保证严格的消息顺序，而ActiveMQ无法保证）
>支持拉（pull）和推（push）两种消息模式
pull其实就是消费者主动从MQ中去拉消息，而push则像rabbit MQ一样，是MQ给消费者推送消息。但是RocketMQ的push其实是基于pull来实现的。
它会先由一个业务代码从MQ中pull消息，然后再由业务代码push给特定的应用/消费者。其实底层就是一个pull模式
>单一队列百万消息的堆积能力 （RocketMQ提供亿级消息的堆积能力，这不是重点，重点是堆积了亿级的消息后，依然保持写入低延迟）
>支持多种消息协议，如 JMS、MQTT 等
>分布式高可用的部署架构,满足至少一次消息传递语义（RocketMQ原生就是支持分布式的，而ActiveMQ原生存在单点性）
>提供 docker 镜像用于隔离测试和云集群部署
>提供配置、指标和监控等功能丰富的 Dashboard

Java创建RocketMQ生产者:
package com.wn.producer;

import com.alibaba.rocketmq.client.exception.MQClientException;
import com.alibaba.rocketmq.client.producer.DefaultMQProducer;
import com.alibaba.rocketmq.client.producer.SendResult;
import com.alibaba.rocketmq.common.message.Message;
public class MQProducer {
public static void main(String[] args) throws MQClientException {
DefaultMQProducer producer=new DefaultMQProducer("rmq-group");
producer.setNamesrvAddr("192.168.138.187:9876;192.168.138.188:9876");
producer.setInstanceName("producer");
producer.start();
try {

for (int i=0;i<10;i++){
Thread.sleep(1000); //每秒发送一次
Message msg = new Message("itmayiedu-topic", // topic 主题名称
"TagA", // tag 临时值
("itmayiedu-"+i).getBytes()// body 内容
);
SendResult sendResult=producer.send(msg);
System.out.println(sendResult.toString());
}

} catch (Exception e) {
e.printStackTrace();
}
producer.shutdown();
}
}



Java创建RocketMQ消费者:

package com.wn.consumer;

import com.alibaba.rocketmq.client.consumer.DefaultMQPushConsumer;
import com.alibaba.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;
import com.alibaba.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;
import com.alibaba.rocketmq.client.consumer.listener.MessageListenerConcurrently;
import com.alibaba.rocketmq.client.exception.MQClientException;
import com.alibaba.rocketmq.common.message.MessageExt;
import java.util.List;

public class MQConsumer {
public static void main(String[] args) throws MQClientException {
DefaultMQPushConsumer consumer=new DefaultMQPushConsumer("rmq-group");
consumer.setNamesrvAddr("192.168.138.187:9876;192.168.138.188:9876");
consumer.setInstanceName("consumer");
consumer.subscribe("itmayiedu-topic","TagA");
consumer.registerMessageListener(new MessageListenerConcurrently() {
@Override
public ConsumeConcurrentlyStatus consumeMessage(List list, ConsumeConcurrentlyContext consumeConcurrentlyContext) {
for (MessageExt msg:list){
System.out.println(msg.getMsgId()+"---"+new String(msg.getBody()));
}
return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
}
});

consumer.start();
System.out.println("Consumer Started...");
}
}

RabbitMQ:
RabbitMQ是由erlang语言开发，基于AMQP（Advanced Message Queue 高级消息队列协议）协议实现的消息队列，
它是一种应用程序之间的通信方法，消息队列在分布式系统开发中应用非常广泛。

RabbitMQ特点：
>RabbitMQ是使用Erlang语言开发的开源消息队列系统，基于AMQP协议来实现。
>AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。
>AMQP协议更多用在企业系统内，对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量的要求还在其次。
>RabbitMQ的可靠性是非常好的，数据能够保证百分之百的不丢失。可以使用镜像队列，它的稳定性非常好。所以说在我们互联网的金融行业。对数据的稳定性和可靠性要求都非常高的情况下，我们都会选择RabbitMQ。当然没有kafka性能好，但是要比AvtiveMQ性能要好很多。也可以自己做一些性能的优化。
>RabbitMQ可以构建异地双活架构，包括每一个节点存储方式可以采用磁盘或者内存的方式。

RabbitMQ创建直连交换机：
import org.springframework.amqp.core.Binding;
import org.springframework.amqp.core.BindingBuilder;
import org.springframework.amqp.core.DirectExchange;
import org.springframework.amqp.core.Queue;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
 
@Configuration
public class DirectRabbitConfig {
 
    //队列 起名：TestDirectQueue
    @Bean
    public Queue TestDirectQueue() {
        // durable:是否持久化,默认是false,持久化队列：会被存储在磁盘上，当消息代理重启时仍然存在，暂存队列：当前连接有效
        // exclusive:默认也是false，只能被当前创建的连接使用，而且当连接关闭后队列即被删除。此参考优先级高于durable
        // autoDelete:是否自动删除，当没有生产者或者消费者使用此队列，该队列会自动删除。
        // return new Queue("TestDirectQueue",true,true,false);
 
        //一般设置一下队列的持久化就好,其余两个就是默认false
        return new Queue("TestDirectQueue",true);
    }
 
    //Direct交换机 起名：TestDirectExchange
    @Bean
    DirectExchange TestDirectExchange() {
      //  return new DirectExchange("TestDirectExchange",true,true);
        return new DirectExchange("TestDirectExchange",true,false);
    }
 
    //绑定  
    //将队列和交换机绑定, 并设置用于匹配键：TestDirectRouting
    @Bean
    Binding bindingDirect() {
        return BindingBuilder.bind(TestDirectQueue()).to(TestDirectExchange()).with("TestDirectRouting");
    }
     
    @Bean
    DirectExchange lonelyDirectExchange() {
        return new DirectExchange("lonelyDirectExchange");
    }
}

写个接口实现消息推送：
import org.springframework.amqp.rabbit.core.RabbitTemplate;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;
import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.util.HashMap;
import java.util.Map;
import java.util.UUID;

@RestController
public class SendMessageController {

    //使用RabbitTemplate,这提供了接收/发送等等方法
    @Autowired
    RabbitTemplate rabbitTemplate;  
 
    @GetMapping("/sendDirectMessage")
    public String sendDirectMessage() {
        String messageId = String.valueOf(UUID.randomUUID());
        String messageData = "test message, hello!";
        String createTime = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss"));
        Map<String,Object> map=new HashMap<>();
        map.put("messageId",messageId);
        map.put("messageData",messageData);
        map.put("createTime",createTime);
        //将消息携带绑定键值：TestDirectRouting 发送到交换机TestDirectExchange
        rabbitTemplate.convertAndSend("TestDirectExchange", "TestDirectRouting", map);
        return "ok";
    }
}


远程过程调用（Remote Procedure Call，RPC）
使用RPC技术进行分布式通信，允许节点之间像调用本地函数一样进行远程调用。RPC提供了一种透明的通信方式，
常见的RPC框架包括gRPC、Apache Thrift和Spring Cloud等。

优缺点及适用场景
优点：简化分布式通信过程；透明的远程调用；支持多种编程语言；高性能。
缺点：服务依赖性高；通信过程对网络要求较高；对系统的管理和维护较为复杂。
适用场景：微服务架构、跨语言通信、高性能计算、分布式计算。

RESTful API
使用基于HTTP协议的RESTful API进行通信，节点之间通过HTTP请求和响应进行数据交换。RESTful API提供了一种简单和标准化的通信方式，常用于构建分布式Web服务和微服务架构。

优缺点及适用场景
优点：简单易用、基于标准的HTTP协议、良好的可扩展性、松耦合。
缺点：同步通信方式、无状态性可能导致性能问题；数据传输较为冗余。
适用场景：Web服务、前后端分离架构、微服务架构。

分布式共享内存（Distributed Shared Memory，DSM）
通过共享内存的方式实现分布式通信，允许多个节点共享内存空间，从而实现数据共享和交互。DSM提供了高性能的通信方式，常见的DSM系统包括Apache Ignite和Hazelcast等。

优缺点及适用场景
优点：高性能的数据共享和交互；简化编程模型；可扩展性好。
缺点：一致性和同步性问题；需要复杂的内存管理和同步机制；依赖于底层网络。
适用场景：分布式缓存、分布式计算、分布式数据库。

网络套接字（Socket）
使用底层的网络套接字进行直接的节点间通信，可以基于TCP或UDP协议实现点对点的数据传输。网络套接字提供了最底层的通信方式，常用于构建自定义的分布式通信协议和框架。

优缺点及适用场景
优点：最底层的通信方式；灵活性高；适用于定制化通信需求。
缺点：需要自行处理通信协议和数据格式；可靠性和一致性问题需要自行解决。
适用场景：定制化分布式通信协议、低级别的网络通信、特定的性能优化需求。

总结
需要根据具体的系统要求、性能需求、可靠性需求、开发团队技术栈和经验等因素，综合考虑选择合适的分布式通信方式。
有时候，系统可能会结合多种方式来满足不同的需求，例如使用消息队列进行异步通信，结合RESTful API进行同步交互。


分布式中间件：
中间件技术是计算机系统中的一个软件层，位于客户端和服务端之间，负责处理两者之间的通信和数据交换。
它可以通过转换格式、路由消息、管理连接等方式支持多种应用场景，并具有提高系统可靠性、安全性、扩展性等优势。
常见的中间件技术包括消息队列、缓存、负载均衡、API网关、数据库代理和文件存储代理等。
它们各具特点，可以应用于分布式系统、微服务架构、大数据系统等不同场景。

中间件技术包括：
消息队列：如RabbitMQ、ActiveMQ、Kafka等。
缓存：如Redis、Memcached等。
负载均衡：如Nginx、HAProxy、F5等。
API网关：如Kong、Zuul、Tyk等。
数据库代理：如MySQL Proxy、PgBouncer等。
文件存储代理：如Ceph、GlusterFS等。



缓存中间件：Redis
Redis是一个使用C语言开发的数据库，与数据库不同，Redis的数据库存在内存中，它是内存数据库。正因为如此他的读写速度非常快，因此Redis作为nosql被广泛应用于缓存方向。
Redis除了做缓存之外，Redis也经常用来做分布式锁，甚至是消息队列。
Redis提供了多种数据类型来支持不同的业务场景。Redis还支持事务、持久化、Lua脚本、多种集群方案。

优点：
读写性能极高
支持数据持久化
支持事务
数据结构丰富
支持主从复制
丰富的特性

缺点：
数据库容量收到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。
主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。

redis可以在分布式系统中当缓存，也可以在分布式系统中用来做分布式锁。
redis用作分布式锁：为了解决分布式系统中的缓存击穿问题，需要分布式锁。
String uuid = UUID.randomUUID().toString();
lock = redisTemplate.opsForValue().setIfAbsent("lock","111"，300，TimeOut.SECONDS); //加锁并设置过期时间，保证了原子性
if(lock){
//加锁成功... 执行业务
Map<String，List<Catelog2Vo>> dataFromDb = getDataFromDb();
//删除锁脚本
String script = "if redis.ca11("get",KEYS[1]) == ARGV[1]then
return redis.ca11("de1",KEYS[1])else return 0 end";
//删除锁
Integer lock1 = redisTemplate.execute(new DefaultRedisScript<INTEGER>(script,Integer.class)
										,Array.asList("lock"),uuid);


return getDataFromDb();
}else {
//加锁失败...重试。
synchronized ()
return getCatalogJsonFromDbwithRedisLock();//自旋的方式
}

可以使用redisson完成分布式锁功能：

一、创建redisson工具类
@Bean(destroyMethod="shutdown")
public RedissonClient redisson() throws IOException {
//1、创建配置
//Redis url should start with redis:// or rediss://
Config config = new Config();
config.useSingleServer().setAddress("redis://192.168,5610:6379");
//2、根据Config创建出RedissonClient示例RedissonClient redissonClient = Redisson.create(config);
return redissonClient;
}

二、redisson创建分布式锁
@ResponseBody
@GetMapping("/he1lo")
public String hello(){

//1、获取一把锁，只要锁的名字一样，就是同一把锁
RLock lock = redisson .getLock( name: "my-lock");

//2、加锁
lock.lock(10,TimeUnit.SECONDS);//10秒自动解锁,自动解锁时间一定要大于业务的执行时间。
//Lock.Lock(10,TimeUnit.SECONDS); 在锁时间到了以后，不会自动续期。
//1、如果我们传递了锁的超时时间，就发送给redis执行脚本，进行占锁，默认超时就是我们指定的时间
//2、如果我们未指定锁的超时时间，就使用30 * 1000[LockWatchdogTimeout看门狗的默认时间];只要占锁成功，
就会启动一个定时任务[重新给锁设置过期时间，新的过期时间就是看门狗的默认时间],每隔10s都会自动续期
//internalLockLeaseTime[看门狗时间] / 3,10s
//1)、锁的自动续期，如果业务超长，运行期间自动给锁续上新的305。不用担心业务时间长，锁自动过期被删掉
//2)加锁的业务只要运行完成，就不会给当前锁续期，即使不手动解锁，锁默认在305以后自动删除。
try{
System.out.println("加锁成功，执行业务..."+Thread.currentThread().getId());
Thread.sleep( millis: 300e0);
}catch (Exception e){

}finally {

//3、解锁 将设解锁代码没有运行，redisson会不会出现死锁
System.out.println("释放锁..."+Thread.currentThread().getId());lock.unlock();
return "hello";
}

Spring缓存：SpringCache
Spring Cache利用了AOP，实现了基于注解的缓存功能，
并且进行了合理的抽象，业务代码不用关心底层是使用了什么缓存框架，只需要简单地加一个注解，就能实现缓存功能了。
@Cacheable({"category"})
public List<CategoryEntity> getLevel1Categorys() {
	......
}

SpringCache自定义缓存：
指定生成的缓存使用的key， key属性指定，接受一个SpEL
@Cacheable(value = {"category"},key = "#root.method.name")
public List<CategoryEntity> getLevel1Categorys() {
    return this.baseMapper.selectList(
            new QueryWrapper<CategoryEntity>().eq("parent_cid",0));
}

将数据保存为json格式，自定义RedisCacheConfiguration即可
@Configuration
@EnableCaching
public class MyCacheConfig {
    @Bean
    RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties){
        RedisCacheConfiguration config  = RedisCacheConfiguration.defaultCacheConfig();
        //修改key和value的序列化机制
        config = config .serializeKeysWith(
                RedisSerializationContext.SerializationPair.fromSerializer(
                        new StringRedisSerializer()));
        config = config.serializeValuesWith(
                RedisSerializationContext.SerializationPair.fromSerializer(
                        new GenericJackson2JsonRedisSerializer()));

        CacheProperties.Redis redisProperties = cacheProperties.getRedis();
        //将配置文件中的所有配置都生效
        if (redisProperties.getTimeToLive() != null) {
            config = config.entryTtl(redisProperties.getTimeToLive());
        }
        if (redisProperties.getKeyPrefix() != null) {
            config = config.prefixKeysWith(redisProperties.getKeyPrefix());
        }
        if (!redisProperties.isCacheNullValues()) {
            config = config.disableCachingNullValues();
        }
        if (!redisProperties.isUseKeyPrefix()) {
            config = config.disableKeyPrefix();
        }
        return config;
    }
}


数据库中间件Mycat：
从定义和分类来看，它是一个开源的分布式数据库系统，Mycat是一个实现了MySQL协议的服务器，
前端用户可以把它看作是一个数据库代理，用MySQL客户端工具和命令行访问，
而其后端可以用MySQL原生协议与多个MySQL服务器通信，也可以用JDBC协议与大多数主流数据库服务器通信，
其核心功能是分表分库，即将一个大表水平分割为N个小表，存储在后端MySQL服务器里或者其他数据库里。

为什么要使用Mycat?
Java与数据库的紧耦合
高访问量高并发对数据库的压力
读写请求数据不一致



分布式文件系统：
分布式文件系统（Distributed File System）是指文件系统管理的物理存储资源不一定直接连接在本地节点上，而是通过计算机网络与节点相连。
它允许程序像访问本地文件一样访问或存储独立的文件，允许程序员从任何网络或计算机访问文件。
通过DFS，可以以受控和授权的方式在网络上的用户之间轻松地共享信息和文件。
DFS的主要目的是允许物理分布式系统的用户通过使用公共文件系统（CFS）来共享他们的数据和资源。

以下是几个分布式文件系统的例子：

1.NFS 。网络文件系统是早期的分布式文件系统，主要解决如何在网络环境中共享和管理文件系统的问题。
2.AFS 。AFS 是卡内基梅隆大学开发的分布式文件系统，特点是在客户端上缓存了服务器的部分数据，从而提高了访问速度。
3.Coda 。Coda是一个可扩展的分布式文件系统，由卡内基梅隆大学开发，它通过分发和冗余技术来提高系统的可用性和健壮性。
4.InterPlanetary File System (IPFS)。 IPFS 是一个基于内容寻址的分布式文件系统，
它通过哈希函数将文件的元数据（如名称、内容等）编码成一个唯一的地址，从而可以在全球范围内进行文件的查找和访问。


分布式微服务框架：
Spring Cloud：
Spring Cloud是一个为构建分布式系统的微服务框架。
准确的说，它不是一个框架，而是一个大的容器，将各个微服务通过接口调用，从而简化了开发者的代码量。
Spring Cloud和普通RPC有很大区别，Spring Cloud使用的是http协议的RPC框架，传统RPC框架使用内部调用的方式。

Spring Cloud常用组件：
SpringCloud的五大核心组件为Eureka、Fegin、Ribbon、Hystrix、Zull

1.Eureka（注册中心）2024.1（Eureka已弃用）
SpringCloud提供了多种注册中心的支持，这其中就包括Eureka、ZooKeeper等，我们平时常用的也是这两种
Eureka主要就是用来注册服务的，其中包括两部分：Eureka Client、Eureka Server
Eureka Client：包含服务提供者、服务消费者，主要负责服务注册、心跳续约与健康状况查询
Eureka Server：提供注册服务，各个节点启动后，都会在Eureka Server中注册，可用的节点信息可以在Eureka Server中的服务注册表中找到（Eureka Server之间通过复制的方式来完成数据的同步）
应用启动后，Eureka Client会向Eureka Server发送心跳，一般默认周期为30秒，如果Eureka在多个心跳周期内（一般为90秒）没有接受到某个节点的心跳，Eureka就会进入自我保护机制


其他注册中心：

Alibaba Nacos (dynamic naming and configuration Service):
Alibaba Nacos是一个开源的分布式系统服务发现、配置和管理平台，它致力于帮助开发者更敏捷和容易地构建、交付和管理微服务平台。
Alibaba Nacos是一个功能强大且易于使用的分布式系统服务发现、配置和管理平台。它可以帮助开发者更快速地构建、交付和管理微服务平台，提高系统的可用性和稳定性，降低维护成本。

Nacos特点：
服务发现与注册
Nacos提供了强大的服务发现与注册功能。在微服务架构中，服务提供者可以将自己的服务注册到Nacos中，而服务消费者则可以通过Nacos发现并获取所需服务的地址信息。
这使得服务之间的调用变得更为灵活和便捷，同时也为服务的动态扩展和负载均衡提供了支持。

配置管理
Nacos还提供了动态配置管理功能。开发者可以将应用的配置信息存储在Nacos中，通过Nacos进行统一的配置管理和分发。
这使得配置信息的修改和发布变得更为方便，同时也支持实时生效，无需重启应用。此外，Nacos还支持配置信息的版本控制，方便开发者追踪和回滚配置变更。

健康检查
Nacos提供了对服务的实时健康检查功能。它可以监控服务的运行状态，及时发现并隔离故障节点，保证服务的稳定性和可用性。这对于构建高可用的微服务架构至关重要。

集群管理
Nacos还支持集群管理功能，可以管理多个应用节点，包括它们的服务注册和发现、配置管理等。这使得在分布式环境下管理和维护服务变得更为简单和高效。

可视化界面
Nacos提供了一个简洁易用的UI控制台，开发者可以通过这个界面方便地管理所有的服务和应用的配置。这使得操作更为直观和便捷，提高了开发效率。





2.Feign
Feign是一个HTTP请求的轻量级客户端框架。
通过 接口+注解 的方式发起HTTP请求的调用，而不是像Java中通过封装HTTP请求报文的方式直接调用。

Feign执行流程：
在主程序上添加@EnableFeignClients注解开启对已经加@FeignClient注解的接口进行扫描加载。
调用接口中的方法时，基于JDK动态代理的方式，通过InvokeHandler调用处理器分发远程调用，生成具体的RequestTemplate
RequestTemplate生成Request请求，结合Ribbon实现服务调用负载均衡策略
Feign最核心的就是动态代理，同时整合了Ribbon和Hystrix，具备负载均衡、隔离、熔断和降级功能

1.添加依赖
2.在主程序上添加注解@EnableFeignClients
@SpringBootApplication
@EnableFeignClients
public class Microservice {
    public static void main(String[] args) {
        SpringApplication.run(Microservice.class, args);
    }
}

3.在需要调用其他微服务的模块中，定义一个继承自FeignClient接口的自定义接口

//其中的@FeignClient注解指定了需要调用的远程服务名，@RequestMapping注解指定了远程服务的接口映射路径。
@FeignClient(name = "remote-service")
public interface RemoteServiceClient {

    @RequestMapping(value = "/api/remote-service/hello", method = RequestMethod.GET)
    public String hello();
}

4.注入并使用Feign接口
import org.springframework.beans.factory.annotation.Autowired;  
import org.springframework.stereotype.Service;  
  
@Service  
public class MyService {  
  
    private final RemoteServiceClient remoteServiceClient;  
  
    @Autowired  
    public MyService(RemoteServiceClient remoteServiceClient) {  
        this.remoteServiceClient = remoteServiceClient;  
    }  
  
    public void doSomething() {  
        String response = remoteServiceClient.hello();  
        // 处理响应...  
    }  
}

注意：
1.在默认情况下，OpenFeign的连接超时时间是10秒，而读取超时时间是60秒。这些超时时间的设置可以在源码feign.Request.Options#Options()方法中找到。
2.OpenFeign 的重试机制允许在发生网络故障或服务端错误时，自动重新发起请求。OpenFeign 的重试机制基于 Retryer 接口实现，该接口定义了重试的策略。默认情况下，OpenFeign 可能不会启用重试机制，需要开发者手动开启并配置。

2.1创建一个自定义的Retryer类
import feign.Retryer;  
import java.util.concurrent.atomic.AtomicInteger;  
  
public class CustomRetryer extends Retryer.Default {  
  
    private final int maxAttempts;  
    private final long period;  
    private final TimeUnit unit;  
  
    public CustomRetryer(int maxAttempts, long period, TimeUnit unit) {  
        super();  
        this.maxAttempts = maxAttempts;  
        this.period = period;  
        this.unit = unit;  
    }  
  
    @Override  
    public void continueOrPropagate(RetryableException e) {  
        AtomicInteger attempt = this.attempt.get();  
        if (attempt.get() < maxAttempts) {  
            try {  
                unit.sleep(period);  
                attempt.incrementAndGet();  
            } catch (InterruptedException ignored) {  
                Thread.currentThread().interrupt();  
                throw new RuntimeException(e);  
            }  
            continueWith(e);  
        } else {  
            throw e;  
        }  
    }  
}

2.2 配置 Feign 客户端使用自定义 Retryer
import feign.Retryer;  
import org.springframework.context.annotation.Bean;  
import org.springframework.context.annotation.Configuration;  
  
@Configuration  
public class FeignConfig {  
  
    @Bean  
    public Retryer feignRetryer() {  
        return new CustomRetryer(3, 1000, TimeUnit.MILLISECONDS); // 重试3次，每次间隔1秒  
    }  
  
    @Bean  
    public MyFeignClient myFeignClient(Decoder decoder, Encoder encoder, Client client, Retryer retryer) {  
        return Feign.builder()  
                .encoder(encoder)  
                .decoder(decoder)  
                .client(client)  
                .retryer(retryer) // 使用自定义的 Retryer  
                .target(MyFeignClient.class, "http://example.com");  
    }  
}



3.Ribbon（负载均衡）2024.1（Ribbon已弃用）
Ribbon是一个客户端的负载均衡器，他提供对大量的HTTP和TCP客户端的访问控制
Ribbon负载均衡策略：简单轮询、权重、随机、重试等多种策略

//编写Ribbon配置类
@Configuration
public class ApplicationContextConfig {
    @Bean
    @LoadBalanced//使用@LoadBalanced注解赋予RestTemplate负载均衡的能力
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}

//编写Ribbon自定义配置类，配置负载均衡策略
@Configuration
public class MySelfRule {
    @Bean //lRule：根据特定算法中从服务列表中选取一个要访问的服务
    public IRule myRule(){
        return new RandomRule();//随机访问
    }
}

其他负载均衡方案：
LoadBalancer：
Spring Cloud中的LoadBalancer是一个关键的组件，它负责在多个服务实例之间实现负载均衡，以确保系统的高可用性和可伸缩性。
这个负载均衡器是客户端的负载均衡，意味着每个发起服务调用的客户端都存有完整的目标服务地址列表，根据配置的负载均衡策略，由客户端自己决定向哪台服务器发起调用。
LoadBalancer的主要作用是根据负载规则从服务发现组件（如Nacos）获取的可用服务节点列表中选取服务调用目标的地址。
它提供了一种在多个服务的实例之间均衡负载的方式，使得系统可以更加高效、稳定地处理请求。
LoadBalancer支持多种负载均衡算法，包括随机算法、轮询算法、权重算法、最少请求算法等。这些算法可以根据不同的需求和场景进行选择，以实现最佳的负载均衡效果。
在Spring Cloud中，LoadBalancer的配置相对灵活，可以通过配置文件或编程方式进行定制。
此外，Spring Cloud LoadBalancer还提供了智能路由功能，可以根据服务的质量、性能等指标进行路由决策，进一步提高系统的性能和可用性。


创建一个LoadBalancer负载均衡，使用轮询算法：
1.配置Nacos服务注册中心的地址等信息。在application.yml或application.properties中添加如下配置：
spring:  
  cloud:  
    nacos:  
      discovery:  
        server-addr: 127.0.0.1:8848 # Nacos服务注册中心的地址

2.创建一个服务调用者（Client），该调用者会使用LoadBalancer和Nacos来选择合适的服务实例进行调用。

import org.springframework.beans.factory.annotation.Autowired;  
import org.springframework.cloud.client.ServiceInstance;  
import org.springframework.cloud.client.loadbalancer.LoadBalancerClient;  
import org.springframework.stereotype.Service;  
import org.springframework.web.client.RestTemplate;  
  
import java.util.List;  
  
@Service  
public class MyServiceClient {  
  
    @Autowired  
    private LoadBalancerClient loadBalancerClient;  
  
    @Autowired  
    private RestTemplate restTemplate;  
  
    public String callMyService() {  
        // 获取服务名，这通常是在配置文件中定义的，例如application.yml或application.properties  
        String serviceName = "my-service";  
  
        // 获取服务实例列表  
        List<ServiceInstance> serviceInstances = loadBalancerClient.getInstances(serviceName);  
  
        if (serviceInstances.isEmpty()) {  
            throw new RuntimeException("No instances available for service: " + serviceName);  
        }  
  
        // 使用轮询算法选择一个服务实例  
        ServiceInstance serviceInstance = serviceInstances.get(serviceInstances.indexOf(loadBalancerClient.choose(serviceName)));  
  
        // 构造请求的URL  
        String url = String.format("http://%s:%d/my-endpoint", serviceInstance.getHost(), serviceInstance.getPort());  
  
        // 发起调用  
        String response = restTemplate.getForObject(url, String.class);  
  
        // 返回调用结果  
        return response;  
    }  
}


负载均衡算法有哪些？
负载均衡算法有多种，它们各自具有不同的特点和适用场景。以下是一些常见的负载均衡算法：

轮询法（Round Robin）：将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。
加权轮询法（Weighted Round Robin）：与轮询法类似，但考虑了后端服务器的不同性能和负载情况，为每台服务器分配不同的权重，权重高的服务器将处理更多的请求。
随机法（Random）：通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。
加权随机法（Weighted Random）：类似于加权轮询法，但它是按照权重随机请求后端服务器，而非顺序。
最小连接数法（Least Connections）：这是一种动态调度算法，通过服务器中当前所活跃的连接数来估计服务器的负载情况，把新的连接请求分配到当前连接数最小的服务器。
加权最小连接数法（Weighted Least Connections）：此算法考虑服务器的处理性能和当前的连接数，将请求分配到具有较少活动连接且权值较高的服务器上。
源地址哈希法（Source Address Hashing）：根据获取客户端的IP地址，通过哈希函数计算得到一个数值，用这个数值对服务器列表的大小进行取模运算，得到的结果便是客户端要访问的服务器序号。

此外，还有一些其他的负载均衡算法，如最短响应时间法（Least Response Time），它根据服务器响应请求的时间长短来选择服务器，响应时间最短的服务器将被优先选中。


阐述一下客户端负载均衡和服务端负载均衡有什么区别：
客户端负载均衡和服务端负载均衡在多个方面存在显著的区别。

首先，从负载均衡的实现位置来看，客户端负载均衡是在客户端和服务器之间增加一个负载均衡设备，这个设备负责将客户端的请求分发到多个服务器上。
而服务端负载均衡则是通过部署在服务器端的负载均衡器来管理和分发请求。

其次，从负载均衡设备的选择和配置来看，客户端负载均衡设备可以是路由器、交换机、负载均衡器等，需要在客户端和服务器之间增加这些设备，并对其进行相应的配置和管理。
而服务端负载均衡则依赖于服务器端的负载均衡器，如Nginx、HAProxy等，这些负载均衡器能够集中管理负载均衡策略，实现各种负载均衡算法。

再次，从负载均衡的效果和优势来看，客户端负载均衡具有提高响应速度、提高带宽利用率和提高数据处理能力的优点。由于客户端负载均衡可以将请求直接分发到最快的服务器上，减少了网络拥塞，因此可以提高响应速度。
同时，通过将网络流量分担到多个服务器上，客户端负载均衡也可以提高带宽利用率和数据处理能力。然而，客户端负载均衡也存在一些缺点，如增加了网络延迟和复杂度，以及无法处理动态内容。

相比之下，服务端负载均衡具有统一管理和集中控制的优势。通过集中管理负载均衡器，可以方便地对服务实例进行监控和管理，并在负载均衡器上实现各种负载均衡算法。
然而，服务端负载均衡也存在一些潜在的问题，如单点故障和额外开销。如果负载均衡器本身发生故障，整个系统的可用性可能会受到影响。同时，需要额外的负载均衡器设备也会增加系统的复杂性和成本。

综上所述，客户端负载均衡和服务端负载均衡在实现位置、设备配置、效果优势等方面存在明显的区别。选择哪种负载均衡方式取决于具体的业务需求和网络环境。


4.Hystrix（服务熔断）2024.1（Hystrix已弃用）
Hystrix提供两个命令，分别是HystrixCommand、HystrixObservableCommand，通常是在Spring中通过注解和AOP来实现对象的构造
熔断：简单来说，就是我们生活中的“保险丝”。如果熔断器打开，就会执行短路，直接进行降级；如果熔断器关闭，就会进入隔离逻辑。
默认触发熔断器的条件为：最近一个时间窗口（默认为10秒），总请求次数大于等于circuitBreakerRequestVolume Threshold（默认为20次）
并且异常请求比例大于circuitBreakerError ThresholdPercentage（默认为50%），此时熔断器触发
隔离：一般分为两种：线程池隔离和信号量隔离。线程池隔离指的是每个服务对应一个线程池，线程池满了就会降级；
信号量隔离是基于tomcat线程池来控制的，当线程达到某个百分比，走降级流程
降级：作为Hystrix中兜底的策略，当出现业务异常、线程池已满、执行超时等情况，调用fallback方法返回一个错误提示

//在application.properties文件配置Hystrix
hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=5000
hystrix.command.default.execution.isolation.strategy=THREAD

//创建Hystrix服务
@Service
public class MyService {
    @Autowired
    private RestTemplate restTemplate;

    @HystrixCommand(fallbackMethod = "fallbackMethod")
    public String doSomething() {
        // 这里调用远程服务
        return restTemplate.getForObject("http://example.com/api/something", String.class);
    }

    public String fallbackMethod() {
        // 这里是熔断后的fallback方法，返回一个默认值或者处理异常的逻辑
        return "fallback";
    }
}

其他服务熔断：

Resilience4j：
Resilience4j是一个轻量级的容错库，专为Java 8和函数式编程而设计，旨在帮助开发人员构建弹性和可靠的Java应用程序。它提供了诸如断路器、限流、重试和超时等功能，以保护应用程序免受故障和异常的影响。
其核心概念是“函数式编程”，允许开发人员使用Java 8的函数式编程特性来定义和组合容错策略，这使得容错逻辑更加灵活、可读性更高，并且易于测试和维护。

Resilience4j的熔断降级：
当某个服务或组件出现故障或响应时间过长时，系统不再继续调用该服务或组件，而是快速失败，并执行一些降级逻辑，以确保系统的整体稳定性和可用性。这种机制可以避免由于某个服务或组件的故障导致的整个系统的崩溃。

实现步骤：
1.添加依赖：
首先，你需要在项目的pom.xml文件中添加Resilience4j的熔断器依赖。例如：
<dependency>  
    <groupId>org.springframework.cloud</groupId>  
    <artifactId>spring-cloud-starter-circuitbreaker-resilience4j</artifactId>  
</dependency>

2.修改接口代码，对外暴露接口还需要配置在OpenFeign上
然后，你需要在需要熔断降级的服务接口上使用@CircuitBreaker注解。这个注解会告诉Resilience4j在该接口调用失败率达到指定阈值时触发熔断机制。例如：

@Restcontroller
public class OrderCircuitcontroller{

    @Resource
    private PayFeignApi payFeignApi;

    @GetMapping(value=v"/feign/pay/circuit/{id}")
    @CircuitBreaker(name ="cloud-payment-service", fallbackMethod = "mycircuitFallback") //服务熔断的注解，name为注册的微服务，fallbackMethod为熔断的兜底处理方法
    public string mycircuitBreaker(@PathVariable("id")Integer id){
        return payFeignApi.myCircuit(id);
    }

    //myCircuitFallback就是服务降级后的兜底处理方法
    public string myCircuitFallback(Integer id,Throwable t){
        //这里是容错处理逻辑。返回各用结果
        return"mycircuitFal1back，系统繁忙，请稍后再试-----/(ToT)/~~"
    };

}


3. 配置熔断策略：
resilience4j:  
  circuitbreaker:  
    instances:  
      myService:  
        failureRateThreshold:50#设置50%的调用失败时打开断路器，超过失败请求百分比circuitBreaker 变为OPEN状态。
        slidingWindowType:COUNT BASED #滑动窗的类型
        slidingWindowsize:6 #滑动窗口的大小配置 COUNT_BASED表示6个请求，配置TIME_BASED表示6秒
        minimumNumberofcalls:6 #断路器计算失败率或慢调用率之前所需的最小调用数(每个滑动窗口周期)。最少调用几次，才能计算失败率。
        automaticTransitionFromopenToHalfopenEnabled:true # 是否启用自动从开启状态过波到半开状态，默认值为true。
        waitDurationInopenstate:5s#从OPEN到HALF OPEN状态需要等待的时间
        permittedNumberofcallsInHalfopenstate:2 #半开状态允许的最大请求数，默认值为10。在半开状态下,CircuitBreaker将允许最多permittedNumberOfCallsInHalfOpenstate个请求通过，如果有一个请求失败，CircuitBreaker将重新进入开启状态


Resilience4j的信号量舱壁熔断隔离：
信号量舱壁隔离是一种轻量级的隔离方法，它主要通过限制同时访问某一资源或服务的并发请求数来实现隔离。
这种方法不需要额外的线程或线程池，因此资源消耗相对较小。当请求到达最大并发限制时，新的请求会被快速拒绝，而不是排队等待，这有助于迅速释放系统资源。
这种隔离方式适用于那些不涉及远程调用或耗时操作的轻量级任务，以及对线程资源敏感的场景。

实现步骤：
1.添加依赖：
首先，你需要在项目的pom.xml文件中添加Resilience4j的舱壁隔离依赖。例如：
<dependency>  
    <groupId>io.github.resilience4j</groupId>  
    <artifactId>resilience4j-bulkhead</artifactId>  
</dependency>


2.修改接口代码，对外暴露接口还需要配置在OpenFeign上
然后，你需要在需要熔断降级的服务接口上使用@CircuitBreaker注解。这个注解会告诉Resilience4j在该接口调用失败率达到指定阈值时触发熔断机制。例如：

@Restcontroller
public class OrderCircuitcontroller{

@GetMapping(value ="/feign/pay/bulkhead/{id}")
@Bulkhead(name ="cloud-payment-service",fallbackMethod = "myBulkheadFallback",type = Bulkhead.Type.SEMAPHORE)  //SEMAPHORE信号量，THREADPOOL线程池
//信号量舱壁隔离更注重于共享资源的访问控制，而线程池隔离则通过为每个任务分配独立线程来实现任务之间的隔离

public string myBulkhead(@PathVariable("id")Integer id){
    return payFeignApi.myBulkhead(id);
}
public string myBulkheadFallback(Throwable t){
    return"myBulkheadFal1back，隔板超出最大数量限制，系统繁忙，请稍后再试-----/(ToT)/~~";
}

}

3.配置隔离策略
resilience4j:
    bulkhead:
        configs:
            default:
                maxConcurrentcalls:2 #隔离允许并发线程执行的最大数量
                maxwaitDuration:1s   #当达到并发调用数量时，新的线程的阻塞时间，我只愿意等待1秒，过时不候进舱壁兜底faLlback
        instances:
            cloud-payment-service:
                baseConfig:default
    timelimiter:
        configs:
            default:
                timeout-duration:20s


Resilience4j的限流器：
Resilience4j的限流器会设定一个固定时间段（如每秒、每分钟或每小时）内允许的最大请求数。当有请求到达时，限流器会检查当前时间段内已经处理的请求数，并与设定的最大请求数进行比较。
如果当前请求数尚未达到最大限制，限流器会允许请求继续处理；如果已经达到或超过最大限制，限流器则会根据配置的策略对请求进行处理，如拒绝请求、返回错误信息或将其放入队列等待处理。

实现步骤：
1.添加依赖（略）
2.修改接口代码，对外暴露接口还需要配置在OpenFeign上
@Restcontroller
public class OrderCircuitcontroller{

@GetMapping(value ="/feign/pay/retelimit/{id}")
@Bulkhead(name ="cloud-payment-service",fallbackMethod = "myRelateLimitFallBack")  
public string myBulkhead(@PathVariable("id")Integer id){
    return payFeignApi.myRelateLimit(id);
}

public string myRelateLimitFallBack(Throwable t){
    return"你被限流了，禁止访问-----/(ToT)/~~";
}

}

3.配置限流策略
resilience4j:
    bulkhead:
        configs:
            default:
                limitForPeriod:2#在次侧新周期内，允许执行的最人请求数
                timeout-duration:1#线程等待权跟的默认等待时间
                limitRefreshperiod:1s # 从流器每厢limitRefreshperiod则新一次，将允许处理的最大诗求数量质置为limitForperiod 
        instances:
            cloud-payment-service:
                baseConfig:default


5.MicroMeter（分布式链路追踪）
分布式链路追踪（Distributed System Tracing，简称DST）是一种用于追踪和分析分布式系统中请求调用链路的技术。
在分布式系统中，一个请求可能经过多个服务节点，涉及多个网络调用，因此追踪整个请求的处理过程对于排查问题、优化性能以及理解系统行为至关重要。

链路追踪原理：
>跟踪请求流转：当一个请求在分布式系统中被发起时，链路追踪系统会开始跟踪这个请求的流转路径。它会记录请求从起点开始，经过哪些服务节点，以及在这些节点上的处理情况。
>引入Span概念：为了表达请求在分布式系统中的父子关系，链路追踪系统引入了Span的概念。每个Span代表了一个操作或一段工作单元，比如一个远程过程调用或者一段本地代码的执行。
Span之间通过父子关系连接，形成了一个完整的调用链。
>收集与传输数据：在请求流转的过程中，链路追踪系统会收集每个Span的信息，包括起始时间、结束时间、服务节点信息、调用状态等。这些信息会被发送到后端的分析系统或存储系统中。
>数据分析与可视化：后端的分析系统会对收集到的Span数据进行处理和分析，生成调用链的拓扑图，展示各个服务节点的调用关系、耗时以及请求状态等。
同时，它还可以提供性能可视化的功能，让用户可以直观地看到系统的运行情况。
>故障定位与性能优化：通过链路追踪系统生成的调用链和性能数据，用户可以快速地定位到故障发生的节点，分析性能瓶颈，从而进行相应的优化。

MicroMeter监控链路实现步骤：
1.添加依赖（略）
2.修改接口代码，对外暴露接口还需要配置在OpenFeign上
@Restcontroller
public class OrderMicroMetercontroller{

    @Resource
    private PayFeignApi payFeignApi；

    @GetMapping(value ="/feign/microMeter/{id}")
    public string myMicroMeter(@PathVariable("id")Integer id){
        return payFeignApi.myMicroMeter(id);
    }

}

3.配置yaml
management:
    zipkin:
        tracing:
            endpoint:http://localhost:9411/api/v2/spans
    tracing:
        sampling:
            probability:1.0 #采样率默认为0.1(0.1就是10次只能有一次被记录下来)，值越大收集越及时。

6.GateWay（网关）
Spring Cloud Gateway是一个由WebFlux、Netty和Reactor实现的响应式API网关，旨在为微服务架构提供简单且有效的API路由管理方式。以下是Spring Cloud Gateway的三大核心概念：

路由：路由是Spring Cloud Gateway的基本构建组成，表示一个具体的路由信息载体。它负责将客户端的请求转发到正确的服务实例。
Spring Cloud Gateway支持动态路由和灵活的路由策略，使得路由的配置和管理变得非常便捷。

过滤器：过滤器是Spring Cloud Gateway中的另一个核心概念，它可以在请求和响应的处理过程中添加自定义的过滤逻辑。这些过滤逻辑可以包括身份验证、请求日志记录、限流、熔断等各种功能。
通过过滤器，我们可以对进入和离开网关的请求和响应进行精细化的控制和处理。

服务发现与集成：Spring Cloud Gateway能够与Spring Cloud的服务注册与发现组件进行集成，自动发现并路由到可用的服务实例。
这使得网关能够动态地感知后端服务的状态，并根据需要调整路由规则，从而保证了服务的高可用性和稳定性。



配置网关路由：
server:
    port: 9527

spring:
    application:
        name:cloud-gateway#以微股务注册进consul或nacos股务列表内
    cloud:
        consul:#配置consul地址
        host:localhost
        port:8500
        discovery:
            prefer-ip-address:true
            service-name:${spring.application.name)
        gateway:
            routes:
                -id:pay routh1 #pay routh1 #路由的ID(类似mysql主键ID)，没有固定规则但要求唯一，建议配合服务名#匹配后提供服务的路由地址
                uri:http://localhost:8001  
                predicates:
                    Path=/pay/gateway/get/** # 断言，路径相匹配的进行路由 

                -id: pay routh2 #pay routh2 # 路由的ID(类似mysql主键ID)，没有固定规则但要求唯一，建议配合服务名#匹配后提供服务的路由地址
                uri: http://localhost:8001
                predicates:
                    Path=/pay/gateway/info/** # 断言、路径相匹配的进行路由

GateWay主流用法：以服务名动态获取服务URI
修改配置 uri: lb://cloud-payment-service #微服务的名字


另一种分布式管理的工具：
Dubbo：
Dubbo是阿里巴巴公司开源的一个高性能优秀的服务框架，使得应用可通过高性能的RPC实现服务的输出和输入功能，可以和Spring框架无缝集成。
它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。

Dubbo架构：
Provider: 暴露服务的服务提供方。
Consumer: 调用远程服务的服务消费方。
Registry: 服务注册与发现的注册中心。
Monitor: 统计服务的调用次数和调用时间的监控中心。

调用流程
0.服务容器负责启动，加载，运行服务提供者。
1.服务提供者在启动时，向注册中心注册自己提供的服务。
2.服务消费者在启动时，向注册中心订阅自己所需的服务。
3.注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。
4.服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。
5.服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心

Dubbo注册中心
对于服务提供方，它需要发布服务，而且由于应用系统的复杂性，服务的数量、类型也不断膨胀；
对于服务消费方，它最关心如何获取到它所需要的服务，而面对复杂的应用系统，需要管理大量的服务调用。
而且，对于服务提供方和服务消费方来说，他们还有可能兼具这两种角色，即既需要提供服务，有需要消费服务。

通过将服务统一管理起来，可以有效地优化内部应用对服务发布/使用的流程和管理。服务注册中心可以通过特定协议来完成服务对外的统一。
Dubbo提供的注册中心有如下几种类型可供选择：
Multicast注册中心
Zookeeper注册中心
Redis注册中心
Simple注册中心

Dubbo优缺点
优点：
透明化的远程方法调用
- 像调用本地方法一样调用远程方法；只需简单配置，没有任何API侵入。
软负载均衡及容错机制
可在内网替代nginx lvs等硬件负载均衡器。
服务注册中心自动注册 & 配置管理
-不需要写死服务提供者地址，注册中心基于接口名自动查询提供者ip。
使用类似zookeeper等分布式协调服务作为服务注册中心，可以将绝大部分项目配置移入zookeeper集群。
服务接口监控与治理
-Dubbo-admin与Dubbo-monitor提供了完善的服务接口管理与监控功能，针对不同应用的不同接口，可以进行 多版本，多协议，多注册中心管理。

缺点：
只支持JAVA语言

分布式应用程序协调服务：
什么是注册中心？
注册中心是微服务架构中的纽带，类似于“通讯录”，它记录了服务和服务地址的映射关系。
在分布式架构中，服务会注册到这里，当服务需要调用其它服务时，就到这里找到服务的地址并进行调用。
注册中心本质上是为了解耦服务提供者和服务消费者。对于任何一个微服务，原则上都应存在或者支持多个提供者，这是由微服务的分布式属性决定的，
更进一步，为了支持弹性扩缩容特性，一个微服务的提供者的数量和分布往往是动态变化的，也是无法预先确定的。
因此，原本在单体应用阶段常用的静态LB机制就不再适用了，需要引入额外的组件来管理微服务提供者的注册与发现，而这个组件就是服务注册中心。

注册中心的核心功能：
服务注册：服务实例将自身服务信息注册到注册中心
服务发现：服务实例通过注册中心，获取到注册到其中的服务实例的信息，通过这些信息去请求它们提供的服务
服务剔除：服务注册中心将出问题的服务自动剔除到可用列表之外，使其不会被调用到


Zookeeper：注册中心
eureka：注册中心
nacos: 注册中心
Ribbon：负载均衡组件
Hystrix：断路器
Zuul：网关服务组件
SpringCloud Config：配置中心

zookeeper和eureka有什么区别？
1：zookeeper保证cp原则（一致性）而Eureka保证的是ap原则（可用性）
2：zookeeper在选举期间注册服务瘫痪不可用，而Eureka各个节点平等，只要一台就能保证服务可以，但查询到的数据不一定是最新的，可以很好的应对网络故障导致的部分节点失联
3：zookeeper有header和follower角色（当header挂掉，会从剩下的follower里面选举一个header），Eureka各个节点平等
4：zookeeper采用半数存活原则（避免脑裂），Eureka采用自我保护机制来解决分区问题
5：kafka就是使用的zookeeper作为注册中心，理论上Eureka更适合作为注册中心

分布式服务跟踪ELK：
ELK 是elastic公司提供的一套完整的日志收集、展示解决方案，是三个产品的首字母缩写，分别是ElasticSearch、Logstash 和 Kibana：

ElasticSearch简称ES，由Java 语言编写，它是一个建立在全文搜索引擎Apache Lucene基础上的、实时的、分布式的搜索和分析引擎，
它可以用于全文搜索，结构化搜索以及分析；
Logstash是一个具有实时传输能力的数据收集引擎，用来进行数据收集（如：读取文本文件）、解析，并将数据发送给ES；
Kibana为Elasticsearch提供了分析和可视化的Web平台。
它可以在Elasticsearch的索引中查找，交互数据，并生成各种维度表格、图形；
在ELK中beats是用于数据采集的工具，相较于logstash，beats是更轻量级的工具。Beats 平台集合了多种单一用途数据采集器，这些采集器安装后可用作轻量型代理，从成百上千或成千上万台机器向 Logstash 或 Elasticsearch 发送数据。

1、elasticSearch
是一个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。
2、logstash
主要是用来日志的搜集、分析、过滤日志的工具，支持大量的数据获取方式（支持以TCP/UDP/HTTP多种方式收集数据）。一般工作方式为c/s架构，client端安装在需要收集日志的主机上，server端负责将收到的各节点日志进行过滤、修改等操作，再一并发往elasticSearch上去。
3、kibana
是一个开源工具，kibana可以为logstash和elasticSearch提供的日志分析友好的web界面，可以帮助汇总、分析和搜索重要数据日志。
4、filebeat
filebeat隶属于beats。目前beats包含四种工具：
（1）packetbeat（搜索网络流量数据）
（2）topbeat（搜索系统、进程和文件系统级别的CPU和内存使用情况等数据）
（3）filebeat（搜集文件数据）
（4）winlogbeat（搜集windows事件日志数据）



安全：
登录-安全框架Spring security：
Spring Security是一个能够为基于Spring的企业应用系统提供声明式的安全访问控制解决方案的安全框架。
它提供了一组可以在Spring应用上下文中配置的Bean，充分利用了Spring IoC，
DI（控制反转Inversion of Control ,DI:Dependency Injection 依赖注入）
和AOP（面向切面编程）功能，为应用系统提供声明式的安全访问控制功能，减少了为企业系统安全控制编写大量重复代码的工作。

Spring Security一般流程为：

1.当用户登录时，前端将用户输入的用户名、密码信息传输到后台，后台用一个类对象将其封装起来，
通常使用的是UsernamePasswordAuthenticationToken这个类。
2.程序负责验证这个类对象。验证方法是调用Service根据username从数据库中取用户信息到实体类的实例中，
比较两者的密码，如果密码正确就成功登陆，同时把包含着用户的用户名、密码、所具有的权限等信息的类对象放到
SecurityContextHolder（安全上下文容器，类似Session）中去。
3.用户访问一个资源的时候，首先判断是否是受限资源。如果是的话还要判断当前是否未登录，没有的话就跳到登录页面。
如果用户已经登录，访问一个受限资源的时候，程序要根据url去数据库中取出该资源所对应的所有可以访问的角色，
然后拿着当前用户的所有角色一一对比，判断用户是否可以访问（这里就是和权限相关）。

创建一个配置类，配置Spring Security以启用JWT认证。您需要配置JWT的过滤器以验证和解析令牌。以下是一个示例配置：
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.security.config.annotation.web.builders.HttpSecurity;
import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;
import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;
import org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter;

@Configuration
@EnableWebSecurity
public class SecurityConfig extends WebSecurityConfigurerAdapter {
    
    @Override
    protected void configure(HttpSecurity http) throws Exception {
        http.csrf().disable()
            .authorizeRequests()
            .antMatchers("/api/login").permitAll() // 允许登录端点
            .anyRequest().authenticated();
        http.addFilterBefore(jwtAuthenticationFilter(), UsernamePasswordAuthenticationFilter.class);
    }
    
    @Bean
    public JwtAuthenticationFilter jwtAuthenticationFilter() {
        return new JwtAuthenticationFilter();
    }
}

创建登录端点：
创建一个登录端点，用户可以通过该端点进行身份验证，并生成JWT令牌。
@RestController
@RequestMapping("/api")
public class AuthenticationController {
    @Autowired
    private AuthenticationManager authenticationManager;

    @Autowired
    private JwtTokenUtil jwtTokenUtil;

    @PostMapping("/login")
    public ResponseEntity<?> createAuthenticationToken(@RequestBody AuthenticationRequest request) {
        // 在这里验证用户身份，并生成JWT令牌
    }
}
这些步骤只是整合Spring Security和JWT的基本步骤。您还需要根据您的项目需求进一步定制和实现这些部分。
确保配置Spring Security和JWT的过滤器以进行身份验证，生成和验证JWT令牌，并提供登录端点用于用户登录。


Shiro：
Shiro是一个Java安全框架，它提供了身份验证、授权、密码和会话管理等安全特性。Shiro可以帮助开发者快速构建安全的应用程序，包括Web应用、移动应用和企业级应用。

使用Shiro进行登录身份验证：

1.创建Shiro的认证类
package com.yourcompany.yourapp.yourpackage;  
  
import org.apache.shiro.authc.*;  
import org.apache.shiro.realm.AuthenticatingRealm;  
import org.apache.shiro.subject.PrincipalCollection;  
import java.util.*;  
  
public class CustomAuthenticationRealm extends AuthenticatingRealm {  
    @Override  
    protected AuthenticationInfo doGetAuthenticationInfo(PrincipalCollection pc) throws AuthenticationException {  
        String username = pc.getPrimaryPrincipal().toString();   
        User user = new User(username, "password"); // 创建用户对象，这里只是简单示例，实际中应该从数据库或其他地方获取用户信息。  
        if (user.authenticate(username, "password")) {   
            return new SimpleAuthenticationInfo(user, user.getPassword(), getName());   
        } else {   
            throw new UsernameNotFoundException("User not found");   
        }   
    }   
}

2.使用Shiro进行安全验证
@RestController  
public class MyController {  
    @RequestMapping("/secure")  
    public String secure() {  
        Subject currentUser = SecurityUtils.getSubject();   
        currentUser.checkPermission("secure:view"); // 检查用户是否有查看这个页面的权限。如果没有，会抛出AuthorizationDeniedException异常。  
        return "This is a secure page.";  
    }  
}

使用Shiro进行密码管理：



1. 配置Shiro Realm：
创建一个自定义的Shiro Realm，这个Realm负责处理认证和授权的逻辑，包括密码的验证和存储。
扩展 AuthorizingRealm 类，并实现 doGetAuthenticationInfo 方法来处理密码验证。

   public class CustomRealm extends AuthorizingRealm {
       // 实现认证逻辑
       @Override
       protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException {
           UsernamePasswordToken upToken = (UsernamePasswordToken) token;
           String username = upToken.getUsername();
           // 获取用户的密码（通常从数据库中查询）
           String storedPassword = getPasswordFromDatabase(username);

           if (storedPassword == null) {
               throw new UnknownAccountException("User not found.");
           }

           return new SimpleAuthenticationInfo(username, storedPassword, getName());
       }

       // 从数据库获取用户的密码（模拟）
       private String getPasswordFromDatabase(String username) {
           // 这里可以连接数据库查询用户密码
           // 通常需要使用加密的密码存储方式，例如BCrypt
           return "hashed_password"; // 替换为实际的密码
       }
   }

2. 存储密码安全：
在实际应用中，开发者应该存储用户密码的哈希值而不是明文密码。
Shiro本身不提供密码哈希功能，所以你可以使用其他库如BCrypt或PBKDF2来安全地存储密码。以下是一个示例使用BCrypt的方法：

import org.mindrot.jbcrypt.BCrypt;

// 生成并存储BCrypt哈希密码
String plainPassword = "password";
String hashedPassword = BCrypt.hashpw(plainPassword, BCrypt.gensalt());
// 存储hashedPassword到数据库


3. 配置Shiro SecurityManager：
   在Shiro配置中，创建 SecurityManager 并将自定义的Realm添加到 SecurityManager 中。

DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager();
securityManager.setRealm(yourCustomRealm);
SecurityUtils.setSecurityManager(securityManager);
   
   
4. 使用Shiro验证密码：
   在用户登录时，使用Shiro来验证用户提供的密码。Shiro会自动从Realm中获取用户的密码进行验证。

UsernamePasswordToken token = new UsernamePasswordToken(username, password);
try {
    SecurityUtils.getSubject().login(token);
    // 登录成功
} catch (AuthenticationException e) {
    // 登录失败
}
   

这是一个基本的使用Shiro进行密码管理的示例。在实际应用中，开发者需要根据具体需求来配置Shiro的Realm、密码哈希算法、密码策略等。
确保密码存储和验证的安全性，以保护用户的凭据。

Java在处理敏感数据的时候如何实现数据的安全性？

使用加密算法：Java提供了多种加密算法，如AES、DES、RSA等，可以对敏感数据进行加密，保护数据不被非法获取。
使用安全协议：Java提供了SSL/TLS协议，可以用于实现加密通信，保证数据在传输过程中的安全性。
使用安全容器：Java提供了安全容器，如Java KeyStore、Java CredentialStore等，可以用于存储密钥和凭据，保护敏感数据不被非法访问。
权限控制：Java可以通过权限控制机制，如Java安全管理器（Security Manager），对敏感数据进行访问控制，防止非法访问和操作。
数据备份：对于重要的敏感数据，应该定期备份，并存储到安全的地方，以防止数据丢失或损坏。

Java安全编码指南：
安全编码指南
安全编码指南为开发人员提供了一组在编写代码时应遵循的建议,以最大程度地减少安全漏洞并减轻常见威胁。

1、输入验证和输出编码
>验证和清理所有用户输入,以防止SQL注入和跨站,点脚本(XSS)等攻击。
>使用参数化查询或预准备语句来防止SQL注入。
>显示用户生成的内容时应用适当的输出编码或转义技术以防止XSS攻击。
>使用强大的数据类型和长度验证来确保输入数据符合预期的格式。

2、认证与授权
>实施强大且安全的身份验证机制,例如多重身份验证(MFA)或强密码策略。
>使用安全密码存储技术(例如盐散列)来保护用户凭据。
>实施适当的授权检查,确保只有授权用户才能访问敏感资源原或执行特权操作。
>实施最小权限原则,仅向每个用户或角色授予必要的权限。

3、安全会话管理
>生成强大的随机会话标识符并安全地处理它们,例如使用仅HTTP和安全cookie。
>实施会话超时和适当的会话终止机制。
>通过在身份验证时生成新的会话标识符来避免会话固定漏洞。
>通过加密或使用服务器端而不是客户端存储来保护敏感会话数据。

4、安全的错误处理和日志记录
>避免在错误消息中暴露可能为攻击者提供帮助的敏感信息。
>实施适当的错误处理机制以防止信息泄露。
>安全地记录与安全相关的事件和异常,避免日志中敏感数据的暴露。
>定期检查和监控应用程序日志是否存在安全事件或异常活动。

5、安全通讯
>使用安全通信协议(例如HTTPS)来保护传输中的数据。
>实施适当的证书验证并避免使用自签名或过期的证书。
>在传输和存储过程中对密码或个人信息等敏感数据进行加密。
>避免通过不安全的渠道(例如电子邮件或未加密的HTTP)传输敏感数据。

6、安全文件和资源处理
>验证和清理文件上传,以防止任意文件执行或目录遍历攻击。
>避免将敏感信息存储在明文或不安全的存储位置。
>设置适当的文件和目录权限以限制仅授权用户的访问。
>谨防不安全的文件操作,例如文件删除或重命名,这可能会导致安全漏洞。


常用的密码加密方式：
哈希算法加密：
哈希算法是一种常用于加密和数据完整性验证的技术。它将任意长度的输入数据映射为固定长度的输出，通常是一个固定长度的哈希值。这个过程是单向的，即从哈希值无法还原出原始数据。因此，哈希算法通常用于存储密码、验证数据完整性等场景。

以下是一些哈希算法加密的关键特性和应用：

1. 单向性（One-way）：哈希函数是单向的，无法通过哈希值还原出原始数据。这使得哈希算法特别适用于密码存储，因为即使哈希值被盗，攻击者也很难还原出原始密码。
2. 固定长度输出：不论输入数据的长度如何，哈希算法的输出长度是固定的。这使得哈希值在存储和比较时更加方便。
3. 唯一性：不同的输入数据应产生唯一的哈希值，即不同的输入不能得到相同的输出。这有助于确保数据的唯一性和完整性。
4. 快速计算：哈希算法需要在合理的时间内计算出哈希值，以便在实际应用中能够高效地使用。
5. 碰撞概率低：碰撞是指两个不同的输入产生相同的哈希值。好的哈希算法应该具有极低的碰撞概率，这有助于保证数据的完整性。
6. 不可逆性：由于哈希是单向的，理论上不应该存在能够逆向计算原始数据的方法。然而，由于哈希函数输出的是固定长度的值，存在哈希碰撞的概率，即不同的输入可能得到相同的哈希值，因此一定程度上是可逆的。

常见的哈希算法包括MD5、SHA-1、SHA-256等。然而，由于计算能力的提升和一些算法漏洞的发现，一些哈希算法已经被认为不再安全，推荐使用更安全的算法，如SHA-256。
在密码存储方面，推荐使用带有盐（salt）的哈希算法，以提高安全性。盐是一个随机值，与密码结合使用，使得相同的密码在不同用户之间产生不同的哈希值。


对称加密：
对称加密是一种加密方法，它使用相同的密钥（称为密钥）来进行加密和解密数据。在对称加密中，发送方和接收方必须共享相同的密钥，这样他们就能够互相加密和解密彼此传递的信息。
对称加密的速度通常很快，因为它只涉及一个密钥，但它也面临一些安全性方面的挑战。

以下是对称加密的一些关键特点和用途：

1. 相同的密钥用于加密和解密：对称加密使用相同的密钥来加密和解密数据。这就要求在通信双方之间安全地交换和保存密钥，以确保没有未授权的第三方能够访问它。
2. 速度快：由于只涉及一个密钥，对称加密通常比非对称加密（如公钥加密）更快。这使得它适用于大量数据的加密和解密操作。
3. 适用于加密通信：对称加密常用于保护网络通信，如TLS/SSL协议中使用的对称加密算法。它也可以用于加密存储在计算机或服务器上的数据。
4. 密钥管理挑战：共享密钥的安全性对对称加密至关重要。在实践中，确保密钥在通信双方之间的安全交换和存储是一个挑战。如果密钥泄漏，可能导致数据的不安全性。
5. 不提供身份验证：对称加密本身不提供身份验证机制。这意味着如果有人截获了密钥并冒充通信的一方，他们可以轻松地解密和访问通信内容。

常见的对称加密算法包括DES（Data Encryption Standard）、3DES、AES（Advanced Encryption Standard）等。AES目前是最常用的对称加密算法之一，由于其高度的安全性和性能表现，广泛应用于安全通信和数据加密领域。


非对称加密：
非对称加密，也称为公钥加密，是一种使用一对密钥来进行加密和解密的加密技术。这一对密钥包括公钥和私钥，它们是数学相关的，但在使用上有着不同的功能。公钥可以公开分享，而私钥必须保持机密。

以下是非对称加密的一些关键特点和用途：

1. 一对密钥： 非对称加密使用一对密钥，分别是公钥和私钥。公钥用于加密数据，而私钥用于解密数据。由于这两个密钥是数学上相关的，通过公钥加密的数据只能通过私钥解密，反之亦然。
2. 加密和数字签名：公钥用于加密敏感信息，私钥用于解密。这使得非对称加密适用于安全地传递密钥或加密小块数据。此外，私钥还可以用于数字签名，以验证数据的来源和完整性。
3. 身份验证：公钥可以用于验证消息的来源。如果消息能够成功解密，说明它是由持有相应私钥的合法用户发送的。这提供了一种身份验证机制。
4. 密钥交换：非对称加密常用于安全地交换对称密钥。两方可以使用对方的公钥来加密一个对称密钥，然后将其传输给对方，对方再使用私钥解密得到对称密钥。接下来的通信可以使用对称密钥进行加密，提高了效率。
5. 安全性高：非对称加密提供了更高的安全性，因为即使攻击者获得了公钥，也无法通过公钥反向计算出私钥。这与对称加密不同，对称加密中同一密钥用于加密和解密，因此一旦密钥泄漏，整个系统的安全性就会受到威胁。

常见的非对称加密算法包括RSA（Rivest–Shamir–Adleman）、DSA（Digital Signature Algorithm）、ECC（Elliptic Curve Cryptography）等。RSA是其中最为广泛应用的非对称加密算法之一。


基于证书的加密：
基于证书的加密是一种使用数字证书来实现身份验证和数据加密的加密方法。数字证书是一种由可信的第三方机构颁发的电子文档，用于确认公钥的拥有者身份。基于证书的加密通常与非对称加密技术相结合，以确保通信的安全性和可信度。

以下是基于证书的加密的关键特点和过程：

1. 数字证书：数字证书是包含公钥及其拥有者身份信息的电子文档。证书由证书颁发机构（CA）签名，CA是一个受信任的第三方机构。数字证书通常包含以下信息：
   - 公钥
   - 拥有者的身份信息，如名称、电子邮件等
   - 证书颁发者的数字签名
   - 证书的有效期限

2. 证书颁发机构（CA）：CA是负责验证申请者身份并签署数字证书的机构。CA的数字签名用于验证证书的真实性。常见的CA包括Verisign、Let's Encrypt等。
3. 身份验证：当通信的一方希望与另一方进行安全通信时，它们可以交换数字证书。通过验证证书的签名和有效期，通信双方可以确保对方的身份是合法的。
4. 密钥交换：一旦身份得到验证，通信的双方可以使用证书中包含的公钥来进行密钥交换。通常，此阶段可以使用非对称加密技术，例如RSA。
5. 对称加密：一旦密钥交换完成，通信的双方可以使用共享的对称密钥来进行数据加密和解密。对称加密相对较快，因此在保护大量数据的传输中，对称密钥通常用于实际的数据加密。
6. 加密通信：现在，通信双方可以使用共享的对称密钥加密和解密其通信内容，确保数据的机密性和完整性。

基于证书的加密提供了一种安全且可信的通信方式，因为它结合了数字证书的身份验证和非对称加密的安全性。这种方法常用于安全套接字层（SSL）和传输层安全性（TLS）协议中，以保护网站和网络通信。

搜索引擎：
搜索引擎的原理：

抓取页面：每个独立的搜索引擎都有自己的网页抓取程序（蜘蛛）。爬虫Spider顺着网页中的链接，从一个链接到另一个链接，从一个网站到另一个网站。通过链接连续访问更多的页面，被抓取的页面称之为网页快照。
由于互联网中的链接应用很普遍，理论上讲，从一定的网页出发就能搜索绝大多数的网页。

处理页面：搜索引擎抓取页面后，还要做大量的预处理工作才能提供检索服务。其中最重要的就是提取关键词，建立索引库和索引，其他还包括去除重复的页面和蜘蛛认为没有意义的页面。然后判断网页类型和分析链接，计算网页的重要度、丰富度等。

提供检索服务：用户利用搜索引擎的搜索框输入想要查询的关键词，搜索引擎在自己的索引库中找到匹配关键词的所有页面。为了便于用户的判断，除了网页标题和URL之外，还会提供一段来自网页的摘要以及其他信息。

分布式搜索引擎Elasticsearch：
Elasticsearch 是一个分布式、高扩展、高实时的搜索与数据分析引擎。它能很方便的使大量数据具有搜索、分析和探索的能力。
Elasticsearch 的实现原理主要分为以下几个步骤，首先用户将数据提交到Elasticsearch 数据库中，再通过分词控制器去将对应的语句分词，将其权重和分词结果一并存入数据，当用户搜索数据时候，再根据权重将结果排名，打分，再将返回结果呈现给用户。

1.首先要存储数据，必须要建立索引。在es中索引实际仅仅是一个逻辑上的命名空间，这个命名空间指向的是一个或多个的分片shard，其中分片的出先可以实现水平扩容，副本分片的出现作用于高可用。
2.一个分片是一个仅仅保存了索引中所有数据中一部分分片数据的低级别的工作单元
3.一个分片就是一个Lucene实例，对于他本身而言就是一个完整的查询搜索引擎。
4.我们的文档是被存储索引在分片中的，但是客户端并不直接和分片交互，而是和index索引进行交互
5.众多分片是ES集群分布式存储数据的方式，可以简单把分片当作存储数据的容器。文档存储在分片中，分片被分配到集群中的节点Node中。
6.当集群扩容、缩容时，es能够自动的对集群节点中分片上的数据进行迁移，最终仍能保证数据均衡分布
7.分片分为主分片和副本分片
8.每个分片从技术实现上来讲，最大可以索引Integer.MAX_VALUE-128个文档；实际上存储的上限取决于你的硬件资源、文档结构的复杂度等

primary shard 主分片
每个文档都只会存储在一个主分片中，不会分散存储在多个主分片中，并且每个分片所存储的容量是有上限的，因此我们配置的每个索引的主分片数量，就决定了该索引最大的容量。主分片的数量是在创建索引时就确定的，不能再修改

replica shard 副本分片
副本分片是主分片的一个copy，有两个目的一是：解决单点问题，用于冗余数据，应对硬件故障，实现高可用；
二是：大流量支撑，每个副本都可以提供查询、检索请求。副本数量在任何时刻都可以变更。
每个主分片的副本分片，不会被和他的主分片分配在同一个Node节点上，因为在同一个节点上的主、副本分配上没有任何意义的，一旦该Node挂掉，这个Node节点上的主、副本副片都会丢失。

在Elasticsearch中，建立索引的过程是通过定义一个映射（mapping）来完成的。映射定义了索引的结构，包括字段的类型、分析器、索引选项等。


Elasticsearch中的索引有什么特点？
在Elasticsearch中，索引具有以下特点：

数据组织：索引是相关文档的集合，每个文档都有自己的特定结构和字段。索引可以根据不同的需求和使用场景进行创建和设计，以便更好地组织和检索数据。
分片和复制：索引中的数据在物理上被分为多个分片，每个分片可以在不同的节点上存储和处理。这种分片使得索引数据可以在集群中分布式存储和查询。复制机制则确保了数据的冗余备份，提高了系统的可靠性和容错性。
多种索引类型：Elasticsearch支持多种索引类型，包括文本索引、数值索引和时间索引等。这些索引类型适用于不同类型的数据和查询需求，可以根据实际情况进行选择和设置。
动态映射：Elasticsearch中的索引可以动态地映射文档类型和字段，根据需要自动确定字段的类型和属性。这使得索引的创建和使用更加灵活和方便。
近实时搜索：Elasticsearch的搜索功能是近实时的，意味着在索引中添加或更新文档后，几乎可以立即进行搜索和查询。这为实时分析和响应提供了便利。
查询功能强大：Elasticsearch提供了强大的查询功能，包括布尔查询、范围查询、匹配查询等。用户可以通过简单的查询语句或复杂的查询语法来搜索和过滤数据。
可扩展性：Elasticsearch是一个分布式搜索引擎，可以轻松地扩展到多个节点和服务器上。这使得它能够处理大规模的数据集和高并发请求。
灵活的配置选项：Elasticsearch提供了许多配置选项，可以根据需求进行灵活的配置和调整，以满足不同的使用场景和性能要求。

总之，Elasticsearch中的索引具有数据组织、分片和复制、多种索引类型、动态映射、近实时搜索、查询功能强大、可扩展性和灵活的配置选项等特点，这些特点使得Elasticsearch成为一个强大、灵活和可靠的搜索引擎。


Elasticsearch中如何建立索引？
创建一个索引：使用PUT请求和index端点来创建一个新的索引。例如，要创建一个名为my_index的索引，可以使用以下命令：
PUT /my_index

定义映射：在创建索引时，需要定义一个映射来指定索引的结构。映射定义了每个字段的类型、分析器和其他索引选项。可以使用PUT请求和mapping端点来定义映射。例如，以下命令定义了一个名为my_index的索引的映射：
PUT /my_index/_mapping  
{  
  "properties": {  
    "title": {  
      "type": "text"  
    },  
    "content": {  
      "type": "text",  
      "analyzer": "standard"  
    }  
  }  
}
在上面的示例中，我们定义了两个字段：title和content。title字段的类型为text，而content字段的类型也为text，并指定了分析器为standard。

添加文档：一旦建立了索引和映射，就可以向索引中添加文档了。文档是包含要索引的数据的JSON对象。可以使用POST请求和_doc端点来添加文档。例如，以下命令将一个文档添加到名为my_index的索引中：
POST /my_index/_doc/1  
{  
  "title": "Elasticsearch",  
  "content": "Elasticsearch is a distributed search and analytics engine."  
}
在上面的示例中，我们添加了一个包含title和content字段的文档，并指定了文档的ID为1。

搜索文档：一旦文档被添加到索引中，就可以使用Elasticsearch的查询API来搜索文档了。可以使用各种查询类型和查询语句来搜索文档，例如布尔查询、范围查询、匹配查询等。
可以使用GET请求和_search端点来执行搜索操作。例如，以下命令搜索名为my_index的索引中的所有文档：
GET /my_index/_search  
{  
  "query": {  
    "match_all": {}  
  }  
}  
在上面的示例中，我们执行了一个匹配所有文档的查询。查询结果将返回匹配的所有文档。



分布式实时数据分析Clickhouse：
ClickHouse 是 Yandex（俄罗斯最大的搜索引擎）开源的一个用于实时数据分析的基于列存储的数据库，其处理数据的速度比传统方法快 100-1000 倍。
ClickHouse 的性能超过了目前市场上可比的面向列的 DBMS，每秒钟每台服务器每秒处理数亿至十亿多行和数十千兆字节的数据。

分布式版本控制系统Git：
Git是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。

从一般开发者的角度来看，git有以下功能：
1、从服务器上克隆完整的Git仓库（包括代码和版本信息）到单机上。(指令 git clone)
2、在自己的机器上根据不同的开发目的，创建分支，修改代码。	(指令 git branch xxx )
3、在单机上自己创建的分支上提交代码。	(指令 git add .)
4、在单机上合并分支。 (指令 git merge xxx(分支名字))
5、把服务器上最新版的代码fetch下来，然后跟自己的主分支合并。
6、生成补丁（patch），把补丁发送给主开发者。
7、看主开发者的反馈，如果主开发者发现两个一般开发者之间有冲突（他们之间可以合作解决的冲突），就会要求他们先解决冲突，然后再由其中一个人提交。如果主开发者可以自己解决，或者没有冲突，就通过。
8、一般开发者之间解决冲突的方法，开发者之间可以使用pull 命令解决冲突，解决完冲突之后再向主开发者提交补丁。

从主开发者的角度（假设主开发者不用开发代码）看，git有以下功能：
1、查看邮件或者通过其它方式查看一般开发者的提交状态。
2、打上补丁，解决冲突（可以自己解决，也可以要求开发者之间解决以后再重新提交，如果是开源项目，还要决定哪些补丁有用，哪些不用）。
3、向公共服务器提交结果，然后通知所有开发人员。

.git文件包含哪些信息？
1.  branches ：这个目录包含分支的相关信息。
2.  hooks ：在此目录中，您可以定义Git挂钩脚本，这些脚本可以在特定的Git操作（如提交或合并）发生时触发。
3.  info ：这个目录包含一些全局信息，如排除文件的规则。
4.  objects ：Git存储数据的核心目录，包括所有提交、树和文件对象。
它有三个子目录： objects/commit 、 objects/tree  和  objects/blob ，分别用于存储提交、树和文件对象。
5.  refs ：此目录包含指向各种Git引用（如分支和标签）的文件，这些引用用于跟踪不同提交。
6.  logs ：包含引用日志，用于跟踪引用的历史变化。
7.  config ：存储仓库特定的配置信息。
8.  description ：一个可读的仓库描述文件。
9.  HEAD ：指向当前分支的符号链接。
10.  index ：Git的暂存区文件，用于跟踪已修改但尚未提交的更改。
11.  packed-refs ：包含指向引用的压缩文件，通常在引用较多时使用。
12.  info/exclude ：包含Git忽略规则的文件，类似于项目根目录中的 .gitignore  文件。

这些文件和目录包含了Git仓库的核心信息，允许Git跟踪历史、分支、标签、配置和文件更改等信息。
请注意， .git  文件夹通常是隐藏的，因此在文件浏览器中不容易看到，但它是Git版本控制系统的核心。
不要删除或修改 .git  文件夹中的文件，以免破坏Git仓库的完整性。

GitHub的一些功能：
watch：观察项目，如果watch了某个项目，表示你以后会关注这个项目的所有动态，以后只要这个项目发生变动，
如别人提交了pull request、被别人发起了issue等等情况，就会收到关于这个项目的通知提醒。
issue：问题，在项目中遇到问题时，可以通过issue来寻求他人的帮助或者提供相关信息；也可以通过issue来告知开发者项目存在的问题。
fork：从别人的仓库里复制一份到自己的仓库里，可以理解成复制一个分支，在复制的这个分支上进行修改、提交，
原仓库的更新不会影响这个分支。
pull request：将自己的修改推送给原仓库，向原仓库的开发者申请将自己在其他分支做的修改合并到原仓库的主分支中，
原仓库的开发者同意后，会自动将修改合并到原仓库的主分支中，这就实现了多人协作开发同一个项目。



分布式计算-大数据：
从业务层面来说，"大数据" 指的是由企业、组织和个人生成的大量和复杂的数据集。
这些数据集太大、太快或太复杂，它们无法用传统的数据处理工具进行处理和分析，它们通常来自多种来源，
包括但不限于社交媒体、电子商务交易、移动设备、传感器和日志文件渠道获取数据。
大数据既给社会带来机会，也给行业带来挑战。一方面，企业可以利用大数据获得有价值的洞察力、改进决策和优化运营。
另一方面，管理、存储和处理大数据需要专门的工具和技术，例如分布式系统、并行处理和机器学习算法。
为了处理大数据，企业通常使用一系列技术，包括 Hadoop、Spark、NoSQL 数据库和云计算平台。
这些技术使企业能够实时存储、处理和分析大量数据，并根据数据派生的洞察力做出明智的决策。
总之，大数据是一个快速发展的领域，涉及从多种来源收集、管理和分析大量数据。
从数据的多方面收集，再到企业的大数据系统，最后再根据数据的应用、数据的分析，来达到影响企业决策的目的，
这才是大数据的终极目标，它有可能通过为组织提供新的洞察力和创新机会，来改变企业和行业。

从技术层面来说，大数据的技术主要是基于Hadoop为底层实现，由hive、spark实现分布式批计算，
spark streaming、flink实现分布式流式传输，由kafka实现消息队列，由Flume实现数据抽取，
zookeeper实现分布式注册中心，clickhouse、hbase实现列式存储，有些系统架构时需要元数据管理、
调度系统、监控系统的一整套处理海量数据的数据处理系统。
大数据的框架众多，大数据技术也在不断进步，处理批数据的pig和流式传输storm已经被淘汰。

Hadoop 的三大主要组件是：
Hadoop 分布式文件系统 (HDFS)：一个分布式文件系统，可以在一组商业化硬件节点上存储大量数据集。
HDFS 旨在具有高度可扩展性和容错性，并提供数据复制以确保数据在硬件故障的情况下可用。
MapReduce：一种在计算机集群上并行处理大数据集的编程模型。
MapReduce 将处理逻辑与数据存储分离，并自动处理数据分布、容错性和负载平衡。
YARN (Yet Another Resource Negotiator)：一个资源管理系统，
可协调在 Hadoop 集群上运行的各种应用程序之间的资源（如 CPU、内存和存储）的分配。
YARN 提供了一个灵活且可扩展的平台，用于运行各种大数据应用，例如批处理、实时流处理和机器学习算法。

总之，这三个组件组成了 Hadoop 生态系统的核心，并提供了一个强大的平台，用于存储、处理和分析大量复杂数据集。。

MapReduce 是一个分布式运算程序的编程框架，是用户开发"基于 Hadoop 的数据分析应用"的核心框架。
MapReduce 核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上。
1.MapReduce运算程序一般需要分成2个阶段：Map阶段和Reduce阶段
2.Map阶段的并发MapTask，完全并行运行，互不相干
3.Reduce阶段的并发ReduceTask，完全互不相干，但是他们的数据依赖于上一个阶段的所有MapTask并发实例的输出
4.MapReduce编程模型只能包含一个Map阶段和一个Reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个MapReduce程序，串行运行

用户编写的程序分成三个部分：Mapper、Reducer 和 Driver。
1．Mapper阶段
（1）用户自定义的Mapper要继承自己的父类
（2）Mapper的输入数据是KV对的形式（KV的类型可自定义）
（3）Mapper中的业务逻辑写在map()方法中
（4）Mapper的输出数据是KV对的形式（KV的类型可自定义）
（5）map()方法（MapTask进程）对每一个<K,V>调用一次

2．Reducer阶段
（1）用户自定义的Reducer要继承自己的父类
（2）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV
（3）Reducer的业务逻辑写在reduce()方法中
（4）ReduceTask进程对每一组相同k的<k,v>组调用一次reduce()方法

3．Driver阶段
相当于YARN集群的客户端，用于提交我们整个程序到YARN集群，提交的是
封装了MapReduce程序相关运行参数的job对象

大数据资源管理系统YARN：
Yarn是Hadoop的分布式资源调度平台，负责为集群的运算提供运算资源。
如果把分布式计算机和单个计算机相对应的话，HDFS就相当于计算机的文件系统，
Yarn就是计算机的操作系统，MapReduce就是计算机上的应用程序。

Yarn主要由三个组件组成：
ResourceManager：他是整个集群资源的老大，负责整个集群系统的资源分配与调度。
NodeManager：他是单个节点的老大，管理本节点的用户作业和工作流。
ApplicationMaster：他是单个应用程序的老大，负责单个应用的监控运行。

1. ResourceManager
ResourceManager 负责整个集群的资源管理和分配，是一个全局的资源管理系统。
NodeManager 以心跳的方式向 ResourceManager 汇报资源使用情况（目前主要是 CPU 和内存的使用情况）。
RM 只接受 NM 的资源回报信息，对于具体的资源处理则交给 NM 自己处理。
YARN Scheduler 根据 application 的请求为其分配资源，不负责application job 的监控、追踪、运行状态反馈、启动等工作。

2. NodeManager
NodeManager 是每个节点上的资源和任务管理器，它是管理这台机器的代理，负责该节点程序的运行，以及该节点资源的管理和监控。YARN 集群每个节点都运行一个NodeManager。
NodeManager 定时向 ResourceManager 汇报本节点资源（CPU、内存）的使用情况和Container 的运行状态。当 ResourceManager 宕机时 NodeManager 自动连接 RM 备用节点。
NodeManager 接收并处理来自 ApplicationMaster 的 Container 启动、停止等各种请求。

3. ApplicationMaster
用户提交的每个应用程序均包含一个 ApplicationMaster ， 它可以运行在ResourceManager 以外的机器上。
负责与 RM 调度器协商以获取资源（用 Container 表示）。
将得到的任务进一步分配给内部的任务(资源的二次分配)。
与 NM 通信以启动/停止任务。
监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务。
当前 YARN 自带了两个 ApplicationMaster 实现，一个是用于演示AM 编写方法的实例程序 DistributedShell，
它可以申请一定数目的Container 以并行运行一个 Shell 命令或者 Shell 脚本；
另一个是运行 MapReduce 应用程序的 AM—MRAppMaster。

YARN工作机制：
1.客户端程序向ResourceManager提交应用并请求一个ApplicationMaster实例。
2.ResourceManager找到可以运行一个Container的NodeManager，并在这个Container中启动ApplicationMaster实例。
3.ApplicationMaster向ResourceManager进行注册，注册之后客户端就可以查询ResourceManager获得自己ApplicationMaster的详细信息，
以后就可以和自己的ApplicationMaster直接交互了。
4.在平常的操作过程中，ApplicationMaster根据resource-request协议向ResourceManager发送resource-request请求。
5.当Container被成功分配之后，ApplicationMaster通过向NodeManager发送container-launch-specification信息来启动
Container，container-launch-specification信息包含了能够让Container和ApplicationMaster交流所需要的资料。
6.应用程序的代码在启动的Container中运行，并把运行的进度、状态等信息通过application-specific协议发送给ApplicationMaster。
7.在应用程序运行期间，提交应用的客户端主动和ApplicationMaster交流获得应用的运行状态、进度更新等信息，
交流的协议也是application-specific协议。
8.一但应用程序执行完成并且所有相关工作也已经完成，ApplicationMaster向ResourceManager取消注册然后关闭，
用到所有的Container也归还给系统。

数据仓库工具Hive：
Hive是由 Facebook 开源用于解决海量结构化日志的数据统计工具，Hive 是基于 Hadoop 的一个数据仓库工具，
可以将结构化的数据文件映射为一张表，并提供类 SQL 查询功能。

Hive常见指令如下：

查看数据库：show databases。
进入数据库：use database_name。
查看库下所有的表：show tables。
查看表结构：desc table_name 或 show create table table_name。
查看Hive分区：show partitions table_name。
删除数据库：drop database database_name。
删除表数据：drop table table_name删掉整个表；truncate table table_name只是删除表的内容，并不会删除表；
delete from table_name where column_name = value，用于删除表中某一行的内容。
插入语句：insert into table_name values(value1,value2...)，或 insert overwrite table table_name select column1,column2... from another_table。

Hive和SQL在建表语句、对等值连接和非等值连接、存储NULL值、落地方式等方面有较大的差异。

建表语句：Hive在创建表时，会根据导入的数据格式来指定字段分隔符和列分隔符，而SQL没有这方面需求。
等值连接：Hive不支持等值连接，如果想进行等值连接操作，需要使用SQL语句。
存储NULL值：在传统数据库中字段没有值或者为空即表示为NULL，但是在Hive中默认的NULL值是\N。
落地方式：Hive将数据落地到HDFS，而SQL将数据落地到文件。


Hive的本质是将HQL转化成MapReduce程序：
Hive 通过给用户提供的一系列交互接口，接收到用户的指令(SQL)，使用自己的 Driver，结合元数据(MetaStore)，
将这些指令翻译成 MapReduce，提交到 Hadoop 中执行，最后，将执行返回的结果输出到用户交互接口。

Hive的优缺点：
优点：
（1）操作接口采用类 SQL 语法，提供快速开发的能力（简单、容易上手）。
（2）避免了去写 MapReduce，减少开发人员的学习成本。
（3）Hive 的执行延迟比较高，因此 Hive 常用于数据分析，对实时性要求不高的场合。
（4）Hive 优势在于处理大数据，对于处理小数据没有优势，因为 Hive 的执行延迟比较高。
（5）Hive 支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。

缺点：
1、Hive 的 HQL 表达能力有限
①迭代式算法无法表达
②数据挖掘方面不擅长，由于 MapReduce 数据处理流程的限制，效率更高的算法却无法实现。

2、Hive 的效率比较低
①Hive 自动生成的 MapReduce 作业，通常情况下不够智能化
②Hive 调优比较困难，粒度较粗

Hive的底层原理：
（1）解析器（SQL Parser）：将 SQL 字符串转换成抽象语法树 AST，
这一步一般都用第三方工具库完成，比如 antlr；对 AST 进行语法分析，
比如表是否存在、字段是否存在、SQL语义是否有误。
（2）编译器（Physical Plan）：将 AST 编译生成逻辑执行计划。
（3）优化器（Query Optimizer）：对逻辑执行计划进行优化。
（4）执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于 Hive 来说，就是 MR/Spark。

Scala：
Scala是一种多范式的编程语言，它集成了面向对象编程和函数式编程的特性，运行在Java虚拟机（JVM）上，并兼容Java程序。下面我们将用更专业的语言对Scala进行详细阐述。具有函数式编程，面向对象编程等特点。

1. 语言特性
Scala的语言设计旨在提供简洁、优雅且类型安全的代码。它支持模式匹配、隐式转换、高阶函数、不可变集合等特性，使得开发者能够编写出更加表达力强且易于维护的代码。
此外，Scala的case类提供了代数数据类型（ADT）的实现，这对于领域特定语言（DSL）的构建特别有用。

2. 函数式编程
Scala强调函数式编程，支持不可变数据、高阶函数和尾递归优化等。这使得Scala在处理并行和并发编程时具有优势，因为函数式编程范式天然地支持无共享状态的并发执行。此外，Scala的集合库提供了丰富的函数式操作，使得数据处理变得简单而高效。

3. 面向对象编程
尽管Scala以函数式编程为特色，但它同样支持传统的面向对象编程特性，如类、继承、封装和多态等。Scala的类系统比Java更加灵活，支持特质（traits）这一特性，可以实现类似于多重继承的效果，同时避免了多重继承带来的复杂性。

4. 与Java的互操作性
Scala运行在JVM上，因此可以与Java代码无缝集成。Scala代码可以调用Java库，反之亦然。这种互操作性使得Scala能够充分利用Java生态系统的丰富资源，同时也为Java开发者提供了一种更加现代和灵活的编程选择。

5. 并发和并行编程
Scala提供了强大的并发和并行编程支持，包括Actor模型、Futures和Promises等机制。这些特性使得Scala在处理大规模并发任务时表现出色，特别是在构建高性能的分布式系统时具有显著优势。

6. 类型系统
Scala的类型系统非常强大且灵活，支持泛型、类型参数化、类型推断和类型别名等特性。这使得开发者能够编写出更加安全且易于理解的代码，同时减少了运行时错误的可能性。

Scala的编译过程是运用了Java jvm生成单例模式，并用静态方法调用它。Scala底层运行在Java虚拟机（JVM）上，并且可以很好地与Java代码互操作。
在Scala中创建单例模式并利用静态方法调用这个单例实例的过程与在Java中非常相似，但Scala提供了更简洁的语法。

object MySingleton {  
  def sayHello(): Unit = {  
    println("Hello from MySingleton!")  
  }  
}  
  
object SingletonCaller {  
  def main(args: Array[String]): Unit = {  
    MySingleton.sayHello() // 调用单例对象的静态方法  
  }  
}

在这个例子中，MySingleton 是一个单例对象，而不是一个类。在Scala中，使用 object 关键字来定义一个单例对象。Scala会自动为这个对象提供线程安全的懒加载实现，保证它在首次使用时才被创建，并且在整个应用程序生命周期中只有一个实例。
sayHello 方法是一个成员方法，但它看起来就像是静态方法一样被调用，因为我们不需要创建 MySingleton 的实例来调用它。实际上，MySingleton 本身就是那个唯一的实例。
SingletonCaller 是另一个单例对象，它包含一个 main 方法作为程序的入口点。在 main 方法中，我们直接调用 MySingleton.sayHello()来执行单例对象中的方法。

这个过程在JVM上的工作原理如下：

1.当Scala程序启动时，Scala运行时环境会初始化所有的单例对象。这包括为它们分配内存空间，并执行它们的构造器代码（如果有的话）。
2.由于 MySingleton 是一个单例对象，Scala运行时环境会确保在整个JVM中只有一个 MySingleton 实例存在。
3.当 SingletonCaller.main 方法被调用时，Scala运行时环境已经准备好了 MySingleton 实例，因此可以直接调用其上的 sayHello 方法。
4.调用 MySingleton.sayHello() 时，实际上是在调用单例对象 MySingleton 的一个成员方法。Scala语法隐藏了创建和访问单例实例的细节，使得调用看起来像是静态方法调用一样简洁。
5.JVM执行 sayHello 方法中的代码，打印出消息 "Hello from MySingleton!"。

这个过程利用了Scala对单例对象的隐式支持和JVM的对象模型。Scala的单例对象语法糖让代码更简洁，而JVM则提供了实际的对象内存管理和方法执行机制。

为什么说Scala是纯面向对象语言？
Scala之所以被认为是纯面向对象语言，主要基于以下几个方面的原因：

一切皆为对象：在Scala中，每一个值都是一个对象，无论是基本数据类型还是复杂的数据结构，都可以被当作对象来处理。
这种设计使得Scala的编程模型更加统一和简洁，开发者可以用一致的方式来处理各种类型的数据。

类和对象的中心地位：Scala中的类和对象是编程的基础。类是对象的模板，定义了对象的属性和方法；而对象是类的实例化，是实际运行的实体。
Scala通过类和对象的概念，实现了代码的模块化和复用，提高了程序的可维护性和可扩展性。

无基本数据类型：与Java等语言不同，Scala没有基本数据类型（如int、float等）。在Scala中，所有的数据类型，包括所谓的“基本”数据类型，都是对象。
这种设计使得Scala的面向对象特性更加纯粹，也更容易理解和使用。

灵活的对象扩展机制：Scala提供了灵活的对象扩展机制，如子类化和基于混合的组合机制。这使得开发者可以方便地扩展对象的功能，
实现多重继承的效果，同时避免了多重继承带来的复杂性。

函数也是对象：Scala不仅是一种面向对象的语言，还融合了函数式编程的特点。在Scala中，函数也是对象，可以像其他对象一样被传递、赋值和调用。
这种设计使得Scala在保持面向对象特性的同时，也具备了函数式编程的灵活性和高效性。


Scala基本数据类型：

数值类型（AnyVal）：
整型：Scala中的整型用于存放整数值，如10、123、3456等。整型分为Byte、Short、Int、Long四类，每种类型都有固定的表示范围和字段长度，不受具体操作系统的影响，保证了Scala程序的可移植性。
在Scala中，整型默认为Int型，如果需要声明Long型，需要在数字后面添加'l'或'L'。
浮点型：Scala的浮点类型用于表示小数，如123.4f、7.8、0.12等。浮点型分为Float和Double两类，其中Float是单精度的，Double是双精度的。在需要高精度小数时，建议使用Double类型。
字符类型（Char）：字符类型可以表示单个字符。
其他数值类型：Scala还包括如Unit等数值类型，Unit对应于Java中的void，表示方法没有返回值。
引用类型（AnyRef）：
字符串类型：Scala中的StringOps是对Java中String的增强，提供了更多的字符串操作功能。
其他引用类型：Scala还包括如数组、自定义类等引用类型。
此外，Scala的数据类型还有一些特殊的规则和特性：

隐式转换：Scala中仍然遵守低精度的值类型向高精度的值类型自动转换（隐式转换）的规则，例如char类型可以自动转换为Int类型。
字面量：Scala中的字面量包括整型字面量、浮点型字面量、布尔型字面量和符号字面量等，它们分别用于表示不同类型的值。

在Scala中表示空有三种：
Unit类型：表示返回值为空，类似Java里的void。
Null类型：实例值Null
Nothing类型：Nothing 类型是一个特殊的底类型（bottom type），它表示不可能有值的类型，它是所有其他类型的子类型。

Scala函数式编程：
def sum ( x : Int, y : Int) : Int = {
    x + y
}
def：定义函数的关键字
sum：函数名
x，y：参数名
Int：参数类型
外层Int：函数返回值类型

函数至简原则：
//return可以省略，Scala会使用两数体的最后一行代码作为返回
def f1(name:string):string ={
        name
}

//如果函数体只有一行代码，可以省略花括号
def f2(name: string):string = name

//返回值类型如果能够推断出来，那么可以省略(:和返回值类型一起省路)
def f3(name :string) = name

//Scala如果期望是无返回值类型，可以省略等号
def f6(name: string){
    println(name)
}

//如果函数无参，但是声明了参数列表，那么满用时，小括号，可加可不加
def f7(): unit ={
printin('atguigu")
}
f7

Scala匿名函数：
val fun=(name:String)=>{println(name)}
fun("atguigu")

//柯里化:函数柯里化是高阶函数的一种，高阶函数是指接收函数作为参数或返回函数的函数。柯里化提供了逐步传参的过程，使得函数的调用更加灵活和模块化。
def addcurrying(a:Int)(b:Int):Int={
    a + b 
}

Scala变量和常量:
var 变量名：变量类型 = 初始值
val 常量名：常量类型 = 初始值
 
tips：1.声明变量时，类型可以省略
      2.类型确定后，就不能修改。（Scala是强类型语言）
      3.变量声明时，必须要有初始值
      
Scala字符串：
通过+号拼接 
val name: String ="I"
val age:Int =18
println(age +"岁的"+ name +"在学习Scala")

printf用法：字符串，通过%传值
printf("%d岁的%s在学习Scala"，age，name)

通过$获取变量值
println(s"${age}岁的S{name}在学习Scala")

Scala处理文件：
//从文件中读取数据
Source.fromFile("src/main/resources/test.txt").foreach(print)

//.将数据写入文件
writer.write("hello scala from java writer")
val writer = new PrintWriter(pew File( pathname= "src/main/resources/output.txt"))
writer.close()

Scala尾递归计算阶乘：
在Scala中，你可以使用尾递归来优化阶乘的计算，以避免栈溢出的问题，尤其是当处理大整数时。
尾递归是函数式编程语言中一种重要的递归形式，因为它可以确保在递归调用之后没有其他的计算需要执行，因此编译器可以优化它，使得递归调用类似于循环，避免了递归深度的限制。

def factorialTailRec(n: BigInt, acc: BigInt = BigInt(1)): BigInt = {  
  if (n <= 0) acc  
  else factorialTailRec(n - 1, n * acc)  
}  
  
// 使用示例  
val result = factorialTailRec(BigInt(5)) // 计算5的阶乘  
println(result) // 输出120

Scala传名函数：
在Scala中，传名参数（By-name Parameter）是一个特殊的参数传递机制，它允许你将一个函数或代码块作为参数传递，并且这个代码块在每次被引用时都会被重新计算。
这与传值参数（By-value Parameter）不同，后者在传递给函数时只计算一次，并将结果传递给函数。

def f1(): Int ={
    printin("f1调用")
    12
}
def f2(a:=>Int):Unit ={
    println("a:" + a)
    println("a:"+ a)
}

输出:
a:23
a:23
f1调用
a:12
f1调用
a:12

当f2函数被调用时，传入的代码块（或表达式）并不会立即执行，而是每次当a在函数体中被引用时才会执行。因此，在你的f2函数示例中，a会被计算两次，并且每次计算时都会打印出a的值。

Scala惰性加载：
Scala中的惰性加载（Lazy Loading）是一种编程模式，用于延迟对象的初始化，直到真正需要使用该对象时再进行初始化。

惰性加载的主要优势在于，它可以帮助我们优化程序的性能。当我们有一个需要消耗大量资源或者时间来进行初始化的对象时，如果我们在程序启动时立即进行初始化，那么可能会浪费资源，
因为该对象可能在程序运行的大部分时间内都不被使用。通过使用惰性加载，我们可以将初始化推迟到真正需要使用该对象的时候，从而节省资源。

lazy val expensiveObject: ExpensiveType = createExpensiveObject()

expensiveObject是一个惰性加载的变量。在程序启动时，createExpensiveObject()函数不会被调用，expensiveObject也不会被初始化。
只有当程序首次访问expensiveObject时，createExpensiveObject()函数才会被调用，expensiveObject才会被初始化。

需要注意的是，惰性加载虽然可以优化性能，但也可能引入一些新的问题。例如，如果在多线程环境下使用惰性加载，需要确保对象的初始化是线程安全的。
此外，如果对象的初始化依赖于其他对象的初始化，那么使用惰性加载时也需要特别注意这些依赖关系。

Scala伴生对象（单例对象）：
在Scala中，伴生对象（companion object）是与类定义相关联的一个单例对象，它提供了与类相关的静态方法或字段的集合。
伴生对象在Scala中是一种特殊的对象，它与一个类共享相同的名称，但不属于类的实例成员，而是作为一个独立的对象存在。

伴生对象的主要用途是提供与类相关的静态功能，而不需要使用Java风格的静态方法或字段。在Scala中，没有显式的静态成员的概念，而是通过使用伴生对象来模拟静态行为。
伴生对象在Scala中的定义非常简单，它只需要在类定义之外使用object关键字，并赋予与类相同的名称即可。例如：

class MyClass {  
  // 类的实例成员  
}  
  
object MyClass {  
  // 伴生对象的成员  
  def myStaticMethod(): Unit = {  
    // 静态方法的实现  
  }  
    
  val myStaticField = "Some value"  
}
在上面的代码中，MyClass是一个类定义，而object MyClass则是与该类相关联的伴生对象。myStaticMethod是伴生对象的一个方法，可以像调用静态方法一样调用它，而不需要创建类的实例。
同样地，myStaticField是伴生对象的一个字段，可以作为静态字段使用。

要使用伴生对象的成员，可以通过类名直接访问，就像访问静态成员一样：

MyClass.myStaticMethod() // 调用伴生对象的方法  
val value = MyClass.myStaticField // 访问伴生对象的字段
伴生对象在Scala中提供了一种优雅的方式来组织与类相关的静态功能，避免了Java中常见的静态方法和字段的使用。
同时，由于伴生对象是一个独立的对象，它也可以拥有自己的状态和行为，这使得它在某些场景下比静态成员更加灵活和强大。

需要注意的是，伴生对象并不是类的成员，它们只是与类共享相同的名称空间。因此，伴生对象不能访问类的私有成员，而只能访问公共成员或通过类提供的方法来进行交互。
此外，伴生对象也可以独立于类存在，即可以定义一个只包含伴生对象的对象而不定义任何类。

PS：在Scala中有很多情况是用伴生对象来创建对象

Scala特质：
Scala 的特质（Traits）和 Java 的接口（Interfaces）在功能和用法上有一些相似之处，但也存在一些关键的差异。
相似之处：
1. 定义方法但不实现它们： Scala 的特质和 Java 的接口都可以定义方法，但不实现它们。它们的主要目的是为类提供一个契约，类必须实现这些方法来满足这个契约。
2. 多重继承： 在 Scala 中，一个类可以继承多个特质。同样，在 Java 8 及以后的版本中，一个类也可以实现多个接口。这允许开发者组合多个接口或特质的功能，实现更灵活的编程。

不同之处：
1. 实现细节：Scala 的特质不仅可以定义方法，还可以包含字段和方法的实现。这意味着特质可以包含更丰富的功能，而不仅仅是方法的声明。
相比之下，Java 的接口在 Java 8 之前只能定义方法的声明，不能包含字段或方法的实现。
从 Java 8 开始，接口可以包含默认方法和静态方法，但字段仍然只能是常量（即，public static final）。

2. 继承与混入：在 Scala 中，特质可以通过混入（mixin composition）的方式与类结合，而不仅仅是像 Java 中的接口那样通过继承。
这提供了更大的灵活性，允许开发者将特质与类以任何顺序组合，从而创建出具有所需功能的对象。

3. 类型检查：Scala 的特质可以用于类型检查，而 Java 的接口也可以。但是，Scala 的特质在这方面提供了更强大的功能，因为它们可以包含更多类型的成员（例如字段和方法）。

4. 特质可以扩展其他特质：Scala 的特质可以扩展其他特质，这使得特质可以像类一样形成一个层次结构。而 Java 的接口则不能继承其他接口（在 Java 8 之前），从 Java 8 开始，接口可以扩展其他接口。

总结来说，Scala 的特质在功能性和灵活性上超过了 Java 的接口。它们提供了更丰富的功能，包括字段和方法的实现，以及更灵活的混入机制。
然而，这并不意味着特质总是优于接口。在选择使用特质还是接口时，应根据具体的需求和场景来决定。

//定义特质
trait Greetable {  
  // 抽象方法，需要在实现该特质的类中定义  
  def greet: String  
  
  // 具体方法，可以直接在特质中实现  
  def sayHello: Unit = {  
    println("Hello, " + greet)  
  }  
}

//创建类，实现特质
class Person(val name: String) extends Greetable {  
  // 实现特质中的抽象方法  
  override def greet: String = "Mr. " + name  
  
  // Person类还可以定义自己的方法  
  def introduce: Unit = {  
    println("My name is " + name)  
  }  
}

//创建对象，并调用它的方法
class Person(val name: String) extends Greetable {  
  // 实现特质中的抽象方法  
  override def greet: String = "Mr. " + name  
  
  // Person类还可以定义自己的方法  
  def introduce: Unit = {  
    println("My name is " + name)  
  }  
}

//输出
Hello, Mr. Alice  
My name is Alice


//Scala特质混入
object Main {  
  def main(args: Array[String]): Unit = {  
    val person = new Person("Alice")  
      
    // 动态混入Greetable特质  
    val greetablePerson = new {  
      val name: String = person.name // 捕获外部person的name字段  
    } with Greetable {  
      override def greet: String = "Ms. " + name // 实现greet方法  
    }  
      
    // 调用混入特质的方法  
    greetablePerson.sayHello  
      
    // 调用原始Person类的方法  
    person.introduce  
  }  
}

关于特质叠加的执行顺序，Scala遵循一定的规则。当特质中存在方法调用super.xx时，Scala会从右到左执行这些调用。
此外，Scala的特质叠加还涉及到了初始化顺序的问题。当实例化一个类时，Scala会按照从左到右的顺序初始化混入的特质。

Scala自身类型：
Scala的自身类型（self-type）是一种特性，它用于声明一个特质（Trait）必须混入（mixin）其他特质，即使该特质没有直接扩展其他特质。这使得所依赖的成员可以在没有导入的情况下使用。
它提供了一种细化`this`或`this`别名类型的方法。自身类型在Scala的类型系统中起到了重要作用，它产生的效果与继承或混入颇为相似。

在Scala中，如果一个类或特质指明了自身类型，它的子类型或对象也必须是相应的类型。这提供了一种类型安全的机制，确保在特质或类之间建立正确的依赖关系。

使用自身类型时，需要写一个标识符，跟上要混入的另一个特质，并使用`=>`符号（例如`someIdentifier: SomeOtherTrait =>`）。
这意味着如果一个特质继承了另一个特质，并且需要混入第三个特质，它必须按照规定的自身类型进行声明。

在实际应用中，自身类型通常用于拆分大型的特质或类，以便更好地组织和管理代码。通过将大型特质拆分为多个小特质，并使用自身类型将它们组合在一起，可以提高代码的可读性和可维护性。

总的来说，Scala的自身类型是一种强大的机制，用于在特质和类之间建立明确的依赖关系，并确保类型安全。它允许开发者以更灵活和可维护的方式组织和管理代码。

trait Logger {  
  def log(message: String): Unit  
}  
  
trait Loggable {  
  this: Logger => // 声明自身类型，表示Loggable的使用者必须混入Logger特质  
  
  def doSomething(): Unit = {  
    // 使用Logger特质中的log方法  
    log("Doing something important")  
    // ... 执行其他操作 ...  
  }  
}  
  
// 一个具体的Logger实现  
class SimpleLogger extends Logger {  
  override def log(message: String): Unit = {  
    println(s"Logging: $message")  
  }  
}  
  
// 一个类，它混入了Loggable特质，并隐式地也混入了Logger特质（通过自身类型的要求）  
class MyService extends SimpleLogger with Loggable {  
  // 由于MyService混入了Loggable，它必须也混入Logger（通过继承SimpleLogger实现）  
  // 因此，doSomething方法中的log调用是有效的  
}  
  
object Main {  
  def main(args: Array[String]): Unit = {  
    val service = new MyService()  
    service.doSomething() // 输出 "Logging: Doing something important"  
  }  
}

Scala集合：
Scala集合主要可以分为两大类：可变集合和不可变集合。

不可变集合一旦创建，其内容就不会再改变，因此可以安全地在多线程应用程序中共享其引用。这种特性使得不可变集合在多线程环境下表现出色，无需担心数据竞态条件。

Scala中的集合类型还包括列表、序列、集等。列表有不可变列表（List）和可变列表（LinkedList）两种。
序列则包括常用的Vector和Range，其中Vector是ArrayBuffer的不可变版本，是一个带下标的序列；Range则表示一个整数序列。
集（Set）则是不重复元素的集合，与列表不同，集并不保留元素插入的顺序。

不可变（Immutable）List
不可变List是Scala集合库中的默认实现，一旦创建，其内容就不能被修改。这并不意味着你不能改变一个不可变List的引用，而是你不能改变List本身的内容。
当你对一个不可变List进行添加、删除或更新操作时，实际上会创建一个新的List，这个新的List是原始List的一个变种，包含了所需的更改。

不可变List的主要优点包括：

线程安全：由于不可变List的内容在创建后不会改变，因此它们天生就是线程安全的。多个线程可以共享同一个不可变List，而无需担心并发修改的问题。
持久化数据结构：不可变List提供了持久化的数据结构，即每次操作都会返回一个新的List，而原始List保持不变。这使得历史数据可以被保留，并可以用于构建复杂的算法或逻辑。
易于推理：由于每次操作都返回新的List，因此你可以更容易地通过链式调用或组合多个操作来构建复杂的集合转换，而无需担心中间状态或副作用。

List:
可变（Mutable）List
可变List允许你在创建后修改其内容，例如添加、删除或更新元素。与不可变List相比，可变List提供了更高的灵活性，但也带来了一些潜在的问题。

可变List的主要特点包括：
可修改性：你可以直接修改可变List的内容，而无需创建新的List。这使得在需要频繁修改List的场景下，可变List可能更加高效。
线程不安全：如果你在多线程环境中使用可变List，并且至少有一个线程修改它，那么你需要确保对它的访问是同步的，以避免并发修改异常或数据不一致。
线程安全性的维护通常需要额外的同步机制，这可能会增加代码的复杂性和性能开销。
状态变化：由于可变List的内容可以被修改，因此其状态可以在运行时发生变化。这可能会导致难以预测和推理的行为，特别是在复杂的算法或逻辑中。

Set:
不可变（Immutable）Set
不可变 Set 是Scala集合库中的默认实现，它提供了线程安全且不可变的集合。一旦一个不可变 Set 被创建，你就不能修改它（例如添加、删除或更新元素）。
但是，你可以通过创建一个新的 Set 来“修改”它，这个新的 Set 是原始 Set 的一个变种。
不可变 Set 的主要优点是线程安全且易于推理。由于它们是不可变的，所以你可以在多个线程之间共享它们，而无需担心并发修改的问题。
此外，由于每次操作都返回一个新的集合，所以你可以很容易地通过链式调用或组合多个操作来构建复杂的集合转换。


可变（Mutable）Set
可变 Set 允许你在创建后修改它（例如添加、删除或更新元素）。与不可变 Set 相比，可变 Set 提供了更高的灵活性，但也带来了线程安全和复杂性方面的问题。
如果你在多线程环境中使用可变 Set，并且至少有一个线程修改它，那么你需要确保对它的访问是同步的，以避免并发修改异常或数据不一致。
此外，由于可变 Set 允许就地修改，所以它们的行为可能更难以预测和推理，特别是在复杂的算法或逻辑中。

Map:
不可变（Immutable）Map
不可变Map是Scala集合库中的默认实现。一旦一个不可变Map被创建，你就不能修改它（例如添加、删除或更新键值对）。如果你试图修改一个不可变Map，Scala会返回一个新的Map，这个新的Map是原始Map的一个变种，包含了所需的更改。

不可变Map的主要优点包括：
线程安全：由于不可变Map的内容在创建后不会改变，因此它们天生就是线程安全的。多个线程可以共享同一个不可变Map，而无需担心并发修改的问题。
持久化数据结构：每次对不可变Map进行操作时，都会返回一个新的Map，而原始Map保持不变。这使得你可以保留历史数据，并构建复杂的算法或逻辑。
易于推理：由于每次操作都返回新的Map，你可以更容易地通过链式调用或组合多个操作来构建复杂的集合转换。

可变（Mutable）Map
可变Map允许你在创建后修改其内容，例如添加、删除或更新键值对。与不可变Map相比，可变Map提供了更高的灵活性，但也带来了一些潜在的问题。

可变Map的主要特点包括：
可修改性：你可以直接修改可变Map的内容，而无需创建新的Map。这使得在需要频繁修改Map的场景下，可变Map可能更加高效。
线程不安全：如果你在多线程环境中使用可变Map，并且至少有一个线程修改它，那么你需要确保对它的访问是同步的，以避免并发修改异常或数据不一致。这通常需要额外的同步机制，可能会增加代码的复杂性和性能开销。
状态变化：由于可变Map的内容可以被修改，因此其状态可以在运行时发生变化。这可能会导致难以预测和推理的行为，特别是在复杂的算法或逻辑中。

Scala隐式转换：
Scala中的隐式转换（Implicit Conversions）是一种强大的特性，它允许编译器在必要时自动地将一个类型的值转换为另一个类型的值。
这种转换是隐式的，也就是说，它不需要程序员显式地调用转换方法。隐式转换在Scala中非常有用，因为它可以帮助简化代码，提高可读性，并减少样板代码。

隐式转换主要通过隐式参数和隐式类来实现。

隐式参数
隐式参数是定义在作用域内的隐式值，它们可以被编译器自动用于方法调用中缺少的显式参数。这意味着你可以定义一个方法，该方法有一个或多个隐式参数，然后在调用该方法时省略这些参数，编译器会自动查找作用域内的相应隐式值来填充这些参数。

例如：
implicit val myImplicitValue: String = "Hello, World!"

def greet(implicit message: String): Unit = {
  println(message)
}

// 调用时省略了隐式参数message
greet() // 输出: Hello, World!


在上面的例子中，`greet`方法有一个隐式参数`message`。当调用`greet()`时，我们没有提供任何参数，但编译器找到了作用域内的隐式值`myImplicitValue`，并将其作为参数传递给`greet`方法。

隐式类
隐式类允许你定义一个类，该类可以在需要时自动将其他类型的值转换为该类的实例。隐式类必须满足以下条件：

1. 隐式类必须在其他对象或类的伴随对象中定义。
2. 隐式类只能有一个参数。

当编译器遇到一个期望的类型，但它得到了一个不匹配的类型时，它会查找是否有可用的隐式类可以将不匹配的类型转换为期望的类型。

例如：
object RichInt {
  implicit class IntWithTimes(x: Int) {
    def times(f: => Unit): Unit = {
      for (_ <- 1 to x) f
    }
  }
}

import RichInt._

// 使用隐式类定义的times方法
5.times { println("Hello") } // 输出Hello五次


在上面的例子中，我们定义了一个名为`RichInt`的对象，并在其中定义了一个隐式类`IntWithTimes`。这个隐式类接受一个`Int`类型的参数，并为其添加了一个`times`方法。
当我们在代码中写`5.times`时，编译器会自动找到并使用这个隐式类来将`Int`类型的值`5`转换为`IntWithTimes`的实例，从而可以调用`times`方法。

注意事项：
虽然隐式转换非常强大，但过度使用它也可能导致代码难以理解和维护。因此，在使用隐式转换时应该谨慎，并遵循一些最佳实践：
- 尽量将隐式定义放在与它们最相关的地方，比如伴随对象或特定的作用域内。
- 避免在全局范围内定义过多的隐式转换，以免产生意外的副作用。
- 隐式转换应该是可预测的，避免产生歧义或令人困惑的行为。
- 在团队开发中，使用隐式转换之前应与团队成员进行沟通和讨论，以确保大家都能理解和接受这种用法。

Scala上下文限定：
Scala的上下文限定（Context Bounds）是一种语法糖，它允许在类型参数上定义隐式参数的约束。这种机制使得在类型层面上引入额外的约束成为可能，而无需显式地传递额外的参数。
上下文限定的语法形式为T: M，其中T是类型参数，M是另一个泛型类或特质（trait）。这表示必须存在一个类型为M[T]的隐式值。

在Scala中，上下文限定常常与隐式转换和隐式参数一起使用，以提供类型安全的扩展和转换。通过上下文限定，你可以要求使用某个类型参数的方法或类必须存在一个满足特定条件的隐式值。
这有助于在编译时捕获潜在的错误，提高代码的可读性和可维护性。

下面是一个使用上下文限定的简单示例：
import scala.math.Ordering  

class Pair[T: Ordering](val first: T, val second: T) {  
  def smaller(implicit ord: Ordering[T]): T = {  
    if (ord.compare(first, second) < 0) first else second  
  }  
}  

// 隐式定义的Ordering，用于Int类型  
implicit val intOrdering: Ordering[Int] = Ordering.Int  
  
// 使用Pair类，并自动使用隐式定义的intOrdering  
val pair = new Pair(3, 4)  
val smallerValue = pair.smaller // 调用smaller方法时，编译器会自动查找并使用intOrdering  
println(smallerValue) // 输出: 3
在上面的例子中，Pair类定义了一个上下文限定T: Ordering，这要求必须存在一个类型为Ordering[T]的隐式值。当创建Pair的实例并调用smaller方法时，编译器会自动查找作用域内是否存在合适的隐式Ordering[T]值，并用于比较first和second的大小。在这个例子中，我们为Int类型定义了一个隐式的Ordering，因此当Pair的类型为Int时，编译器能够自动找到并使用它。

上下文限定提供了一种灵活且类型安全的方式来扩展现有类型的功能，而无需修改这些类型的源代码。它使得代码更加模块化，并允许开发者以声明式的方式定义类型之间的约束和关系。
注意：Scala中的语法糖运用得非常普遍。Scala作为一种多范式编程语言，旨在融合面向对象编程和函数式编程的最佳特性，并通过语法糖来简化这些特性的使用，这些语法糖使得代码更加简洁、易读和易于维护。

大数据Spark：
Spark 是一个分布式数据快速分析项目。它的核心技术是弹性分布式数据集（Resilient Distributed Datasets），
提供了比 MapReduce 丰富的模型，可以快速在内存中对数据集进行多次迭代，来支持复杂的数据挖掘算法和图形计算算法。
Spark底层是由Hadoop实现，但是和Hadoop有明显不同。

Spark和MapReduce对比:
1.MapReduce多个作业间的数据通信是基于磁盘, 而Sparke多个作业间的数据通信是基于内存
2.一个MapReduce程序只有map+reduce, 而Spark程序可以有多个算子
3.MapReduce是批处理, 而Spark是批处理 & 微批准实时处理
4.Shuffle中Spark不用落盘, 而MapReduce要磁盘
5.Spark有丰富的RDD算子, SQL操作, Streaming流处理, 还可以处理机器学习, 而MapReduce只有Mapper和Reducer
6.Spark有容错机制可以切断血缘, 避免失败后从源头数据开始全部重新计算

Spark Core:Spark Core 中提供了 Spark 最基础与最核心的功能，
Spark 其他的功能如：Spark SQL，Spark Streaming，GraphX, MLlib 都是在 Spark Core 的基础上进行扩展。
MapReduce 框架采用非循环式的数据流模型，把中间结果写入到 HDFS 中，带来了大量的数据复制、磁盘 IO 和序列化开销。
且这些框架只能支持一些特定的计算模式(map/reduce)，并没有提供一种通用的数据抽象。因此Spark发展出了RDD这个概念。

RDD(Resilient Distributed Dataset)叫做弹性分布式数据集，
是 Spark 中最基本的数据抽象，代表一个不可变、可分区、里面的元素可并行计算的集合。

RDD单词拆解：
Resilient ：它是弹性的，RDD 里面的中的数据可以保存在内存中或者磁盘里面；
Distributed ： 它里面的元素是分布式存储的，可以用于分布式计算；
Dataset: 它是一个集合，可以存放很多元素。

RDD 的算子分为两类:
Transformation转换操作:返回一个新的 RDD
Action动作操作:返回值不是 RDD(无返回值或返回其他的)

注意:
RDD 不实际存储真正要计算的数据，而是记录了数据的位置在哪里，数据的转换关系(调用了什么方法，传入什么函数)。
RDD 中的所有转换都是惰性求值/延迟执行的，也就是说并不会直接计算。
只有当发生一个要求返回结果给 Driver 的 Action动作时，这些转换才会真正运行。
之所以使用惰性求值/延迟执行，是因为这样可以在 Action 时对 RDD 操作形成 DAG有向无环图进行 Stage 的划分和并行优化，
这种设计让 Spark 更加有效率地运行。

Spark Core常用API：
>转换算子：transfromation
1.value类型 ：
map（）映射：参数f是一个函数可以写作匿名子类，它可以接收一个参数。当某个RDD执行map方法时，会遍历该RDD中的每一个数据项，并依次应用f函数，从而产生一个新的RDD。即，这个新RDD中的每一个元素都是原来RDD中每一个元素依次应用f函数而得到的。 
mapPartitons()：遍历RDD的每个分区
flatmap（）扁平化：
与map操作类似，将RDD中的每一个元素通过应用f函数依次转换为新的元素，并封装到RDD中。 很像hive中的炸裂函数。和map（）的区别：在flatMap操作中，f函数的返回值是一个集合，并且会将每一个该集合中的元素拆分出来放到新的RDD中。

groupBy()分组：按照传入函数的返回值进行分组。将相同的key对应value值放入一个迭代器。
groupBy会存在shuffle过程(将不同的分区数据进行打乱重组的过程)

filter()过滤：接收一个返回值为布尔类型的函数作为参数。当某个RDD调用filter方法时，会对该RDD中每一个元素应用f函数，
如果返回值类型为true，则该元素会被添加到新的RDD中，如果为false，则不会加入到RDD中。

distinct()去重：对内部的元素去重，并将去重后的元素放到新的RDD中。distinct的层层实际是groupBy()+map()（根据key值进行分组，将key值放到迭代器，
然后通过map()求出pariRDD的key值），因此distinct也是有shuffle的。

sortBy()：在排序之前，将数据通过f函数进行处理，之后按照f函数处理的结果进行排序，默认为正序排列。
排序后新产生的RDD的分区数与原RDD的分区数一致。Spark的排序结果是全局有序。

PS：全局有序是怎么做到的？首先我们知道在hive中sortBy是分区内有序的，spark中是全局有序，是因为是分桶排序，
先对数据抽样、排序、选取等分点，然后将对应数据进入分区，这样可以保证分区间有序，再对分内内排序，保证了全局有序。
因此我们在web界面会看到两个任务，第一个job就是用来分桶来指定分区内数据范围。


2.key value类型(pairRDD是kv结构的RDD)
创建一个pairRDD：
System.out.println("==========直接创建javaPairRDD==============");
ArrayList<Tuple2<String,Integer>> list = new ArrayList<>();
list.add(new Tuple2<>("A", 1));
list.add(new Tuple2<>("B", 1));
list.add(new Tuple2<>("C", 1));
list.add(new Tuple2<>("D", 1));
JavaPairRDD<String, Integer> javaPairRDD = sc.parallelizePairs(list, 2);

PS：Spark Core中的Tuple是元组（元祖）类型的一种表现形式。它们允许你存储多个不同类型的数据，并可以通过名称访问这些数据。
pairRDD的转换算子：
mapValues()：针对于(K,V)形式的类型只对V进行操作

groupByKey()：groupByKey对每个key进行操作，但只生成一个seq（sequencer序列），并不进行聚合。
该操作可以指定分区器或者分区数（默认使用HashPartitioner）。
根据value进行分组：①使用groupBy ②先将javaPairRDD的key和value交换（使用mapToPair），再使用groupByKey  
③先将javaPairRDD的key和value交换（使用map，变为javaRDD），再使用groupByKey。

reduceByKey()：该操作可以将RDD[K,V]中的元素按照相同的K对V进行聚合。其存在多种重载形式，还可以设置新RDD的分区数。
两者的区别不仅仅是 reduceByKey减少了聚合的步骤，reduceByKey还提前进行了combine，reduceByKey效率是groupByKey的100倍多，
数据量越大，reduceByKey对于shuffle的效果文件越明显。在不影响业务逻辑的前提下，优先选用reduceByKey。

sortByKey()：按照key进行排序，key必须实现ordered接口。
如果按照value值进行排序：将 javaPairRDD转换成RDD或使用map对pairRDD进行k、v倒转然后再使用sortBy


行动算子：action
行动算子作用：触发整个作业的执行，转换算子是懒加载，只有action算子执行后才会执行。
行动算子：
collect()：collect 将所有executor（rdd的数据）的分区数据，收集到driver ，并且按照分区号顺序收集（0 ，1， 2），
慎用collect，因为executor数据量大， 而driver的内存小，一般driver内存就4G足够。
count()：返回RDD中元素的个数。作用：一般拿来预估总数据量，先预估出每条数据的平均大小 x count值，就能预估出总数据量大小。
first()：返回RDD中的第一个元素
take()：返回由RDD前n个元素组成的数组，类似于 sql当中的 limit 获取几条数据查看结果。
countByKey()：统计每种key的个数。作用：判断数据倾斜的key
saveAsTextFile(path)：保存成Text文件
saveAsObjectFile(path) ：序列化成对象保存到文件
foreach()：遍历RDD中每一个元素
foreach 和 collect 的区别：foreach是在executor直接循环遍历打印，collect是将数据拉取到driver然后循环遍历打印。
在driver是单线程进行遍历，在executor是多线程进行，所以foreach不是按照分区顺序进行打印的，collect是按照分区号顺序打印。
foreach用的最多，因为计算之后的数据要写到各种各样的数据目的地（hdfs、hbase、mysql、redis）。
foreachPartition ()：遍历RDD中每一个分区

存储级别
默认的存储级别都是仅在内存存储一份，Spark 的存储级别还有好多种，存储级别在 object StorageLevel 中定义的。
>RDD 持久化/缓存的目的是为了提高后续操作的速度
>缓存的级别有很多，默认只存在内存中,开发中使用 memory_and_disk
>只有执行 action 操作的时候才会真正将 RDD 数据进行持久化/缓存
>实际开发中如果某一个 RDD 后续会被频繁的使用，可以将该 RDD 进行持久化/缓存

RDD 容错机制Checkpoint
持久化的局限：

持久化/缓存可以把数据放在内存中，虽然是快速的，但是也是最不可靠的；
也可以把数据放在磁盘上，也不是完全可靠的！例如磁盘会损坏等。
问题解决：
Checkpoint 的产生就是为了更加可靠的数据持久化，在Checkpoint的时候一般把数据放在在 HDFS 上，
这就天然的借助了 HDFS 天生的高容错、高可靠来实现数据最大程度上的安全，实现了 RDD 的容错和高可用。

SparkContext.setCheckpointDir("目录") //HDFS的目录
RDD.checkpoint

持久化和 Checkpoint 的区别：
位置：Persist 和 Cache 只能保存在本地的磁盘和内存中(或者堆外内存–实验中) Checkpoint 可以保存数据到 HDFS 这类可靠的存储上。
生命周期：Cache 和 Persist 的 RDD 会在程序结束后会被清除或者手动调用 unpersist 方法 Checkpoint 的 RDD 在程序结束后依然存在，不会被删除。

RDD的依赖关系：宽依赖和窄依赖
对于窄依赖：
>窄依赖的多个分区可以并行计算；
>窄依赖的一个分区的数据如果丢失只需要重新计算对应的分区的数据就可以了。

对于宽依赖：
划分 Stage(阶段)的依据:对于宽依赖,必须等到上一阶段计算完成才能计算下一阶段。

DAG(Directed Acyclic Graph 有向无环图)：指的是数据转换执行的过程，有方向，无闭环(其实就是 RDD 执行的流程)；
原始的 RDD 通过一系列的转换操作就形成了 DAG 有向无环图，任务执行时，可以按照 DAG 的描述，执行真正的计算(数据被操作的一个过程)。
DAG 的边界:
开始：通过 SparkContext 创建的 RDD；
结束：触发 Action，一旦触发 Action 就形成了一个完整的 DAG。

划分stage可以运用在并行计算。一个复杂的业务逻辑如果有 shuffle，那么就意味着前面阶段产生结果后，
才能执行下一个阶段，即下一个阶段的计算要依赖上一个阶段的数据。
那么我们按照 shuffle 进行划分(也就是按照宽依赖就行划分)，就可以将一个 DAG 划分成多个 Stage/阶段，
在同一个 Stage 中，会有多个算子操作，可以形成一个 pipeline 流水线，流水线内的多个平行的分区可以并行执行。

总结：Spark 会根据 shuffle/宽依赖使用回溯算法来对 DAG 进行 Stage 划分，
从后往前，遇到宽依赖就断开，遇到窄依赖就把当前的 RDD 加入到当前的 stage/阶段中。

广播变量：广播变量用来把变量在所有节点的内存之间进行共享，
在每个机器上缓存一个只读的变量，而不是为机器上的每个任务都生成一个副本。

import org.apache.spark.broadcast.Broadcast
import org.apache.spark.rdd.RDD
import org.apache.spark.{SparkConf, SparkContext}

object BroadcastVariablesTest {
  def main(args: Array[String]): Unit = {
    val conf: SparkConf = new SparkConf().setAppName("wc").setMaster("local[*]")
    val sc: SparkContext = new SparkContext(conf)
    sc.setLogLevel("WARN")

    //不使用广播变量
    val kvFruit: RDD[(Int, String)] = sc.parallelize(List((1,"apple"),(2,"orange"),(3,"banana"),(4,"grape")))
    val fruitMap: collection.Map[Int, String] =kvFruit.collectAsMap
    //scala.collection.Map[Int,String] = Map(2 -> orange, 4 -> grape, 1 -> apple, 3 -> banana)
    val fruitIds: RDD[Int] = sc.parallelize(List(2,4,1,3))
    //根据水果编号取水果名称
    val fruitNames: RDD[String] = fruitIds.map(x=>fruitMap(x))
    fruitNames.foreach(println)
    //注意:以上代码看似一点问题没有,但是考虑到数据量如果较大,且Task数较多,
    //那么会导致,被各个Task共用到的fruitMap会被多次传输
    //应该要减少fruitMap的传输,一台机器上一个,被该台机器中的Task共用即可
    //如何做到?---使用广播变量
    //注意:广播变量的值不能被修改,如需修改可以将数据存到外部数据源,如MySQL、Redis
    println("=====================")
    val BroadcastFruitMap: Broadcast[collection.Map[Int, String]] = sc.broadcast(fruitMap)
    val fruitNames2: RDD[String] = fruitIds.map(x=>BroadcastFruitMap.value(x))
    fruitNames2.foreach(println)

  }
}

Spark SQL:Spark SQL 是 Spark 用来操作结构化数据的组件。
通过 Spark SQL，用户可以使用 SQL或者 Apache Hive 版本的 SQL 方言（HQL）来查询数据。

Spark SQL常用语句如下：
SELECT：用于从数据表中查询数据。
INSERT INTO：用于向表中插入数据。
UPDATE：用于更新数据表中的数据。
DELETE FROM：用于从数据表中删除数据。
CREATE TABLE：用于创建一个新的数据表。
ALTER TABLE：用于修改现有的数据表结构。
DROP TABLE：用于删除一个数据表。
LOAD DATA：用于加载本地文件系统中的数据文件到数据表中。
SHOW COLUMNS：用于显示表中的所有列。
COUNT：用于计算表中的行数。
GROUP BY：用于根据指定的列对数据进行分组。
ORDER BY：用于根据指定的列对数据进行排序。
WHERE：用于对数据进行过滤。

Spark SQL的数据抽象：
Spark SQL数据抽象可以分为两类：
① DataFrame：DataFrame 是一种以 RDD 为基础的分布式数据集，类似于传统数据库的二维表格，
带有 Schema 元信息(可以理解为数据库的列名和类型)。DataFrame = RDD ＋ 泛型 + SQL 的操作 + 优化
② DataSet：DataSet是DataFrame的进一步发展，它比RDD保存了更多的描述信息，概念上等同于关系型数据库中的二维表，
它保存了类型信息，是强类型的，提供了编译时类型检查。调用 Dataset 的方法先会生成逻辑计划，
然后被 spark 的优化器进行优化，最终生成物理计划，然后提交到集群中运行！DataFrame = Dateset[Row]

RDD[Person]：以 Person 为类型参数，但不了解其内部结构。
DataFrame：提供了详细的结构信息 schema 列的名称和类型。这样看起来就像一张表了。
DataFrame = RDD - 泛型 + Schema + SQL + 优化

DataSet[Person]：不光有 schema 信息，还有类型信息。
DataSet = DataFrame + 泛型
DataSet = RDD + Schema + SQL + 优化

Spark Streaming:Spark Streaming 是 Spark 平台上针对实时数据进行流式计算的组件，提供了丰富的处理数据流的API。
Spark Streaming 的特点：
易用：可以像编写离线批处理一样去编写流式程序，支持 java/scala/python 语言。
容错：SparkStreaming 在没有额外代码和配置的情况下可以恢复丢失的工作。
易整合到 Spark 体系：流式处理与批处理和交互式查询相结合。

Spark Streaming常用语句：

输出操作：writeStream.format("parquet")或writeStream.format("kafka")等输出操作。
定义输出路径：.option("path", "path/to/destination/dir")或.option("kafka.bootstrap.servers", "host1:port1,host2:port2")
等参数定义输出路径等参数。
指定输出topic：.option("topic", "updates")等参数指定输出对应的Kafka topic。
启动流计算：使用start()操作来执行查询语句。

Spark Streaming工作流程：
① Spark Streaming 中，会有一个接收器组件 Receiver，作为一个长期运行的 task 跑在一个 Executor 上，
Receiver 接收外部的数据流形成 input DStream。
② DStream 会被按照时间间隔划分成一批一批的 RDD，当批处理间隔缩短到秒级时，便可以用于处理实时数据流
（时间间隔的大小可以由参数指定，一般设在 500 毫秒到几秒之间）。
③ 对 DStream 进行操作就是对 RDD 进行操作，计算处理的结果可以传给外部系统。
④ 接受到实时数据后，给数据分批次，然后传给 Spark Engine 处理最后生成该批次的结果。

Spark Streaming的实时性：
Spark Streaming 将流式计算分解成多个 Spark Job，对于每一时间段数据的处理都会经过 Spark DAG 图分解
以及 Spark 的任务集的调度过程。
对于目前版本的 Spark Streaming 而言，其最小的 Batch Size 的选取在 0.5~5 秒钟之间。
所以 Spark Streaming 能够满足流式准实时计算场景，对实时性要求非常高的如高频实时交易场景则不太适合。

Structure Streaming：
Structured Streaming 是一个基于 Spark SQL 引擎的可扩展、容错的流处理引擎。
统一了流、批的编程模型，你可以使用静态数据批处理一样的方式来编写流式计算操作。
并且支持基于 event_time 的时间窗口的处理逻辑。
Structured Streaming 最核心的思想就是将实时到达的数据看作是一个不断追加的 unbound table 无界表，
到达流的每个数据项(RDD)就像是表中的一个新行被附加到无边界的表中，
这样用户就可以用静态结构化数据的批处理查询方式进行流计算，如可以使用 SQL 对到来的每一行数据进行实时查询处理。

Transform实时计算：
case class DeviceData(device: String, deviceType: String, signal: Double, time: DateTime)
val df: DataFrame = ... // streaming DataFrame with IOT device data with schema { device: string, deviceType: string, signal: double, time: string }
val ds: Dataset[DeviceData] = df.as[DeviceData]    // streaming Dataset with IOT device data
// Select the devices which have signal more than 10
df.select("device").where("signal > 10")      // using untyped APIs
ds.filter(_.signal > 10).map(_.device)         // using typed APIs
// Running count of the number of updates for each device type
df.groupBy("deviceType").count()                 // using untyped API
// Running average signal for each device type
import org.apache.spark.sql.expressions.scalalang.typed
ds.groupByKey(_.deviceType).agg(typed.avg(_.signal))    // using typed API

计算结果可以选择输出到多种设备并进行如下设定：
output mode：以哪种方式将 result table 的数据写入 sink,即是全部输出 complete 还是只输出新增数据；
format/output sink 的一些细节：数据格式、位置等。如 console；
query name：指定查询的标识。类似 tempview 的名字；
trigger interval：触发间隔，如果不指定，默认会尽可能快速地处理数据；
checkpointLocation：一般是 hdfs 上的目录。注意：Socket 不支持数据恢复，如果设置了，第二次启动会报错，Kafka 支持。

Spark MLlib:
MLlib 是 Spark 提供的一个机器学习算法库。MLlib 不仅提供了模型评估、数据导入等额外的功能，
还提供了一些更底层的机器学习原语。

Spark GraphX:GraphX 是 Spark 面向图计算提供的框架与算法库。
Spark 计算框架为了能够进行高并发和高吞吐的数据处理，封装了三大数据结构，用于处理不同的应用场景。

Spark运行流程：
1.SparkContext 向资源管理器注册并向资源管理器申请运行 Executor
2.资源管理器分配 Executor，然后资源管理器启动 Executor
3.Executor 发送心跳至资源管理器
4.SparkContext 构建 DAG 有向无环图
5.将 DAG 分解成 Stage（TaskSet）
6.把 Stage 发送给 TaskScheduler
7.Executor 向 SparkContext 申请 Task
8.TaskScheduler 将 Task 发送给 Executor 运行
9.同时 SparkContext 将应用程序代码发放给 Executor
10.Task 在 Executor 上运行，运行完毕释放所有资源


Flink 大数据批处理运算+流式运算：
Apache Flink 是一个开源的、分布式的大数据处理框架，可以处理批量数据和实时数据处理。
它被设计成快速、可扩展和可靠，并提供统一的批量和流数据处理编程模型。

Flink 的一些关键特性包括：
低延迟处理：Flink 提供了实时数据流的低延迟处理，适用于实时分析、欺诈检测和网络监测等场景。
容错性：Flink 提供了内置的容错性，确保数据处理即使在节点故障的情况下也可以继续。
可扩展性：Flink 可以水平扩展，添加额外的节点来处理不断增加的数据。
高效数据处理：Flink 通过其流水线数据处理架构提供高效的数据处理，减少了中间数据存储的需求。
易于使用：Flink 提供了一个用户友好的编程模型，支持 Java 和 Scala，并提供类似 SQL 的查询语言进行流数据处理。

Flink的运行中必须依靠Hadoop组件吗？
Flink是一个开源的流处理和批处理框架，与Apache Hadoop不同，它不直接依赖Hadoop。
尽管Flink在某些情况下可以与Hadoop生态系统中的一些组件集成，但Flink本身并不依赖Hadoop。

Flink 应用程序结构：
Source: 数据源，Flink 在流处理和批处理上的 source 大概有 4 类：基于本地集合的 source、基于文件的 source、
基于网络套接字的 source、自定义的 source。自定义的 source 常见的有 Apache kafka、RabbitMQ 等，
当然你也可以定义自己的 source。

Transformation：数据转换的各种操作，有 Map / FlatMap / Filter / KeyBy / Reduce / Fold / Aggregations / Window 
/ WindowAll / Union / Window join / Split / Select等，操作很多，可以将数据转换计算成你想要的数据。

Sink：接收器，Flink 将转换计算后的数据发送的地点 ，你可能需要存储下来，Flink 常见的 Sink 大概有如下几类：
写入文件、打印出来、写入 socket 、自定义的 sink 。自定义的 sink 常见的有 
Apache kafka、RabbitMQ、MySQL、ElasticSearch、Apache Cassandra、Hadoop FileSystem 等，
同理你也可以定义自己的 sink。

2. Flink 并行数据流
Flink 程序在执行的时候，会被映射成一个 Streaming Dataflow，一个 Streaming Dataflow 是由一组 Stream 和 Transformation Operator 组成的。
在启动时从一个或多个 Source Operator 开始，结束于一个或多个 Sink Operator。
Flink 程序本质上是并行的和分布式的，在执行过程中，一个流(stream)包含一个或多个流分区，
而每一个 operator 包含一个或多个 operator 子任务。操作子任务间彼此独立，在不同的线程中执行，甚至是在不同的机器或不同的容器上。
operator 子任务的数量是这一特定 operator 的并行度。相同程序中的不同 operator 有不同级别的并行度。

一个 Stream 可以被分成多个 Stream 的分区，也就是 Stream Partition。一个 Operator 也可以被分为多个 Operator Subtask。
每一个 Operator Subtask 都是在不同的线程当中独立执行的。一个 Operator 的并行度，就等于 Operator Subtask 的个数。
而一个 Stream 的并行度就等于它生成的 Operator 的并行度。

数据在两个 operator 之间传递的时候有两种模式：
One to One 模式：两个 operator 用此模式传递的时候，会保持数据的分区数和数据的排序；如上图中的 Source1 到 Map1，它就保留的 Source 的分区特性，以及分区元素处理的有序性。
Redistributing （重新分配）模式：这种模式会改变数据的分区数；每个一个 operator subtask 会根据选择 transformation 把数据发送到不同的目标 subtasks,比如 keyBy()会通过 hashcode 重新分区,broadcast()和 rebalance()方法会随机重新分区；

3. Task 和 Operator chain
Flink的所有操作都称之为Operator，客户端在提交任务的时候会对Operator进行优化操作，
能进行合并的Operator会被合并为一个Operator，合并后的Operator称为Operator chain，实际上就是一个执行链，
每个执行链会在TaskManager上一个独立的线程中执行。


4. 任务调度与执行
当Flink执行executor会自动根据程序代码生成DAG数据流图；
ActorSystem创建Actor将数据流图发送给JobManager中的Actor；
JobManager会不断接收TaskManager的心跳消息，从而可以获取到有效的TaskManager；
JobManager通过调度器在TaskManager中调度执行Task（在Flink中，最小的调度单元就是task，对应就是一个线程）；
在程序运行过程中，task与task之间是可以进行数据传输的。

Job Client：
主要职责是提交任务, 提交后可以结束进程, 也可以等待结果返回；
Job Client 不是 Flink 程序执行的内部部分，但它是任务执行的起点；
Job Client 负责接受用户的程序代码，然后创建数据流，将数据流提交给 Job Manager 以便进一步执行。
执行完成后，Job Client 将结果返回给用户。

JobManager：
主要职责是调度工作并协调任务做检查点；
集群中至少要有一个 master，master 负责调度 task，协调checkpoints 和容错；
高可用设置的话可以有多个 master，但要保证一个是 leader, 其他是standby；
Job Manager 包含 Actor System、Scheduler、CheckPoint三个重要的组件；
JobManager从客户端接收到任务以后, 首先生成优化过的执行计划, 再调度到TaskManager中执行。

TaskManager：
主要职责是从JobManager处接收任务, 并部署和启动任务, 接收上游的数据并处理；
Task Manager 是在 JVM 中的一个或多个线程中执行任务的工作节点；
TaskManager在创建之初就设置好了Slot, 每个Slot可以执行一个任务。

5. 任务槽和槽共享
每个TaskManager是一个JVM的进程, 可以在不同的线程中执行一个或多个子任务。
为了控制一个worker能接收多少个task。worker通过task slot来进行控制（一个worker至少有一个task slot）。

1) 任务槽
每个task slot表示TaskManager拥有资源的一个固定大小的子集。
flink将进程的内存进行了划分到多个slot中。
图中有2个TaskManager，每个TaskManager有3个slot的，每个slot占有1/3的内存。
内存被划分到不同的slot之后可以获得如下好处:
TaskManager最多能同时并发执行的任务是可以控制的，那就是3个，因为不能超过slot的数量。
slot有独占的内存空间，这样在一个TaskManager中可以运行多个不同的作业，作业之间不受影响。

2) 槽共享
默认情况下，Flink允许子任务共享插槽，即使它们是不同任务的子任务，只要它们来自同一个作业。结果是一个槽可以保存作业的整个管道。允许插槽共享有两个主要好处：
只需计算Job中最高并行度（parallelism）的task slot,只要这个满足，其他的job也都能满足。
资源分配更加公平，如果有比较空闲的slot可以将更多的任务分配给它。图中若没有任务槽共享，负载不高的Source/Map等subtask将会占据许多资源，而负载较高的窗口subtask则会缺乏资源。
有了任务槽共享，可以将基本并行度（base parallelism）从2提升到6.提高了分槽资源的利用率。同时它还可以保障TaskManager给subtask的分配的slot方案更加公平。

FLink的Time和Window：
流式：就是数据源源不断的流进来，也就是数据没有边界，但是我们计算的时候必须在一个有边界的范围内进行，
所以这里面就有一个问题，边界怎么确定？无非就两种方式，根据时间段或者数据量进行确定，
根据时间段就是每隔多长时间就划分一个边界，根据数据量就是每来多少条数据划分一个边界，
Flink 中就是这么划分边界的，本文会详细讲解。

实时：就是数据发送过来之后立马就进行相关的计算，然后将结果输出。这里的计算有两种：
一种是只有边界内的数据进行计算，这种好理解，比如统计每个用户最近五分钟内浏览的新闻数量，
就可以取最近五分钟内的所有数据，然后根据每个用户分组，统计新闻的总数。
另一种是边界内数据与外部数据进行关联计算，比如：统计最近五分钟内浏览新闻的用户都是来自哪些地区，
这种就需要将五分钟内浏览新闻的用户信息与 hive 中的地区维表进行关联，然后在进行相关计算。

Flink的Window API提供了以下几种窗口函数：

Tumbling Windows：这种窗口函数将数据分成固定大小的窗口。每个窗口内的数据是一组数据。
Sliding Windows：这种窗口函数将数据分成固定大小的窗口，并且窗口可以滑动。每个窗口内的数据也是一组数据。
Session Windows：这种窗口函数将数据分成会话窗口。每个会话窗口内的数据是一组数据。会话窗口是根据时间或数据之间的距离来定义的。
Global Windows：这种窗口函数将数据分成一个全局窗口。每个全局窗口内的数据是一组数据。全局窗口的大小取决于数据的数量。

此外，Flink还提供了以下几种窗口函数的方法：

countWindow(size)：将数据分成指定大小的窗口，每个窗口内的数据是一组数据。
timeWindow(size, slide)：将数据按照时间分成指定大小和滑动间隔的窗口，每个窗口内的数据是一组数据。
sessionWindow(size, slide)：将数据按照时间分成指定大小和滑动间隔的会话窗口，每个会话窗口内的数据是一组数据。
globalWindow()：将数据分成一个全局窗口，每个全局窗口内的数据是一组数据。


Time：
在Flink中，如果以时间段划分边界的话，那么时间就是一个极其重要的字段。
Flink中的时间有三种类型：

Event Time：是事件创建的时间。它通常由事件中的时间戳描述，例如采集的日志数据中，
每一条日志都会记录自己的生成时间，Flink通过时间戳分配器访问事件时间戳。
Ingestion Time：是数据进入Flink的时间。
Processing Time：是每一个执行基于时间操作的算子的本地系统时间，与机器相关，默认的时间属性就是Processing Time。

例如，一条日志进入Flink的时间为2021-01-22 10:00:00.123，到达Window的系统时间为2021-01-22 10:00:01.234，
日志的内容：2021-01-06 18:37:15.624 INFO Fail over to rm2
对于业务来说，要统计1min内的故障日志个数，哪个时间是最有意义的？—— eventTime，因为我们要根据日志的生成时间进行统计。

此外，Flink还提供了以下几种时间函数的方法：

timeWindow(size, slide)：将数据按照时间分成指定大小和滑动间隔的窗口，每个窗口内的数据是一组数据。
sessionWindow(size, slide)：将数据按照时间分成指定大小和滑动间隔的会话窗口，每个会话窗口内的数据是一组数据。
countWindow(size)：将数据分成指定大小的窗口，每个窗口内的数据是一组数据。
globalWindow()：将数据分成一个全局窗口，每个全局窗口内的数据是一组数据。


总之，Flink 是一个强大的大数据处理框架，适用于批量数据和实时数据处理。它提供了低延迟处理、容错性、可扩展性


ClickHouse 大数据列式存储：
ClickHouse是一个开源的，用于联机分析（OLAP）的列式数据库管理系统（DBMS-database manager system）, 它是面向列的，
并允许使用SQL查询，实时生成分析报告。ClickHouse最初是一款名为Yandex.Metrica的产品，主要用于WEB流量分析。
ClickHouse的全称是Click Stream，Data WareHouse，简称ClickHouse。

ClickHouse不是一个单一的数据库,它允许在运行时创建表和数据库，加载数据和运行查询，而无需重新配置和重新启动服务器。
ClickHouse同时支持列式存储和数据压缩，这是对于一款高性能数据库来说是必不可少的特性。
一个非常流行的观点认为，如果你想让查询变得更快，最简单且有效的方法是减少数据扫描范围和数据传输时的大小，
而列式存储和数据压缩就可以帮助我们实现上述两点，列式存储和数据压缩通常是伴生的，因为一般来说列式存储是数据压缩的前提。

ClickHouse的特性包括：
1.完备的DBMS功能：ClickHouse具备DDL（数据定义语言）、DML（数据操作语言）、分布式管理、权限控制、数据备份与恢复等功能。
2.数据压缩：ClickHouse具有数据压缩功能，可以减少数据存储空间和网络带宽的使用。
3.数据的磁盘存储：ClickHouse将数据存储在磁盘上，不同于其他列式数据库大多需要在内存中处理。
4.多核心并行处理：ClickHouse具有多核心并行处理能力，可以充分利用多核CPU的性能。
5.多服务器分布式处理：ClickHouse支持多服务器分布式处理，可以处理大规模的数据。
6.支持SQL：ClickHouse支持SQL语言，可以方便地进行数据查询和操作。
7.向量引擎：ClickHouse采用向量引擎，能够高效地处理大规模的向量数据。
8.实时数据更新：ClickHouse支持实时数据更新，可以快速地响应数据变化。
9.索引：ClickHouse支持索引，可以提高查询效率。
10.适合在线查询：ClickHouse适合在线查询，可以快速地返回查询结果。
11.支持近似计算：ClickHouse支持近似计算，可以在一定程度上减少计算误差。
12.支持数据复制和数据完整性：ClickHouse支持数据复制和数据完整性，可以保证数据的可靠性和一致性。
13.角色的访问控制：ClickHouse提供角色的访问控制功能，可以按照用户粒度设置数据库或者表的操作权限，保障数据的安全性。

例：在clickhouse中进行模糊查询 SELECT * FROM table_name WHERE column_name LIKE '%keyword%';

Zookeeper 大数据分布式协调服务
Zookeeper从设计模式角度来理解：是一个基于观察者模式设计的分布式服务管理框架，
它负责存储和管理大家都关心的数据，然后接受观察者的注册，
一旦这些数据的状态发生变化，Zookeeper就将负责通知已经在Zookeeper上注册的那些观察者做出相应的反应。

特点：
1.Zookeeper：一个领导者（Leader），多个跟随者（Follower）组成的集群。
2.集群中只要有半数以上节点存活，Zookeeper集群就能正常服务。所 以Zookeeper适合安装奇数台服务器。
3.全局数据一致：每个Server保存一份相同的数据副本，Client无论连接到哪个Server，数据都是一致的。
4.更新请求顺序执行，来自同一个Client的更新请求按其发送顺序依次执行。
5.数据更新原子性，一次数据更新要么成功，要么失败。
6.实时性，在一定时间范围内，Client能读到最新数据。

zookeeper的选举机制：
半数机制，超过半数的投票通过，即通过。
（1）第一次启动选举规则：
投票过半数时，服务器 id 大的胜出
（2）第二次启动选举规则：
①EPOCH 大的直接胜出
②EPOCH 相同，事务 id 大的胜出
③事务 id 相同，服务器 id 大的胜出

zookeeper可以保证数据的一致性。底层采用Paxos算法，对分布式系统中某个数据达成一致。

Paxos算法流程：
（1）Prepare: Proposer生成全局唯一且递增的Proposal ID，向所有Acceptor发送Propose请求，这里无需携带提案内容，只携带Proposal ID即可。
（2）Promise: Acceptor收到Propose请求后，做出“两个承诺，一个应答”。
➢ 不再接受Proposal ID小于等于（注意：这里是<= ）当前请求的Propose请求。
➢ 不再接受Proposal ID小于（注意：这里是< ）当前请求的Accept请求。
➢ 不违背以前做出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值。
（3）Propose: Proposer收到多数Acceptor的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。
如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。
然后携带当前Proposal ID，向所有Acceptor发送Propose请求。
（4）Accept: Acceptor收到Propose请求后，在不违背自己之前做出的承诺下，接受并持久化当前Proposal ID和提案Value。
（5）Learn: Proposer收到多数Acceptor的Accept后，决议形成，将形成的决议发送给所有Learner。

PS：如果系统中有一个以上的 Proposer，多个 Proposers 相互争夺 Acceptor，针对这种情况，一种改进的 Paxos 算法被提出：从系统中选
出一个节点作为 Leader，只有 Leader 能够发起提案。这样能避免活锁的情况出现。改进后的算法被称作ZAB协议。
Zookeeper保证了CAP理论中的CP，即一致性和分区容错性。Zookeeper不能保证每次服务请求的可用性，进行leader选举时集群不可用。

ZAB过程：
（1）客户端发起一个写操作请求。
（2）Leader服务器将客户端的请求转化为事务Proposal 提案，同时为每个Proposal 分配一个全局的ID，即zxid。
（3）Leader服务器为每个Follower服务器分配一个单独的队列，然后将需要广播的 Proposal依次放到队列中去，并且根据FIFO策略进行消息发送。
（4）Follower接收到Proposal后，会首先将其以事务日志的方式写入本地磁盘中，写入成功后向Leader反馈一个Ack响应消息。
（5）Leader接收到超过半数以上Follower的Ack响应消息后，即认为消息发送成功，可以发送commit消息。
（6）Leader向所有Follower广播commit消息，同时自身也会完成事务提交。Follower 接收到commit消息后，会将上一条事务提交。
（7）Zookeeper采用Zab协议的核心，就是只要有一台服务器提交了Proposal，就要确保所有的服务器最终都能正确提交Proposal。


Flume 大数据数据采集：Flume 是 Cloudera 提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。
Flume最主要的作用是实时读取服务器本地的文件，将数据写入到HDFS。

Flume基础结构：
1 Agent
Agent 是一个 JVM 进程，它以事件的形式将数据从源头送至目的。
Agent 主要有 3 个部分组成，Source、Channel、Sink。

2 Source
Source 是负责接收数据到 Flume Agent 的组件。Source 组件可以处理各种类型、各种格式的日志数据，
包括 avro、thrift、exec、jms、spooling directory、netcat、taildir、sequence generator、syslog、http、legacy。

3 Sink
Sink 不断地轮询 Channel 中的事件且批量地移除它们，并将这些事件批量写入到存储或索引系统、或者被发送到另一个 Flume Agent。
Sink 组件目的地包括 hdfs、logger、avro、thrift、ipc、file、HBase、solr、自定义。

4 Channel
Channel 是位于 Source 和 Sink 之间的缓冲区。因此，Channel 允许 Source 和 Sink 运作在不同的速率上。
Channel 是线程安全的，可以同时处理几个 Source 的写入操作和几个Sink 的读取操作。
Flume 自带两种 Channel：Memory Channel 和 File Channel。
Memory Channel 是内存中的队列。Memory Channel 在不需要关心数据丢失的情景下适用。
如果需要关心数据丢失，那么 Memory Channel 就不应该使用，因为程序死亡、机器宕机或者重启都会导致数据丢失。
File Channel 将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数据。

5 Event
传输单元，Flume 数据传输的基本单元，以 Event 的形式将数据从源头送至目的地。
Event 由 Header 和 Body 两部分组成，Header 用来存放该 event 的一些属性，为 K-V 结构，Body 用来存放该条数据，形式为字节数组。

kafka 大数据消息队列

传统的消息队列的主要应用场景包括：缓存/消峰、解耦和异步通信。
两种模式：点对点模式（消费者主动拉取数据，消息收到后清除数据），发布/订阅模式（可以有多个主题，消费者通过主题消费数据，每个消费者互相独立，都可以消费的到数据）

kafka特点：
1.为方便扩展，并提高吞吐量，一个topic分为多个partition
2.配合分区的设计，提出消费者组的概念，组内每个消费者并行消费
3.为提高可用性，为每个partition增加若干副本，类似NameNode HA
4. ZK中记录谁是leader，Kafka2.8.0以后也可以配置不采用ZK

Azkaban 大数据任务调度
Azkaban是由Linkedin公司推出的一个批量工作流任务调度器，主要用于在一个工作流内以一个特定的顺序运行一组工作和流程，
它的配置是通过简单的<key, value>对的方式，通过配置中的dependencies来设置依赖关系。
Azkaban使用job配置文件建立任务之间的依赖关系，并提供一个易于使用的Web用户界面维护和跟踪你的工作流。


常见工作流调度系统:
1.简单的任务调度：直接使用 Linux 的 Crontab 来定义；
2.复杂的任务调度：开发调度平台或使用现成的开源调度系统，比如 Ooize、Azkaban、Airflow、DolphinScheduler 等。

Azkaban由三个关键组件构成：
元数据
AzkabanWebServer
AzkabanExecutorServer

元数据
Azkaban使用关系型数据库存储元数据和执行状态。

AzkabanWebServer
项目管理：项目、项目权限以及上传的文件。
作业状态：跟踪执行流程以及执行程序正在运行的流程。
以前的流程/作业：通过以前的作业和流程执行以及访问其日志文件进行搜索。
计划程序：保留计划作业的状态。
SLA：保持所有的SLA规则

AzkabanExecutorServer
访问项目：从数据库检索项目文件。
执行流程/作业：检索和更新正在执行的作业流的数据
日志：将作业和工作流的输出日志存储到数据库中。
交互依赖关系：如果一个工作流在不同的执行器上运行，它将从数据库中获取状态。

AzkabanWebServer
AzkabanWebServer是整个Azkaban工作流系统的主要管理者，它负责Project管理、用户登录认证、定时执行工作流、跟踪工作流执行进度等
一系列任务。同时，它还提供Web服务操作接口，利用该接口，用户可以使用curl或其他Ajax的方式，来执行Azkaban的相关操作。
操作包括：用户登录、创建Project、上传Workflow、执行Workflow、查询Workflow的执行进度、杀掉Workflow等一系列操作，
且这些操作的返回结果均是JSON格式。并且Azkaban使用方便，Azkaban使用以.job为后缀名的键值属性文件来定义工作流中的各个任务，
以及使用dependencies属性来定义作业间的依赖关系链。这些作业文件和关联的代码最终以*.zip的方式通过Azkaban UI上传到Web服务器上。

AzkabanExecutorServer
以前版本的Azkaban在单个服务中具有AzkabanWebServer和AzkabanExecutorServer功能，
目前Azkaban已将AzkabanExecutorServer分离成独立的服务器，拆分AzkabanExecutorServer的原因有如下几点：

某个任务流失败后，可以更方便将其重新执行
便于Azkaban升级
AzkabanExecutorServer主要负责具体的工作流提交、执行，可以启动多个执行服务器，它们通过关系型数据库来协调任务的执行。

作业流执行过程：
WebServer根据内存中缓存的各Executor的资源（WebServer有一个线程会遍历各个Active Executor，
去发送Http请求获取其资源状态信息缓存到内存中），按照选择策略（包括executor资源状态、最近执行流个数等）选择一个Executor下发作业流；
Executor判断是否设置作业粒度分配，如果未设置作业粒度分配，则在当前Executor执行所有作业；
如果设置了作业粒度分配，则当前节点会成为作业分配的决策者，即分配节点；
分配节点从Zookeeper获取各个Executor的资源状态信息，然后根据策略选择一个Executor分配作业；
被分配到作业的Executor即成为执行节点，执行作业，然后更新数据库。


Atlas 大数据元数据管理
Apache Atlas 为组织提供开放式元数据管理和治理功能，用以构建其数据资产目录，对
这些资产进行分类和管理，形成数据字典。并为数据分析师和数据治理团队，提供围绕这些
数据资产的协作功能。
注：数据字典：可以查到 hive 库的释义，表的介绍以及字段的解释和说明。
1.表与表之间的血缘依赖
2.字段与字段之间的血缘依赖

Atlas的使用：
Atlas 的使用相对简单，其主要工作是同步各服务（主要是 Hive）的元数据，
并构建元数据实体之间的关联关系，然后对所存储的元数据建立索引，最终未用户提供数据血缘查看。

Apache Atlas为Hadoop的元数据治理提供了以下特性：

数据分类
- 为元数据导入或定义业务导向的分类注释
- 定义，注释，以及自动捕获数据集和底层元素之间的关系
- 导出元数据到第三方系统

集中审计
- 捕获与所有应用，过程以及与数据交互的安全访问信息
- 捕获执行，步骤，活动等操作的信息

搜索与血缘
- 预定义的导航路径用来探索数据分类以及审计信息
- 基于文本的搜索特性来快速和准确的定位相关联的数据和审计事件
- 对数据集血缘关系的可视化浏览使用户可以下钻到操作，安全以及数据起源相关的信息

安全与策略引擎
- 基于数据分类模式，属性以及角色的运行时合理合规策略
- 基于分类-预测的高级策略定义以防止数据推导
- 基于cell的属性和值的行/列级别的masking

Core
- Type System: Atlas 允许用户为他们想要管理的元数据对象定义一个模型。该模型由称为 "类型" 的定义组成。
"类型" 的 实例被称为 "实体" 表示被管理的实际元数据对象。类型系统是一个组件，允许用户定义和管理类型和实体。
由 Atlas 管理的所有元数据对象（例如Hive表）都使用类型进行建模，并表示为实体。要在 Atlas 中存储新类型的元数据，
需要了解类型系统组件的概念。

- Ingest/Export：Ingest 组件允许将元数据添加到 Atlas。类似地，Export 组件暴露由 Atlas 检测到的元数据更改，
以作为事件引发，消费者可以使用这些更改事件来实时响应元数据更改。

- Graph Engine：在内部，Atlas 通过使用图形模型管理元数据对象。以实现元数据对象之间的巨大灵活性和丰富的关系。
图形引擎是负责在类型系统的类型和实体之间进行转换的组件，以及基础图形模型。除了管理图形对象之外，
图形引擎还为元数据对象创建适当的索引，以便有效地搜索它们。

- Titan：目前，Atlas 使用 Titan 图数据库来存储元数据对象。 Titan 使用两个存储：默认情况下元数据存储配置为 HBase ，
索引存储配置为 Solr。也可以通过构建相应的配置文件使用BerkeleyDB存储元数据存储 和使用ElasticSearch存储 Index。
元数据存储用于存储元数据对象本身，索引存储用于存储元数据属性的索引，其允许高效搜索。

Integration
用户可以使用两种方法管理 Atlas 中的元数据：
- API： Atlas 的所有功能都可以通过 REST API 提供给最终用户，允许创建，更新和删除类型和实体。
它也是查询和发现通过 Atlas 管理的类型和实体的主要方法。
- Messaging：除了 API 之外，用户还可以选择使用基于 Kafka 的消息接口与 Atlas 集成。
这对于将元数据对象传输到 Atlas 以及从 Atlas 使用可以构建应用程序的元数据更改事件都非常有用。
如果希望使用与 Atlas 更松散耦合的集成，这可以允许更好的可扩展性，可靠性等，消息传递接口是特别有用的。
Atlas 使用 Apache Kafka 作为通知服务器用于钩子和元数据通知事件的下游消费者之间的通信。
事件由钩子(hook)和 Atlas 写到不同的 Kafka 主题。
- ATLAS_HOOK: 来自各个组件的Hook 的元数据通知事件通过写入到名为 ATLAS_HOOK 的 Kafka topic 发送到 Atlas
- ATLAS_ENTITIES：从 Atlas 到其他集成组件（如Ranger）的事件写入到名为 ATLAS_ENTITIES 的 Kafka topic



Metadata source
- Hive：通过hive bridge， atlas可以接入Hive的元数据，包括hive_db/hive_table/hive_column/hive_process
- Sqoop：通过sqoop bridge，atlas可以接入关系型数据库的元数据，包括sqoop_operation_type/ sqoop_dbstore_usage/sqoop_process/sqoop_dbdatastore
- Falcon：通过falcon bridge，atlas可以接入Falcon的元数据，包括falcon_cluster/falcon_feed/falcon_feed_creation/falcon_feed_replication/ falcon_process
- Storm：通过storm bridge，atlas可以接入流式处理的元数据，包括storm_topology/storm_spout/storm_bolt
- HBase: 通过hbase bridge

Atlas集成大数据组件的元数据源需要实现以下两点：

- 首先，需要基于atlas的类型系统定义能够表达大数据组件元数据对象的元数据模型
(例如Hive的元数据模型实现在org.apache.atlas.hive.model.HiveDataModelGenerator)；

- 然后，需要提供hook组件去从大数据组件的元数据源中提取元数据对象，实时侦听元数据的变更并反馈给atlas；

Applications
- Atlas Admin UI: 该组件是一个基于 Web 的应用程序，允许数据管理员和科学家发现和注释元数据。
Admin UI提供了搜索界面和类SQL的查询语言，可以用来查询由 Atlas 管理的元数据类型和对象。
Admin UI 使用 Atlas 的 REST API 来构建其功能。

- Tag Based Policies: Apache Ranger 是针对 Hadoop 生态系统的高级安全管理解决方案，与各种 Hadoop 组件具有广泛的集成。
通过与 Atlas 集成，Ranger 允许安全管理员定义元数据驱动的安全策略，以实现有效的治理。 
Ranger 是由 Atlas 通知的元数据更改事件的消费者。

- Business Taxonomy:从元数据源获取到 Atlas 的元数据对象主要是一种技术形式的元数据。
为了增强可发现性和治理能力，Atlas 提供了一个业务分类界面，允许用户首先定义一组代表其业务域的业务术语，
并将其与 Atlas 管理的元数据实体相关联。业务分类法是一种 Web 应用程序，目前是 Atlas Admin UI 的一部分，
并且使用 REST API 与 Atlas 集成。

 
ATlas类型系统
Atlas 允许用户为他们想要管理的元数据对象定义一个模型。该模型由称为 “类型” (type)的定义组成。被称为 “实体” (entities)的 “类型” 实例表示被管理的实际元数据对象。由 Atlas 管理的所有元数据对象（例如Hive表）都使用类型进行建模，并表示为实体。

- Type：Atlas中的 “类型” 定义了如何存储和访问特定类型的元数据对象。类型表示了所定义元数据对象的一个或多个属性集合。
具有开发背景的用户可以将 “类型” 理解成面向对象的编程语言的 “类” 定义的或关系数据库的 “表模式”。
类型具有元类型，元类型表示 Atlas 中此模型的类型：

- 基本元类型： Int，String，Boolean等
- 集合元类型：例如Array，Map
- Class，Struct，Trait

- Entities：Atlas中的 “实体” 是类 “类型” 的特定值或实例，因此表示真实世界中的特定元数据对象。
  回顾我们的面向对象编程语言的类比，“实例” 是某个 “类” 的 “对象”。
- Attributes：Atlas中的属性还有一些属性，其定义了与类型系统相关的更多概念，包括：
- isComposite - 是否复合
- isIndexable - 是否索引
- isUnique - 是否唯一
- multiplicity - 指示此属性是（必需的／可选的／还是可以是多值）的

Atlas 提供了一些预定义的系统类型：

- Referenceable：此类型表示可使用名为 qualifiedName 的唯一属性搜索的所有实体
- Asset：此类型包含名称，说明和所有者等属性
- Infrastructure：此类型扩展了Referenceable和Asset ，通常可用于基础设施元数据对象（如群集，主机等）的常用超类型
- DataSet：此类型扩展了Referenceable和Asset 。在概念上，它可以用于表示存储数据的类型。在 Atlas 中，hive表，Sqoop RDBMS表等
都是从 DataSet 扩展的类型。扩展 DataSet 的类型可以期望具有模式，它们将具有定义该数据集的属性的属性。
例如， hive_table 中的 columns 属性。另外，扩展 DataSet 的实体类型的实体参与数据转换，
这种转换可以由 Atlas 通过 lineage（或 provenance）生成图形。
- Process：此类型扩展了Referenceable和Asset 。在概念上，它可以用于表示任何数据变换操作。
例如，将原始数据的 hive 表转换为存储某个聚合的另一个 hive 表的 ETL 过程可以是扩展过程类型的特定类型。
流程类型有两个特定的属性，输入和输出。
 
Prometheus 大数据监控系统	
Prometheus 是一个开源的完整监控解决方案，其对传统监控系统的测试和告警模型进行了彻底的颠覆，
形成了基于中央化的规则计算、统一分析和告警的新模型。

Prometheus 基本原理是通过 HTTP 协议周期性抓取被监控组件的状态，这样做的好处是任意组件只要提供 HTTP 接口就可以接入监控系统，
不需要任何 SDK 或者其他的集成过程。这样做非常适合虚拟化环境比如 VM 或者 Docker 。

Prometheus 应该是为数不多的适合 Docker、Mesos、Kubernetes 环境的监控系统之一。

相比于传统监控系统，Prometheus 具有以下优点：

1 易于管理
➢ Prometheus 核心部分只有一个单独的二进制文件，不存在任何的第三方依赖(数据库，缓存等等)。唯一需要的就是本地磁盘，因此不会有潜在级联故障的风险。
➢ Prometheus 基于 Pull 模型的架构方式，可以在任何地方（本地电脑，开发环境，测试环境）搭建我们的监控系统。
➢ 对于一些复杂的情况，还可以使用 Prometheus 服务发现(Service Discovery)的能力动态管理监控目标。

2 监控服务的内部运行状态
Pometheus 鼓励用户监控服务的内部状态，基于 Prometheus 丰富的 Client 库，
用户可以轻松的在应用程序中添加对 Prometheus 的支持，从而让用户可以获取服务和应用内部真正的运行状态。

3 强大的数据模型
所有采集的监控数据均以指标(metric)的形式保存在内置的时间序列数据库当中(TSDB)。
所有的样本除了基本的指标名称以外，还包含一组用于描述该样本特征的标签。
每一条时间序列由指标名称(Metrics Name)以及一组标签(Labels)唯一标识。每条时间序列按照时间的先后顺序存储一系列的样本值。
➢ http_request_status：指标名称(Metrics Name)
➢ {code='200',content_path='/api/path',environment='produment'}：表示维度的
标签，基于这些 Labels 我们可以方便地对监控数据进行聚合，过滤，裁剪。
➢ [value1@timestamp1,value2@timestamp2...]：按照时间的先后顺序 存储的样本值。

4 强大的查询语言 PromQL
Prometheus 内置了一个强大的数据查询语言 PromQL。 通过 PromQL 可以实现对
监控数据的查询、聚合。同时 PromQL 也被应用于数据可视化(如 Grafana)以及告警当中。
通过 PromQL 可以轻松回答类似于以下问题：
➢ 在过去一段时间中 95%应用延迟时间的分布范围？
➢ 预测在 4 小时后，磁盘空间占用大致会是什么情况？
➢ CPU 占用率前 5 位的服务有哪些？(过滤)

5 高效
对于监控系统而言，大量的监控任务必然导致有大量的数据产生。
而 Prometheus 可以高效地处理这些数据，对于单一 Prometheus Server 实例而言它可以处理：
➢ 数以百万的监控指标
➢ 每秒处理数十万的数据点

6 可扩展
可以在每个数据中心、每个团队运行独立的 Prometheus Sevrer。
Prometheus 对于联邦集群的支持，可以让多个 Prometheus 实例产生一个逻辑集群，
当单实例 Prometheus Server 处理的任务量过大时，通过使用功能分区(sharding)+联邦集群(federation)可以对其进行扩展。

7 易于集成
使用 Prometheus 可以快速搭建监控服务，并且可以非常方便地在应用程序中进行集成。
目前支持：Java，JMX，Python，Go，Ruby，.Net，Node.js 等等语言的客户端 SDK，
基于这些 SDK 可以快速让应用程序纳入到 Prometheus 的监控当中，或者开发自己的监控数据收集程序。
同时这些客户端收集的监控数据，不仅仅支持 Prometheus，还能支持 Graphite 这些其他的监控工具。
同时 Prometheus 还支持与其他的监控系统进行集成：Graphite，Statsd，Collected，Scollector，muini，Nagios等。 
Prometheus 社区还提供了大量第三方实现的监控数据采集支持：
JMX，CloudWatch，EC2，MySQL，PostgresSQL，Haskell，Bash，SNMP，
Consul，Haproxy，Mesos，Bind，CouchDB，Django，Memcached，RabbitMQ，
Redis，RethinkDB，Rsyslog 等等。

8 可视化
➢ Prometheus Server 中自带的 Prometheus UI，可以方便地直接对数据进行查询，并且支持直接以图形化的形式展示数据。
同时 Prometheus 还提供了一个独立的基于Ruby On Rails 的 Dashboard 解决方案 Promdash。
➢ 最新的 Grafana 可视化工具也已经提供了完整的 Prometheus 支持，基于 Grafana 可以创建更加精美的监控图标。
➢ 基于 Prometheus 提供的 API 还可以实现自己的监控可视化 UI。

9 开放性
通常来说当我们需要监控一个应用程序时，一般需要该应用程序提供对相应监控系统协议的支持，
因此应用程序会与所选择的监控系统进行绑定。为了减少这种绑定所带来的限制，
对于决策者而言要么你就直接在应用中集成该监控系统的支持，要么就在外部创建单独的服务来适配不同的监控系统。
而对于 Prometheus 来说，使用 Prometheus 的 client library 的输出格式不止支持Prometheus 的格式化数据，
也可以输出支持其它监控系统的格式化数据，比如 Graphite。
因此你甚至可以在不使用 Prometheus 的情况下，采用 Prometheus 的 client library 来让你的应用程序支持监控数据采集。



分布式账本：
分布式账本是一种基于分布式计算和密码学技术的数据记录和交互方式。它是一种去中心化的数据库系统，由多个参与方共同管理和维护。

分布式账本技术的核心是区块链技术。区块链是一个由区块组成的链式结构，每个区块包含了一定的数据记录和相应的验证信息。
每个参与方维护一个完整的账本副本，并通过共识机制来确保所有账本之间的一致性。
通过分布式账本技术，参与方可以在无需信任中心的情况下进行数据交换和交易。数据记录被加密并保存在多个节点中，
这使得数据更加安全、透明和不可篡改。而且，由于数据的分布式特性，分布式账本具有较高的容错性和可扩展性。
分布式账本技术在金融领域的应用最为广泛，例如比特币和以太坊等加密货币就是基于分布式账本技术实现的。
此外，它还被应用于供应链管理、物联网、医疗保健等领域，以提高数据的安全性、可追溯性和可信度。

除了区块链技术，还有其他形式的分布式账本技术，例如分布式共享账本（Distributed Ledger Technology，简称DLT）。
DLT是广义的分布式账本技术，可以包括不仅限于区块链的其他形式。与区块链不同，DLT技术的数据记录可以采用不同的结构和共识机制。
DLT技术的一个重要特点是可选择性的共识，即参与方可以根据自身需求和场景选择适合的共识机制。
DLT技术的应用场景非常广泛，包括金融服务、供应链管理、物联网、数字身份认证等领域。
它可以解决传统中心化账本的信任问题，提高数据交换的效率和安全性。

总的来说，分布式账本技术是一种基于分布式计算和密码学技术的数据记录和交互方式，通过去中心化和共识机制实现参与方之间的数据交换和交易。
它具有数据安全、透明、不可篡改、容错性高和可扩展性强的优势，被广泛应用于各个领域。

用Java实现一个区块链：
区块链技术可以使用各种编程语言来实现，包括Java。下面是一个简单的示例，说明如何使用Java实现一个基本的区块链。

注意，这个示例只是为了教育目的，以帮助您理解区块链的基本概念。实际的区块链实现，如比特币或以太坊，会更加复杂和具有更多的功能。

首先，我们需要一个Block类：

java
public class Block {

    private String hash;
    private String previousHash;
    private String data;
    private long timestamp;

    public Block(String hash, String previousHash, String data, long timestamp) {
        this.hash = hash;
        this.previousHash = previousHash;
        this.data = data;
        this.timestamp = timestamp;
    }

    // getters and setters...
}
然后我们需要一个Blockchain类，它会存储一个链表，链表中的每个元素都是一个Block对象：

java
import java.util.ArrayList;
import java.util.List;

public class Blockchain {

    private List<Block> blockchain;

    public Blockchain() {
        blockchain = new ArrayList<>();
    }

    public void addBlock(Block block) {
        blockchain.add(block);
    }

    public Block getBlock(int index) {
        return blockchain.get(index);
    }

    // more methods...
}

现在我们有了基本的区块链结构，我们需要一种方法来创建新的区块并将其添加到链上。这可以通过一个名为"mining"的过程来完成，其中我们可以创建新的区块并将其添加到链的末尾。
为了简化，我们只包括一个简单的哈希计算：

public class Miner {

    private Blockchain blockchain;
    private static final int HASH_difficulty = 2; // made this up, but in reality it would be a large number like 20 or 32

    public Miner(Blockchain blockchain) {
        this.blockchain = blockchain;
    }

    public boolean mineBlock(String data) {
        String hash = calculateHash(data); // this should be a function that takes the data and calculates a hash (using SHA-256 or something)
        if (isHashValid(hash)) { // check if the hash starts with enough zeros for the difficulty level
            Block newBlock = new Block(hash, blockchain.getBlock(blockchain.blockchain.size() - 1).getHash(), data, System.currentTimeMillis()); 
            blockchain.addBlock(newBlock); 
            return true; 
        } else { 
            return false; 
        } 
    } 
   private boolean isHashValid(String hash) { 
       return hash.substring(0, HASH_difficulty).equals(String.format("%" + HASH_difficulty + "$0", "0")); 
   } 
   // here we would need a function that calculates a hash from the block's data - for simplicity, we'll leave it out here, but in a real blockchain implementation, this is crucial! 
}

在这个例子中，mineBlock() 方法尝试添加一个新的区块到区块链上。它首先计算数据的哈希值，并检查该哈希值是否满足难度要求（在本例中，哈希值的前两个字符是否为零）。如果哈希值满足难度要求，那么它将创建一个新的区块并将其添加到链上。
否则，它将继续尝试直到成功为止。这只是一个基本的示例，实际的区块链实现将更加复杂。

区块链的加密技术和传统密码加密技术有什么不同？
区块链的加密技术与传统密码加密技术有一些关键的不同之处，这些不同主要是为了满足区块链分布式、去中心化的特性。以下是一些区块链加密技术与传统密码加密技术之间的不同点：

1. 去中心化的信任模型：
   - 传统密码加密：在传统的密码学中，通常依赖于中央授权机构（例如，证书颁发机构）来验证和签署数字证书，确保公钥的合法性。
   - 区块链加密：区块链采用去中心化的信任模型，通过分布式账本和共识算法来验证和记录交易。公钥的合法性通常是通过区块链网络中的节点共同验证的。

2. 智能合约和可编程性：
   - 传统密码加密：传统加密主要用于点对点的通信加密，通常不涉及可编程逻辑。
   - 区块链加密：区块链技术引入了智能合约，这是一种可编程的、自动执行的合约。智能合约通常使用特定的编程语言（如Solidity），并通过区块链上的节点进行执行。加密在智能合约中发挥关键作用，以确保合约的安全性和不可篡改性。

3. 共识算法和网络安全：
   - 传统密码加密：传统网络通常依赖于中央授权机构和传统的网络安全措施，如防火墙和入侵检测系统。
   - 区块链加密：区块链网络通过共识算法（如工作量证明、权益证明）来保护网络安全。加密技术用于确保交易的保密性和完整性，以及在共识过程中的节点身份验证。

4. 不可篡改的分布式账本：
   - 传统密码加密：传统系统的数据通常存储在中心化的数据库中，容易成为攻击目标。
   - 区块链加密：区块链使用去中心化的、不可篡改的分布式账本，每个区块都包含了前一个区块的哈希值，确保数据的安全性和完整性。加密技术用于确保区块链的不可篡改性。

总体而言，区块链加密技术强调了去中心化、智能合约、分布式共识和不可篡改性等特性，以满足区块链的独特需求。传统密码学主要用于传统网络通信的保密性和身份验证。
